[
{
	"uri": "/kr/ros_basic_noetic/",
	"title": "ROS Basics",
	"tags": [],
	"description": "",
	"content": "\nLecture1. Lecture1 - Introduction to ROS Lecture2. Dev Env Setup Lecture3. Core of ROS Lecture4. ROS Launch, RViz Lecture5. First Programming, ROS Topic Lecture6. ROS Service, Parameter Lecture7. Rqt Tools and rosbag, ROS Time Lecture8. Deal with Open Source Projects, Custom Interfaces Lecture9. ROS TF and Examples Lecture10. TF2 Examples, Outro "
},
{
	"uri": "/kr/advanced_contents_ros1/",
	"title": "ROS",
	"tags": [],
	"description": "",
	"content": "\nLecture1 - ROSCPP Lecture2 - More About ROS System Lecture2 - SROS "
},
{
	"uri": "/kr/ros2_basic_foxy/",
	"title": "ROS 2 Basics",
	"tags": [],
	"description": "",
	"content": "\nLecture1. Lecture1 - Introduction to ROS 2 Lecture2. ROS 2 Node, Package Lecture3. ROS 2 Node Programming, ROS 2 Parameter Lecture4. ROS 2 Node C++ Programming Lecture5. ROS 2 Topic and Examples Lecture6. ROS 2 Service and Examples Lecture7. Useful ROS 2 Examples, Nav2 Lecture8. ROS 2 Action and Examples Lecture9. C++ Programming Again, Outro "
},
{
	"uri": "/kr/ros2_foxy/",
	"title": "ROS 2 Basics",
	"tags": [],
	"description": "",
	"content": "\nLecture1. What is ROS? Lecture2. Dev Env Setup Lecture3. Core of ROS Lecture4. ROS 2 Node and Parameter Programming Lecture5. ROS 2 Communication Mechanisms Lecture6. ROS 2 Tools Lecture7. ROS 2 Topic and Programming Lecture8. ROS 2 Service and Programming Lecture9. ROS 2 Action Programming Lecture10. TF2 and ROS 2 Lecture11. About Gazebo - 1 Lecture12. About Gazebo - 2 Lecture13. Useful ROS 2 Examples (Sensor Part) Lecture14. Useful ROS 2 Examples (Control Part) Lecture15. Advanced ROS 2, Package Management Lecture16. Useful ROS 2 Examples (Misc) Lecture17. Real Hardware Examples Lecture18. Point Cloud Deep Learning Example (PointNet) Lecture19. NVIDIA Isaac Sim Lecture20. NVIDIA Jetson Platform "
},
{
	"uri": "/kr/advanced_contents_ros2/",
	"title": "ROS 2",
	"tags": [],
	"description": "",
	"content": "\nLecture1 - About DDS Lecture2 - About DDS (2) Lecture2 - SROS2 "
},
{
	"uri": "/kr/ros_and_gazebo/",
	"title": "Gazebo and ROS",
	"tags": [],
	"description": "",
	"content": "\nLecture1 - Gazebo and ROS Lecture2 - Gazebo and ROS (2) "
},
{
	"uri": "/kr/",
	"title": "2023 Road Balance ROS Lecture Note",
	"tags": [],
	"description": "",
	"content": "2023 ROAD BALANCE ROS LECTURE NOTE 본 사이트는 2023년 Road Balance의 ROS/ROS 2 강의에 사용되는 강의 노트입니다.\nROS Noetic Lecture Lecture1. Lecture1 - Introduction to ROS Lecture2. Dev Env Setup Lecture3. Core of ROS Lecture4. ROS Launch, RViz Lecture5. First Programming, ROS Topic Lecture6. ROS Service, Parameter Lecture7. Rqt Tools and rosbag, ROS Time Lecture8. Deal with Open Source Projects, Custom Interfaces Lecture9. ROS TF and Examples Lecture10. TF2 Examples, Outro Lecture11 - ROSCPP Lecture12 - More About ROS System Lecture13 - SROS [New Version] ROS 2 Foxy Lecture [Old Version] ROS 2 Foxy Lecture Lecture1. Lecture1 - Introduction to ROS 2 Lecture2. ROS 2 Node, Package Lecture3. ROS 2 Node Programming, ROS 2 Parameter Lecture4. ROS 2 Node C++ Programming Lecture5. ROS 2 Topic and Examples Lecture6. ROS 2 Service and Examples Lecture7. Useful ROS 2 Examples, Nav2 Lecture8. ROS 2 Action and Examples Lecture9. C++ Programming Again, Outro Lecture10 - About DDS Lecture11 - About DDS (2) Lecture12 - SROS2 Lecture13 - Gazebo and Robot(1) Lecture14 - Gazebo and Robot(2) Advanced Contents ROS Lecture1 - ROSCPP Lecture2 - More About ROS System Lecture2 - SROS ROS 2 Lecture1 - About DDS Lecture2 - About DDS (2) Lecture2 - SROS2 ROS and Simulations Gazebo Lecture1 - Gazebo and ROS Lecture2 - Gazebo and ROS (2) Issac Sim Ongoing \u0026hellip; "
},
{
	"uri": "/kr/ros2_foxy/lecture1/",
	"title": "Lecture1. What is ROS?",
	"tags": [],
	"description": "",
	"content": "What is ROS? 강의를 제작하고 있는 현 시점, 세상은 chatgpt로 인해 큰 격변을 맞이하고 있는데요, chatgpt에게 ROS가 무엇인지 한 번 물어보았습니다. 😊\n💡 앞으로 프로그래밍과 실습 시 chatgpt를 적극 활용하여 강의를 이어나가도록 하겠습니다. 😉\nchatgpt가 잘 정리해주었지만, 제가 조금 더 설명을 이어나가보도록 하겠습니다. ROS란, 로봇 소프트웨어 개발에 사용되는 일종의 프레임워크입니다. 프레임워크라는 말은, ROS 나름대로의 실행 시나리오를 갖고 있다는 뜻입니다. 사용자인 우리들은, 이 시나리오를 사용하여 로봇을 다루는 우리만의 Application을 만들게 됩니다. image from : wikimedia\n그런데 왜 OS라는 이름이 붙게 되었을까요? 로봇을 실행하기 위해서, 수많은 프로그램들이 실행되며, ROS는 이들 사이의 우선순위와, 프로그램 사이의 데이터 흐름을 책임집니다. 이 작업은 스케쥴링이라고 불리며, 이러한 동작을 수행하는 시스템을 Operating System이라고 부르기 때문에 ROS라는 이름을 갖게 되었습니다.\nimage from : tutorialspoint 그럼, 로봇을 개발하기 위해서 어떠한 프로그램들이 필요할까요? =\u0026gt; 로봇이 수행하는 임무들을 크게 3가지로 분류하면 인지, 판단, 제어의 3가지로 나뉩니다.\n인지란, 센서들을 통한 물체 인지, 자기 자신의 위치와 방향 인지, 상황 인지 등 로봇에게 있어 환경과 상호작용하는 과정에 해당합니다. 판단이란, 앞/뒤로 움직일지, 로봇 팔을 뻗을지와 같이 인지를 기반으로 얻은 데이터를 통해 결정을 내리는 작업들이 해당할 것입니다. 제어 또한 빼놓을 수 없는 영역으로, 로봇은 역학이라는 법칙이 존재하는 실제 세상에서 움직이기 때문에, 이 시스템을 분석하여 적절한 움직임을 취하도록 해야합니다. 이렇게 로봇 시스템은 무척 복잡하며, 여러 작업을 수행하는 프로그램들 사이 수많은 데이터가 오가고, 데이터의 신뢰성과 속도 모두 충축시켜야 하며, 또 사람과 상호 작용해야 합니다.\nimage from : ROS Industrial ROS는 이러한 작업을 손쉽게 해주는 시스템입니다. 예를 들면, 로봇의 센서, 구동부, 알고리즘이 모두 준비되어 있는 상황에서, 이들을 하나의 시스템으로 엮어주는 역할을 하는 것이 바로 ROS입니다.\nimage from : ros wiki 그렇다면, ROS와 ROS 2는 어떤 점에서 다를까요? ROS의 시작은 연구실이었습니다. 그리고 PR2라는 단일 로봇을 위해 만들어진 시스템이었기에 연구용, 간단한 프로젝트용으로는 사용될 수 있지만, 상용화를 위한 여러 조건들은 고려하지 못하고 있었습니다. image from : https://robots.ieee.org/robots/pr2/\n보안 안정성 실시간성 개발 용이성 기술 지원 하드웨어 연동 etc… 연구용으로 설계된 기존 ROS를 통해서는 이러한 모든 조건을 충족할 수 없다는 결론을 내렸고, Open Robotics는 ROS 2를 새롭게 선보이게 됩니다.\nimage from : maker.pro 💡 기존 언급되었던 ROS 1의 모든 문제들이 ROS 2에서 해결되었다고 할 수는 없지만 적어도 해결을 고려하여 설계되었다고 말하고 싶습니다.\n상용화를 고려한 가장 큰 변화 중 하나는 패킷 통신에 TCPROS/UPDROS가 아닌 DDS를 도입하였다는 것입니다. image from : omg.org DDS는 Data Distribution Service의 약자이며, 다양한 프로그램이 동시에 동작하는 시스템을 위한 일종의 약속입니다. 기존의 ROS가 지양하던 방식이 DDS와 일치하는 부분이 많았고, 산업 표준에 널리 사용되고 있었기 때문에 채택하지 않았나 싶습니다. (자세한 내용은 강의를 통해 함께 살펴보겠습니다.)\nAbout this lecture 앞서 이야기한 바와 같이 ROS는 특정 알고리즘을 위한 라이브러리가 아닌 시스템입니다.\n따라서, 이 시스템을 이해하고, 익숙해지고, 실습하고, 코딩하고, 기존의 코드를 연동하는 작업들을 통해 여러분들의 코드와 알고리즘을 ROS로 감쌀 수 있게 됩니다.\nROS Wrapper Google 검색 결과 이번 강의를 기획하는 시점에서 세상에 큰 변화가 있었습니다. 바로 ChatGPT인데요. C++ 코드를 Python 코드로 바꾼다거나, 내가 원하는 ROS 2 코드를 말만 하면 순식간에 짜주는 세상이 되었습니다.\nChatGPT를 통해 생성한 코드 예시 뿐만 아니라 코드 작성 시에도 Github Copilot, Code GPT 등 자동 완성 기능들이 등장하여 개발자들의 편의를 높여주고 있습니다.\ncopliot을 통해 생성한 rclcpp 예시 #include \u0026#34;rclcpp/rclcpp.hpp\u0026#34; // rclcpp node example int main(int argc, char *argv[]) { rclcpp::init(argc, argv); auto node = rclcpp::Node::make_shared(\u0026#34;test_node\u0026#34;); rclcpp::spin(node); rclcpp::shutdown(); return 0; } 이러한 이유로 개발자들은 더이상 코드 API를 외우고, 예제를 뒤적이고 할 필요가 없어졌다고 생각합니다. 이는 ROS 2 개발시에도 물론 적용될 것입니다.\n따라서, 이번 강의에서는 AI가 알려줄 수 없는 것들을 위주로 진행하고자 합니다.\nROS 2를 어떻게 손쉽게 설치하고, 어떠한 명령으로 다룰 수 있는지, 또 어떠한 개념을 갖고 있으며, 내가 원하는 기능을 위해 어떤 코드 구현이 필요한지 이 강의에서 모두 다루어 보겠습니다. 😉 강의를 수강하기 위해 필요한 선수지식 본 강의는 최대한 많은 분들이 끝까지 이해할 수 있도록 설계되었습니다. 따라서, 최대한 쉽고, 프로그래밍 실력이 출중하지 않아도 모두 완강할 수 있게 진행합니다. 프로그래밍 지식은 아래 코드를 이해할 수 있을 정도면 괜찮습니다.\npython basic class OOPNode: def __init__(self): self.counter_ = 0 def hello_du(self, event=None): hello_du = f\u0026#34;hello du {rospy.get_time()}, counter: {self.counter_}\u0026#34; print(hello_du) self.counter_ += 1 def my_first_oop_node(): oop_node = OOPNode() if __name__ == \u0026#39;__main__\u0026#39;: try: my_first_oop_node() except Exception as e: print(e) C++의 경우 이야기가 조금 다른데요. C++11 이후, 통칭 Modern C++에 대한 지식이 필요합니다.\ntype deduction smart pointer lambda, bind etc… 더불어 빌드 시스템에 대한 이해 (make, CMake)도 어느 정도 필요합니다.\n파이썬으로 개념을 익히고, C++ 언어 공부는 언제든 추가로 하면 되니 강의에서 이해에 어려움이 있다면 추가로 리서치하면 되시겠습니다.\n강의 코드와 강의 노트 사용법 강의 도중 사용되는 코드들은 Github Repository를 통해 배포되어 있습니다.\nhttps://github.com/RB2023ROS/du2023-ros2 강의 노트의 주소는 https://rb2023ros.github.io/kr/ 입니다. 코드와 명령어 등 필요한 리소스를 모두 담고 있으므로 복사/붙여넣기를 활용하여 강의 청취 시간을 절약하시기 바랍니다.\n해당 노트는 hugo를 사용하여 제작된 웹 페이지임을 밝힙니다.\n"
},
{
	"uri": "/kr/ros2_foxy/lecture2/",
	"title": "Lecture2. Dev Env Setup",
	"tags": [],
	"description": "",
	"content": "\nDevelpoment Environment Setup 프로젝트 기반의 강의인 만큼, 개발 환경이 구축되지 않으면 앞으로의 실습을 진행할 수 없습니다.\n따라서 이번 파트에 많은 시간을 배정하였고, 힘들 수 있지만 끝까지 따라와주시면 감사합니다.\n준비한 환경은 다음과 같습니다.\nUbuntu Linux \u0026amp; ROS 2 Setup Windows 11 \u0026amp; WSL 2 Setup Windows 10 \u0026amp; WSL 2 Setup 1,2,3 순서로 추천하는 설정입니다. 강의 컨텐츠를 따라오면서 선호하는 설정에 맞추어 작업하시다가 도저히 해결할 수 없는 문제가 발생한 경우 github issue를 발행하시거나 현장 강의의 경우 저를 불러 주시면 됩니다.\nUbuntu Linux \u0026amp; ROS 2 Setup 해당 메뉴얼은 우분투 리눅스 20.04버전을 사용하는 PC를 위한 ROS 2 설치 튜토리얼입니다. 기존 Windows를 사용하고 있었다면 듀얼 부팅이라는 것을 통해 Ubuntu + Windows를 모두 사용 가능합니다. 듀얼 부팅에 방법에 대해선 잘 설명한 영상들이 많으므로 링크로 대체하겠습니다.\n=\u0026gt; https://www.itechguides.com/dual-boot-ubuntu-windows-10/\nDual Booting 관련 자료 링크\nHow to Dual Boot Ubuntu 20.04 LTS and Windows 10 How to Dual Boot Ubuntu and Windows 11 ROS 2를 설치하기 전, 유용한 유틸리티 프로그램들을 몇가지 소개해드리겠습니다.\nternimator 설치 - 다중 터미널을 지원하는 훌륭한 터미널 프로그램입니다. sudo apt update sudo apt install terminator -y terminator 화면 분할 예시\nctrl + shift + e : 가로 분할 ctrl + shift + o : 세로 분할 ctrl + shift + w : 창 닫기 alt + 화살표 : 창 간 이동 peek - gif 제작 시 유용한 프로그램입니다. 저는 Gazebo와 같은 시뮬레이션 상황의 디버깅 시 사용하고 있습니다. sudo add-apt-repository ppa:peek-developers/stable sudo apt-get update sudo apt install peek 다음으로, 제가 미리 준비해둔 스크립트를 통해 ROS / ROS 2의 한줄 설치를 진행합니다. 설치 여부를 묻는 질문에는 y를 입력하시면 되며, OpenVINO를 설치하는 질문에서는 n를 입력하시면 됩니다. cd ~/ sh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/kimsooyoung/ros_menu/main/scripts/setup.sh)\u0026#34; … Do you want to install ROS automatically? (y/N): y 설치 후, 여러분들의 PC는 아래와 같이 실행 전, ROS 사용 여부를 선택하실 수 있습니다. ********* RoadBalance Startup Menu for ROS *********** * Usage: Please select the following options to load * * ROS environment automatically. * ****************************************************** 0) Do nothing 1) ROS 1 noetic 2) ROS 2 foxy 3) ROS 2 galactic 4) ROS2/ROS1_bridge h) Help Please choose an option: 2 ------------------------------------------------------ * ROS_DOMAIN_ID = 30 ------------------------------------------------------ ... 해당 setup은 ADLINK의 오픈소스를 참고하였음을 밝힙니다. ADLINK는 DDS Vendor 중 하나로 ROS 2 보급에도 힘쓰고 있답니다. 😃\nGazebo와 Rviz2의 설치 여부를 함께 확인해 봅시다. # 1. gazebo install check gazebo # 2. rviz2 install check rviz2 그림와 같이 Gazebo의 화면이 어둡거나, 그림자가 보이지 않는다면 호환되는 그래픽 드라이버를 설치해야 하는 상황입니다. 당장 크게 불편하지 않다면 상관은 없습니다.\n혹시나 Gazebo가 설치되지 않았다면, 아래의 커멘드 라인을 통해 설치해줍니다. sudo sh -c \u0026#39;echo \u0026#34;deb http://packages.osrfoundation.org/gazebo/ubuntu-stable `lsb_release -cs` main\u0026#34; /etc/apt/sources.list.d/gazebo-stable.list\u0026#39; wget https://packages.osrfoundation.org/gazebo.key -O - | sudo apt-key add - sudo apt update sudo apt install gazebo11 libgazebo11-dev -y sudo apt install ros-foxy-gazebo-ros-pkgs -y sudo apt install ros-noetic-gazebo-ros-pkgs -y Windows 11 \u0026amp; WSL 2 Setup 해당 메뉴얼은 Windows11을 사용하는 PC를 위한 ROS 2 설치 튜토리얼입니다.\n설치 전, “Windows Key ⇒ 업데이트”를 통해 최신 업데이트를 반영합니다. (상황에 따라 재부팅이 필요할 수 있습니다.) 더불어, Ctrl + Alt + Delete ⇒ 작업관리자 ⇒ 왼쪽 성능 탭을 통해 가상화 기능이 Enable 되어 있는지 확인합니다. 이 시점에서 문제가 있다면, 링크를 통해 문제를 해결해봅시다.\n⇒ https://www.manualfactory.net/15704\n다음으로, 터미널 프로그램을 관리자 권한으로 실행합니다. 이는 “Windows Key + X” ⇒ 터미널(관리자)를 통해 실행 가능합니다. 관리자 권한 Powershell에서 아래와 같은 커멘드 라인을 입력합니다. 사진과 같이 가상 머신 플렛폼 / WSL / Ubuntu가 모두 한번에 설치됩니다. - 여기에서 설치되는 Ubuntu는 22.04버전입니다. wsl --install 다음으로 동일 터미널에서 아래의 두 커멘드 라인을 입력합니다. # 1. WSL Enable dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart # 2. VirtualMachinePlatform Enable dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 아래와 같이 모든 작업이 성공적으로 완료되어야 합니다!\n\u0026gt; dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart 배포 이미지 서비스 및 관리 도구 버전: 10.0.19041.844 이미지 버전: 10.0.19043.1348 기능을 사용하도록 설정하는 중 [==========================100.0%==========================] 작업을 완료했습니다. \u0026gt; dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 배포 이미지 서비스 및 관리 도구 버전: 10.0.19041.844 이미지 버전: 10.0.19043.1348 기능을 사용하도록 설정하는 중 [==========================100.0%==========================] 작업을 완료했습니다. WSL 2 설정이 완료되었는지 확인을 해볼까요? PS C:\\Users\\tge13\u0026gt; wsl -l -v NAME STATE VERSION * Ubuntu Stopped 2 설치된 Ubuntu는 22.04 버전으로, 강의에서 사용되는 20.04버전은 MS Store에서 다시 다운로드받아야 합니다. 설치 이후, “열기” 버튼을 눌러 초기 실행을 하면 아래과 같은 터미널을 확인할 수 있으며, username, password를 설정합니다. - password는 보이지 않음에 유의합니다. 다음으로, 제가 미리 준비해둔 스크립트를 통해 ROS / ROS 2의 한줄 설치를 진행합니다. 설치 여부를 묻는 질문에는 y를 입력하시면 되며, OpenVINO를 설치하는 질문에서는 n를 입력하시면 됩니다. cd ~/ sh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/kimsooyoung/ros_menu/main/scripts/setup.sh)\u0026#34; … Do you want to install ROS automatically? (y/N): y 설치 후, 여러분들의 PC는 아래와 같이 실행 전, ROS 사용 여부를 선택하실 수 있습니다. ********* RoadBalance Startup Menu for ROS *********** * Usage: Please select the following options to load * * ROS environment automatically. * ****************************************************** 0) Do nothing 1) ROS 1 noetic 2) ROS 2 foxy 3) ROS 2 galactic 4) ROS2/ROS1_bridge h) Help Please choose an option: 2 ------------------------------------------------------ * ROS_DOMAIN_ID = 30 ------------------------------------------------------ ... GUI 인터페이스 설정 Gazebo, Rviz2, Rqt와 같은 시각화 프로그램을 사용하기 위해 Windows용 X Server인 VcXsrv를 사용하고자 합니다.\n링크를 통해 VcXsrv를 설치합니다. ⇒ https://sourceforge.net/projects/vcxsrv/ 설치 이후, “Windows Key” ⇒ XLaunch를 검색하여 실행하고, 사진과 같은 설정을 진행합니다. 첫번째 페이지 하단 Display Number를 -1에서 0으로 변경 두번째 페이지 통과 세번째 페이지 Native opengl 체크해제 후 Disable access control 체크 네번째 페이지 통과 앞으로 재부팅 시마다 이 설정을 반복해줘야 하며, 종종 Gazebo의 메모리 누수로 인해 화면이 종료되지 않는 경우가 있는데, 이런 경우 XLaunch를 강제 종료해주면 됩니다.\n설정이 잘 되었는지 Gazebo를 실행해봅시다. 터미널 상의 아래의 4줄 커멘드 라인을 입력합니다. export GAZEBO_IP=127.0.0.1 export DISPLAY=$(cat /etc/resolv.conf | grep nameserver | awk \u0026#39;{print $2}\u0026#39;):0 export LIBGL_ALWAYS_INDIRECT=0 # 설정 완료 후 Gazebo 실행 gazebo 마지막으로, 앞선 설정 커멘드 라인을 매번 수고스럽게 입력하지 않도록 bashrc 설정 파일을 수정합니다. echo \u0026#39;export GAZEBO_IP=127.0.0.1\u0026#39; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#34;export DISPLAY=$(cat /etc/resolv.conf | grep nameserver | awk \u0026#39;{print $2}\u0026#39;):0 \u0026#34; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#39;export LIBGL_ALWAYS_INDIRECT=0\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 오류 FAQ Ubuntu 실행 시 0x80370114 에러 Installing, this may take a few minutes... WslRegisterDistribution failed with error: 0x80370114 Error: 0x80370114 ??? ??? ???? ?? ?? ??? ??? ??? ? ????. Press any key to continue... ⇒ 관리자 권한 Powershell에서 아래의 커멘드 라인을 입력해주세요\ndism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart Windows 10 \u0026amp; WSL 2 Setup 해당 메뉴얼은 Windows 10을 사용하는 PC를 위한 ROS 2 설치 튜토리얼입니다.\n설치 전, “Windows Key ⇒ 업데이트”를 통해 최신 업데이트를 반영합니다. (상황에 따라 재부팅이 필요할 수 있습니다.) powershell을 관리자 권한으로 실행한 뒤, 설치 되어있는 WSL 2를 활성화시킵니다. 이는 “Windows Key + X” ⇒ 터미널(관리자)를 통해 실행 가능합니다. 관리자 권한 Powershell에서 아래와 같은 커멘드 라인을 입력합니다. # 1. WSL Enable dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart # 2. VirtualMachinePlatform Enable dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 아래와 같이 모든 작업이 성공적으로 완료되어야 합니다!\n\u0026gt; dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart 배포 이미지 서비스 및 관리 도구 버전: 10.0.19041.844 이미지 버전: 10.0.19043.1348 기능을 사용하도록 설정하는 중 [==========================100.0%==========================] 작업을 완료했습니다. \u0026gt; dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 배포 이미지 서비스 및 관리 도구 버전: 10.0.19041.844 이미지 버전: 10.0.19043.1348 기능을 사용하도록 설정하는 중 [==========================100.0%==========================] 작업을 완료했습니다. “Windows Key” ⇒ MS Store로 이동하여 windows terminal을 설치합니다. windows terminal 화면 분할 예시\nalt + shift + - : 가로 분할 alt + shift + + : 세로 분할 ctrl + shift + w : 창 닫기 alt + 화살표 : 창 간 이동 다음 링크를 통해 WSL 업데이트 프로그램을 다운받고 WSL 2 Linux 커널 업데이트를 설치/진행 후 재부팅합니다.\n커널 업데이트를 마친 다음, powershell에 아래 커맨드 라인을 입력하여 WSL 2를 기본 사용하도록 설정합니다. \u0026gt; wsl --set-default-version 2 WSL 2와의 주요 차이점에 대한 자세한 내용은 https://aka.ms/wsl2를 참조하세요 작업을 완료했습니다. 지금까지 진행한 작업들이 제대로 설정 되어있는지 확인해봅시다. \u0026gt; wsl -l -v NAME STATE VERSION * Ubuntu-20.04 Running 2 MS Store 진입 후, Ubuntu 20.04 버전을 설치합니다. 설치 이후, 열기 버튼을 눌러 초기 실행을 하고 username, password를 설정합니다. 설치 이후에는 windows terminal에서 Ubuntu Terminal을 선택하여 실행 및 진입이 가능합니다. 설정 탭을 통해 Ubuntu 20.04를 기본 터미널로 설정 후 저장합시다. ROS / ROS 2를 한줄 설치합니다. $ cd ~/ $ sh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/kimsooyoung/ros_menu/main/scripts/setup.sh)\u0026#34; Installing Neuron Startup Menu... Cloning into \u0026#39;/home/kimsooyoung/ros_menu\u0026#39;... remote: Enumerating objects: 583, done. remote: Counting objects: 100% (290/290), done. remote: Compressing objects: 100% (193/193), done. remote: Total 583 (delta 179), reused 173 (delta 93), pack-reused 293 Receiving objects: 100% (583/583), 154.50 KiB | 3.22 MiB/s, done. Resolving deltas: 100% (340/340), done. Do you want to install ROS automatically? (y/N): y 설치가 완료되었다면, 앞으로 터미널을 새로 등장시킬 때마다 다음과 같이 사용할 ROS 버전을 묻게 됩니다. GUI 인터페이스 설정 Gazebo, Rviz2, Rqt와 같은 시각화 프로그램을 사용하기 위해 Windows용 X Server인 VcXsrv를 사용하고자 합니다.\n링크를 통해 VcXsrv를 설치합니다. ⇒ https://sourceforge.net/projects/vcxsrv/ 설치 이후, “Windows Key” ⇒ XLaunch를 검색하여 실행하고, 사진과 같은 설정을 진행합니다. 첫번째 페이지 하단 Display Number를 -1에서 0으로 변경 두번째 페이지 통과 세번째 페이지 Native opengl 체크해제 후 Disable access control 체크 네번째 페이지 통과 앞으로 재부팅 시마다 이 설정을 반복해줘야 하며, 종종 Gazebo의 메모리 누수로 인해 화면이 종료되지 않는 경우가 있는데, 이런 경우 XLaunch를 강제 종료해주면 됩니다.\n설정이 잘 되었는지 Gazebo를 실행해봅시다. 터미널 상의 아래의 4줄 커멘드 라인을 입력합니다. export GAZEBO_IP=127.0.0.1 export DISPLAY=$(cat /etc/resolv.conf | grep nameserver | awk \u0026#39;{print $2}\u0026#39;):0 export LIBGL_ALWAYS_INDIRECT=0 # 설정 완료 후 Gazebo 실행 gazebo 마지막으로, 앞선 설정 커멘드 라인을 매번 수고스럽게 입력하지 않도록 bashrc 설정 파일을 수정합니다. echo \u0026#39;export GAZEBO_IP=127.0.0.1\u0026#39; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#34;export DISPLAY=$(cat /etc/resolv.conf | grep nameserver | awk \u0026#39;{print $2}\u0026#39;):0 \u0026#34; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#39;export LIBGL_ALWAYS_INDIRECT=0\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 오류 FAQ wsl --set-default-version 2 에서 작업 완료 메세지가 등장하지 않는 경우 ⇒ Linux용 Windows 하위 시스템 설정 여부를 확인해보신 뒤, 제일 처음 명령어부터 제가 보여드린 예시와 동일한 결과를 얻었는지 확인해보세요\nUbuntu 설치 후 ‘The WSL Optional Component is not Enabled. Please Enable it and Try again’ 오류가 발생하는 경우 ⇒ 관리자 권한 Powershell에서 아래의 커멘드 라인을 입력합니다.\n\u0026gt; Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux Ubuntu 설치 후 0x80370102 에러가 발생한 경우 부팅 BIOS에서 가상화 기능을 활성화해줍니다.\nUbuntu 설치 후 0xc03a001a 에러가 발생한 경우 다음 블로그 포스팅을 참고합니다.\nGazebo 실행 시 symbol lookup error가 발생하는 경우 sudo apt upgrade -y libignition-math2 을 통해 누락된 패키지를 설치합니다.\n$ gazebo gazebo: symbol lookup error: /usr/lib/x86_64-linux-gnu/libgazebo_common.so.9: undefined symbol: _ZN8ignition10fuel_tools12ClientConfig12SetUserAgentERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE Gazebo 자체가 실행되지 않는 경우 PC 재시작 후 백신 프로그램을 종료시킵니다. 제어판 ⇒ 시스템 및 보안 ⇒ Windows 방화벽 ⇒ 고급 설정 =\u0026gt; 인바운드 규칙 ⇒ VcXsrv 사용 허용을 적용합니다. Gazebo는 실행되지만, Grid (실선)이 등장하지 않는 경우 안타깝지만 그래픽 드라이버 문제일 가능성이 큽니다. Window ⇒ 업데이트 확인 진입 후 가장 최신 버전으로 모두 업그레이드를 실행해줍니다 기타 개발 환경 강의 중 사용할 코드 환경은 다음과 같습니다.\nVSCode + Github Copilot 강의 중 실행한 한 줄 설치에는 제가 기본적으로 설정한 여러 단축 커멘드들이 있습니다. 몇가지만 실습하고 넘어가보겠습니다.\neb : edit bashrc의 약자로 ~/.bashrc 파일을 gedit을 통해 수정할 수 있습니다. sb : source bashrc의 약자로 수정된 ~/.bashrc 파일을 반영시킵니다. killg : 실행중인 Gazebo관련 모든 프로그램을 종료시킵니다. "
},
{
	"uri": "/kr/ros2_foxy/lecture3/",
	"title": "Lecture3. Core of ROS",
	"tags": [],
	"description": "",
	"content": "Husky Gazebo 강의에 앞서, Gazebo상에 ClearPath의 Husky라는 로봇을 등장시켜보고자 합니다.\nimage from : clearpath robotics\n예제 패키지 설치 sudo apt-get update sudo apt install ros-foxy-husky-gazebo sudo apt install ros-foxy-husky-simulator sudo apt install ros-foxy-husky-viz 시뮬레이션 실행 # Terminal 1 ros2 launch husky_gazebo husky_playpen.launch.py Rviz2 + Controller 실행 (Rviz2상의 interactive marker를 사용하여 로봇을 이동시킬 수 있습니다.) # Terminal 2 ros2 launch husky_viz view_robot.launch.py 다음으로, 새로운 터미널에서 아래 커멘드 라인을 실행시켜 봅시다. rqt_graph 위 그림은 방금 전 실행한 예제 내부적으로 어떠한 동작들이 이루어지고 있었는지를 보여주는 것으로, 강의를 마칠 때면 여러분들은 위 그림이 어떠한 의미를 갖는지 모두 이해하실 수 있을 것입니다.\n다음으로, 터미널을 새로 실행시켜 아래의 명령어들을 실행시켜 봅시다.\nros2 node list $ ros2 node list /controller_manager /ekf_node /gazebo /gazebo_ros2_control /gps_plugin /husky_velocity_controller /imu_filter /imu_plugin ... ros2 topic list $ ros2 topic list /clicked_point /clock /cmd_vel /diagnostics /dynamic_joint_states /e_stop /goal_pose /gps/data /husky_velocity_controller/cmd_vel_unstamped /imu/data /imu/data_raw /imu/mag /initialpose ... 위 명령어들이 어떠한 의미를 갖는지 하나하나씩 함께 살펴보겠습니다.\nROS 2 Node ROS 2는 각 프로세스들을 Node라는 단위로 관리합니다.\n로봇을 움직이는 Node, 센서와 통신하는 Node, 시각화 Node 등 다양한 Node들이 얽혀 로봇 시스템을 구성하게 됩니다. Node들 사이에는 데이터의 송수신이 필요합니다. 이를 담당하는 ROS의 통신 메커니즘들이 있으며 각기 다른 특성을 갖고 있습니다. (topic, service, action) 실행중인 Node를 확인하는 방법으로 저는 크게 두가지를 사용합니다. ROS 2 command line interface $ ros2 node list /node1 /node2 /node3 ... rqt_graph rqt_graph # or ros2 run rqt_graph rqt_graph rqt graph를 살펴보면, 동그란 Node와 Node들 사이의 데이터 송수신이 화살표로 표현된 것을 알 수 있습니다. Rviz2 marker를 통해 제어 데이터가 송신되어 twist_mux로 전달되고 있으며, 따라서 gazebo는 이 데이터를 통해 실제 로봇을 움직이게 되는 것입니다. 특정 Node에 대해서 더 자세한 정보를 얻고 싶다면, info 커맨드를 사용합니다. $ ros2 node info /ekf_node /ekf_node Subscribers: /imu/data: sensor_msgs/msg/Imu /odom: nav_msgs/msg/Odometry /parameter_events: rcl_interfaces/msg/ParameterEvent /set_pose: geometry_msgs/msg/PoseWithCovarianceStamped Publishers: /diagnostics: diagnostic_msgs/msg/DiagnosticArray /odometry/filtered: nav_msgs/msg/Odometry /parameter_events: rcl_interfaces/msg/ParameterEvent /rosout: rcl_interfaces/msg/Log /tf: tf2_msgs/msg/TFMessage Service Servers: /ekf_node/describe_parameters: rcl_interfaces/srv/DescribeParameters ... 현재 예시를 실행하며 수많은 프로그램들이 동작되어 매우 복잡한 상황입니다. 이전 예제들은 일단 종료시킨 뒤, 보다 간단한 예시를 실행해봅시다. # Terminal 1 ros2 run examples_rclcpp_minimal_publisher publisher_member_function # Terminal 2 ros2 run examples_rclcpp_minimal_subscriber subscriber_member_function # Terminal 3 rqt_graph rqt_graph를 보면 publisher ⇒ subscriber 로 데이터가 전송되는 것을 알 수 있습니다.\n이것이 바로 ROS 2가 데이터를 송수신하는 가장 기본적인 구조입니다.\n서로 다른 두 프로그램(Node)을 생성하고 ROS 2에서 사용하는 특정한 형식에 이 둘 사이에 오가야 하는 데이터를 채워넣습니다. 두 프로그램 사이 통신은 DDS를 사용합니다. image from : MDS 테크 ROS 2 Workspace 생성 ROS 2의 Package는 관련된 파일들과 코드를 한데 모아둔 폴더이자, 빌드의 단위입니다. 그리고 이러한 패키지는 특정 Workspace안에 담겨있어야 합니다. image from : packthub Workspace?? 마치 파이썬의 가상 환경을 사용하는 것처럼, ROS 2 개발을 하다 보면 진행하는 프로젝트에 따라 하나의 PC에 여러 ROS 2 환경이 필요해지는 경우가 생깁니다.\n강의용 WS 개발용 WS 배포용 Clean WS etc… ROS 2에서 사용중인 colcon 시스템은 Workspace를 나눔으로 이 작업을 손쉽게 해줍니다.\n이번 강의용 WS를 만들어보겠습니다. 이후 여러분들만의 WS도 만들어 작업해보세요!\n일반적으로 ROS 2의 workspace는 _ws라는 이름을 갖는 것이 일반적이며, 우리는 ros2_ws라는 workspace를 만들어보고자 합니다. cd ~/ # colcon workspace는 반드시 src라는 폴더가 있어야 합니다. mkdir -p ros2_ws/src cd ros2_ws colcon build image from : colcon.readthedocs ros2_ws ├── build │ └── COLCON_IGNORE ├── install │ ├── COLCON_IGNORE │ ├── setup.bash ├── log └── src 작업을 완료하면, 위와 같은 폴더 구조가 자동 생성되었을 것입니다.\nbuild : 컴파일 된 프로그램, custom interface 등이 위치하게 됩니다. install : ros2 launch와 ros2 run 등의 명령어는 프로그램의 실행 시 이 install 폴더 내 파일들을 조회합니다. 일종의 바로가기들의 모임이라고 생각하면 됩니다. log : colcon build 시 발생하는 로드들이 위치하게 됩니다. src : 모든 소스 코드들이 위치하게 됩니다. package를 지우고 싶은 경우에는 src에서 코드 원본을 지운 뒤, build와 install 폴더에서 해당 package에 해당하는 내용들도 삭제해야 합니다!\nPackage 생성 실습 ROS 2에서는 colcon을 사용하여 새로운 package를 생성합니다. 하지만, ROS 2에서는 사용하는 프로그래밍 언어에 따라 다른 build type을 사용합니다. 자주 사용되는 두 언어(python/c++)에 대해서 패키지를 생성해보겠습니다.\nROS 2 Python Package\n파이썬 패키지의 생성은 다음과 같습니다. $ ros2 pkg create --build-type ament_python \u0026lt;package_name\u0026gt; # example $ ros2 pkg create --build-type ament_python my_first_pkg going to create a new package package name: my_first_pkg destination directory: /home/kimsooyoung/ros2_ws/src package format: 3 version: 0.0.0 ... 다음과 같은 폴더 구조가 자동 생성됩니다. my_first_pkg/ ├── my_first_pkg │ └── __init__.py ├── package.xml ├── resource │ └── my_first_pkg ├── setup.cfg ├── setup.py └── test ├── test_copyright.py ├── test_flake8.py └── test_pep257.py 새롭게 생성된 패키지를 빌드해봅시다. (여기서의 빌드는 컴파일을 거치는 빌드가 아니라 colcon 시스템에서의 빌드를 뜻합니다.) $ cd ~/ros2_ws $ colcon build --packages-select my_first_pkg Starting \u0026gt;\u0026gt;\u0026gt; my_first_pkg Finished \u0026lt;\u0026lt;\u0026lt; my_first_pkg [1.56s] Summary: 1 package finished [1.96s] 빌드 결과로, workspace 내부 build와 install 폴더 내부에 해당 패키지 이름을 갖는 폴더가 생성됩니다. $ cd ~/ros2_ws/build $ ls **COLCON_IGNORE my_first_pkg/ $ cd ~/ros2_ws/install $ ls **COLCON_IGNORE my_first_pkg/ ... ROS 2 Cpp Package 대부분의 오픈소스 패키지들은 C++로 개발되어 있는 경우가 많습니다. 따라서, 실제 작업 시 파이썬을 위주로 사용하더라도 적어도 C++ 패키지의 구조는 파악하고 있어야 오류 상황에 대처할 수 있습니다.\nC++ 패키지의 생성은 다음과 같습니다. $ ros2 pkg create --build-type ament_cmake \u0026lt;package_name\u0026gt; # example $ ros2 pkg create --build-type ament_cmake my_first_cpp_pkg going to create a new package package name: my_first_cpp_pkg destination directory: /home/kimsooyoung/ros2_ws/src package format: 3 version: 0.0.0 ... C++ 패키지는 다음과 같은 구조를 갖습니다. 파이썬과 달리, C++는 컴파일 언어이기 때문에 make를 위한 CMakeLists.txt 파일이 추가되어 있습니다. my_first_cpp_pkg ├── CMakeLists.txt ├── include │ └── my_first_cpp_pkg ├── package.xml └── src 일반적으로 C++ 개발을 하다보면 header와 source의 분리를 시키곤 합니다. 비슷하게, ROS 2에서도 보통 include 폴더 안에 헤더 파일을 위치시키고, src 폴더 안에 소스 코드를 위치시킵니다.\n빌드와 실행은 파이썬과 동일한 커멘드 라인을 사용합니다. $ colcon build --packages-select my_first_cpp_pkg Starting \u0026gt;\u0026gt;\u0026gt; my_first_cpp_pkg Finished \u0026lt;\u0026lt;\u0026lt; my_first_cpp_pkg [1.56s] Summary: 1 package finished [1.96s] 이 시점에서, colcon을 사용하여 package를 빌드하는 방법들을 정리하여 소개합니다.\ncolcon build : src 폴더 내부에 존재하는 모든 package들을 빌드합니다. colcon build \u0026ndash;packages-up-to : 해당 package의 종속성이 존재할 시, 이들을 먼저 빌드하고 pkg-name을 빌드합니다. colcon build \u0026ndash;packages-select : 해당 package만을 빌드합니다. 새로운 Package를 빌드했다면, 변경 내용을 갱신 (source) 해주어야 합니다. 이 작업에는 크게 두가지가 존재합니다.\nsource install/setup.bash ⇒ workspace를 source하고 ROS 2시스템 전체를 갱신합니다. source install/local_setup.bash ⇒ workspace만을 sources합니다. (여러 ROS 2 workspace가 있는 경우 local_setup.bash를 사용합시다.) 참고로, setup.bash에는 결국 local_setup.bash가 포함되어 있습니다.\n# source chained prefixes # setting COLCON_CURRENT_PREFIX avoids determining the prefix in the sourced script COLCON_CURRENT_PREFIX=\u0026#34;/opt/ros/foxy\u0026#34; _colcon_prefix_chain_bash_source_script \u0026#34;$COLCON_CURRENT_PREFIX/local_setup.bash\u0026#34; # source this prefix # setting COLCON_CURRENT_PREFIX avoids determining the prefix in the sourced script COLCON_CURRENT_PREFIX=\u0026#34;$(builtin cd \u0026#34;`dirname \u0026#34;${BASH_SOURCE[0]}\u0026#34;`\u0026#34; \u0026gt; /dev/null \u0026amp;\u0026amp; pwd)\u0026#34; _colcon_prefix_chain_bash_source_script \u0026#34;$COLCON_CURRENT_PREFIX/local_setup.bash\u0026#34; unset COLCON_CURRENT_PREFIX unset _colcon_prefix_chain_bash_source_script apt를 통한 패키지 설치하기 널리 사용되고 검증된 패키지들은 소스 코드 빌드 없이 apt 명령어 하나만으로 빌드된 형태를 사용할 수 있습니다. 다만, 같은 ROS 2일지라도 버전에 따라 재설치를 해줘야 합니다.\n$ sudo apt install ros-\u0026lt;DISTRO\u0026gt;-\u0026lt;pkg-name\u0026gt; $ sudo apt install ros-foxy-turtlesim 일전, 우리가 사용했던 husky관련 패키지들은 모두 apt install 을 통해 설치가 가능하였기에 코드에 대한 고려 없이 바로 실행할 수 있던 것입니다.\nROS 2에서는 husky를 비롯한 다양한 로보틱스 패키지들을 제공하며, 개발 초기에는 이를 사용하여 빠르게 검증을 하고, 이후 직접 Customizing해야 하는 부분은 별도 소스코드 빌드를 통해 업그레이드를 하곤 합니다.\nROS 2 Launch 3종류의 ROS 2 프로그램을 실행한다고 해봅시다.\nA 프로그램 실행 터미널 B 프로그램 실행 터미널 C 프로그램 실행 터미널 터미널 3개 정도야 실행하면 그만일 수 있지만, 이 프로그램의 개수가 10개, 20개로 늘어난다고 생각해 봅시다. 😂\n실행해야 하는 프로그램들을 모두 하나의 파일로 정리한 다음, 해당 파일만 실행시키면 어떨까요? 이것이 바로 launch의 개념입니다.\nROS 2의 launch파일은 python과 xml을 통해 구성할 수 있는데요, 저는 기본적으로 Python 문법을 선호합니다. 원래 사용하는 언어이기도 하고, 많은 오픈소스 프로젝트들이 Python launch를 사용하고 있기 때문입니다.\n일전 실행했던 husky 예제 분석을 통해 launch 구조에 대해 짚고 넘어가겠습니다. ros2의 launch 명령어는 다음과 같이 구성되어 있습니다. $ ros2 launch \u0026lt;package-name\u0026gt; \u0026lt;launch-file-name\u0026gt; $ ros2 launch husky_gazebo husky_playpen.launch.py 해당 launch 파일을 열어보면, 아래와 같습니다.(링크) 참고로, python 파일의 경우 .launch.py로 이름짓는 것이 암묵적인 규칙입니다. from launch import LaunchDescription from launch.actions import IncludeLaunchDescription from launch.launch_description_sources import PythonLaunchDescriptionSource from launch.substitutions import PathJoinSubstitution from launch_ros.substitutions import FindPackageShare def generate_launch_description(): world_file = PathJoinSubstitution( [FindPackageShare(\u0026#34;husky_gazebo\u0026#34;), \u0026#34;worlds\u0026#34;, \u0026#34;clearpath_playpen.world\u0026#34;], ) gazebo_launch = PathJoinSubstitution( [FindPackageShare(\u0026#34;husky_gazebo\u0026#34;), \u0026#34;launch\u0026#34;, \u0026#34;gazebo.launch.py\u0026#34;], ) gazebo_sim = IncludeLaunchDescription( PythonLaunchDescriptionSource([gazebo_launch]), launch_arguments={\u0026#39;world_path\u0026#39;: world_file}.items(), ) ld = LaunchDescription() ld.add_action(gazebo_sim) return ld 항상 launch file의 분석은 가장 하단부터 시작합니다. ld = LaunchDescription() ld.add_action(gazebo_sim) return ld LaunchDescription안에 실행을 원하는 프로그램들을 전달하고, launch 명령 시 이들을 실제 실행하는 것이 launch file을 작성하는 이유입니다.\n상단 옵션을 하나씩 살피겠습니다. launch file에서 특정 폴더, 파일에 접근하기 위해 package에 기반하여 경로를 탐색합니다. world_file = PathJoinSubstitution( [FindPackageShare(\u0026#34;husky_gazebo\u0026#34;), \u0026#34;worlds\u0026#34;, \u0026#34;clearpath_playpen.world\u0026#34;], ) gazebo_launch = PathJoinSubstitution( [FindPackageShare(\u0026#34;husky_gazebo\u0026#34;), \u0026#34;launch\u0026#34;, \u0026#34;gazebo.launch.py\u0026#34;], ) world란 gazebo상의 환경을 나타내는 파일로 아래와 같은 텍스트 형식을 갖습니다. (이후 Gazebo 시간에 살펴보고자 합니다.) \u0026lt;sdf version=\u0026#39;1.4\u0026#39;\u0026gt; \u0026lt;world name=\u0026#39;default\u0026#39;\u0026gt; \u0026lt;light name=\u0026#39;sun\u0026#39; type=\u0026#39;directional\u0026#39;\u0026gt; \u0026lt;cast_shadows\u0026gt;1\u0026lt;/cast_shadows\u0026gt; \u0026lt;pose\u0026gt;0 0 10 0 -0 0\u0026lt;/pose\u0026gt; \u0026lt;diffuse\u0026gt;0.8 0.8 0.8 1\u0026lt;/diffuse\u0026gt; \u0026lt;specular\u0026gt;0.2 0.2 0.2 1\u0026lt;/specular\u0026gt; \u0026lt;attenuation\u0026gt; \u0026lt;range\u0026gt;1000\u0026lt;/range\u0026gt; \u0026lt;constant\u0026gt;0.9\u0026lt;/constant\u0026gt; \u0026lt;linear\u0026gt;0.01\u0026lt;/linear\u0026gt; \u0026lt;quadratic\u0026gt;0.001\u0026lt;/quadratic\u0026gt; \u0026lt;/attenuation\u0026gt; \u0026lt;direction\u0026gt;-0.5 0.1 -0.9\u0026lt;/direction\u0026gt; \u0026lt;/light\u0026gt; \u0026lt;model name=\u0026#39;ground_plane\u0026#39;\u0026gt; ... 현재 husky_playpen는 다른 launch 파일을 또다시 include하고 있습니다. 이렇게 실행시켜야 할 프로그램들이 많을 때, launch file 자체를 계층 구조로 실행시키는 것도 가능합니다. gazebo_launch = PathJoinSubstitution( [FindPackageShare(\u0026#34;husky_gazebo\u0026#34;), \u0026#34;launch\u0026#34;, \u0026#34;gazebo.launch.py\u0026#34;], ) gazebo_sim = IncludeLaunchDescription( PythonLaunchDescriptionSource([gazebo_launch]), launch_arguments={\u0026#39;world_path\u0026#39;: world_file}.items(), ) 하위 launch file인 gazebo.launch.py 내부는 다음과 같습니다. 복잡한 형태를 갖고 있어 현재 모든 내용을 설명할 수는 없지만, launch 파일은 받드시 LaunchDescription을 포함하고, LaunchDescription으로 전달되는 프로그램들이 실행되는 주체임을 다시 한 번 강조드립니다! ld = LaunchDescription(ARGUMENTS) ld.add_action(gz_resource_path) ld.add_action(node_robot_state_publisher) ld.add_action(spawn_joint_state_broadcaster) ld.add_action(diffdrive_controller_spawn_callback) ld.add_action(gzserver) ld.add_action(gzclient) ld.add_action(spawn_robot) ld.add_action(launch_husky_control) ld.add_action(launch_husky_teleop_base) return ld [간략버전] Launch file 작성법 ROS 2는 워낙 방대한 오프 소스 패키지들을 갖고 있어 약간의 과장을 보태면 코드 한 줄 없이 로봇을 제작할 수도 있습니다.\n하지만, 어떠한 프로그램들을 실행하고, 실행 시 옵션은 어떻게 할당해야 하는지는 알고 있어야 합니다. 이러한 이유에서, 프로그래밍 학습보다 앞서 ROS 2의 launch file 작성법을 간단하게 설명하고 넘어가겠습니다.\n방금 전 생성한 my_first_pkg 패키지 내부에 launch 폴더를 생성하고, 아래 코드를 복사 \u0026amp; 붙여넣기 합니다. (my_first_pkg입니다! my_first_cpp_pkg가 아닙니다.) # my_first_launch.launch.py from launch import LaunchDescription from launch_ros.actions import Node def generate_launch_description(): turtlesim_node = Node( package=\u0026#34;turtlesim\u0026#34;, executable=\u0026#34;turtlesim_node\u0026#34;, name=\u0026#34;turtlesim_node\u0026#34;, ) return LaunchDescription([ turtlesim_node, ]) Keyword Description Node Node 하나를 실행시킬 수 있는 옵션입니다. package 실행시킬 Node가 포함된 package를 선택해줍니다. executable c++ Node의 경우, colcon build를 하면 실행 가능한 프로그램이 생성됩니다. python의 경우도 스크립트를 실행 시키게 되며, 이는 추후 코딩 실습을 거치면 완벽히 이해하실 수 있을 것입니다. parameters 실행시킬 Node의 추가 매개변수가 있다면 이 부분에 추가됩니다. 자, 새로운 launch 파일을 실행해보겠습니다.\n$ ros2 launch my_first_pkg my_first_launch.launch.py file \u0026#39;my_first_launch.launch.py\u0026#39; was not found in the share directory of package... ⇒ 오류가 발생하였습니다! 이는 install 폴더 내부에 symbolic link가 생성되지 않아 발생한 오류입니다.\ncolcon build 시 colcon은 install/\u0026lt;package_name\u0026gt;/share 폴더 내부에 파일들의 symbolic link를 생성합니다. 더불어 어떠한 파일들에 대해 link를 만들 것인지 전달해주어야 하며, 이는 setup.py에서 설정 가능합니다.\nsetup.py 수정 import os from glob import glob from setuptools import setup package_name = \u0026#39;my_first_pkg\u0026#39; setup( name=package_name, version=\u0026#39;0.0.0\u0026#39;, packages=[package_name], data_files=[ (\u0026#39;share/ament_index/resource_index/packages\u0026#39;, [\u0026#39;resource/\u0026#39; + package_name]), (\u0026#39;share/\u0026#39; + package_name, [\u0026#39;package.xml\u0026#39;]), (os.path.join(\u0026#39;share\u0026#39;, package_name, \u0026#39;launch\u0026#39;), glob(\u0026#39;launch/*.launch.py\u0026#39;)), ], ... 다음으로 아래의 커멘드 라인을 순서대로 입력해 주세요! # 폴더 이동 cd ~/ros2_ws # colcon build colcon build --packages-select my_first_pkg # 변경 적용 source install/setup.bash # 실행! ros2 launch my_first_pkg my_first_launch.launch.py 이렇게 launch file을 직접 생성해 보았습니다. 주목할 점은, 제가 보여드린 것이 하나의 예시일 뿐이며, launch file은 여러 형식으로 사용된다는 것입니다.\n# my_first_pkg return LaunchDescription([ turtlesim_node, ]) # husky_gazebo ld = LaunchDescription(ARGUMENTS) ld.add_action(gz_resource_path) ld.add_action(node_robot_state_publisher) ld.add_action(spawn_joint_state_broadcaster) ld.add_action(diffdrive_controller_spawn_callback) ld.add_action(gzserver) ld.add_action(gzclient) ld.add_action(spawn_robot) ld.add_action(launch_husky_control) ld.add_action(launch_husky_teleop_base) return ld ROS 2 자체가 오픈소스에 기반하기 때문에 사용자들마다 각기 다른 방식이 있습니다. 모든 방식을 다 설명할 수는 없으나 가장 널리 사용되는 것들은 대부분 같이 다루어보겠습니다!\n"
},
{
	"uri": "/kr/ros2_foxy/lecture4/",
	"title": "Lecture4. ROS 2 Node and Parameter Programming",
	"tags": [],
	"description": "",
	"content": "지난 시간 살펴본 바와 같이 ROS 2에서 프로그램이 실행되는 단위는 Node라는 이름으로 관리됩니다.\n여러분들께서 원하는 기능을 수행하는 Node를 생성하고, 이를 담은 패키지를 작성하고, 관련된 패키지들을 묶어 메타패키지를 구성하는 식으로 ROS 2 개발이 진행됩니다.\n오늘은 그 시작이 되는 Node의 기초 프로그래밍을 실습해보겠습니다.\n첫 코딩 강의의 시작이므로, 제가 사용하는 환경과 셋업도 공유드릴 예정입니다.\nPython 개발 : VSCode와 Copilot C++ 개발 : Clion과 Copilot ROS 2 프로그래밍의 경우 일반적인 프로그래밍과 더불어 tf, 통신 메커니즘, 멀티 프로세싱 등 실제 동작시켜보지 않으면 알 수 없는 기능들의 구현이 잦습니다. 잦은 확인과 Command and Conquer 방식으로 접근해보겠습니다. 😊\nROS 2 Node Programming - Python 제가 미리 준비해 둔 패키지를 빌드해봅시다. cd ~/ros2_ws/src git clone https://github.com/RB2023ROS/du2023-ros2.git # 빌드는 항상 WS의 최상단 디렉토리에서 진행합니다!!! cd ~/ros2_ws cbp py_node_tutorial # or colcon build --packages-select py_node_tutorial # 빌드 후 항상 소싱!!! cd ~/ros2_ws rosfoxy # or source install/local_setup.bash example 1 - Hello ROS 2 앞서 빌드된 예시를 실행시켜보겠습니다. $ ros2 run py_node_tutorial example_node_1 [INFO] [1680692820.096342214] [example_node_1]: ==== Hello ROS 2 ==== 모든 예제 코드는 Github 링크에서도 확인할 수 있습니다.\n코드 분석 rcl은 ROS Client Libraries의 약자로 ROS 2에서는 rclc, rclcpp, rclpy, rcljs와 같은 다양한 언어를 지원하고 있습니다. 파이썬에서 ROS 2 개발을 하기 위해서는 필수적으로 rclpy의 import가 필요하며 Node의 사용을 위해서 Node class를 import 해야 합니다.\n# !/usr/bin/env python3 import rclpy from rclpy.node import Node rclpy 코딩 규칙 ROS 2에서 파이썬 파일을 조회하고 실행하는 일련의 정해진 과정이 있어 아래와 같이 main()부분을 항상 따로 분리하여 작성하도록 합니다.\nif __name__ == \u0026#39;__main__\u0026#39;: \u0026#34;\u0026#34;\u0026#34;main function\u0026#34;\u0026#34;\u0026#34; main() Node 생성 def main(args=None): \u0026#34;\u0026#34;\u0026#34;Do enter into this main function first.\u0026#34;\u0026#34;\u0026#34; rclpy.init(args=args) node = Node(\u0026#39;node_name\u0026#39;) node.get_logger().info(\u0026#39;\\n==== Hello ROS 2 ====\u0026#39;) node.destroy_node() rclpy.shutdown() 실제 동작을 수행하는 main 함수를 살펴보면 다음과 같은 과정을 거치고 있습니다.\nFunction Description rclpy.init initialization, 즉 초기화를 하고 있습니다. node = Node(\u0026rsquo;node_name') Node를 생성하는 부분으로 앞서 import한 Node class를 사용하고 있습니다. 매개변수로 node의 이름이 들어갑니다. node.destroy_node() Node를 생성하고 원하는 작업을 모두 수행했다면, 이제 사용했던 Node를 제거해야 할 것입니다. (그래야 불필요한 자원의 낭비를 줄일 수 있겠지요.) rclpy.shutdown() 이번 예시 첫 부분, rclpy.init()을 통하여 초기화를 해주었습니다. 이제 rclpy를 통한 작업이 모두 끝났으므로 안전하게 종료시켜줍니다. ⇒ 위 과정이 Python에서 rclpy를 통해 Node를 다루는 기본 절차입니다. (get_logger 부분은 이후에 계속해서 살펴보겠습니다.)\nsetup.py 수정 파이썬 파일을 ros2 run 으로 실행하기 위해서 패키지 내 setup.py 파일에 entry_points를 추가해 주어야 합니다. entry_points={ \u0026#39;console_scripts\u0026#39;: [ \u0026#39;example_node_1 = py_node_tutorial.node_example_1:main\u0026#39;, \u0026#39;example_node_2 = py_node_tutorial.node_example_2:main\u0026#39;, \u0026#39;example_node_3 = py_node_tutorial.node_example_3:main\u0026#39;, \u0026#39;example_node_4 = py_node_tutorial.node_example_4:main\u0026#39;, \u0026#39;example_node_5 = py_node_tutorial.node_example_5:main\u0026#39;, ], }, 작성하는 방법은 다음과 같습니다. ⇒ 실행 시 사용될 이름 = \u0026lt;패키지 이름\u0026gt;.\u0026lt;파일 이름\u0026gt;.main 실행 시 이름 패키지 이름 파일 이름 example_node_1 py_node_tutorial node_example_1 진입 지점(entry_points)를 설정하지 않으면 파이썬 파일이 있어도 ros2 run 과 같은 커멘드를 사용할 수 없게 됩니다.\n[과제] 나만의 Node를 구현하는 파이썬 스크립트를 생성하여 ros2 run으로 실행할 수 있도록 해보세요!\nexample 2 - timer 계속해서 Timer 예시입니다. 로봇은 일반적으로 실행된 이후 계속해서 작업을 수행해야 하기에 주기적으로 무언가를 실행하는 일이 잦습니다. 이를 구현하는 Timer를 살펴봅시다. $ ros2 run py_node_tutorial example_node_2 ==== Hello ROS 2 : 1==== ==== Hello ROS 2 : 2==== ==== Hello ROS 2 : 3==== ==== Hello ROS 2 : 4==== ==== Hello ROS 2 : 5==== main문에 추가된 create_timer와 timer_callback 함수를 확인할 수 있습니다. def timer_callback(): \u0026#34;\u0026#34;\u0026#34;Timer will run this function periodically.\u0026#34;\u0026#34;\u0026#34; global count count += 1 print(f\u0026#39;==== Hello ROS 2 : {count}====\u0026#39;) def main(args=None): \u0026#34;\u0026#34;\u0026#34;Do enter into this main function first.\u0026#34;\u0026#34;\u0026#34; rclpy.init(args=args) node = Node(\u0026#39;node_name\u0026#39;) node.create_timer(0.2, timer_callback) rclpy.spin(node) node.destroy_node() rclpy.shutdown() timer 생성 시 create_timer라는 함수가 사용됩니다.\nCode Description timer_period_sec 실행 주기 (초) callback 해당 주기마다 실행될 함수 동기/비동기의 측면에서 timer와 Node의 분석은 이후 강의에서 이어집니다. 지금은 기본적인 코딩에만 집중하겠습니다!\nexample 3 - spin_once, spin Node의 상태를 살피면서 반복 실행시키는 spin 함수에 대해 좀 더 자세하게 살펴봅니다. $ ros2 run py_node_tutorial example_node_3 ==== Hello ROS 2 : 1==== ==== Hello ROS 2 : 2==== ==== Hello ROS 2 : 3==== ... Node는 상태를 지속 유지하면서 변경된 내용에 따라 지정된 동작을 수행해야 합니다. 이는 로봇 프로그램에서 매우 보편적인 작업으로, ROS 2에서는 **spin()**이라는 이름의 함수로 기능을 제공하고 있습니다. def main(args=None): \u0026#34;\u0026#34;\u0026#34;Do enter into this main function first.\u0026#34;\u0026#34;\u0026#34; rclpy.init(args=args) node = Node(\u0026#39;node_name\u0026#39;) node.create_timer(0.2, timer_callback) # 1. spin_once() will run node only once. # timeout_sec: Seconds to wait. # Block forever if ``None`` or negative. Don\u0026#39;t wait if 0. rclpy.spin_once(node, timeout_sec=10) # # 2. spin() will run node until Ctrl+C. rclpy.spin(node) # # 3. spin_once() with while loop will run node periodically. while True: rclpy.spin_once(node, timeout_sec=10) node.destroy_node() rclpy.shutdown() spin을 비롯하여 spin_once, spin_until_future_complete와 같이 프로그램의 실행을 관리하기 위한 다양한 추가 함수들이 존재하며, 예시에서는 3가지 자주 사용되는 패턴을 제시하고 있습니다.\nCode Description spin_once() Node를 단 한번만 실행 spin() Ctrl+C 입력 전까지 계속해서 실행 while + spin_once() spin과 더불어 다른 무언가를 추가할 수 있는 패턴 example 4 - OOP Node 예제 실행의 결과는 이전과 같습니다. 하지만 구현에서 OOP를 사용한다는 차이를 갖는 예시입니다. $ ros2 run py_node_tutorial example_node_4 [INFO] [1657348011.971419700] [composition_example_node]: ==== Hello ROS 2 : 1==== [INFO] [1657348012.163466100] [composition_example_node]: ==== Hello ROS 2 : 2==== [INFO] [1657348012.363590700] [composition_example_node]: ==== Hello ROS 2 : 3==== class를 사용하여 Node를 구현한 모습을 확인할 수 있습니다. class NodeClass(Node): \u0026#34;\u0026#34;\u0026#34;Second Node Class. Just print log periodically. \u0026#34;\u0026#34;\u0026#34; def __init__(self): \u0026#34;\u0026#34;\u0026#34;Node Initialization. You must type name of the node in inheritanced initializer. \u0026#34;\u0026#34;\u0026#34; super().__init__(\u0026#39;composition_example_node\u0026#39;) self.create_timer(0.2, self.timer_callback) self._count = 1 def timer_callback(self): \u0026#34;\u0026#34;\u0026#34;Timer will run this function periodically.\u0026#34;\u0026#34;\u0026#34; self.get_logger().info(f\u0026#39;==== Hello ROS 2 : {self._count}====\u0026#39;) self._count += 1 ROS 1과 달리, ROS 2의 OOP 구현은 Node를 상속받습니다. (때문에 생성 시, Node이름을 super().__init__()안에 넣어주어야 합니다.) 이렇게 객체지향을 사용하면 Node의 기능들을 적극 활용하여 더욱 쉽고 강력한 ROS 2 개발이 가능해집니다.\nrclpy logger super().__init__(\u0026#39;node_name\u0026#39;) ... node.get_logger().info(\u0026#39;\\n==== Hello ROS 2 ====\u0026#39;) ROS 1의 rospy.loginfo()와 같이 rclpy에서도 get_logger()라는 logging API를 제공합니다. 다만, rclpy의 logger는 Node에 종속되는 개념입니다. (ROS 2에서는 여러 Node가 하나의 프로세스 안에서 실행될 수 있기 때문입니다.)\nget_logger()를 사용하면 일반적인 print 콘솔 출력과는 달리, 실행중인 Node이름, 시간, 위험성 등을 디버깅할 수 있어 이후 복잡한 시스템에서 큰 도움이 됩니다.\nexample 5 - Logger Level 기본 node 프로그래밍의 마지막 예시입니다. $ ros2 run py_node_tutorial example_node_5 [INFO] [1657348108.163389800] [node_name]: ==== Hello ROS 2 : 1==== [WARN] [1657348108.163810900] [node_name]: ==== Hello ROS 2 : 1==== [ERROR] [1657348108.164126200] [node_name]: ==== Hello ROS 2 : 1==== [FATAL] [1657348108.164514300] [node_name]: ==== Hello ROS 2 : 1==== ... ROS 2에서는 위험도에 따라서 다른 logger level을 적용할 수 있습니다. info를 기준으로 아래로 갈수록 높은 레벨의 log이며, 제일 심각한 error와 fatal의 경우, 콘솔 출력시에도 빨간 글씨로 보이는 것을 확인할 수 있습니다.\ndebug의 경우 실제 콘솔 출력으로는 나타나지 않으며, 효과적인 Tracking을 위해 이후 학습할 rqt console 사용을 권장합니다. ROS 2 Parameter Programming - Python 모터의 게인값, 카메라의 Focal Lenght, Intrinsic, Extrinsic Parameter, Point Cloud의 resolution과 min/max range 등 로봇 프로그래밍 시 수많은 매개변수들이 사용됩니다.\nROS 2에서는 각종 매개변수를 다룰 수 있는 별도의 Parameter Server를 제공하며, Node들은 모두 개별 Parameter Server를 갖고 있습니다.\n예제 Package 빌드와 실행 $ colcon build --packages-select py_param_tutorial $ source install/local_setup.bash $ ros2 run py_param_tutorial param_example [INFO] [1672390971.030532687] [param_ex_node]: string_param: world int_param: 119 float_param: 3.1415 arr_param: [1, 2, 3] nested_param.string_param: Wee Woo ⇒ param_ex_node에서 5종류의 매개변수가 선언되었습니다. 이들을 확인하는 커멘드 라인을 배워봅시다.\nros2 param list $ ros2 param list /param_ex_node: arr_param float_param int_param nested_param.string_param string_param use_sim_time ⇒ param_ex_node의 Parameter Server는 현재 6개의 값을 갖고 있습니다.\n개별 Parameter들의 값을 다루고 싶은 경우 ros2 param get/set 을 사용합니다. $ ros2 param get /param_ex_node arr_param Integer values are: array(\u0026#39;q\u0026#39;, [1, 2, 3]) $ ros2 param set /param_ex_node arr_param \u0026#39;[1,2,3,4]\u0026#39; Set parameter successful $ ros2 param get /param_ex_node arr_param Integer values are: array(\u0026#39;q\u0026#39;, [1, 2, 3, 4]) ⇒ node 이름과 매개변수 이름을 모두 필요로 함에 주의합니다.\n코드 분석 parameter의 생성은 node 내에서 이루어지며, declare_parameter를 통해 생성합니다. (함수의 두번째 인자는 기본값입니다.) class ParamExNode(rclpy.node.Node): def __init__(self): super().__init__(\u0026#39;param_ex_node\u0026#39;) self.declare_parameter(\u0026#39;string_param\u0026#39;, \u0026#39;world\u0026#39;) self.declare_parameter(\u0026#39;int_param\u0026#39;, 119) self.declare_parameter(\u0026#39;float_param\u0026#39;, 3.1415) self.declare_parameter(\u0026#39;arr_param\u0026#39;, [1,2,3]) self.declare_parameter(\u0026#39;nested_param.string_param\u0026#39;, \u0026#39;Wee Woo\u0026#39;) ⇒ nested_param과 같이 parameter는 계층 구조를 가질 수 있으며 온점을 통해 구분할 수 있습니다. ⇒ 현재 string_param이라는 이름을 가진 parameter가 두 종류 존재하지만 서로 소속된 계층이 달라 공존할 수 있는 것입니다.\n선언된 매개변수의 값은 get_parameter를 통해 확인 가능합니다. get_parameter 자체는 Object이고, value 속성이 실제 값을 갖고 있음에 주의합니다. string_param = self.get_parameter(\u0026#39;string_param\u0026#39;) int_param = self.get_parameter(\u0026#39;int_param\u0026#39;) float_param = self.get_parameter(\u0026#39;float_param\u0026#39;) arr_param = self.get_parameter(\u0026#39;arr_param\u0026#39;) nested_param = self.get_parameter(\u0026#39;nested_param.string_param\u0026#39;) self.get_logger().info(f\u0026#34;\\nstring_param: {string_param.value} \\ \\nint_param: {int_param.value} \\ \\nfloat_param: {float_param.value} \\ \\narr_param: {arr_param.value} \\ \\nnested_param.string_param: {nested_param.value}\u0026#34; ) parameter는 launch file에서도 설정할 수 있는데요. 예시를 우선 실행해봅시다. - 변경된 Parameter값도 확인해봅시다. $ ros2 launch py_param_tutorial launch_with_param.launch.py ... [param_example-1] [INFO] [1672387864.135213913] [param_example]: [param_example-1] string_param: Hello [param_example-1] int_param: 112 [param_example-1] float_param: 3.1415 [param_example-1] arr_param: [1, 2, 3] $ ros2 launch py_param_tutorial launch_with_yaml.launch.py ... [param_example-1] [INFO] [1680857428.211772092] [param_example]: [param_example-1] string_param: Yaml Yaml [param_example-1] int_param: 5 [param_example-1] float_param: 3.14 [param_example-1] arr_param: [\u0026#39;I\u0026#39;, \u0026#39;love\u0026#39;, \u0026#39;ROS 2\u0026#39;] [param_example-1] nested_param.string_param: Ooh Wee Node를 실행하는 launch file을 기억하시지요? Node의 parameters 옵션을 사용하면 코드를 직접 바꾸지 않고 parameter의 변경이 가능합니다. def generate_launch_description(): param_ex_node = Node( package=\u0026#39;py_param_tutorial\u0026#39;, executable=\u0026#39;param_example\u0026#39;, name=\u0026#39;param_example\u0026#39;, output=\u0026#39;screen\u0026#39;, parameters=[ {\u0026#39;string_param\u0026#39;: \u0026#39;Hello\u0026#39;}, {\u0026#39;int_param\u0026#39;: 112}, ], ) parameter가 매우 많은 경우에는 yaml 형식의 파일을 사용해 관리할 수 있는데요, yaml 파일을 사용하는 launch 파일의 일부를 함께 살펴봅시다. def generate_launch_description(): config = os.path.join( get_package_share_directory(\u0026#39;py_param_tutorial\u0026#39;), \u0026#39;config\u0026#39;, \u0026#39;params.yaml\u0026#39; ) param_ex_node = Node( package = \u0026#39;py_param_tutorial\u0026#39;, executable = \u0026#39;param_example\u0026#39;, name = \u0026#39;param_example\u0026#39;, output=\u0026#39;screen\u0026#39;, parameters = [config] ) return LaunchDescription([ param_ex_node ]) 추가 설명 - os.path.join, get_package_share_directory를 사용하는 이유!\nyaml 파일은 config/params.yaml에 위치하고 있습니다. parameter 관리 용도로 사용하기 위해서 yaml 파일은 일정한 규칙을 갖춰야 합니다. \u0026lt;node-name\u0026gt;: ros__parameters: \u0026lt;param-name\u0026gt;: \u0026lt;param-value\u0026gt; ... \u0026lt;nested-layer-name\u0026gt;: \u0026lt;param-name\u0026gt;: \u0026lt;param-value\u0026gt; param_example: ros__parameters: string_param: \u0026#34;Yaml Yaml\u0026#34; int_param: 5 float_param: 3.14 arr_param: [\u0026#39;I\u0026#39;, \u0026#39;love\u0026#39;, \u0026#39;ROS 2\u0026#39;] nested_param: string_param: \u0026#34;Ooh Wee\u0026#34; 이렇게 새로운 폴더와 파일을 추가한 경우, python 패키지의 setup.py를 수정해주어야 하며 패키지 빌드도 새로 해주어야 합니다. import os from glob import glob from setuptools import setup package_name = \u0026#39;py_param_tutorial\u0026#39; setup( name=package_name, version=\u0026#39;0.0.0\u0026#39;, packages=[package_name], data_files=[ (\u0026#39;share/ament_index/resource_index/packages\u0026#39;, [\u0026#39;resource/\u0026#39; + package_name]), (\u0026#39;share/\u0026#39; + package_name, [\u0026#39;package.xml\u0026#39;]), (os.path.join(\u0026#39;share\u0026#39;, package_name, \u0026#39;config\u0026#39;), glob(\u0026#39;config/*.yaml\u0026#39;)), (os.path.join(\u0026#39;share\u0026#39;, package_name, \u0026#39;launch\u0026#39;), glob(\u0026#39;launch/*.launch.py\u0026#39;)), ], launch file에 추가된 내용을 다시 살펴보면, 방금 전의 yaml 파일을 불러와서 node의 실행 option에 전달하고 있습니다. Namespace Parameter 아직 이른 감이 있지만, 다수의 로봇을 다루는 경우를 생각해봅시다. 종류는 같지만 별도의 Parameter가 필요할 것입니다.\n⇒ 이러한 경우를 대비해서 ROS 2에서는 namespace라는 기능을 지원합니다. topic과 node 앞에 별도의 접미사를 추가하여 서로 다른 객체임을 구별하는 방식입니다.\n이를 지금 언급하는 이유는, Parameter의 namespace를 지정하는 일이 매우 빈번하고 그 사용 방식이 node나 topic과는 조금 다르기 때문입니다.\nnamespace를 지정하는 가장 일반적인 방법은 launch 파일에서 옵션을 지정하는 것입니다. param_ex_node = Node( package = \u0026#39;py_param_tutorial\u0026#39;, # namespace 지정! namespace = \u0026#39;robot1\u0026#39;, executable = \u0026#39;param_example\u0026#39;, name = \u0026#39;param_example\u0026#39;, output=\u0026#39;screen\u0026#39;, parameters = [config] ) 예시를 다시 실행시킨 다음 어떤 결과를 얻게 되는지 살펴봅시다. $ ros2 launch py_param_tutorial launch_with_yaml.launch.py ... [param_example-1] [INFO] [1680861992.330212575] [robot1.param_example]: [param_example-1] string_param: world [param_example-1] int_param: 119 [param_example-1] float_param: 3.1415 [param_example-1] arr_param: [1, 2, 3] [param_example-1] nested_param.string_param: Wee Woo ⇒ yaml 파일이 반영되지 않은 결과를 얻었습니다!\nyaml 파일에도 namespace를 반영해주어야 하기 때문이며 예를 들어 robot1이라는 namespace를 반영하고 싶다면 yaml 파일을 아래와 같이 변경해야 합니다. robot1/param_example: ros__parameters: string_param: \u0026#34;Yaml Yaml\u0026#34; int_param: 5 float_param: 3.14 arr_param: [\u0026#39;I\u0026#39;, \u0026#39;love\u0026#39;, \u0026#39;ROS 2\u0026#39;] nested_param: string_param: \u0026#34;Ooh Wee\u0026#34; 하지만 namespace를 바꿀 때마다 새로운 yaml파일을 만들 수는 없습니다. 이를 대비하여 ROS 2에서는 다음과 같은 yaml 문법을 허용합니다. /**: ros__parameters: string_param: \u0026#34;Namespaced Param\u0026#34; int_param: 10 float_param: 2.718 arr_param: [\u0026#39;I\u0026#39;, \u0026#39;absolutely\u0026#39;, \u0026#39;love\u0026#39;, \u0026#39;ROS 2\u0026#39;] nested_param: string_param: \u0026#34;Yeah Hee\u0026#34; 새롭게 작성한 yaml 파일을 반영한 새로운 예시를 실행해봅시다. $ ros2 launch py_param_tutorial launch_with_namespace.launch.py ... [param_example-1] [INFO] [1680862245.965886805] [robot1.param_example]: [param_example-1] string_param: Namespaced Param [param_example-1] int_param: 10 [param_example-1] float_param: 2.718 [param_example-1] arr_param: [\u0026#39;I\u0026#39;, \u0026#39;absolutely\u0026#39;, \u0026#39;love\u0026#39;, \u0026#39;ROS 2\u0026#39;] [param_example-1] nested_param.string_param: Yeah Hee 다수의 센서를 사용하거나, 다수의 로봇을 사용하는 경우 지금 학습한 namespace를 꼭 기억해주세요!!\nROS 2 Node Programming - C++ 앞선 Node 프로그래밍 예시들을 C++에서 구현하는 방법을 배워봅시다. 제가 미리 준비해 둔 패키지를 빌드하며 시작하겠습니다. # 빌드는 항상 WS의 최상단 디렉토리에서 진행합니다!!! cd ~/ros2_ws cbp cpp_node_tutorial # or colcon build --packages-select cpp_node_tutorial # 빌드 후 항상 소싱!!! cd ~/ros2_ws rosfoxy # or source install/local_setup.bash example 1 - Hello ROS 2 파이썬 때와 마찬가지로, 앞서 빌드된 예시를 실행시켜보겠습니다. $ ros2 run cpp_node_tutorial example_node_1 [INFO] [1680692820.096342214] [example_node_1]: ==== Hello ROS 2 ==== ROS 2 C++ 코드 빌드와 실행 ROS 2에서는 C++ 코드의 빌드를 위해 CMake를 사용하고 있습니다. 코드 분석 이전에 새로운 코드를 생성하고, 빌드하는 과정을 간단히 설명해보고자 합니다.\n새로운 코드 생성 -C++ 코드는 패키지 내 src 폴더에 생성하는 것이 관례입니다. 단, 작업 전 해당 패키지가 C++용으로 만들어져 있는지 꼭 확인하셔야 합니다. (ament_cmake를 사용했던 점을 복기해봅시다.)\n코드 작성- 우선, 패키지 내 존재하는 예시 혹은 copilot을 사용하여 가장 간단한 node code를 생성하겠습니다.\nCMakeLists.txt 수정\nfind_package(rclcpp REQUIRED) add_executable(test_node src/test.cpp) ament_target_dependencies(test_node rclcpp) install( TARGETS test_node DESTINATION lib/${PROJECT_NAME} ) Function Description find_package 필요한 종속성들을 추가합니다. ROS 2 종속성 뿐만 아니라, 3rd party 종속성도 여기에서 추가됩니다. add_executable Build 후 실행 파일을 생성합니다. (일반적인 CMake 과정과 동일합니다.) ament_target_dependencies CMake의 target_link_libaries와 동일한 역할을 하지만, ROS 2에서 사용을 위해 편의성이 추가된 Function입니다. install 빌드 결과물을 특정 디렉토리에 위치시킵니다. 모든 CMake function들은 ament_package() 상단에 위치해야 합니다!\n다음으로, 새로운 코드의 빌드 작업을 함께 해봅시다. # 빌드는 항상 WS의 최상단 디렉토리에서 진행합니다!!! cd ~/ros2_ws cbp cpp_node_tutorial # or colcon build --packages-select cpp_node_tutorial # 빌드 후 항상 소싱!!! cd ~/ros2_ws rosfoxy # or source install/local_setup.bash # 새롭게 빌드한 예시 실행 $ ros2 run cpp_node_tutorial test_node [INFO] [1681299676.469101345] [example_node_1]: ==== Hello ROS 2 ==== 코드 분석 python 코드 작성 시 rclpy를 import 했던 것처럼, cpp 코딩 시 rclcpp을 import 해야 합니다. (해당 header안에는 memory, vector, string 등 범용적으로 사용되는 웬만한 라이브러리가 포함되어 있습니다.) #include \u0026lt;rclcpp/rclcpp.hpp\u0026gt; Node 생성 int main(int argc, char **argv) { // Initialize ROS 2 rclcpp::init(argc, argv); // Create a node auto node = rclcpp::Node::make_shared(\u0026#34;example_node_1\u0026#34;); // Log a message RCLCPP_INFO(node-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 ====\u0026#34;); // Shutdown ROS 2 rclcpp::shutdown(); return 0; } python 코드 분석 시 대부분의 함수를 살펴보았으므로 간단하게 짚고 넘어가겠습니다. Function Description rclcpp::init(argc, argv) initialization, 즉 초기화를 하고 있습니다. rclcpp::Node::make_shared() Node를 생성하는 부분으로 앞서 import한 Node class를 사용하고 있습니다. 매개변수로 node의 이름이 들어갑니다. rclcpp::shutdown() 이번 예시 첫 부분, rclpy.init()을 통하여 초기화를 해주었습니다. 이제 rclpy를 통한 작업이 모두 끝났으므로 안전하게 종료시켜줍니다. 스마트 포인터를 사용하기 때문에 destroy_node라는 것은 별도로 호출하지 않습니다. example 2 - timer 계속해서 Timer 예시입니다. #include \u0026#34;rclcpp/rclcpp.hpp\u0026#34; using namespace std::chrono_literals; static int count = 0; void timer_callback(){ std::cout \u0026lt;\u0026lt; \u0026#34;==== Hello ROS 2 : \u0026#34; \u0026lt;\u0026lt; count \u0026lt;\u0026lt; \u0026#34; ====\u0026#34; \u0026lt;\u0026lt; std::endl; count++; } int main(int argc, char **argv) { rclcpp::init(argc, argv); auto node = rclcpp::Node::make_shared(\u0026#34;example_node_2\u0026#34;); auto timer = node-\u0026gt;create_wall_timer(200ms, timer_callback); rclcpp::spin(node); rclcpp::shutdown(); return 0; } Code Description create_wall_timer Timer 생성, 실행 주기와 callback을 매개변수로 갖습니다. timer_callback 특정 해당 주기마다 실행될 함수 Timer, Node와 같은 인터페이스들은 모두 스마트 포인터를 사용하고 있습니다. 따라서 함수의 인자로 전달하거나, 내부 함수를 호출할 시 포인터라는 점을 기억하시어 코딩하셔야 합니다. auto node =\u0026gt; std::shared_ptr\u0026lt;rclcpp::Node\u0026gt; auto timer =\u0026gt; std::shared_ptr\u0026lt;rclcpp::Timer\u0026gt; example 3 - OOP Node OOP를 사용한 Timer Node 구현입니다. #include \u0026#34;rclcpp/rclcpp.hpp\u0026#34; class NodeClass: public rclcpp::Node { public: NodeClass(): Node(\u0026#34;example_node_4\u0026#34;) {} }; int main(int argc, char **argv) { rclcpp::init(argc, argv); auto node = std::make_shared\u0026lt;NodeClass\u0026gt;(); RCLCPP_INFO(node-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 ====\u0026#34;); rclcpp::shutdown(); return 0; } 모든 rclcpp Node들은 반드시 rclcpp::Node를 public 상속받아야 합니다. class NodeClass: public rclcpp::Node { public: NodeClass(): Node(\u0026#34;example_node_4\u0026#34;) {} }; 상속을 받은 만큼 구현 시 주의해야 하는 부분들이 있으며, 생성자는 반드시 Access Modifier public을 가져야 합니다.\nrclcpp logger RCLCPP_INFO(node-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 ====\u0026#34;); python의 get_logger()와 동일하지만, RCLCPP_INFO로 wrapping이 되어있다는 차이점을 기억하시기 바랍니다.\nOOP 구현 시 새로운 Node 생성을 위해 template을 사용합니다. auto node = std::make_shared\u0026lt;NodeClass\u0026gt;(); example 4 - spin_once, spin Node의 상태를 살피면서 반복 실행시키는 spin 함수가 추가되며 OOP 구현이 보입니다. class NodeClass: public rclcpp::Node { private: size_t count; rclcpp::TimerBase::SharedPtr timer; void timer_callback() { RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 : %d ====\u0026#34;, count); count++; } public: NodeClass() : Node(\u0026#34;example_node_5\u0026#34;) { timer = this-\u0026gt;create_wall_timer( std::chrono::milliseconds(200), // timer_callback, std::bind(\u0026amp;NodeClass::timer_callback, this) ); } }; int main(int argc, char **argv) { rclcpp::init(argc, argv); auto node = std::make_shared\u0026lt;NodeClass\u0026gt;(); rclcpp::spin(node); rclcpp::shutdown(); return 0; } rclpy와 마찬가지로, rclcpp에서도 spin, spin_some, spin_until_future_complete등 다양한 기능을 제공하는데요. spin을 이해하기 위해서 많은 배경지식이 필요하니 구체적인 내용은 이후에 살펴보고 지금은 기능 구현에 집중하겠습니다. rclcpp::spin(node); Timer를 비롯한 인터페이스들은 모두 shared_ptr 타입을 갖습니다. SharedPtr은 ROS 2 단에서 편의를 위해 wrapping한 것입니다. - 참고 링크 rclcpp::TimerBase::SharedPtr timer; example 5 - Logger Level 기본 node 프로그래밍의 마지막 예시였습니다. 실행 후 간단하게 살펴보고 넘어가겠습니다. class NodeClass: public rclcpp::Node { private: size_t count; rclcpp::TimerBase::SharedPtr timer; void timer_callback() { RCLCPP_DEBUG(this-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 : %d ====\u0026#34;, count); RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 : %d ====\u0026#34;, count); RCLCPP_WARN(this-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 : %d ====\u0026#34;, count); RCLCPP_ERROR(this-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 : %d ====\u0026#34;, count); RCLCPP_FATAL(this-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 : %d ====\u0026#34;, count); count++; } public: NodeClass() : Node(\u0026#34;example_node_5\u0026#34;) { timer = this-\u0026gt;create_wall_timer( std::chrono::milliseconds(200), std::bind(\u0026amp;NodeClass::timer_callback, this) ); } }; int main(int argc, char **argv) { rclcpp::init(argc, argv); auto node = std::make_shared\u0026lt;NodeClass\u0026gt;(); rclcpp::spin(node); rclcpp::shutdown(); return 0; } 코드 중 logger level을 지정하는 부분을 확인 가능합니다. RCLCPP_DEBUG(this-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 : %d ====\u0026#34;, count); RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 : %d ====\u0026#34;, count); RCLCPP_WARN(this-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 : %d ====\u0026#34;, count); RCLCPP_ERROR(this-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 : %d ====\u0026#34;, count); RCLCPP_FATAL(this-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 : %d ====\u0026#34;, count); ROS 2 Parameter Programming - C++ 예제 Package 빌드와 실행 $ colcon build --packages-select cpp_param_tutorial $ source install/local_setup.bash $ ros2 run cpp_param_tutorial cpp_param_example [INFO] [1681300487.037502527] [param_ex_node]: str: world int: 119 double: 3.141500 arr: [1, 2, 3] nested: Wee Woo 코드 분석 rclcpp 코드에서 parameter의 생성과 사용은 다음과 같습니다. Code Description declare_parameter(name, default_value) parameter의 생성 get_parameter() parameter object를 받아옵니다. as_() get_parameter 결과는 object로 실제 값을 파싱하기 위해서 필요합니다. 코드를 통해서도 확인이 가능하며, 최소 3 줄의 라인이 필요하기 때문에 get_parameter와 as_type을 한번에 사용하기도 합니다. class ParamExNode : public rclcpp::Node { public: ParamExNode() : Node(\u0026#34;param_ex_node\u0026#34;) { this-\u0026gt;declare_parameter(\u0026#34;string_param\u0026#34;, \u0026#34;world\u0026#34;); ... rclcpp::Parameter str_param = this-\u0026gt;get_parameter(\u0026#34;string_param\u0026#34;); ... std::string my_str = str_param.as_string(); 간소화 버전 this-\u0026gt;declare_parameter(\u0026#34;string_param\u0026#34;, \u0026#34;world\u0026#34;); auto my_str = this-\u0026gt;get_parameter(\u0026#34;string_param\u0026#34;).as_string(); cpp로 구현된 node의 parameter도 ros2 launch와 yaml 파일을 통해 손쉽게 수정이 가능합니다. $ ros2 launch cpp_param_tutorial launch_with_yaml.launch.py ... [cpp_param_example-1] [INFO] [1681301614.005450889] [param_example]: [cpp_param_example-1] str: Yaml Yaml [cpp_param_example-1] int: 5 [cpp_param_example-1] double: 3.141500 [cpp_param_example-1] arr: [1, 2, 3] [cpp_param_example-1] nested: Ooh Wee "
},
{
	"uri": "/kr/ros2_foxy/lecture5/",
	"title": "Lecture5. ROS 2 Communication Mechanisms",
	"tags": [],
	"description": "",
	"content": " 이번 시간에는 ROS 2의 핵심인 3가지 통신 메커니즘(Topic,Service, Action)에 대해서 개념을 다잡고 넘어가고자 합니다. 프로그래밍은 없지만, 각각의 통신 메커니즘들에 대해 반드시 숙지하고 넘어가시기 바랍니다!\nROS 2 Topic 3강의 husky 예시 실행 후 살펴보았던 rqt_graph 이미지입니다. ⇒ 위 그림에서 동그라미는 Node를 뜻하고, 화살표는 topic을 뜻하는데요, 첫번째로 이 Topic이라는 것이 무엇인지 배워보고자 합니다.\nTopic은 Node들 사이에 데이터(Message)가 오가는 길(Bus)의 이름이며, 적절한 이름으로 데이터를 송수신하지 않으면 원하는 동작을 수행할 수 없습니다. ROS 2에서 사용하는 DDS는 목적지를 정해두고 통신하는 것이 아니라 통신 매개체의 ID를 통해 송수신하기 때문에 기존 웹 기반 통신과는 다른 개념임을 상기드립니다. image from : docs.ros.org\nTopic은 N:N 통신이 가능합니다. (여러 Node들로부터 데이터를 받을 수 있고, 전송 시에도 여러 Node들에게 전송이 가능합니다. 하지만 대부분 1:N 혹은 1:1, N:1로 사용합니다.) image from : docs.ros.org\ntopic을 통해 데이터가 전달되는 과정은 다음과 같습니다. 데이터를 보내는 주체인 publisher는 데이터를 받는 주체, subscriber를 지정한 뒤, topic을 통해 원하는 정보를 전달합니다. 이것을 topic publish라고 부르지요. 반대로, 데이터를 받는 주체인 subscriber 입장에선 topic을 통해 데이터를 받게 되며 이것은 topic subscribe라고 불립니다. ROS 2 Topic msg 로봇 프로그래밍 시 센서, 제어 데이터를 비롯하여 다양한 유형의 데이터들이 Topic을 통해 오고 갑니다. ROS에서는 이러한 데이터 형식을 msg(Message)라는 형태로 제공하며, 원하는 데이터에 적합한 topic msg를 사용하면 더욱 효율적인 로봇 프로그래밍이 가능해집니다. image from : ethz.ch\nROS 1과 ROS 2는, msg를 구분하는 필드에서 차이를 보입니다. ROS 1 geometry_msgs/Twist ROS 2 geometry_msgs/msg/Twist 세부 필드 정보를 위해 구글링을 하면 ROS 1 결과가 나올 때가 있는데 해당하는 필드를 중간에 추가해주시면 됩니다. 출처 : http://docs.ros.org/ ROS 2 Topic CLI ROS에서는 topic에 대한 정보, 파싱, 송수신과 같은 여러 인터페이싱이 가능하도록 CLI를 제공하고 있습니다. topic과 msg에 대한 CLI들을 살펴봅시다!\n이번 예시를 위해 2개의 터미널을 실행하고 아래와 같은 명령어를 각각 입력합니다. (그리고 세번째 터미널에서 이어지는 학습을 진행하시면 됩니다.) # Terminal 1 $ ros2 topic pub /chatter std_msgs/String \u0026#34;data: Hello ROS Developers\u0026#34; # Terminal 2 $ ros2 topic echo /chatter ros2 topic list ⇒ 사용중인 topic list 조회 $ ros2 topic list /topic_a /topic_b ... /clock /parameter_events /performance_metrics /rosout ros2 topic info ⇒ 특정 topic에 대한 자세한 정보 조회 $ ros2 topic info /chatter Type: std_msgs/msg/String Publisher count: 1 Subscription count: 1 ⇒ verbose option을 통해 더욱 자세한 내용을 알 수 있지만 지금은 넘어가겠습니다.\n$ ros2 topic info /chatter --verbose Type: std_msgs/msg/String Publisher count: 1 Node name: _ros2cli_84037 Node namespace: / Topic type: std_msgs/msg/String Endpoint type: PUBLISHER GID: 30.06.10.01.46.68.e4.44.22.bd.f2.21.00.00.08.03.00.00.00.00.00.00.00.00 QoS profile: Reliability: RMW_QOS_POLICY_RELIABILITY_RELIABLE Durability: RMW_QOS_POLICY_DURABILITY_VOLATILE Lifespan: 9223372036854775807 nanoseconds Deadline: 9223372036854775807 nanoseconds Liveliness: RMW_QOS_POLICY_LIVELINESS_AUTOMATIC Liveliness lease duration: 9223372036854775807 nanoseconds Subscription count: 1 Node name: _ros2cli_84065 Node namespace: / Topic type: std_msgs/msg/String Endpoint type: SUBSCRIPTION GID: 48.95.10.01.ea.a0.fa.d5.31.c6.85.40.00.00.08.04.00.00.00.00.00.00.00.00 QoS profile: Reliability: RMW_QOS_POLICY_RELIABILITY_BEST_EFFORT Durability: RMW_QOS_POLICY_DURABILITY_VOLATILE Lifespan: 9223372036854775807 nanoseconds Deadline: 9223372036854775807 nanoseconds Liveliness: RMW_QOS_POLICY_LIVELINESS_AUTOMATIC Liveliness lease duration: 9223372036854775807 nanoseconds ros2 topic type ⇒ 해당 topic이 사용중인 msg 조회 $ ros2 topic type /chatter std_msgs/msg/String ros2 interface show ⇒ 특정 msg 정보 조회 $ ros2 interface show std_msgs/msg/String # This was originally provided as an example message. # It is deprecated as of Foxy # It is recommended to create your own semantically meaningful message. # However if you would like to continue using this please use the equivalent in example_msgs. string data ros2 topic echo ⇒ 특정 topic 데이터를 엿볼 수 있습니다. $ ros2 topic echo /chatter ... data: Hello ROS Developers --- data: Hello ROS Developers --- ros2 topic hz ⇒ topic의 publish/subscribe 주기를 분석할 수 있습니다. $ ros2 topic hz /chatter average rate: 1.000 min: 1.000s max: 1.000s std dev: 0.00013s window: 3 average rate: 1.000 min: 1.000s max: 1.000s std dev: 0.00017s window: 5 ... ros2 topic pub ⇒ 프로그래밍 없이 터미널 라인에서 publish가 가능합니다. (단, 주로 간단한 문자열 정도에만 사용되며 이미지 데이터 등에는 사용이 불가합니다.) $ ros2 topic pub /chatter std_msgs/String \u0026#34;data: Hello ROS Developers\u0026#34; ... publishing #1: std_msgs.msg.String(data=\u0026#39;Hello ROS Developers\u0026#39;) publishing #2: std_msgs.msg.String(data=\u0026#39;Hello ROS Developers\u0026#39;) publishing #3: std_msgs.msg.String(data=\u0026#39;Hello ROS Developers\u0026#39;) ROS 2 Topic CLI 정리 CMD Description ros2 topic list 전체 topic 조회 ros2 topic info 특정 topic 정보 조회 ros2 topic type 특정 topic type 조회 ros2 interface show msg type 조회 ros2 topic echo topic 엿보기 ros2 topic hz topic pub/sub 주기 조회 ros2 topic pub 간단한 publish ROS 2 Service Topic에 이어 ROS의 통신 메커니즘 두번째로 Service를 배워보겠습니다.\nClient Node가 Server Node로 request를 주면, 해당 request에 대응하는 적절한 response가 다시 Client에게로 전달됩니다. 이 과정을 Service Call이라고 부릅니다. image from : docs.ros.org\n하나의 Service Server에는 여러 Client Node가 request 할 수 있지만, Server는 동시에 여러 request를 처리하지는 못합니다. 두 Node에서 동시에 request가 왔다면, 조금이라도 먼저 통신한 Node의 작업을 우선 진행하고, 그동안 다른 Node는 기다리고 있어야 합니다. image from : https://docs.ros.org/en/foxy/Tutorials/Services/Understanding-ROS2-Services.html\nService 개념 정리 Service를 요청하는 주체를 Service Client라고 하며, Service 요청 자체를 Request(혹은 Call)라고 합니다. Service를 요청받는 주체를 Service Server라고 하며, Service Server는 Request에 대한 응답, 즉 Service Response를 다시 Service Client에게 회답합니다. Request와 Response를 위해 사용되는 데이터 타입은 srv라고 하며 Request와 Response로 나뉩니다. Service의 중요한 특징 ⇒ 하나의 Service Server에 여러 Client가 request 할 수 있지만, Server는 동시에 여러 request를 처리하지 못합니다.\nimage from : docs.ros.org\n마지막으로, Topic과 비교하여 Service의 특징을 알아봅시다.\n1:1 통신 : Topic publish를 하면 여러 Node가 Subscribe 가능합니다. 반면, Service는 request가 온 대상에게만 response를 줍니다. 순차적 통신 : Service Server는 동시에 여러 request를 처리할 수 없습니다. 현재 작업중인 request가 처리될 때 까지 다른 request는 기다리고 있어야 합니다. 단발성 : Topic은 대부분 지속적으로 publish를 진행하는 반면, Service는 1회성 통신입니다. ROS 2 Service CLI Service는 Topic과는 다르게 일회성이기 때문에 CLI를 사용할 일이 매우 잦습니다. 자주 사용되는 만큼 얼른 학습해봅시다!\n이번 학습을 위해 일전의 husky simulator를 실행하겠습니다. ros2 launch husky_gazebo husky_playpen.launch.py ros2 service list ⇒ 전체 service list를 조회합니다. $ ros2 service list /controller_manager/configure_and_start_controller /controller_manager/configure_controller /controller_manager/describe_parameters ... ros2 service type ⇒ 특정 service에 대한 정보를 조회합니다. (사용되는 type 정도를 알 수 있습니다.) $ ros2 service type /controller_manager/configure_and_start_controller controller_manager_msgs/srv/ConfigureStartController ros2 interface show ⇒ Topic의 msg와 유사하게, Service에는 srv가 존재하는데요, 이 타입에 대한 자세한 정보를 조회할 수 있습니다. $ ros2 interface show controller_manager_msgs/srv/ConfigureStartController # The ConfigureStartController service allows you to configure and start a single controller # inside controller_manager # To configure and start a controller, specify the \u0026#34;name\u0026#34; of the controller. # The return value \u0026#34;ok\u0026#34; indicates if the controller was successfully # configured and started or not. string name --- bool ok 서비스 타입 중간에 보이는 - - - 부분은 request와 response의 구분자라고 생각하시면 됩니다.\nros2 service call ⇒ 커멘드 라인 상에서 Service Call을 할 수 있습니다. 간단한 service를 실행해보겠습니다. $ ros2 service call /get_model_list gazebo_msgs/srv/GetModelList {} requester: making request: gazebo_msgs.srv.GetModelList_Request() response: gazebo_msgs.srv.GetModelList_Response(header=std_msgs.msg.Header(stamp=builtin_interfaces.msg.Time(sec=1594, nanosec=330000000), frame_id=\u0026#39;\u0026#39;), model_names=[\u0026#39;ground_plane\u0026#39;, \u0026#39;jersey_barrier\u0026#39;, \u0026#39;jersey_barrier_0\u0026#39;, \u0026#39;jersey_barrier_1\u0026#39;, \u0026#39;jersey_barrier_2\u0026#39;, \u0026#39;jersey_barrier_3\u0026#39;, \u0026#39;jersey_barrier_4\u0026#39;, \u0026#39;jersey_barrier_5\u0026#39;, \u0026#39;jersey_barrier_6\u0026#39;, \u0026#39;jersey_barrier_7\u0026#39;, \u0026#39;jersey_barrier_8\u0026#39;, \u0026#39;jersey_barrier_9\u0026#39;, \u0026#39;jersey_barrier_10\u0026#39;, \u0026#39;jersey_barrier_11\u0026#39;, \u0026#39;jersey_barrier_12\u0026#39;, \u0026#39;jersey_barrier_13\u0026#39;, \u0026#39;jersey_barrier_14\u0026#39;, \u0026#39;fire_hydrant\u0026#39;, \u0026#39;fire_hydrant_0\u0026#39;, \u0026#39;fire_hydrant_1\u0026#39;, \u0026#39;Dumpster\u0026#39;, \u0026#39;Dumpster_0\u0026#39;, \u0026#39;jersey_barrier_15\u0026#39;, \u0026#39;Construction Cone\u0026#39;, \u0026#39;Construction Barrel\u0026#39;, \u0026#39;Construction Cone_0\u0026#39;, \u0026#39;Construction Barrel_0\u0026#39;, \u0026#39;asphalt_plane\u0026#39;, \u0026#39;Construction Barrel_1\u0026#39;, \u0026#39;Construction Barrel_2\u0026#39;, \u0026#39;Construction Barrel_3\u0026#39;, \u0026#39;Construction Barrel_4\u0026#39;, \u0026#39;Construction Barrel_5\u0026#39;, \u0026#39;Construction Barrel_6\u0026#39;, \u0026#39;Construction Barrel_7\u0026#39;, \u0026#39;Construction Cone_1\u0026#39;, \u0026#39;husky\u0026#39;], success=True) ⇒ Gazebo 상에 존재하는 모델들의 리스트를 response로 받았습니다. (gazebo ros에서 이러한 기능들이 제공됩니다.)\nROS 2 Service CLI 정리 CMD Description ros2 service list 전체 Service 리스트 ros2 service type 특정 Service가 사용하는 데이터 타입 조회 ros2 interface show 특정 srv에 대한 자세한 정보 조회 ros2 service call 터미널을 통해 Service Call ROS 2 Action ROS 2의 마지막 통신 메커니즘인 Action을 배워보겠습니다.\n복습 차원에서 Service의 중요한 특징 한 가지를 복기해보겠습니다. 하나의 Service Server에 여러 Client가 request 할 수 있지만, Server는 동시에 여러 request를 처리하지 못합니다. image from : docs.ros.org Action은 바로 이러한 Service의 단점을 극복하기 위해 탄생한 통신 메커니즘입니다. Action은 Service와 Topic의 특성을 모두 갖고 있으며, 실제로 가장 늦게 탄생한 통신 메커니즘입니다.\nAction의 특징\naction client는 action server가 Result를 보내기 전까지 마냥 기다리지 않고, 다른 일을 할 수 있습니다. action client는 Result Response를 받기 전에도 지속적으로 Feedback을 받을 수 있습니다. 따라서, Feedback을 받고 있다가, 뭔가 잘못 돌아가고 있다는 것을 감지한 경우 cancel을 할 수도 있습니다. ⇒ 하지만, 여러 request를 동시에 작업하는 것이나, Feedback 중에 topic subscribe와 같은 작업은 본질적으로 불가합니다. 이에 대한 해결 방법도 후에 살펴보겠습니다.\nimage from : https://docs.ros.org/en/foxy/Tutorials/Understanding-ROS2-Actions.html 사진과 같이 Action Client와 Server가 주고받는 내용은 크게 5가지가 있습니다.\nClient ⇒ Server, Goal Request (service request와 유사합니다.) server ⇒ client, Goal Response client ⇒ server, Result Request server ⇒ client, Feedback (topic과 유사합니다.) server ⇒ client, Result Response 만약 4번 도중 cancel이 발생하면 Action은 종료됩니다.\n이렇게 Action은 Topic, Service의 특징을 모두 갖고 있으며 Feedback 결과에 따라 Cancel이라는 추가 기능까지 갖추고 있는 복잡한 통신 메커니즘입니다.\nROS 2 Action CLI 이번 예시를 위해 turtlesim이라는 프로그램을 실행시킨 뒤, 실습을 진행해봅시다. sudo apt install ros-foxy-turtlesim -y ros2 run turtlesim turtlesim_node ros2 action list ⇒ 실행 중인 action들을 조회 가능합니다. $ ros2 action list /turtle1/rotate_absolute ros2 action info ⇒ ****특정 action의 정보를 조회합니다. $ ros2 action info /turtle1/rotate_absolute Action: /turtle1/rotate_absolute Action clients: 0 Action servers: 1 /turtlesim ros2 interface show ⇒ Action에서 사용되는 데이터 타입은 action입니다. 이에 대한 자세한 정보를 조회합니다. $ ros2 interface show turtlesim/action/RotateAbsolute # The desired heading in radians float32 theta --- # The angular displacement in radians to the starting position float32 delta --- # The remaining rotation in radians float32 remaining ros2 action send_goal ⇒ 커멘드 라인에서 손쉽게 Action Goal을 보낼 수 있습니다. (feedback option을 제공합니다.) $ ros2 action send_goal \u0026lt;action_name\u0026gt; \u0026lt;action_type\u0026gt; \u0026lt;values\u0026gt; $ ros2 action send_goal /turtle1/rotate_absolute turtlesim/action/RotateAbsolute \u0026#34;{theta : 0.0}\u0026#34; --feedback 1657646954.088327 [0] ros2: using network interface enp7s0 (udp/166.104.135.89) selected arbitrarily from: enp7s0, docker0 Waiting for an action server to become available... Sending goal: theta: 0.0 Goal accepted with ID: d3ddca85948d4099a13dbeb8183e5ecc Result: delta: -0.7839995622634888 Goal finished with status: SUCCEEDED /turtle1/rotate_absolute는 거북이를 특정한 절대 각도로 회전시키는 action으로 feedback 옵션 지정 시 커멘드 라인 상에 변화하는 각도록 실시간으로 확인 가능합니다.\nROS 2 Action CLI 정리 CMD Description ros2 action list 전체 action list 조회 ros2 action info 특정 action 정보 조회 ros2 interface show 특정 action 데이터 타입에 대한 조회 ros2 action send_goal 터미널을 통한 action goal request 여기까지 배웠다면 ROS 2의 개념적인 부분은 대부분 습득하셨다고 보아도 좋습니다. 그럼 앞으로 프로그래밍과 예시들을 통해 ROS 2 시스템에 더욱 능숙해져보겠습니다.\n"
},
{
	"uri": "/kr/ros2_foxy/lecture6/",
	"title": "Lecture6. ROS 2 Tools",
	"tags": [],
	"description": "",
	"content": "\nROS 2는 rqt라는 프로그램의 집합을 제공합니다. rqt의 GUI를 사용하면 데이터 시각화, 코딩 없이 통신 메커니즘과 상호 작용, tf frame의 시각화 등 ROS 2 프로그래밍이 매우 매우 편해집니다.\n이번 시간을 통해 몇가지 자주 사용되는 rqt들을 살펴보고, 약간의 실습도 진행해보겠습니다.\nrqt의 실행은 다음과 같습니다. rqt ⇒ 초기 실행 시 빈 화면이 등장하지만, 상단 탭을 통해 수많은 응용 프로그램들을 확인할 수 있습니다.\nrqt_graph rqt_graph는 node와 topic에 대해 시각화하여 한 장의 이미지를 보여주는 툴로, 가장 많이 사용되는 Rqt Tool입니다.\nrqt_graph는 자주 사용되는 만큼 보통 개별적으로 실행합니다. rqt_graph 사진에 보이는 동그라미는 node를, 네모는 topic을 의미합니다. 더불어 화살표의 방향을 통해 topic의 송/수신자를 구별할 수 있습니다. 더불어 rqt_graph는 다양한 시각화 옵션들을 제공하고 있습니다. Node Option Hide Option ETC Node Only Dead sinks Group Option Nodes/Topics (Active) Leaf Topics Actions Nodes/Topics (All) Debug tf tf Images Unreachable Highlight Params Fit ⇒ 참고로, rqt_graph의 node에 마우스 커서를 가져가면 관련 topic들의 색상을 바꿔줍니다. (Highlight)\nTopic 이름을 잘못 생성하거나 겹치는 경우, 코드 차원에서 디버깅이 힘들지만 rqt_graph를 사용하면 손쉽게 판별 가능합니다.\nTopic Tools - Message Publisher \u0026amp; Topic Monitor rqt 상단의 탭에서 다음과 같이 화면을 구성합니다.\nplugins ⇒ topics ⇒ Message Publisher pulgins ⇒ topics ⇒ Topic Monitor message publisher를 사용하면 코딩 없이 원하는 topic을 publish 가능합니다. Topic Msg에 원하는 데이터를 채워넣은 뒤, 체크박스를 클릭하면 로봇이 움직이기 시작합니다. 실습을 위해 일전 husky gazebo를 실행시키고 로봇을 제어해 보겠습니다. # Terminal 1 ros2 launch husky_gazebo husky_playpen.launch.py # Terminal 2 rqt Topic Monitor를 사용하면, Topic 데이터들을 효과적으로 모니터링 가능합니다. Topic Publisher와 동일하게 체크박스를 눌러 topic을 선택한 뒤, 변하는 데이터를 확인해봅시다. Service Tools - Service Caller rqt 상단의 탭에서 다음과 같이 화면을 구성합니다.\nplugins ⇒ services ⇒ Service Caller Service Caller를 통해 코딩 없이 간편하게 Service Call이 가능합니다. Service Srv에 원하는 데이터를 채워넣은 뒤, Call 버튼을 클릭하면 Request와 Response를 받을 수 있습니다. Gazebo상의 물체를 제거하는 간단한 실습을 해봅시다. gazebo_ros와 rqt를 실행합니다. # Terminal 1 - Run Gazebo ROS ros2 launch gazebo_ros gazebo.launch.py # Terminal 2 - rqt \u0026amp; Service Caller rqt rqt Service Caller를 실행시킨 뒤, /delete_entity service를 선택합니다. gazebo상에서 모델을 등장시킨 뒤, 해당 모델의 이름을 service srv를 통해 전달하면 물체가 사라집니다! Rviz2 Rviz2는 ROS 2 개발 중 발생하는 수많은 로봇 데이터들을 시각화해주는 고마운 툴입니다. 다른 rqt 프로그램들은 몰라도, Rviz2의 사용법은 반드시 익혀두시기를 추천합니다.\nrviz2 예시를 위해 좀 더 갖춰진 gazebo 환경을 실행해보겠습니다. # install requirements cd du2023-ros2 ./setup_scripts.sh # package build cd ~/ros2_ws cbp src_controller \u0026amp;\u0026amp; source install/local_setup.bash cbp src_gazebo \u0026amp;\u0026amp; source install/local_setup.bash cbp src_odometry \u0026amp;\u0026amp; source install/local_setup.bash # demo env launch ros2 launch src_gazebo racecourse.launch.py ⇒ 현재는 제가 미리 준비해둔 rviz2 화면이 등장했지만, 실습을 통해 이런 rviz2 화면을 구성하고 launch file을 통해 실행하는 법까지 다루어 보겠습니다.\nRviz2의 개별 실행은 터미널에서 가능합니다. rviz2 rviz에서 view를 전환하는 방식은 gazebo와는 다르게 마우스 휠 클릭이 평행이동, 왼쪽 클릭이 회전이동입니다. 더불어, 우측 상단의 view를 통해 시점을 바꿀 수도 있습니다. ⇒ Orbit이 기본이며, 종종 TopDownOrtho도 사용됩니다.\n좌측 Displays 패널을 통해 각종 Topic, TF 데이터들을 추가, 수정, 옵션 변경할 수 있습니다. 새로운 display를 추가하기 위해서, 패널 하단 Add 버튼을 사용합니다. rviz2에서는 By display type / By Topic의 두가지 add option을 제공합니다.\nTopic type을 사용하면 rviz2가 현재 실행되고 있는 topic을 인식하여 적합한 시각화를 해주게됩니다.\nDisplay type은 원하는 시각화 타입을 먼저 선택하고, 해당 타입을 갖는 topic을 사용자가 매칭하는 방식입니다.\n시각화 시, 색상/크기/투명도 등 다양한 옵션을 바꿀 수 있습니다. ros2 launch로 rviz2 실행하기 rviz2 또한 ros2 node입니다. 그렇기에 launch file에서의 실행은 일반 node와 동일합니다.\n# Launch RViz rviz = Node( package=\u0026#39;rviz2\u0026#39;, executable=\u0026#39;rviz2\u0026#39;, name=\u0026#39;rviz2\u0026#39;, output=\u0026#39;screen\u0026#39;, ) 하지만, 이렇게 실행 시, 매번 시각화할 데이터를 선택하고, 옵션을 바꾸는 등의 수고스러움이 생깁니다. 따라서 rviz2는 설정을 저장하고 불러오는 기능을 제공합니다. (이는 rviz2 상단 패널에서도 확인 가능합니다.) save config를 통해 나만의 설정을 저장하고, launch file을 통해 실행하는 실습을 진행해봅시다. 여러분만의 rviz2 화면을 구성합니다. 해당 설정(config file)을 특정 패키지 내부에 저장하고, 위치를 기억합니다. 패키지 내 새로운 launch file을 작성하고 rviz2 node를 추가한 뒤, config file을 옵션으로 전달합니다. import os from ament_index_python.packages import get_package_share_directory from launch import LaunchDescription from launch_ros.actions import Node def generate_launch_description(): pkg_path = os.path.join(get_package_share_directory(\u0026#39;src_gazebo\u0026#39;)) rviz_config_file = os.path.join(pkg_path, \u0026#39;rviz\u0026#39;, \u0026#39;gazebo_racecourse.rviz\u0026#39;) # Launch RViz rviz = Node( package=\u0026#39;rviz2\u0026#39;, executable=\u0026#39;rviz2\u0026#39;, name=\u0026#39;rviz2\u0026#39;, output=\u0026#39;screen\u0026#39;, arguments=[\u0026#39;-d\u0026#39;, rviz_config_file] ) return LaunchDescription([ rviz ]) 참고로, 새로운 폴더가 추가되었을 시 CMakeLists.txt에 해당 폴더를 추가하여야 이후 launch file에서 접근 가능합니다. install( DIRECTORY launch meshes models config worlds rviz urdf DESTINATION share/${PROJECT_NAME}/ ) 새로운 파일, 폴더가 추가되었으므로 colcon build를 수행한 뒤, 예제를 실행합니다. # Package build again cbp src_gazebo source install/local_setup.bash # execute your launch file ros2 launch src_gazebo \u0026lt;your-launch-file\u0026gt; rqt_robot_steering rqt_robot_steering를 사용하면 움직이는 로봇을 조종하기 위해 별도의 코딩을 하지 않고도 GUI를 통한 조종이 가능합니다. # package install sudo apt install ros-foxy-rqt-robot-steering # run node rqt_robot_steering GUI의 가로 슬라이드는 angular velocity, 세로 슬라이드는 linear velocity를 뜻하며 로봇의 topic이름을 맞춰준 뒤 원하는 조종이 가능합니다. 실습을 위해 이전 husky 예시를 실행하고 rqt_robot_steering를 통해 로봇을 조종해보겠습니다. # Terminal 1 ros2 launch husky_gazebo husky_playpen.launch.py # Terminal 2 rqt_robot_steering rosbag2 rosbag은 프로그램 동작 중 발생하는 message 데이터를 기록하고 복기할 수 있게 해주는 툴입니다. 로봇 알고리즘을 개발할 때, 같은 상황에 대해 성능을 비교하는 경우, 혹은 교육 목적으로 데이터셋을 제공하는 경우 등에 매우 유용하게 사용할 수 있습니다.\nrosbag 사용법을 함께 실습해보겠습니다! 실습을 위해 gazebo 예시를 빌드하고 실행합니다. # Example package clone cd ~/ros2_ws/src git clone https://github.com/RB2023ROS/gz_ros2_examples cd ~/ros2_ws # Example package build cbp lidar_world # Run Example package ros2 launch lidar_world lidar_world.launch.py 해당 예시는 GPU Sensor를 사용하므로 일반 랩탑에서 실행 시 오류가 발생할 수 있습니다. 랩탑에서의 실행을 원하신다면 lidar_world/urdf/sensor_stick.urdf.xacro 파일에서 CPU 버전으로 토글합니다.\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;robot name=\u0026#34;sensor_stick\u0026#34; xmlns:xacro=\u0026#34;http://www.ros.org/wiki/xacro\u0026#34;\u0026gt; ... \u0026lt;!--Import gazebo elements--\u0026gt; \u0026lt;!-- \u0026lt;xacro:include filename=\u0026#34;$(find lidar_world)/urdf/sensor_stick.gazebo.xacro\u0026#34; /\u0026gt; --\u0026gt; \u0026lt;!-- \u0026lt;xacro:include filename=\u0026#34;$(find lidar_world)/urdf/sensor_stick_gpu.gazebo.xacro\u0026#34; /\u0026gt; --\u0026gt; 이런 여러 기능을 가진 시뮬레이션은 매우 느리게 동작하기 때문에 정확한 알고리즘의 검증이 불가능합니다.\nROS 개발자들은 이러한 이유로 rosbag2를 통해 환경에서의 데이터셋을 제작합니다. 실제로 컴퓨터 비전 학회나 로봇 학회에서도 본인의 테스트베드를 rosbag으로 저장한 뒤 publish하는 경우가 많습니다. 그럼 실습을 통해 rosbag2의 사용 방법을 알아봅시다. # Terminal 1 - gazebo env ros2 launch lidar_world lidar_world.launch.py # Terminal 2 - rosbag2 install \u0026amp; run sudo apt-get install ros-foxy-ros2bag ros-foxy-rosbag2* # create seperate dir for rosbag2 mkdir ~/ros2_ws/rosbag2 cd ~/ros2_ws/rosbag2 ros2 bag record -a -o lidar_world ... [INFO] [1681816765.163369771] [rosbag2_transport]: Listening for topics... [INFO] [1681816765.164494950] [rosbag2_transport]: Subscribed to topic \u0026#39;/tf_static\u0026#39; [INFO] [1681816765.165085302] [rosbag2_transport]: Subscribed to topic \u0026#39;/clicked_point\u0026#39; [INFO] [1681816765.165696583] [rosbag2_transport]: Subscribed to topic \u0026#39;/tf\u0026#39; [INFO] [1681816765.166304849] [rosbag2_transport]: Subscribed to topic \u0026#39;/goal_pose\u0026#39; ⇒ record의 종료는 ctrl + c를 사용합니다.\ninfo 옵션을 통해 저장을 마친 rosbag2의 정보를 조회할 수 있습니다. 16초 동안 약 570MB의 데이터가 저장된 것을 알 수 있습니다. $ ros2 bag info lidar_world/lidar_world_0.db3 [INFO] [1681817128.588731891] [rosbag2_storage]: Opened database \u0026#39;lidar_world/lidar_world_0.db3\u0026#39; for READ_ONLY. Files: lidar_world/lidar_world_0.db3 Bag size: 569.4 MiB Storage id: sqlite3 Duration: 16.325s Start: Apr 18 2023 20:19:25.172 (1681816765.172) End: Apr 18 2023 20:19:41.497 (1681816781.497) Messages: 1068 Topic information: Topic: /clock | Type: rosgraph_msgs/msg/Clock | Count: 173 | Serialization Format: cdr Topic: /performance_metrics | Type: gazebo_msgs/msg/PerformanceMetrics | Count: 82 | Serialization Format: cdr ... 저장 완료된 rosbag2를 다시 복기해보고 rviz2를 통해 시각화까지 해봅시다. # Terminal 1 - ros2 bag play $ ros2 bag play lidar_world/lidar_world_0.db3 [INFO] [1681817182.011798950] [rosbag2_storage]: Opened database \u0026#39;lidar_world/lidar_world_0.db3\u0026#39; for READ_ONLY. ... # Terminal 2 - rviz2 $ rviz2 ⇒ Fixed Frame을 link_1으로 변경해야 포인트들을 확인 가능합니다.\n한차례 실습을 진행해 보았는데요, 이제 각각의 커멘드 라인 옵션들을 살펴보겠습니다.\nros2 bag 키워드 Command Description record topic data를 저장합니다. info 저장된 rosbag 데이터의 정보를 조회합니다. play 저장된 rosbag 데이터를 재생합니다. ros2 bag record 옵션 Command Description -a 모든 topic data를 저장합니다. -o 저장될 rosbag의 이름을 지정합니다. -b rosbag 저장 시, 최대 사이즈를 지정하며 사이즈 초과 시 새로운 rosbag으로 저장됩니다. -d rosbag 저장 시, 최대 시간을 지정하며 사이즈 초과 시 새로운 rosbag으로 저장됩니다. 더불어, convert 기능을 통해 rosbag2를 쪼개거나 합할 수 있습니다. 자세한 사용법은 링크로 남겨두겠습니다. https://github.com/ros2/rosbag2#converting-bags\n실제 로봇 제품이 없더라도 기록된 rosbag2 데이터를 통해 알고리즘의 검증과 시연이 가능합니다. 이번 강의에서도 rosbag2 데이터를 적극 사용하고자 하니 잘 기억해주세요!\n"
},
{
	"uri": "/kr/ros2_foxy/lecture7/",
	"title": "Lecture7. ROS 2 Topic and Programming",
	"tags": [],
	"description": "",
	"content": "ROS 2 Topic and Programming 강의를 열심히 따라오면서 개념을 잊어버렸을 수 있으므로 Topic에 대해서 간단히 개념 복습을 해보겠습니다.\nTopic은 Node들 사이에 데이터(Message)가 오가는 길(Bus)의 이름이며, 적절한 이름으로 데이터를 송수신하지 않으면 원하는 동작을 수행할 수 없습니다. image from : docs.ros.org\nTopic의 중요한 특징으로 Topic은 여러 Node들로부터 데이터를 받을 수 있고, 전송 시에도 여러 Node들에게 전송이 가능한 방식입니다. image from : docs.ros.org\ntopic을 통해 데이터가 전달되는 과정은 다음과 같습니다.\n데이터를 보내는 주체인 publisher는 데이터를 받는 주체, subscriber를 지정한 뒤, topic을 통해 원하는 정보를 전달합니다. 이것을 topic publish라고 부르지요. 반대로, 데이터를 받는 주체인 subscriber 입장에선 topic을 통해 데이터를 받게 되며 이것은 topic subscribe라고 불립니다. Topic을 사용할 시 Publisher, Subscriber 사이에는 특정한 형식을 갖는 데이터, msg가 오갑니다. 원하는 데이터에 적합한 topic msg를 사용하면 더욱 효율적인 로봇 프로그래밍이 가능해집니다. image from : ethz.ch\n특정 message가 어떻게 구성되어 있는지 알고 싶을 때는 다음과 같은 커멘드 라인을 사용합니다. $ ros2 interface show geometry_msgs/msg/Twist # This expresses velocity in free space broken into its linear and angular parts. Vector3 linear Vector3 angular SRC Gazebo 이번 ROS 2 강의의 실습들은 Road Balance의 차량형 로봇 SRC를 통해 진행하고자 합니다. 실습을 진행하기 전 Gazebo 환경을 함께 세팅해보겠습니다.\nsrc_gazebo 실행 세팅 cd ~/ros2_ws/src/du2023-ros2 ./setup_scripts.sh # Package build cbp src_controller source install/local_setup.bash cbp src_gazebo source install/local_setup.bash 모든 준비가 완료되었다면 ros2 launch를 통해 이번 실습에 사용될 Gazebo 환경을 실행합니다. ros2 launch src_gazebo empty_world.launch.py 아무것도 없는 Gazebo 환경에 차량형 로봇이 등장할 것입니다. 함께 등장하는 rqt_robot_steering을 통해 로봇을 움직여보세요. ⇒ 현재 /cmd_vel topic을 사용해서 로봇을 조종하고 있는 상황입니다. 지난 시간 학습한 rqt tool들을 사용해서 시스템 분석을 진행해봅시다.\nrqt_graph를 통해 해당 topic의 publisher / subscriber 확인 topic 조회 $ ros2 topic list /clicked_point /clock /cmd_vel /dynamic_joint_states /forward_position_controller/commands /goal_pose /imu/data /initialpose /joint_states /logi_camera_sensor/camera_info /logi_camera_sensor/image_raw /parameter_events /performance_metrics /robot_description /rosout /scan /steering_angle_middle /tf /tf_static /throttling_vel_middle /velocity_controller/commands 특정 topic 정보 확인 $ ros2 topic info /forward_position_controller/commands Type: std_msgs/msg/Float64MultiArray Publisher count: 1 Subscription count: 1 ⇒ 이렇게 시스템에 대한 분석을 해두면 코딩 전 명확한 목표와 기능을 세울 수 있고, 많은 시간을 단축할 수 있습니다.\nROS 2 Topic 프로그래밍 - python example 1 - cmd_vel publish 준비된 예시를 우선 실행해봅시다. # Terminal 1 ros2 launch src_gazebo empty_world.launch.py # Terminal 2 cd ~/ros2_ws colcon build --packages-select py_topic_tutorial source install/local_setup.bash ros2 run py_topic_tutorial topic_pub_node ⇒ 로봇이 원을 그리며 움직이기 시작합니다.\n코드 분석 ROS 2에서 파이썬 프로그래밍을 하기 위해서, rclpy.node.Node를 import 해야 했습니다. 더불어, Topic에 사용되는 msg, Twist를 import하는 부분도 눈여겨봅시다. import random from geometry_msgs.msg import Twist import rclpy from rclpy.node import Node 핵심이 되는 TwistPubNode 클래스의 생성자부터 살펴보겠습니다. class TwistPubNode(Node): def __init__(self): super().__init__(\u0026#39;twist_pub_node\u0026#39;) self.get_logger().info( f\u0026#39;TwistPubNode Created at {self.get_clock().now().to_msg().sec}\u0026#39; ) # self.twist_publisher = self.create_publisher(Twist, \u0026#34;twist_topic\u0026#34;, 10) self.twist_publisher = self.create_publisher(Twist, \u0026#39;/cmd_vel\u0026#39;, 10) create_publisher는 topic publisher를 생성하는 함수로 3개의 매개변수를 받으며 각각에 대한 설명은 다음과 같습니다. Parameters Description message type Topic 통신에 사용될 msg Type topic name 사용할 Topic 이름을 지정 (이 이름을 잘못 설정하면 존재하지 않는 topic에 Publish하는 오류 상황이 발생하니 주의합니다.) queue_size topic 통신 시 대기열의 크기 이어서, timer callback에서 publish가 이루어집니다. 인스턴스화한 publisher에서 publish 함수를 사용하며 매개변수로 message가 전달됩니다. ... self.create_timer(0.2, self.timer_callback) def timer_callback(self): \u0026#34;\u0026#34;\u0026#34;Timer will run this function periodically.\u0026#34;\u0026#34;\u0026#34; msg = Twist() # Fill in msg with compatible values msg.linear.x = 0.5 msg.angular.z = 1.0 self.twist_publisher.publish(msg) example 2 - scan subscription 이번 예시는 2D 라이다 데이터를 다뤄보고자 합니다. 아래의 커멘드 라인들을 실행해주세요. # Terminal 1 $ ros2 launch src_gazebo empty_world.launch.py # Terminal 2 $ ros2 run py_topic_tutorial topic_sub_node [INFO] [1672494602.141200628] [scan_sub_node]: msg.ranges[0] : inf msg.ranges[30] : inf msg.ranges[60] : 0.7975894212722778 msg.ranges[90] : inf msg.ranges[119] : inf ... 예시를 실행시킨 상황에서 Gazebo 상의 로봇 주변으로 물체를 등장시킨 뒤, topic node를 실행하고 있는 터미널 창의 변화를 살펴봅시다. ⇒ scan data의 ranges는 사진과 같은 거리 데이터를 담고 있으며, 각 지점에 해당하는 lidar data를 터미널에 표시하는 예시였습니다.\n코드 분석 이번 예시는 2D lidar 데이터를 위해 제공되는 sensor_msgs/msg/LaserScan msg를 사용하고 있습니다. import rclpy from rclpy.node import Node from sensor_msgs.msg import LaserScan ⇒ 해당 msg에 대한 정보를 조회하는 방법, 이제는 모두 숙지하셨으리라 믿습니다.\n$ ros2 interface show sensor_msgs/msg/LaserScan ScanSubNode 클래스의 생성자에서는 scan topic의 subscriber가 생성됩니다. class ScanSubNode(Node): def __init__(self): super().__init__(\u0026#39;scan_sub_node\u0026#39;) queue_size = 10 # Queue Size self.pose_subscriber = self.create_subscription( LaserScan, \u0026#39;scan\u0026#39;, self.sub_callback, queue_size ) create_subscription은 4개의 매개변수를 필요로 합니다. 각각의 매개변수를 보면서 왜 이런 값들이 필요할지 생각해보세요. Parameters Description Message Type Topic 통신에 사용될 msg Type topic name 데이터를 Subscribe할 Topic의 이름 subscribe callback 데이터가 전달될 때마다 실행되는 callback 함수. 전달된 데이터를 통해 실행할 작업이 이 함수 안에 구현됨 queue_size create_publisher때와 마찬가지로, 대기열의 크기 더불어, sub_callback의 첫번쨰 매개변수는 항상 topic message data가 됩니다. 대부분의 구현에서는 해당 message에서 원하는 데이터를 추출한 다음, 이후의 처리를 진행합니다. def sub_callback(self, msg): \u0026#34;\u0026#34;\u0026#34;Timer will run this function periodically.\u0026#34;\u0026#34;\u0026#34; self.get_logger().info(f\u0026#39; \\ \\nmsg.ranges[0] : {msg.ranges[0]} \\ \\nmsg.ranges[30] : {msg.ranges[30]} \\ \\nmsg.ranges[60] : {msg.ranges[60]} \\ \\nmsg.ranges[90] : {msg.ranges[90]} \\ \\nmsg.ranges[119] : {msg.ranges[119]} \\ \u0026#39;) example 3 - parking 이번 예시를 실행하기 전에, empty_world.launch.py를 수정해야 합니다. gazebo_ros server의 실행 시 전달되는 환경 파일을 변경하는 작업입니다. # gazebo pkg_gazebo_ros = FindPackageShare(package=\u0026#39;gazebo_ros\u0026#39;).find(\u0026#39;gazebo_ros\u0026#39;) pkg_path = os.path.join(get_package_share_directory(\u0026#39;src_gazebo\u0026#39;)) # world_path = os.path.join(pkg_path, \u0026#39;worlds\u0026#39;, \u0026#39;empty_world.world\u0026#39;) world_path = os.path.join(pkg_path, \u0026#39;worlds\u0026#39;, \u0026#39;wall_world.world\u0026#39;) 이번 예시는 일정 거리 내 벽이 검출되면 자동으로 로봇을 정지시킵니다. # Terminal 1 $ ros2 launch src_gazebo empty_world.launch.py # Terminal 2 $ ros2 run py_topic_tutorial parking_node ... [INFO] [1672563255.067421128] [parking_node]: Distance from Front Object : 0.6280616521835327 [INFO] [1672563255.173734128] [parking_node]: Distance from Front Object : 0.5546504259109497 [INFO] [1672563255.281276729] [parking_node]: Distance from Front Object : 0.5124648809432983 [INFO] [1672563255.389067729] [parking_node]: ==== Parking Done!!! ==== ... 이 기능을 위해 Topic Publish와 Subscribe가 모두 필요합니다.\n/cmd_vel topic publish /scan topic subscribe 따라서, Node의 생성자에서 Publisher와 Subscriber를 모두 생성합니다. class ParkingNode(Node): def __init__(self): super().__init__(\u0026#39;parking_node\u0026#39;) queue_size = 10 # Queue Size self.twist_publisher = self.create_publisher(Twist, \u0026#39;cmd_vel\u0026#39;, queue_size) self.scan_subscriber = self.create_subscription( LaserScan, \u0026#39;scan\u0026#39;, self.sub_callback, queue_size ) sub_callback에서 전방 (msg.ranges[60]) 물체와의 거리를 탐지하고, 이 거리가 0.5m 이하가 될 시 정지 topic을 publish 합니다. def sub_callback(self, msg): twist_msg = Twist() distance_forward = msg.ranges[60] if distance_forward \u0026gt; 0.5: self.get_logger().info(f\u0026#39;Distance from Front Object : {distance_forward}\u0026#39;) twist_msg.linear.x = 0.5 self.twist_publisher.publish(twist_msg) else: self.get_logger().info(\u0026#39;==== Parking Done!!! ====\\n\u0026#39;) twist_msg.linear.x = 0.0 self.twist_publisher.publish(twist_msg) ROS 2 Topic Programming - C++ example 1 - cmd_vel publish 준비된 예시들을 빌드 해봅시다. cbp cpp_topic_tutorial source install/local_setup.bash # Terminal 1 ros2 launch src_gazebo empty_world.launch.py # Terminal 2 ros2 run cpp_topic_tutorial cpp_topic_pub_node ⇒ 구현 자체는 동일합니다. 로봇이 원을 그리며 움직이기 시작합니다.\n코드 분석 로봇을 움직이기 위해서 geometry_msgs/msg/Twist 형식의 topic message type을 사용해야 함을 배운 바 있습니다. 이를 위해서 다음과 같이, 헤더를 include 하면 됩니다. #include \u0026#34;geometry_msgs/msg/twist.hpp\u0026#34; #include \u0026#34;rclcpp/rclcpp.hpp\u0026#34; 단, 파이썬과 달리 c++ 헤더는 snake_case를 취하며, 코드 사용 시 CamelCase를 사용함에 주의합니다.\nImplementation Python from geometry_msgs.msg import Twist Cpp #include \u0026ldquo;geometry_msgs/msg/twist.hpp\u0026rdquo; publisher는 create_publisher 함수를 통해 생성할 수 있습니다. Implementation rclcpp::Publisher template을 통해 message type을 적습니다. topic_name publish할 topic의 이름 queue size 일전과 동일 rclcpp::Publisher\u0026lt;geometry_msgs::msg::Twist\u0026gt;::SharedPtr twist_publisher; ... twist_publisher = this-\u0026gt;create_publisher\u0026lt;geometry_msgs::msg::Twist\u0026gt;(\u0026#34;turtle1/cmd_vel\u0026#34;, 10); geometry_msgs::msg::Twist와 같이 타입이 길기 때문에 using을 사용하여 축약하곤 합니다.\nexample 2 - scan subscription 로봇 내 장착된 2D Lidar data를 적절히 표시하는 예시였습니다. # Terminal 1 $ ros2 launch src_gazebo empty_world.launch.py # Terminal 2 $ ros2 run cpp_topic_tutorial cpp_topic_sub_node [INFO] [1672494602.141200628] [scan_sub_node]: msg.ranges[0] : inf msg.ranges[30] : inf msg.ranges[60] : 0.7975894212722778 msg.ranges[90] : inf msg.ranges[119] : inf ... 코드 분석 subscriber는 create_subscription 함수를 통해 생성할 수 있습니다. Implementation rclcpp::Subscription\u0026lt;\u0026gt; template을 통해 message type을 적습니다. topic_name subscribe할 topic의 이름 queue size 일전과 동일 callback std::bind를 통해 callback 함수를 전달합니다. 예시에서는 callback 함수의 매개변수가 1개이기에 std::placeholders::_1이 사용되었습니다. LaserSubNode() : Node(\u0026#34;laser_sub_node\u0026#34;) { laser_subscriber = this-\u0026gt;create_subscription\u0026lt;LaserScan\u0026gt;( \u0026#34;scan\u0026#34;, 10, std::bind(\u0026amp;LaserSubNode::sub_callback, this, std::placeholders::_1) ); } callback 함수의 첫번째 매개변수인 데이터는 SharedPtr 타입이 사용된다는 것에 주의하며, 때문에 레퍼런스를 사용할 수 없습니다. (자주 있는 실수이므로 오류 상황도 함께 살펴보겠습니다.) void sub_callback(const LaserScan::SharedPtr msg){ RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;msg.ranges[0]: \u0026#39;%f\u0026#39;\u0026#34;, msg-\u0026gt;ranges[0]); RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;msg.ranges[30]: \u0026#39;%f\u0026#39;\u0026#34;, msg-\u0026gt;ranges[30]); RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;msg.ranges[60]: \u0026#39;%f\u0026#39;\u0026#34;, msg-\u0026gt;ranges[60]); RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;msg.ranges[90]: \u0026#39;%f\u0026#39;\u0026#34;, msg-\u0026gt;ranges[90]); RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;msg.ranges[119]: \u0026#39;%f\u0026#39;\\n\u0026#34;, msg-\u0026gt;ranges[119]); } SharedPtr은 rclcpp 내부적으로 정의되어 있는 스마트 포인터입니다. 현 상황에서 레퍼런스를 사용하기 위해서는 ConstSharedPtr을 사용하면 됩니다. void sub_callback(const LaserScan::ConstSharedPtr \u0026amp;msg){ RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;msg.ranges[0]: \u0026#39;%f\u0026#39;\u0026#34;, msg-\u0026gt;ranges[0]); RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;msg.ranges[30]: \u0026#39;%f\u0026#39;\u0026#34;, msg-\u0026gt;ranges[30]); RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;msg.ranges[60]: \u0026#39;%f\u0026#39;\u0026#34;, msg-\u0026gt;ranges[60]); RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;msg.ranges[90]: \u0026#39;%f\u0026#39;\u0026#34;, msg-\u0026gt;ranges[90]); RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;msg.ranges[119]: \u0026#39;%f\u0026#39;\\n\u0026#34;, msg-\u0026gt;ranges[119]); } example 3 - parking 일정 거리 내 벽이 검출되면 자동으로 로봇이 정지하는 예시였습니다. # Terminal 1 $ ros2 launch src_gazebo empty_world.launch.py # Terminal 2 $ ros2 run cpp_topic_tutorial cpp_parking_node ... [INFO] [1672563255.067421128] [parking_node]: Distance from Front Object : 0.6280616521835327 [INFO] [1672563255.173734128] [parking_node]: Distance from Front Object : 0.5546504259109497 [INFO] [1672563255.281276729] [parking_node]: Distance from Front Object : 0.5124648809432983 [INFO] [1672563255.389067729] [parking_node]: ==== Parking Done!!! ==== ... 이 기능을 위해 Topic Publish와 Subscribe가 모두 필요합니다. 따라서, Node의 생성자에서 Publisher와 Subscriber를 모두 생성합니다. public: ParkingNode() : Node(\u0026#34;laser_sub_node\u0026#34;) { twist_publisher = this-\u0026gt;create_publisher\u0026lt;Twist\u0026gt;(\u0026#34;cmd_vel\u0026#34;, 10); laser_subscriber = this-\u0026gt;create_subscription\u0026lt;LaserScan\u0026gt;( \u0026#34;scan\u0026#34;, 10, std::bind(\u0026amp;ParkingNode::sub_callback, this, std::placeholders::_1) ); } sub_callback에서 전방 (msg.ranges[60]) 물체와의 거리를 탐지하고, 이 거리가 0.5m 이하가 될 시 정지 topic을 publish 합니다. void sub_callback(const LaserScan::SharedPtr msg){ auto distance_forward = msg-\u0026gt;ranges[60]; if(distance_forward \u0026gt; 0.5){ auto msg = Twist(); msg.linear.x = 0.5; twist_publisher-\u0026gt;publish(msg); }else{ auto msg = Twist(); msg.linear.x = 0.0; twist_publisher-\u0026gt;publish(msg); } } rclcpp의 경우 CMakeLists.txt를 수정하여 node를 컴파일해야 했습니다. 이번 예시에서도 마찬가지 작업이 필요하며, 특히 코드에서 include 하였던 sensor_msgs geometry_msgs를 바인딩 하는 점에 유의하세요. # find_package를 통해 종속성들을 추가합니다. find_package(rclcpp REQUIRED) find_package(geometry_msgs REQUIRED) find_package(sensor_msgs REQUIRED) ... add_executable(cpp_topic_pub_node src/cpp_topic_pub_node.cpp) ament_target_dependencies(cpp_topic_pub_node rclcpp geometry_msgs) add_executable(cpp_topic_sub_node src/cpp_topic_sub_node.cpp) ament_target_dependencies(cpp_topic_sub_node rclcpp sensor_msgs) add_executable(cpp_parking_node src/cpp_parking_node.cpp) ament_target_dependencies(cpp_parking_node rclcpp sensor_msgs geometry_msgs) Custom Interface Generation Topic의 msg, Service의 srv, Action의 action… 각각 통신 메커니즘마다. 사용하는 데이터 타입은 이제 익숙해지셨으리라 생각합니다. 그리고 ROS 2 에서는 자주 사용되는 데이터 타입들을 제공하고 있습니다.\n몇가지를 함께 조회해 봅시다. ros2 interface show sensor_msgs/msg/PointCloud2 ros2 interface show geometry_msgs/msg/Quaternion ros2 interface show nav_msgs/srv/GetPlan 이렇게 미리 제공되는 데이터 타입들은 common interfaces라는 이름으로 제공되고 있습니다.\n⇒ https://github.com/ros2/common_interfaces\n그런데, 만약 나만의 새로운 데이터 타입을 만들고 싶다면 어떻게 해야 할까요? ROS 2에서는 custom interface의 생성을 제공하고 있습니다. 함께 실습해봅시다. ROS 2에서 custom interface를 만들기 위해서는 C++ Package에서 작업이 이루어져야 합니다. C++ package는 build type ament_cmake를 사용하는 package였습니다.\n$ ros2 pkg create --build-type ament_cmake \u0026lt;package-name\u0026gt; $ ros2 pkg create --build-type ament_cmake custom_interfaces 해당 패키지 내 action, msg, srv 라는 폴더를 만들고 해당 폴더 안에 나만의 인터페이스를 작성합니다. example - MyFirstMsg.msg string name float32 height float32 weight uint8 age example - TurningControl.srv uint32 time_duration float64 angular_vel_z float64 linear_vel_x --- bool success example - Parking.action #goal definition bool start_flag --- #result definition string message --- #feedback definition float32 distance custom interface 내부에는 primitive type / pre-defined type이 존재 가능합니다. ⇒ primitive type은 아래의 그림을 참고하시고\n⇒ pre-defined type은 해당 ROS 2 시스템에서 이미 정의된 (std_msgs, std_srvs, etc…)가 가능합니다.\nimage from : https://design.ros2.org/articles/interface_definition.html\n⇒ 이제 해당 interface를 rclpy, rclcpp에서 사용 가능하도록 해봅시다.\nCMakeLists.txt 수정 rosidl_generate_interfaces(${PROJECT_NAME} \u0026#34;action/DataGen.action\u0026#34; \u0026#34;action/Parking.action\u0026#34; \u0026#34;srv/CircleTurtle.srv\u0026#34; \u0026#34;srv/TurtleJail.srv\u0026#34; ) package.xml 수정 \u0026lt;build_depend\u0026gt;rosidl_default_generators\u0026lt;/build_depend\u0026gt; \u0026lt;exec_depend\u0026gt;rosidl_default_runtime\u0026lt;/exec_depend\u0026gt; \u0026lt;member_of_group\u0026gt;rosidl_interface_packages\u0026lt;/member_of_group\u0026gt; 패키지 빌드와 소싱 $ colcon build --packages-select custom_interfaces Starting \u0026gt;\u0026gt;\u0026gt; custom_interfaces Finished \u0026lt;\u0026lt;\u0026lt; custom_interfaces [0.62s] Summary: 1 package finished [0.84s] $ source install/local_setup.bash 이제 ROS 2에서 해당 인터페이스를 사용할 수 있습니다 (단, 현재 custom_interfaces 패키지는 ros2_ws에 존재하기 때문에 해당 workspace를 소싱한 터미널에서만 조회가 가능합니다. ) $ ros2 interface show custom_interfaces/srv/TurtleJail float32 width float32 height --- bool success ⇒ 그럼, custom interface의 실제 사용은 어떻게 할까요? 방금 생성한 custom_interfaces/srv/TurtleJail를예시로 살펴보겠습니다.\nrclpy from custom_interfaces.srv import TurtleJail rclcpp #include \u0026#34;custom_interfaces/srv/turtle_jail.hpp\u0026#34; using TurtleJail = custom_interfaces::srv::TurtleJail; python을 사용하는 패키지에서 별도 작업 없이 사용 가능하지만 C++ 패키지는 코딩 시 CMakeLists.txt의 수정이 필요합니다. find_package(ament_cmake REQUIRED) find_package(rclcpp REQUIRED) find_package(\u0026lt;custom-interface-pkg\u0026gt; REQUIRED) # CHANGE add_executable(talker src/publisher_member_function.cpp) ament_target_dependencies(talker rclcpp \u0026lt;custom-interface-pkg\u0026gt;) # CHANGE install(TARGETS talker DESTINATION lib/${PROJECT_NAME}) ament_package() 실제 ROS 2 호환 카메라 패키들을 보아도 필요에 따라 custom interface들을 선언한 모습을 확인 가능합니다.\nrealsense_ros "
},
{
	"uri": "/kr/ros2_foxy/lecture8/",
	"title": "Lecture8. ROS 2 Service and Programming",
	"tags": [],
	"description": "",
	"content": "ROS 2 Service ROS 2 Service의 개념을 다시 복습해봅시다.\nimage from : docs.ros.org\nService 개념 정리\nService를 요청하는 주체를 Service Client라고 하며, Service 요청 자체를 **Request(혹은 Call)**라고 합니다. Service를 요청받는 주체를 Service Server라고 하며, Service Server는 Request에 대한 응답, 즉 Service Response를 다시 Service Client에게 회답합니다. Request와 Response를 위해 사용되는 데이터 타입은 srv라고 하며 Request와 Response로 나뉩니다. Service의 중요한 특징 한 가지 추가하자면, 하나의 Service Server에 여러 Client가 request 할 수 있지만, Server는 동시에 여러 request를 처리하지 못합니다.\nimage from : docs.ros.org\nService 통신 시 srv라는 데이터 형식이 사용됩니다. 특정 srv가 어떻게 구성되어 있는지 알고 싶을 때는 ros2 interface show를 사용합니다. $ ros2 interface show gazebo_msgs/srv/SpawnEntity string name # Name of the entity to be spawned (optional). string xml # Entity XML description as a string, either URDF or SDF. string robot_namespace # Spawn robot and all ROS interfaces under this namespace geometry_msgs/Pose initial_pose # Initial entity pose. string reference_frame # initial_pose is defined relative to the frame of this entity. # If left empty or \u0026#34;world\u0026#34; or \u0026#34;map\u0026#34;, then gazebo world frame is # used. # If non-existent entity is specified, an error is returned # and the entity is not spawned. --- bool success # Return true if spawned successfully. string status_message # Comments if available. 서비스 타입 중간에 보이는 - - - 부분은 request와 response의 구분자라고 생각하시면 됩니다.\n이번 시간의 실습을 위해, 새로운 Gazebo 환경을 소개하고자 합니다. 해당 환경의 실행을 위해 아래와 같은 작업을 함께해주세요! # package clone cd ~/ros2_ws/src git clone https://github.com/RB2023ROS/gz_ros2_examples.git # package build \u0026amp; sourcing cd ~/ros2_ws cbp rgbd_world \u0026amp;\u0026amp; source install/setup.bash ros2 launch를 통해 이번 실습을 위한 환경을 실행해봅시다. ros2 launch rgbd_world depth_world.launch.py ⇒ 카메라와 벽이 포함된 간단한 환경을 구성하였습니다. 참고로 PC 성능에 따라 Rviz2 화면이 매우 느릴 수 있으니 불편하시다면 point cloud 시각화는 제거해주세요!!\nROS 2 Service Programming - Python example 1 - Service Client Example (Spawn Entity) 이번 예시의 데모를 먼저 보여드리겠습니다. # Demo package build cd ~/ros2_ws/src cbp py_service_tutorial source install/local_setup.bash # Terminal 1 - gazebo env launch ros2 launch rgbd_world depth_world.launch.py # Terminal 2 - Execute Service Client ros2 run py_service_tutorial spawn_object_wo_gravity Terminal 2에서 아래와 같은 콘솔 로그를 볼 수 있으며, 원하는 물체를 선택하면 gazebo 환경 상에서 해당 물체가 등장하는 것을 확인 가능합니다. Enter Model name Among Below List 1.arm_part\t2.beer 3.biscuits 4.book 5.bowl 6.create 7.disk_part\t8.eraser 9.glue 10.hammer 11.plastic_cup\t12.snacks 13.soap 14.soap2 15.soda_can 16.sticky_notes [Type your choice]: 예시 설명 Gazebo는 개발 초기부터 ROS의 사용을 고려한 시스템입니다. Gazebo와 ROS 사이의 인터페이스는 gazebo_ros_pkg가 담당하고 있습니다.\n⇒ https://github.com/ros-simulation/gazebo_ros_pkgs\n⇒ https://classic.gazebosim.org/tutorials?cat=connect_ros\ngazebo_ros_pkg를 통해 gazebo를 실행하면 여러 유용한 topic, service가 함께 실행됩니다. # Terminal 1 ros2 launch gazebo_ros_pkg gazebo.launch.py # Terminal 2 ros2 topic list ros2 servie list 이들 중, 지금 예시에서는 “/spawn” service에 request한 것이며, 이는 xml 문법을 통해 원하는 모델을 Gazebo Client에 등장시켜즙니다. (즉, Service Client를 실행한 것입니다.) # get info about service ros2 service type /spawn # get info about srv ros2 interface show \u0026lt;sth\u0026gt; 코드 분석 첫 번째로 분석할 코드는 spawn_object.py 입니다. 사용할 srv를 import하고 있습니다. from gazebo_msgs.srv import SpawnEntity import rclpy from rclpy.node import Node Service Client의 생성은 create_client를 사용합니다. class SpawnClientNode(Node): def __init__(self): super().__init__(\u0026#39;gazebo_model_spawner\u0026#39;) self.client = self.create_client(SpawnEntity, \u0026#39;spawn_entity\u0026#39;) Parameter Description Srv Type Service에 사용될 데이터 타입 Service Name Request 대상이 되는 Service 이름 Client 입장에서 존재하지도 않은 Server를 계속 기다리면 안될 것입니다. 이를 방지하기 위해 일반적으로 특정 시간 동안 대기하는 로직을 사용합니다. while not self.client.wait_for_service(timeout_sec=1.0): self.get_logger().error(\u0026#39;service not available, waiting again...\u0026#39;) 클래스를 더 분석하기 전에 main문을 살펴보겠습니다. Node를 생성하며, 해당 Node내부에는 Service Client가 구현되어 있습니다. send_req()를 통해 Service Call을 실행합니다. (내부적으로 call_async() 실행) 이에 따른 결과로 future라는 값이 반환됩니다. spin_until_future_complete()를 통해 future가 진행되는 동안 비동기로 대기합니다. future가 완료 상태가 되면 Response를 출력하게 됩니다. def main(args=None): rclpy.init(args=args) robot_spawn_node = SpawnClientNode() future = robot_spawn_node.send_req() rclpy.spin_until_future_complete(robot_spawn_node, future) if future.done(): try: response = future.result() except Exception: raise RuntimeError( \u0026#39;exception while calling service: %r\u0026#39; % future.exception() ) else: robot_spawn_node.get_logger().info(\u0026#39;==== Service Call Done ====\u0026#39;) robot_spawn_node.get_logger().info(f\u0026#39;Status_message : {response.status_message}\u0026#39;) finally: robot_spawn_node.get_logger().warn(\u0026#39;==== Shutting down node. ====\u0026#39;) robot_spawn_node.destroy_node() rclpy.shutdown() Future란 rclpy에서 멀티쓰레딩을 위해 사용되며, task의 상태를 담고 있는 객체입니다.\n다시 클래스로 돌아와서, send_req() 메소드를 살펴봅시다. Srv를 채우고 call_async() 함수를 통해 이를 Service Server에게 전달합니다. 그 결과로 얻게 된 future를 반환하게 됩니다. def send_req(self): ... self.get_logger().debug(\u0026#39;==== Sending service request to `/spawn_entity` ====\u0026#39;) self.future = self.client.call_async(self.req) return self.future 동기 Request인 call()도 있지만, 이렇게 되는 경우 다른 callback의 사용, 혹은 spin의 동작을 막게 되어 전체 시스템의 deadlock을 유발합니다. 때문에 공식 튜토리얼에서도 비동기 Call을 추천하고 있습니다. def send_req(self): ... self.get_logger().debug(\u0026#39;==== Sending service request to `/spawn_entity` ====\u0026#39;) self.future = self.client.call(self.req) return self.future Service Client 관련 메소드들을 정리해봅시다. Code Description create_client(, ) client 생성 spin_until_future_complete(,) Client Request Task가 완료되기까지 비동기 대기 future.done(), future.result() Future의 상태를 다루는 함수들 call_async(), call() 비동기, 동기 service call 기능상으로, 새로운 물체를 등장시키면 중력에 의해 물체가 바닥으로 떨어져버립니다. 이를 방지하기 위해 gazebo의 물성치 옵션을 꺼줘야 합니다. spawn_object_wo_gravity.py에는 이를 위한 구현이 추가되어 있습니다. self.physics_client = self.create_client(Empty, \u0026#39;pause_physics\u0026#39;) ... # physics pause request pause_future = robot_spawn_node.send_pause_req() rclpy.spin_until_future_complete(robot_spawn_node, pause_future) future_pending_logic(\u0026#34;Pause\u0026#34;,robot_spawn_node, pause_future) example 2 - Service Server Example (Snapshot) 이번에 보여드릴 ROS 2 service 예시는 Gazebo상의 카메라를 통해 사진을 찍는 Service Server입니다.\n예시 실행 - rqt를 통해 service call이 성공하면 현재 시간에 해당하는 파일이름으로 카메라가 바라보는 시야 이미지가 저장됩니다. # Terminal 1 - Execute Gazebo World ros2 launch rgbd_world depth_world.launch.py # Terminal 2 - Execute Service Server ros2 run py_service_tutorial take_picture_server # Terminal 3 - Execute rqt\u0026#39;s service caller rqt Service Caller의 사용법과 결과는 다음과 같습니다. ⇒ data 필드에 True를 전달하면 사진을 찍어 workspace에 저장해줍니다.\n코드 분석 코드를 살펴보기 전에, 이를 어떻게 구현할 수 있을지 같이 생각해봅시다.\n사진 촬영 신호를 받아 수행하는 Service Server 카메라 image data Subscriber 항상 사진을 찍는 것이 아니라 Service Call이 오는 그 순간에만 사진을 저장해야 합니다.\n⇒ 위 조건에 따라 작성한 Node의 생성자는 다음과 같습니다.\nclass PictureNode(Node): def __init__(self): super().__init__(\u0026#39;turtle_circle_server\u0026#39;) self.img_topic_name = \u0026#34;/rgb_cam/rgb_cam/image_raw\u0026#34; self.server = self.create_service( SetBool, \u0026#39;take_picture\u0026#39;, self.take_picture_callback ) self.subscriber = self.create_subscription( Image, self.img_topic_name, self.sub_callback, 10 ) self.br = CvBridge() self.is_request = False Service Server의 생성은 create_service를 사용하며 필요한 매개변수들은 아래와 같습니다. Parameter Description SetBool Srv Type \u0026rsquo;take_picture' Service Name self.take_picture_callback Request 시 실행될 Service Callback 참고로 이번에 사용하는 srv는 example_interfaces/srv/SetBool이며, Bool Type의 request와 String response를 갖고 있습니다. (ros2 interface show를 통해 조회 가능합니다.) $ ros2 interface show example_interfaces/srv/SetBool # This is an example of a service to set a boolean value. # This can be used for testing but a semantically meaningful # one should be created to be built upon. bool data # e.g. for hardware enabling / disabling --- bool success # indicate successful run of triggered service string message # informational, e.g. for error messages service call에 대한 callback, take_picture_callback()입니다. 이 callback은 request와 response 2개의 매개변수를 필요로 하는 함수로, bool type의 data가 True이면 내부 상태를 변화시킵니다. def take_picture_callback(self, request, response): if request.data is True: self.get_logger().info(\u0026#39;KimChi~\u0026#39;) self.is_request = True response.success = True response.message = \u0026#34;Successfully image written\u0026#34; return response 클래스 내부 is_request의 상태가 변화하면 subscription callback에서 이미지를 저장하는 로직이 실행됩니다. CV Bridge를 통해 ROS topic을 OpenCV 포맷으로 바꿀 수 있으며, imwrite를 통해 이미지를 저장할 수 있습니다. def sub_callback(self, data): if self.is_request: current_frame = self.br.imgmsg_to_cv2(data, \u0026#34;bgr8\u0026#34;) file_name = str(self.get_clock().now().to_msg().sec) + \u0026#39;.png\u0026#39; cv2.imwrite(file_name, current_frame) self.get_logger().info(f\u0026#39;Image saved in {file_name}\u0026#39;) self.is_request = False ROS 2 Service Programming - C++ example 1 - Service Client Example (Spawn Entity) 이번에는 동일한 코드를 C++로 구현해 봅시다. 일전 예시와 기능은 동일하므로 실행만 해보겠습니다. # Terminal 1 - gazebo env launch ros2 launch rgbd_world depth_world.launch.py # Terminal 2 - Execute Service Client ros2 run cpp_service_tutorial spawn_object_wo_gravity 코드 분석 이번에 분석할 코드는 spawn_object_wo_gravity.cpp ****입니다. include시 snake case를 사용한다는 점에 유의합니다. (저는 copilot을 통해 손쉽게 개발하고 있습니다.) #include \u0026#34;rclcpp/rclcpp.hpp\u0026#34; #include \u0026#34;std_srvs/srv/empty.hpp\u0026#34; #include \u0026#34;gazebo_msgs/srv/spawn_entity.hpp\u0026#34; Service Client의 생성은 create_client를 사용합니다. 중력을 정지키시는 service와 모델을 등장시키는 service 총 2가지를 사용합니다. class GZSpawnClient : public rclcpp::Node { private: rclcpp::Client\u0026lt;Spawn\u0026gt;::SharedPtr spawn_client; rclcpp::Client\u0026lt;Empty\u0026gt;::SharedPtr pause_client; ... public: GZSpawnClient() : Node(\u0026#34;gazebo_model_spawner\u0026#34;){ pause_client = this-\u0026gt;create_client\u0026lt;Empty\u0026gt;(\u0026#34;pause_physics\u0026#34;); spawn_client = this-\u0026gt;create_client\u0026lt;Spawn\u0026gt;(\u0026#34;spawn_entity\u0026#34;); Parameter Description template argument Service에 사용될 데이터 타입 service name Request 대상이 되는 Service 이름 python예시와 동일하게 각 Service Client 마다 특정 시간 동안 대기하는 로직을 사용합니다. while (!pause_client-\u0026gt;wait_for_service(1s)) { if (!rclcpp::ok()) { RCLCPP_ERROR(this-\u0026gt;get_logger(), \u0026#34;Interrupted while waiting for the service. Exiting.\u0026#34;); exit(0); } RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;Pause service not available, waiting again...\u0026#34;); } main문을 살펴보겠습니다. Node를 생성하며, 해당 Node내부에는 Service Client가 구현되어 있습니다. send_pause_request()를 통해 Pause Service Call을 실행합니다. (내부적으로 async_send_request() 실행) 이에 따른 결과로 future가 반환됩니다. Pause에 대한 response를 완료합니다. Spawn Service를 위해 사용자로부터 등장시킬 물체를 선택받습니다. spin_until_future_complete()를 통해 spawn future가 진행되는 동안 비동기로 대기합니다. future가 완료 상태가 되면 Response를 출력하게 됩니다. int main(int argc, char **argv) { rclcpp::init(argc, argv); auto node = std::make_shared\u0026lt;GZSpawnClient\u0026gt;(); auto pause_result = node-\u0026gt;send_pause_request(); if (rclcpp::spin_until_future_complete(node, pause_result) == rclcpp::FutureReturnCode::SUCCESS) { RCLCPP_INFO(node-\u0026gt;get_logger(), \u0026#34;Pause Successfully Done.\u0026#34;); } else { RCLCPP_ERROR(node-\u0026gt;get_logger(), \u0026#34;Failed to pause physics!\u0026#34;); } std::string model_name; ... auto spawn_result = node-\u0026gt;send_spawn_request(model_name); // Wait for the spawn_result. if (rclcpp::spin_until_future_complete(node, spawn_result) == rclcpp::FutureReturnCode::SUCCESS) { RCLCPP_INFO(node-\u0026gt;get_logger(), \u0026#34;Spawn Successfully Done.\u0026#34;); } else { RCLCPP_ERROR(node-\u0026gt;get_logger(), \u0026#34;Failed to spawn model!\u0026#34;); } rclcpp::shutdown(); return 0; } rclcpp::FutureReturnCode는 3가지 상태를 갖는 enum type입니다. Enumerator SUCCESS INTERRUPTED TIMEOUT 물성치를 정지시키는 pause service call은 딱히 추가 작업이 필요 없습니다. (Empty Call이기 때문입니다.) auto send_pause_request(){ return pause_client-\u0026gt;async_send_request(pause_request); } spawn request에서는 물체의 sdf 파일을 읽어들이고 이를 service srv 데이터 필드에 채운 뒤, 최종 service call이 이루어집니다. 물체의 이름과 번호 매칭을 위해 map 자료구조를 사용합니다. auto send_spawn_request(const std::string \u0026amp;model_name){ auto item = model_map.find(model_name); std::string model_path; ... spawn_request-\u0026gt;xml = ss.str(); ... return spawn_client-\u0026gt;async_send_request(spawn_request); } service call의 동기, 비동기 실행에 대해서는 이후 Advanced 강의에서 좀 더 자세하게 다루어 볼 예정입니다.\nService Client 관련 메소드들을 정리해봅시다. Code Description create_client() client 생성 rclcpp::spin_until_future_complete(,) Client Request Task가 완료되기까지 비동기 대기 rclcpp::FutureReturnCode Future의 상태를 담고 있는 enum type async_send_request(std::make_sharedSpawn::Request) 비동기 service call example 2 - Service Server Example (Snapshot) python 때와 마찬가지로 예시를 실행해봅시다. # Terminal 1 - Execute Gazebo World ros2 launch rgbd_world depth_world.launch.py # Terminal 2 - Execute Service Server ros2 run cpp_service_tutorial take_picture_server # Terminal 3 - Execute rqt\u0026#39;s service caller rqt Service Caller의 사용법과 결과는 다음과 같습니다. 코드 분석 지금, 우리에게 필요한 통신 메커니즘은 2가지 입니다.\n사진 촬영 신호를 받아 수행하는 Service Server 카메라 image data Subscriber 복습을 해볼 겸, 이 부분을 직접 코딩해보는 것도 좋은 학습이 될 것입니다.\nNode의 생성자는 다음과 같습니다. class PictureNode : public rclcpp::Node { private: rclcpp::Service\u0026lt;SetBool\u0026gt;::SharedPtr bool_server; rclcpp::Subscription\u0026lt;Image\u0026gt;::SharedPtr image_subscriber; ... public: PictureNode() : Node(\u0026#34;take_picture_server\u0026#34;){ image_subscriber = this-\u0026gt;create_subscription\u0026lt;Image\u0026gt;( this-\u0026gt;img_topic_name, 10, std::bind(\u0026amp;PictureNode::img_sub_callback, this, std::placeholders::_1) ); bool_server = this-\u0026gt;create_service\u0026lt;SetBool\u0026gt;( \u0026#34;take_picture\u0026#34;, std::bind(\u0026amp;PictureNode::server_callback, this, std::placeholders::_1, std::placeholders::_2) ); client service 먼저 살펴보겠습니다.\nService Server의 생성은 create_service를 사용하며 필요한 매개변수들은 아래와 같습니다. Parameter Description template argument Srv Type “take_picture” Service Name std::bind(Class, Method) Request 시 실행될 Service Callback create_service의 callback 함수는 request와 response 2개의 매개변수를 갖습니다. request를 통해 일련의 로직을 실행하고 결과를 response로 리턴하는 방식을 갖고 있습니다. void server_callback(const std::shared_ptr\u0026lt;SetBool::Request\u0026gt; request, const std::shared_ptr\u0026lt;SetBool::Response\u0026gt; response){ if (request-\u0026gt;data) { RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;KimChi~\u0026#34;); this-\u0026gt;is_request = true; } response-\u0026gt;success = true; response-\u0026gt;message = \u0026#34;Successfully image written\u0026#34;; } subscription callback에서는 이미지를 저장하는 로직이 실행됩니다. CV Bridge를 통해 ROS topic을 OpenCV 포맷으로 바꿀 수 있는데요. OpenCV와 ROS 2를 다루는 내용이 등장했는데 지금은 우선 간단하게 살펴본 뒤, 이후 강의에서 다시 한 번 자세히 다룰 예정입니다. #include \u0026lt;cv_bridge/cv_bridge.h\u0026gt; #include \u0026lt;image_transport/image_transport.hpp\u0026gt; // Using image_transport allows us to publish and subscribe to compressed image streams in ROS2 #include \u0026lt;opencv2/opencv.hpp\u0026gt; // We include everything about OpenCV as we don\u0026#39;t care much about compilation time at the moment. #include \u0026#34;rclcpp/rclcpp.hpp\u0026#34; #include \u0026#34;sensor_msgs/msg/image.hpp\u0026#34; #include \u0026#34;example_interfaces/srv/set_bool.hpp\u0026#34; ... void img_sub_callback(const Image::ConstSharedPtr msg){ if (this-\u0026gt;is_request){ cv::Mat img = cv_bridge::toCvShare(msg, \u0026#34;bgr8\u0026#34;)-\u0026gt;image; std::string file_name = std::to_string(this-\u0026gt;get_clock()-\u0026gt;now().seconds()) + \u0026#34;.jpg\u0026#34;; cv::imwrite(file_name, img); RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;Image saved as %s\u0026#34;, file_name.c_str()); this-\u0026gt;is_request = false; } } 주의할 점으로 빌드 시 OpenCV 종속성을 기입해줘야 합니다. find_package(rclcpp REQUIRED) find_package(std_srvs REQUIRED) find_package(turtlesim REQUIRED) find_package(sensor_msgs REQUIRED) find_package(gazebo_msgs REQUIRED) find_package(geometry_msgs REQUIRED) find_package(custom_interfaces REQUIRED) find_package(example_interfaces REQUIRED) find_package(OpenCV REQUIRED) find_package(cv_bridge REQUIRED) find_package(image_transport REQUIRED) add_executable(take_picture_server src/take_picture_server.cpp) ament_target_dependencies(take_picture_server rclcpp example_interfaces std_msgs sensor_msgs cv_bridge image_transport OpenCV) 참고로 저는 ROS 2를 설치할 시 기본 세팅되는 OpenCV를 사용하였습니다. "
},
{
	"uri": "/kr/ros2_foxy/lecture9/",
	"title": "Lecture9. ROS 2 Action Programming",
	"tags": [],
	"description": "",
	"content": "ROS 2 Action Programming 강의를 열심히 따라오면서 개념을 잊어버렸을 수 있으므로 Action에 대해서 간단히 개념 복습을 해보겠습니다.\nimage from : https://docs.ros.org/en/foxy/Tutorials/Understanding-ROS2-Actions.html 사진과 같이 Action Client와 Server가 주고받는 내용은 크게 5가지가 있습니다.\nClient ⇒ Server, Goal Request (service request와 유사합니다.) server ⇒ client, Goal Response client ⇒ server, Result Request server ⇒ client, Feedback (topic과 유사합니다.) server ⇒ client, Result Response 만약 4번 도중 cancel이 발생하면 Action은 종료됩니다.\n이렇게 Action은 Topic, Service의 특징을 모두 갖고 있으며 Cancel이라는 추가 기능까지 갖추고 있는 복잡한 통신 메커니즘이었습니다. 이번 예시에서는 ActionServer와 ActionClient, 그리고 과제로 별도 ActionServer까지 제시해보겠습니다.\nROS 2 Action Programming - python example 1 - Action Server (Parking Master) image from : 기호일보\nAction을 사용하는 재미있는 예시를 준비해 보았습니다. 아래 명령어를 입력해 주세요\n# Terminal 1 ros2 launch src_gazebo wall_world.launch.py # Terminal 2 cbp py_action_tutorial \u0026amp;\u0026amp; source install/local_setup.bash ros2 run py_action_tutorial parking_action_server # Terminal 3 ros2 action send_goal /src_parking custom_interfaces/action/Parking \u0026#34;start_flag: true\u0026#34; --feedback 현재 custom interface를 사용하고 있으므로 workspace를 sourcing 해야 합니다!\n예시 실행 시 벽에 인접하여 흰색 상자들이 주차 공간을 배정해줄 것입니다 ⇒ rqt_robot_steering으로 로봇을 잘 제어하여 주어진 주차 공간에 알맞게 주차를 해보세요!\n터미널 상의 Feedback을 통해 벽과의 거리를 확인할 수 있으며, 이 거리가 0.5m 이내가 되면 주차가 완료됩니다. 완료 시 좌우 공간이 얼마가 균형이 맞는지에 따라 다른 Result를 얻게 됩니다. Feedback: distance: 0.7399989366531372 Feedback: distance: 0.630066454410553 Result: message: \u0026#39;[Success!] Oh... Teach me how you did :0\u0026#39; 프로그래밍을 시작하기 전, 필요한 통신 메커니즘들을 살펴봅시다.\nAction Server : Goal을 받으면, 정면 벽과의 거리를 feedback으로 전달합니다. 최종 Result는 String으로 성공 여부를 알려줍니다.\nLaserScan Sub : 주변 물체와의 스캔된 거리를 알 수 있습니다.\n⇒ Feedback Callback과 Subscription Callback 두 Callback 함수도 구현해야 할 것입니다.\n이번 예시를 위해 custom interface를 만들어 보았습니다. (custom interface를 생성하는 방법에 대해 복습을 해볼 좋은 기회입니다. ⇒ 7강. ROS 2 Topic and Programming) $ ros2 interface show custom_interfaces/action/Parking #goal definition bool start_flag --- #result definition string message --- #feedback definition float32 distance 코드 분석 rclpy에서 Action Server를 사용하기 위해서는 ActionServer라는 별도의 패키지를 import 해야 합니다. import rclpy from rclpy.node import Node from rclpy.action import ActionServer 코드 분석 전 살펴본 바와 같이 두 종류의 핸들러가 필요합니다. class ParkingActionServer(Node): def __init__(self): super().__init__(\u0026#39;parking_action_server\u0026#39;) self.laser_sub = self.create_subscription( LaserScan, \u0026#39;scan\u0026#39;, self.sub_callback, 10 ) self.action_server = ActionServer( self, Parking, \u0026#39;src_parking\u0026#39;, goal_callback=self.goal_callback, cancel_callback=self.cancel_callback, execute_callback=self.execute_callback, ) 이제 Action의 callback 지옥을 시작해보려 하는데요, 다시 한 번 개념을 다잡고 갑시다. Description goal_callback client로부터 첫 goal request 발생 시 실행되는 cb cancel_callback feedback 도중 cancel request 발생 시 실행되는 cb execute_callback feedback 중 실행되는 cb goal_callback은 goal message를 매개변수로 가지며, ACCEPT 혹은 Reject 값을 리턴합니다. from rclpy.action import GoalResponse ... def goal_callback(self, goal_request): self.get_logger().info(\u0026#39;Received goal request.\u0026#39;) self.goal = goal_request return GoalResponse.ACCEPT cancel_callback은 goal_handle이라는 action handler object를 매개변수로 받습니다. 이 goal_handle 내부에는 여러 API들이 구현되어 있어 직접 확인해보고 넘어가고자 합니다. from rclpy.action import CancelResponse ... def cancel_callback(self, goal_handle): self.is_sub = False self.is_done = True # print(dir(goal_handle)) goal_handle.canceled() self.get_logger().info(\u0026#39;Received cancel request\u0026#39;) return CancelResponse.ACCEPT execute_callback에서 주로 실제 로직이 구현되며, 업데이트되는 환경에 따라 client에게 feedback을 전달하고, 최종 result가 발동되는 조건도 구현합니다. def execute_callback(self, goal_handle): ... feedback_msg = Parking.Feedback() while self.f_obs_distance \u0026gt; 0.5 and self.is_done == False: goal_handle.publish_feedback(feedback_msg) ... ... return result 이번 예시의 로직을 간단하게 설명해보겠습니다. 로봇이 벽에 인접하게 되어 while loop를 벗어나면 goal succed를 수행하고, Result를 리턴합니다. 완료 시 좌우 물체와의 거리가 균일할 때 성공으로 판정짓습니다.\ngoal_handle.succeed() result = Parking.Result() lr_diff = abs(self.r_obs_distance - self.l_obs_distance) if lr_diff \u0026lt; 0.15: result.message = \u0026#34;[Success!] Oh... Teach me how you did :0\u0026#34; else: result.message = \u0026#34;[Fail] Be careful, Poor Driver! \u0026#34; self.is_done = True return result 이번 예시의 main문에서 특별한 점을 찾아볼 수 있습니다. MultiThreadedExecutor를 사용하고 있는데요. 이것이 하는 역할이 무엇일지 지금은 간단하게 실습을 통해 살펴봅시다. ⇒ main 문의 주석을 토글하고, 다시 예제를 실행 시켜봅니다. 어떠한 결과를 얻으셨나요? def main(args=None): rclpy.init(args=args) # parking_action_server = ParkingActionServer() # rclpy.spin(parking_action_server) # parking_action_server.destroy_node() # rclpy.shutdown()ㅁ ... 현 예시는 여러 종류의 callback을 갖고 있습니다. 문제는 execute_callback이 실행되면서 while loop로 진입하면, 자원을 점유하여 sub_callback이 동작할 수 없는 구조가 됩니다. 이를 해결하기 위해 ROS 2에서는 Executor라는 개념을 도입합니다. (자세한 내용은 이후 살펴보겠습니다.) image from : docs.ros.org 이후 여러가지 구현을 하다 보면 지금처럼 다중 Subscribe를 해야하는 경우, 혹은 하나의 프로세스에서 여러개의 Node를 실행시켜야 하는 경우가 발생합니다. 이때, Node Composition과 MultiThreadedExecutor를 적극 사용해보세요!\nexample 2 - Action Client (Parking Master) Action 자체도 쉽지 않은 개념인데 MultiThreadedExecutor등 새로운 개념으로 많은 혼란이 있을 것 같습니다. 따라서 Action Client는 일전 Parking Example의 Client만 구현해보도록 하겠습니다.\n이전 예시에서는 콘솔 창을 통해 직접 Action Client를 실행하였습니다. ⇒ ros2 action send_goal ros2 action send_goal /src_parking custom_interfaces/action/Parking \u0026#34;start_flag: true\u0026#34; --feedback Action Client 예시는 바로 이 커멘드 라인을 코드로 호출하는 것입니다. ros2 run cpp_action_tutorial parking_status_client 코드 분석 parking_status_client.py를 참고하시면 됩니다. 파일의 처음으로 ActionClient와 action data type을 import하고 있습니다. import rclpy from rclpy.node import Node from rclpy.action import ActionClient from custom_interfaces.action import Parking 이번 예시에서도 Callback이 많아 정리부터 하고 넘어가겠습니다. Description feedback_callback Action Server로부터의 feedback cb goal_response_callback Action Server로부터의 Response cb get_result_callback Action Server로부터의 Result cb cancel_goal Action Server로 전달하는 Cancel cb goal_canceled_callback Action Server로부터의 Cancel cb 생성자에서는 Action Client 생성 외에 큰 작업은 없습니다. class ParkingActionClient(Node): def __init__(self): super().__init__(\u0026#39;parking_action_client\u0026#39;) self._action_client = ActionClient(self, Parking, \u0026#39;src_parking\u0026#39;) Description Parking Action data type \u0026lsquo;src_parking’ Action name send_goal()은 main에서 직접 호출되는 함수로, feedback_callback과 goal_response_callback을 바인딩합니다. def send_goal(self): ... self._send_goal_future = self._action_client.send_goal_async(goal_msg, feedback_callback=self.feedback_callback) self._send_goal_future.add_done_callback(self.goal_response_callback) def main(args=None): ... action_client.send_goal() goal_response_callback 완료 시, get_result_callback이 실행되며, result를 받았다는 것은 action이 완료되었다는 뜻이므로 종료 로직이 포함됩니다. def goal_response_callback(self, future): self.goal_handle = future.result() if not self.goal_handle.accepted: self.get_logger().info(\u0026#39;Goal rejected :(\u0026#39;) return self.get_logger().info(\u0026#39;Goal accepted :)\u0026#39;) self._get_result_future = self.goal_handle.get_result_async() self._get_result_future.add_done_callback(self.get_result_callback) def get_result_callback(self, future): result = future.result().result self.get_logger().info(f\u0026#39;Result: {result.message}\u0026#39;) rclpy.shutdown() cancel 로직은 feedback_callback안에 존재합니다. 피드백을 통해 받은 전방 물체와의 거리가 너무 멀어져버리면 오류로 인지하고 cancel이 이루어지는 것입니다. def feedback_callback(self, feedback_msg): ... if feedback.distance \u0026gt; 6.0: self.cancel_goal() def cancel_goal(self): self.get_logger().info(\u0026#39;Canceling goal\u0026#39;) future = self.goal_handle.cancel_goal_async() future.add_done_callback(self.goal_canceled_callback) def goal_canceled_callback(self, future): cancel_response = future.result() if len(cancel_response.goals_canceling) \u0026gt; 0: self.get_logger().info(\u0026#39;Cancelling of goal complete\u0026#39;) else: self.get_logger().warning(\u0026#39;Goal failed to cancel\u0026#39;) ⇒ 따라서 예시 실행 시 의도적으로 뒤로 가버리면 Action이 종료됩니다.\nmain문에서 send_goal을 호출하는 것을 잊지 마세요. def main(args=None): rclpy.init(args=args) action_client = ParkingActionClient() action_client.send_goal() rclpy.spin(action_client) example 3 - Action Server (Dataset Generation) 이제 Topic, Service, Action을 모두 배워보았습니다. 때문에 이를 모두 사용하는 과제를 내드리고자 합니다.\nDataset Generation # Terminal1 - gazebo env ros2 launch rgbd_world depth_world.launch.py # Terminal2 - Assignment Node ros2 run py_action_tutorial dataset_generation_server # Terminal3 - Action Call ros2 action send_goal /dataset_generation custom_interfaces/action/DataGen \u0026#34;{x: 1, z: 1, model_name: beer}\u0026#34; 선택한 물체와 위치에 따라 총 6번 spawn, capture, deletion이 반복됩니다. ⇒ 모든 작업이 완료된 후 workspace에는 다음과 같이 사진 dataset이 생성됩니다.\n💪 이 Node를 개발해보는 것이 이번 시간의 과제입니다. Hint 1. 필요한 통신 메커니즘 Description create_subscription image topic을 받아 저장해야 합니다. create_client 일전 Service Client 때처럼 물성치를 정지시키고, 원하는 위치에 물체를 등장시키고, 또 삭제하는 작업이 필요합니다. ActionServer Action을 통해 잘 진행되고 있는지 로직을 구현하고, Service들도 핸들링합니다. Hint 2. action data type 이번 예시를 위해 사용할 데이터 타입을 미리 준비해두었습니다. 하지만, 직접 여러분만의 interface를 만들어보고, 사용해보기를 추천드립니다.\n#goal definition string model_name float32 x float32 y float32 z --- #result definition string message --- #feedback definition string message Hint 3. sleep 사진이 찍히기까지 시간 여유를 주기 위해 create_rate 함수 사용을 권장합니다. (단위는 Hz)\nself.rate = self.create_rate(0.3) self.rate.sleep() ⇒ 해설은 다음 시간에 진행하도록 하겠습니다!!\nROS 2 Action Programming - C++ example 1 - Action Server (Parking Master) 바로 예시 실행은 다음과 같습니다. # Terminal 1 ros2 launch src_gazebo wall_world.launch.py # Terminal 2 ros2 run cpp_action_tutorial parking_status_server # Terminal 3 ros2 action send_goal /src_parking custom_interfaces/action/Parking \u0026#34;start_flag: true\u0026#34; --feedback 코드 분석 프로그래밍 중 타이핑을 최소화하기위해 ServerGoalHandle에 대한 키워드를 재정의하였습니다. #include \u0026#34;rclcpp/rclcpp.hpp\u0026#34; #include \u0026#34;sensor_msgs/msg/laser_scan.hpp\u0026#34; #include \u0026#34;rclcpp_action/rclcpp_action.hpp\u0026#34; #include \u0026#34;custom_interfaces/action/parking.hpp\u0026#34; using LaserScan = sensor_msgs::msg::LaserScan; using Parking = custom_interfaces::action::Parking; using GoalHandleParking = rclcpp_action::ServerGoalHandle\u0026lt;Parking\u0026gt;; 파이썬 때와 동일하게 Action Server와 Topic Subscriber가 필요합니다. public: ParkingActionServer() : Node(\u0026#34;parking_action_server\u0026#34;) { using namespace std::placeholders; m_action_server = rclcpp_action::create_server\u0026lt;Parking\u0026gt;( this, \u0026#34;src_parking\u0026#34;, std::bind(\u0026amp;ParkingActionServer::handle_goal, this, _1, _2), std::bind(\u0026amp;ParkingActionServer::handle_cancel, this, _1), std::bind(\u0026amp;ParkingActionServer::handle_accepted, this, _1) ); m_laser_sub = this-\u0026gt;create_subscription\u0026lt;LaserScan\u0026gt;( \u0026#34;scan\u0026#34;, 10, std::bind(\u0026amp;ParkingActionServer::laser_callback, this, _1) ); RCLCPP_INFO(get_logger(), \u0026#34;Action Ready...\u0026#34;); } rclcpp Action Server의 callback들은 다음과 같습니다. 파이썬과 달리 accept에 대한 callback을 갖습니다. Description handle_goal client로부터 첫 goal request 발생 시 실행되는 cb handle_cancel feedback 도중 cancel request 발생 시 실행되는 cb handle_accepted goal accept 시 실행되는 cb template argument action data type \u0026ldquo;src_parking\u0026rdquo; action name handle_goal은 goal id, goal 자체를 매개변수로 가지며, REJECT, ACCEPT_AND_EXECUTE, ACCEPT_AND_DEFER을 리턴으로 가질 수 있습니다. rclcpp_action::GoalResponse handle_goal(const rclcpp_action::GoalUUID \u0026amp;uuid, std::shared_ptr\u0026lt;const Parking::Goal\u0026gt; goal) { RCLCPP_INFO(get_logger(), \u0026#34;Got goal request with order %s\u0026#34;, goal-\u0026gt;start_flag ? \u0026#34;true\u0026#34; : \u0026#34;false\u0026#34;); (void)uuid; return rclcpp_action::GoalResponse::ACCEPT_AND_EXECUTE; } handle_cancel은 action goal handler object를 매개변수로 받습니다. 파이썬과 동일하게 이 goal_handle 내부에는 여러 API들이 구현되어 있습니다. ⇒ CancelResponse는 ACCEPT, REJECT 두종류가 가능합니다.\nrclcpp_action::CancelResponse handle_cancel(const std::shared_ptr\u0026lt;GoalHandleParking\u0026gt; goal_handle) { RCLCPP_WARN(get_logger(), \u0026#34;Got request to cancel goal\u0026#34;); (void)goal_handle; return rclcpp_action::CancelResponse::ACCEPT; } handle_accepted에서 feedback을 구현하는 execute로 연결이 됩니다. 이 부분에서 파이썬과 차이를 갖는데, 복습을 해볼 겸 비교를 해보겠습니다. void handle_accepted(const std::shared_ptr\u0026lt;GoalHandleParking\u0026gt; goal_handle) { // this needs to return quickly to avoid blocking the executor, so spin up a // new thread using namespace std::placeholders; std::thread{std::bind(\u0026amp;ParkingActionServer::execute, this, _1), goal_handle}.detach(); } class ParkingActionServer(Node): def __init__(self): super().__init__(\u0026#39;parking_action_server\u0026#39;) self.laser_sub = self.create_subscription( LaserScan, \u0026#39;scan\u0026#39;, self.sub_callback, 10 ) self.action_server = ActionServer( self, Parking, \u0026#39;src_parking\u0026#39;, goal_callback=self.goal_callback, cancel_callback=self.cancel_callback, execute_callback=self.execute_callback, ) execute의 로직은 살펴볼 바 있어 간단히 넘어가겠습니다. 다만, cancel 로직이 삽입되는 부분과 구현에 집중하시기 바랍니다. while (f_obs_distance \u0026gt; 0.5 \u0026amp;\u0026amp; is_done == false) { if (goal_handle-\u0026gt;is_canceling()) { result-\u0026gt;message = \u0026#34;Canceled\u0026#34;; goal_handle-\u0026gt;canceled(result); is_done = true; RCLCPP_WARN(get_logger(), \u0026#34;Goal Canceled\u0026#34;); return; } feedback-\u0026gt;distance = f_obs_distance; goal_handle-\u0026gt;publish_feedback(feedback); RCLCPP_INFO(get_logger(), \u0026#34;Distance from forward obstacle %f\u0026#34;, f_obs_distance); loop_rate.sleep(); } rclcpp에서 MultiThreadedExecutor를 사용하는 방법은 아래와 같습니다. add_node에 여러 node를 추가할 수 있는 것이지요. int main(int argc, char * argv[]){ rclcpp::init(argc, argv); rclcpp::executors::MultiThreadedExecutor executor; auto server_node = std::make_shared\u0026lt;ParkingActionServer\u0026gt;(); executor.add_node(server_node); executor.spin(); rclcpp::shutdown(); return 0; } example 2 - Action Client (Parking Master) cancel을 포함한 rclcpp Action Client 작성법을 알아봅시다.\nros2 run cpp_action_tutorial parking_status_client 코드 분석 Action은 자체가 쉽지 않은 개념이어 코딩 시 개념이 잡혀있지 않으면 무척 힘들어집니다. 코드 분석 전, 개요를 먼저 살펴보고 넘어갑시다.\nAction Client Logic 생성자에서 Action Client 생성 main에서 send_goal 실행 send_goal에서 여러 callback이 정의되어 있으며 상황에 따라 적절한 callback이 실행됨 goal_response_callback feedback_callback result_callback action server 때와 마찬가지로 rclcpp_action의 include와 편의를 위해 ClientGoalHandle 키워드를 다시 정의하고 있습니다. #include \u0026#34;rclcpp/rclcpp.hpp\u0026#34; #include \u0026#34;rclcpp_action/rclcpp_action.hpp\u0026#34; #include \u0026#34;custom_interfaces/action/parking.hpp\u0026#34; using namespace std::placeholders; using Parking = custom_interfaces::action::Parking; using GoalHandleParking = rclcpp_action::ClientGoalHandle\u0026lt;Parking\u0026gt;; rclcpp action client는 다음과 같이 생성합니다. (실제 callback들은 send_goal 시 Handler에 의해 바인딩됩니다.) class ParkingActionClient : public rclcpp::Node { private: rclcpp_action::Client\u0026lt;Parking\u0026gt;::SharedPtr m_action_client; public: ParkingActionClient() : Node(\u0026#34;parking_action_client\u0026#34;){ m_action_client = rclcpp_action::create_client\u0026lt;Parking\u0026gt;(this, \u0026#34;src_parking\u0026#34;); } Description Parking Action data type \u0026lsquo;src_parking’ Action name 다시금 이번 예시에서의 callback과 주요 함수를 정리해보았습니다. Description feedback_callback Action Server로부터의 feedback cb goal_response_callback Action Server로부터의 Response cb result_callback Action Server로부터의 Result cb async_cancel_all_goals Action Server로 Cancel call goal_response_callback은 GoalHandler shared_pointer의 shared_future를 매개변수로 갖습니다. 다소 복잡한데, GoalHandler 자체가 아닌 future이기 때문에 get() 함수를 통해 값을 따로 받아 처리해야 합니다. void goal_response_callback(std::shared_future\u0026lt;GoalHandleParking::SharedPtr\u0026gt; future){ auto goal_handle = future.get(); if (!goal_handle) { RCLCPP_ERROR(this-\u0026gt;get_logger(), \u0026#34;Goal was rejected by server\u0026#34;); } else { RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;Goal accepted by server, waiting for result\u0026#34;); } } feedback_callback 내부 cancel 로직에서 이전과 새로운 점을 볼 수 있습니다. 구현의 편의를 위해 async_cancel_all_goals을 사 용하였는데요, 현재 사용중인 action이 하나뿐이라 문제가 없지만 다수의 action이 존재하는 경우 async_cancel_goal 사용을 권장합니다. void feedback_callback(GoalHandleParking::SharedPtr, const std::shared_ptr\u0026lt;const Parking::Feedback\u0026gt; feedback){ RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;Received feedback: %f\u0026#34;, feedback-\u0026gt;distance); if(feedback-\u0026gt;distance \u0026gt; 6.0) m_action_client-\u0026gt;async_cancel_all_goals(); } Description async_cancel_goal(goal_handler) async_cancel_goal (typename GoalHandle::SharedPtr goal_handle, CancelCallback cancel_callback=nullptr) async_cancel_all_goals() async_cancel_all_goals (CancelCallback cancel_callback=nullptr) result_callback은 WrappedResult라는 1개의 매개변수를 갖습니다. goal result를 다루기 위한 별도의 객체이며, ResultCode라는 enum type을 갖고 있습니다. void result_callback(const GoalHandleParking::WrappedResult \u0026amp; result){ switch (result.code) { case rclcpp_action::ResultCode::SUCCEEDED: break; case rclcpp_action::ResultCode::ABORTED: RCLCPP_ERROR(this-\u0026gt;get_logger(), \u0026#34;Goal was aborted\u0026#34;); return; case rclcpp_action::ResultCode::CANCELED: RCLCPP_ERROR(this-\u0026gt;get_logger(), \u0026#34;Goal was canceled\u0026#34;); return; default: RCLCPP_ERROR(this-\u0026gt;get_logger(), \u0026#34;Unknown result code\u0026#34;); return; } RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;Result received: %s\u0026#34;, result.result-\u0026gt;message.c_str()); rclcpp::shutdown(); } Enumerator UNKNOWN SUCCEEDED CANCELED ABORTED 이번 예시에서도 main문에서 send_goal을 호출하는 것을 잊지 마세요.\n"
},
{
	"uri": "/kr/ros2_foxy/lecture10/",
	"title": "Lecture10. TF and ROS 2",
	"tags": [],
	"description": "",
	"content": "Introduction to tf2 대부분의 로보틱스 과정들에서 가장 먼저 다루는 것이 바로 좌표계 변환 - Transformation입니다. 로봇은 수많은 joint와 link로 이루어져 있으며, 센서와 움직임을 다루기 때문에 좌표계를 다루는 일이 매우 빈번합니다.\nROS 2에서는 TF2라는 특수한 형태로 이 좌표계와 시간을 함께 다루고 있습니다. 예시와 설명을 통해 ROS 2의 TF2에 대해 배워봅시다 😊\nimage from : eth robot dynamics lecture notes Husky Again 일전 husky 예시를 통해 tf2에 대한 개요을 파악해보고자 합니다.\n# Terminal 1 - husky gazebo ros2 launch husky_gazebo husky_playpen.launch.py # Terminal 2 - rviz rviz2 ⇒ rviz에서 보이는 세가지 색상의 막대가 바로 tf2 입니다. x,y,z의 각 축을 각기 다른 색으로 표현하였으며, 연관된 좌표계끼리는 노란 선을 통해 연결한 모습이 보입니다.\nrviz2 화면에서 fixed frame을 변경해보면, 모든 데이터, 좌표들의 원점이 바뀌는 것을 볼 수 있습니다. ⇒ 이렇게 좌표변환에 따른 데이터 시각화가 가능하려면 모든 좌표계들 사이의 회전, 평행 이동 변환 정보를 알고 있어야 할 것입니다. ROS 2에서 이를 어떻게 다룰 수 있는지 또 하나의 예시를 살펴보겠습니다.\nTF2 Tree tf2 view frame - 이전 husky는 실행 상태로 유지합니다. # Terminal1 - husky gazebo ros2 launch husky_gazebo husky_playpen.launch.py # Terminal2 - tf2 view frame cd ~/ros2_ws ros2 run tf2_tools view_frames.py 약 5초간 대기 후, 폴더를 조회해보면 아래와 같은 tree 사진이 저장된 것을 확인할 수 있습니다. tree를 확대해서 살펴봅시다.\n모든 node들끼리는 하나의 연결 상태를 갖습니다. rviz2의 fixed frame에서는 바로 이 node를 선택했던 것입니다. 해당 연결을 담당하는 Broadcaster 정보, 평균 rate, buffer length 등의 정보를 확인 가능합니다. 만약 tf tree가 온전히 연결되어 있지 않다면 어떤 일이 발생할까요?\n⇒ tf2간 연결이 끊어지게 되면, 끊어진 아래 시점에 대해서는 그 어떠한 정보도 알 수 없습니다. 따라서 rviz2에서의 시각화나, SLAM, 자율주행 시 이는 큰 문제가 됩니다.\n더불어, tf2가 제대로 연결되어 있더라고 정확한 시간과 정확한 좌표 변환을 갖는 것이 매우 중요합니다. 예를 들어, 라이다의 tf를 180도 반대로 설정해버리면 후방에 있는 장애물을 전방 장애물로 잘못 인식할 수 있습니다. image from : answers.ros.org\n때문에 sensor topic message들은 공통적으로 tf2 정보를 포함하고 있습니다. $ ros2 interface show sensor_msgs/msg/PointCloud2 **std_msgs/Header header** uint32 height uint32 width sensor_msgs/PointField[] fields bool is_bigendian uint32 point_step uint32 row_step uint8[] data bool is_dense $ ros2 interface show std_msgs/msg/Header uint32 seq time stamp string frame_id ⇒ frame_id와 stamp이 바로 tf2와 관련된 데이터로 이렇게 센서 데이터들은 대부분 좌표와 시간에 대한 정보를 포함하게 됩니다.\n이번 시간에는 크게 3가지 예시를 통해 tf2에 대해 학습할 예정입니다.\nstatic transform ⇒ 움직이지 않는 좌표계 tf2 broadcast ⇒ tf2 데이터의 송신 tf2 listen ⇒ tf2 데이터의 수신 topic publish를 하는데 왜 또 tf2 boradcast가 필요할까요?\n⇒ 바로 위 예시처럼 topic에 담긴 정보는 실제 좌표변환이 아닌, frame id입니다. 이는 topic data를 받은 subscriber node 입장에서 센서 데이터를 다루는 상황을 생각해보면 이해하기 쉽습니다.\ntopic sub sub msg내 frame id 확인 tf2 데이터에서 해당 frame의 변환 listen 이후 로직 구현 그럼, 예시와 코드를 통해 tf2를 마스터해봅시다!\nstatic broadcaster Orbit World tf2의 학습을 위해 gazebo 환경을 만들어 두었습니다. 함께 실행해봅시다.\ncd ~/ros2_ws cbp tf2_world \u0026amp;\u0026amp; source install/local_setup.bash ros2 launch tf2_world tf2_world.launch.py 마치 행성과 위성 같은 환경을 볼 수 있습니다.\n현 상황에서 tf2 tree를 조회해봅시다. ros2 run tf2_tools view_frames.py tf2 데이터는 아무것도 없지요? 이번 시간의 목표는 우리가 직접 코딩과 launch file을 통해 tree를 구성해 보는 것입니다.\nlaunch file 실행 터미널을 자세히 살펴보면, 아래와 같은 문구를 볼 수 있습니다. [gzserver-1] [INFO] [1681981785.437867364] [gazebo_ros_state]: Publishing states of gazebo models at [/model_states] [gzserver-1] [INFO] [1681981785.438120429] [gazebo_ros_state]: Publishing states of gazebo links at [/link_states] 현 gazebo 환경에서의 존재하는 모든 모델의 state를 /model_state topic을 통해 알 수 있습니다. topic monitor를 통해 살펴봅시다. static transform publisher image from : theegeek 움직이지 않는 static object의 tf2 데이터는 static transform publisher가 담당합니다. 덕분에 우리는 굳이 코딩을 하지 않아도 미리 준비된 node를 실행하기만 하면 됩니다.\nlaunch file을 통해 static transform publisher를 사용해봅시다. static_transform_publisher = Node( package = \u0026#34;tf2_ros\u0026#34;, executable = \u0026#34;static_transform_publisher\u0026#34;, arguments = [\u0026#34;0\u0026#34;, \u0026#34;0\u0026#34;, \u0026#34;0.5\u0026#34;, \u0026#34;0\u0026#34;, \u0026#34;0\u0026#34;, \u0026#34;0\u0026#34;, \u0026#34;world\u0026#34;, \u0026#34;unit_sphere\u0026#34;], ) return LaunchDescription( [ static_transform_publisher, ] ) arguments에 들어가는 매개변수들은 순서대로 (x y z roll pitch yaw parent_frame child_frame)이 됩니다. ⇒ world frame 기준 unit_sphere frame를 z축으로 0.5만큼 떨어뜨려 tf2 data가 생성됩니다.\n로봇 개발자들은 암묵적으로 모든 상황의 원점이 되는 절대 좌표계를 world frame이라고 정합니다.\n다시 한 번 tf2 tree를 살펴봅시다 ros2 run tf2_tools view_frames.py ⇒ world to unit_sphere tf가 성공적으로 생성되었습니다!\n이제 rviz2 화면을 통해서도 tf2를 시각화 할 수 있습니다. 움직이지 않는 물체 뿐만 아니라, 로봇 내부에서 고정된 부분에서도 static_transform_publisher를 사용할 수 있습니다. 자주 탈부착되는 센서 frame이 대표적인 예시입니다.\nimage from : articulatedrobotics TF2 Broadcaster \u0026amp; Lisenter \u0026amp; Add frame 지난 강의에서 고정된 물체에 대한 tf2 데이터를 다루는 방법을 알아보았습니다. 이번 시간부터 tf2를 다루는 코드를 작성해 보겠으며, 최종적으로 아래와 같은 시스템을 만들어보겠습니다.\nTF2 Python Programming TF2 Broadcaster (Python) topic에서는 publish/subscribe라는 용어를 사용하였지만 tf2에서는 broadcast/listen이라는 용어를 사용합니다. topic과 tf2는 완전 별개의 개념입니다! 혼란되지 않도록 주의하세요.\n우선, 예시를 실행해봅시다. # Terminal1 - gazebo ros2 launch tf2_world tf2_world.launch.py # Terminal2 - tf2 broadcaster cbp py_tf2_tutorial \u0026amp;\u0026amp; source install/local_setup.bash ros2 run py_tf2_tutorial tf2_broadcaster rviz2를 통해 움직이는 구의 tf2를 확인할 수 있습니다. 이를 구현하는 것이 이번 예제의 목표입니다. 코드 분석 이전 강의에서 gazebo 내 모든 물체들의 정보를 담은 /model_state topic을 살펴본 바 있습니다. 이를 코드 구현에 사용하기 위해 정보를 조회해봅시다. $ ros2 interface show gazebo_msgs/msg/ModelStates # broadcast all model states in world frame string[] name # model names geometry_msgs/Pose[] pose # desired pose in world frame geometry_msgs/Twist[] twist # desired twist in world frame ⇒ 이 모양을 기억하면서 코드로 진입해보겠습니다.\n더불어, tf2의 데이터 타입은 geometry_msgs/msg/TransformStamped 입니다. ⇒ link $ ros2 interface show geometry_msgs/msg/TransformStamped # This expresses a transform from coordinate frame header.frame_id # to the coordinate frame child_frame_id # # This message is mostly used by the # tf package. # See its documentation for more information. Header header string child_frame_id # the frame id of the child frame Transform transform 코드로 돌아와 import 부분입니다. tf2 데이터를 다루기 위한 패키지인 tf2_ros, ModelStates 데이터 타입을 import합니다. import rclpy from rclpy.node import Node from tf2_ros import TransformBroadcaster from gazebo_msgs.msg import ModelStates from geometry_msgs.msg import TransformStamped 우리의 목표를 정리해봅시다. model_state topic에서 움직이는 물체의 정보를 조회합니다. 해당 데이터를 정제하여 TF2의 형태로 변형한 뒤 broadcast 합니다. ⇒ 따라서 topic sub과 tf2 broadcast가 필요한 상황입니다.\nclass OrbitBroadcaster(Node): def __init__(self): super().__init__(\u0026#39;tf2_frame_broadcaster\u0026#39;) # Initialize the transform broadcaster self.tf_broadcaster = TransformBroadcaster(self) # Subscribe to a turtle{1}{2}/pose topic and call handle_turtle_pose # callback function on each message self.m_model_state_sub = self.create_subscription( ModelStates, \u0026#34;model_states\u0026#34;, self.handle_turtle_pose, 1 ) 코드의 핵심은 sub callback에 담겨 있습니다. model_state msg중 우리가 원하는 animated_sphere의 정보를 파싱하여 TransformStamped msg에 집어넣은 뒤, broadcast 합니다. def handle_turtle_pose(self, msg): index = [i for i in range(len(msg.name)) if msg.name[i] == \u0026#34;animated_sphere\u0026#34;][0] t = TransformStamped() # Read message content and assign it to # corresponding tf variables t.header.stamp = self.get_clock().now().to_msg() t.header.frame_id = \u0026#39;world\u0026#39; t.child_frame_id = \u0026#39;animated_sphere\u0026#39; t.transform.translation.x = msg.pose[index].position.x t.transform.translation.y = msg.pose[index].position.y t.transform.translation.z = msg.pose[index].position.z t.transform.rotation.x = msg.pose[index].orientation.x t.transform.rotation.y = msg.pose[index].orientation.y t.transform.rotation.z = msg.pose[index].orientation.z t.transform.rotation.w = msg.pose[index].orientation.w # Send the transformation self.tf_broadcaster.sendTransform(t) tf2 broadcastt를 위한 API를 정리하고 넘어갑시다. 다시 한 번 말하지만 topic과 헷갈리면 안됩니다! Description TransformBroadcaster() broadcaster 생성 TransformStamped() tf2 msg 생성 sendTransform(msg) tf2 broadcast TF2 Listener [Python] rqt_monitor를 통해 model_state topic을 조회한 결과입니다. pose는 잘 보이는데, 속도 데이터인 twist는 비어있는 모습을 볼 수 있습니다. ⇒ TF2 Listener를 사용하여 이를 구현해봅시다!\n예시 실행 ⇒ 선속도와 각속도를 콘솔에서 확인할 수 있습니다. # Terminal1 - gazebo $ ros2 launch tf2_world tf2_world.launch.py # Terminal2 - tf2 broadcaster $ ros2 run py_tf2_tutorial tf2_broadcast # Terminal3 - tf2 listener $ ros2 run py_tf2_tutorial tf2_listener [INFO] [1681998128.822169076] [tf2_frame_listener]: linear vel : 2.542703, angular vel : 1.810120 [INFO] [1681998128.922124745] [tf2_frame_listener]: linear vel : 2.501199, angular vel : 1.610775 ... 코드의 import 부분입니다. tf2 listen을 위해 TransformListener와 Buffer를 import하고 있습니다. import math from geometry_msgs.msg import Twist import rclpy from rclpy.node import Node from tf2_ros import TransformException from tf2_ros.buffer import Buffer from tf2_ros.transform_listener import TransformListener 현재 우리가 구현해야 하는 작업은 다음과 같습니다. tf2 데이터 listen ⇒ 이를 통해 움직이는 물체의 좌표 변화를 감지합니다. 속도 계산 ⇒ 위치를 통해 선속도와 각속도를 계산합니다. topic publish class TF2Listener(Node): def __init__(self): super().__init__(\u0026#39;tf2_frame_listener\u0026#39;) self.tf_buffer = Buffer() self.tf_listener = TransformListener(self.tf_buffer, self) # Create turtle2 velocity publisher self.publisher = self.create_publisher(Twist, \u0026#39;sphere_vel\u0026#39;, 10) # Call timer_cb function every 10 seconds self.timer = self.create_timer(0.1, self.timer_cb) ⇒ TransformListener의 생성 이후, 모든 tf2의 listen을 시작하면 이를 Buffer에 담아두는 식입니다.\n⇒ 주기적으로 listen, publish를 위해 timer를 사용합니다.\n다음으로, timer_cb 함수를 뜯어봅시다.\ntf2 listen을 위해 lookup_transform이라는 함수를 사용하며 3개의 매개변수를 필요로 합니다. Target frame Source frame time from_frame_rel = \u0026#39;animated_sphere\u0026#39; to_frame_rel = \u0026#39;world\u0026#39; try: t = self.tf_buffer.lookup_transform( from_frame_rel, to_frame_rel, rclpy.time.Time()) except TransformException as ex: self.get_logger().info( f\u0026#39;Could not transform {to_frame_rel} to {from_frame_rel}: {ex}\u0026#39;) return tf2 데이터에서 우리가 원하는 속도를 계산하기 위해 간단한 연산을 추가하였습니다. msg = Twist() scale_rotation_rate = 1.0 msg.angular.z = scale_rotation_rate * math.atan2( t.transform.translation.y, t.transform.translation.x) scale_forward_speed = 0.5 msg.linear.x = scale_forward_speed * math.sqrt( t.transform.translation.x ** 2 + t.transform.translation.y ** 2) 최종 완성된 Twist msg를 publish 합니다. self.get_logger().info(f\u0026#34;linear_vel: {msg.linear.x}, angular_vel: {msg.angular.z}\u0026#34;) self.publisher.publish(msg) ⇒ 현재 예시이므로 정확한 3차원 속도를 계산하지는 않았지만, gazebo의 model_state 데이터에 기반하여 환경의 ground_truth로 사용할 수 있습니다.\nTF2 Add Frame (Python) tf2 구현의 마지막 예시입니다. # Terminal1 - gazebo $ ros2 launch tf2_world tf2_world.launch.py # Terminal2 - tf2 broadcaster $ ros2 run py_tf2_tutorial tf2_broadcast # Terminal3 - tf2 add frame $ ros2 run py_tf2_tutorial tf2_add_frame animated_sphere의 주위를 위성처럼 궤도 운동하는 새로운 frame이 보입니다. ⇒ 이번 예시는 새로운 dynamic frame을 추가하는 것입니다. 일전 정적 frame은 일전 launch file에서 static_transform_publisher를 사용하였지요? dynamics frame은 코드로 구현해보겠습니다.\ntf2 데이터를 broadcast해야 하는 것은 일전 예시와 동일합니다. 따라서 import와 생성자 부분에 대한 설명은 생략하겠습니다. import rclpy import numpy as np from rclpy.node import Node from tf2_ros import TransformBroadcaster from geometry_msgs.msg import TransformStamped class InverOrbitFrame(Node): def __init__(self): super().__init__(\u0026#39;inverse_orbit_frame_tf2_broadcaster\u0026#39;) self.count = 0 self.freq_factor = 2* np.pi / 20; self.tf_broadcaster = TransformBroadcaster(self) self.timer = self.create_timer(0.1, self.broadcast_timer_callback) timer에 의해 반복 실행되는 callback 함수를 살펴봅시다. ⇒ animated_sphere을 기준으로 원 운동을 하는 새로운 frame을 만드는 것이 목표입니다. 따라서 (cos(theta), sin(theta))의 좌표를 갖는 tf2 data를 구축하고 이를 시간에 따라 broadcast 하였습니다.\ndef broadcast_timer_callback(self): t = TransformStamped() t.header.stamp = self.get_clock().now().to_msg() t.header.frame_id = \u0026#39;animated_sphere\u0026#39; t.child_frame_id = \u0026#39;inverse_orbit_frame\u0026#39; t.transform.translation.x = np.cos(-self.count * self.freq_factor) t.transform.translation.y = np.sin(-self.count * self.freq_factor) t.transform.translation.z = 0.5 t.transform.rotation.x = 0.0 t.transform.rotation.y = 0.0 t.transform.rotation.z = 0.0 t.transform.rotation.w = 1.0 self.tf_broadcaster.sendTransform(t) self.count += 1 if self.count \u0026gt;= 20: self.count = 0 TF2 C++ Programming TF2 Broadcaster (C++) 실제 개발에서 tf2 데이터는 실시간성이 무척 중요한 좌표변환을 다루므로, c++ 코드를 사용하는 비중이 더 큽니다. 따라서, 우선 모든 예시를 살펴보고 센서 패키지에 기반하여 실 사용 사례도 확인해보겠습니다.\n예시를 실행해봅시다. # Terminal1 - gazebo ros2 launch tf2_world tf2_world.launch.py # Terminal2 - tf2 broadcaster ros2 run cpp_tf2_tutorial tf2_broadcaster rviz2를 통해 움직이는 구의 tf2를 확인할 수 있습니다. 코드 분석 코드로 돌아와 include 부분입니다. tf2 데이터를 다루기 위한 패키지인 tf2_ros, ModelStates 데이터 타입을 import합니다. #include \u0026#34;rclcpp/rclcpp.hpp\u0026#34; #include \u0026#34;tf2/LinearMath/Quaternion.h\u0026#34; #include \u0026#34;tf2_ros/transform_broadcaster.h\u0026#34; #include \u0026#34;gazebo_msgs/msg/model_states.hpp\u0026#34; #include \u0026#34;geometry_msgs/msg/transform_stamped.hpp\u0026#34; tf_broadcaster를 초기화하는 코드 API에서 unique_ptr이 사용됩니다. 개발자의 실수로 tf2_broadcaster가 여러개 생길 시 이를 디버깅하기 힘들어 사전에 방지한 경우입니다. class OrbitBroadcaster : public rclcpp::Node { private: rclcpp::Subscription\u0026lt;ModelStates\u0026gt;::SharedPtr m_model_state_sub; std::unique_ptr\u0026lt;tf2_ros::TransformBroadcaster\u0026gt; m_tf_broadcaster; public: OrbitBroadcaster() : Node(\u0026#34;tf2_frame_broadcaster\u0026#34;){ m_model_state_sub = this-\u0026gt;create_subscription\u0026lt;ModelStates\u0026gt;( \u0026#34;model_states\u0026#34;, 10, std::bind(\u0026amp;OrbitBroadcaster::model_state_sub_cb, this, std::placeholders::_1) ); // Initialize the transform broadcaster m_tf_broadcaster = std::make_unique\u0026lt;tf2_ros::TransformBroadcaster\u0026gt;(*this); } model_states 타입은 3개의 std::vector로 구성됩니다. 따라서 우리가 원하는 값, animated_sphere의 index를 먼저 알아낸 뒤, pose 데이터를 파싱합니다. private: void model_state_sub_cb(const ModelStates::ConstSharedPtr msg) { geometry_msgs::msg::TransformStamped t; std::string model_name = \u0026#34;animated_sphere\u0026#34;; auto it = find(msg-\u0026gt;name.begin(), msg-\u0026gt;name.end(), model_name); auto index = it - msg-\u0026gt;name.begin(); 이번 코드에서 다루지는 않지만, tf2는 기본적으로 오일러 각도 체계가 아닌 쿼터니언을 사용합니다. 오일러 각도 ⇒ 쿼터니언의 변환과 같은 API는 tf2 패키지에 구현되어 있습니다. #include \u0026#34;tf2/LinearMath/Quaternion.h\u0026#34; // tf2::Quaternion q; // q.setRPY(0, 0, msg-\u0026gt;theta); t.transform.rotation.x = msg-\u0026gt;pose[index].orientation.x; t.transform.rotation.y = msg-\u0026gt;pose[index].orientation.y; t.transform.rotation.z = msg-\u0026gt;pose[index].orientation.z; t.transform.rotation.w = msg-\u0026gt;pose[index].orientation.w; // Send the transformation m_tf_broadcaster-\u0026gt;sendTransform(t); } cpp 코드인만큼 CMakeLists.txt도 살펴보겠습니다. find_package(tf2 REQUIRED) find_package(tf2_ros REQUIRED) find_package(gazebo_msgs REQUIRED) find_package(geometry_msgs REQUIRED) add_executable(tf2_broadcast src/tf2_broadcast.cpp) ament_target_dependencies(tf2_broadcast tf2 tf2_ros gazebo_msgs geometry_msgs) tf2 broadcast를 위한 API를 정리하고 넘어갑시다. Description std::make_unique\u0026lt;tf2_ros::TransformBroadcaster\u0026gt; broadcaster 생성 geometry_msgs::msg::TransformStamped tf2 msg 생성 tf_broadcaster-\u0026gt;sendTransform(t) tf2 broadcast TF2 Listener (C++) animated_sphere의 tf2 listen을 통해 속도 topic을 publish하는 예시였습니다. # Terminal1 - gazebo $ ros2 launch tf2_world tf2_world.launch.py # Terminal2 - tf2 broadcaster $ ros2 run py_tf2_tutorial tf2_broadcast # Terminal3 - tf2 listener $ ros2 run py_tf2_tutorial tf2_listener [INFO] [1681998128.822169076] [tf2_frame_listener]: linear vel : 2.542703, angular vel : 1.810120 [INFO] [1681998128.922124745] [tf2_frame_listener]: linear vel : 2.501199, angular vel : 1.610775 ... 코드의 include 부분입니다. tf2 listen을 위해 tf2_ros/transform_listener.h를 사용합니다. #include \u0026#34;rclcpp/rclcpp.hpp\u0026#34; #include \u0026#34;tf2/exceptions.h\u0026#34; #include \u0026#34;tf2_ros/transform_listener.h\u0026#34; #include \u0026#34;tf2_ros/buffer.h\u0026#34; #include \u0026#34;geometry_msgs/msg/twist.hpp\u0026#34; #include \u0026#34;geometry_msgs/msg/transform_stamped.hpp\u0026#34; using namespace std::chrono_literals; using Twist = geometry_msgs::msg::Twist; using TransformStamped = geometry_msgs::msg::TransformStamped; listener의 생성 시 Buffer가 필요한 부분도 동일하며, 대신, buffer가 unique_ptr 타입을 취하고 있어 pointer가 아닌 value를 전달함에 유의합니다. public: TF2Listener(): Node(\u0026#34;tf2_frame_listener\u0026#34;){ m_tf_buffer = std::make_unique\u0026lt;tf2_ros::Buffer\u0026gt;(this-\u0026gt;get_clock()); m_tf_listener = std::make_shared\u0026lt;tf2_ros::TransformListener\u0026gt;(*m_tf_buffer); python과 동일하게 lookupTransform은 3가지 매개변수를 필요로 합니다. Target frame Source frame time void timer_cb(){ // Store frame names in variables that will be used to // compute transformations TransformStamped t; try { t = m_tf_buffer-\u0026gt;lookupTransform( \u0026#34;animated_sphere\u0026#34;, \u0026#34;world\u0026#34;, tf2::TimePointZero ); TF2 Add Frame (C++) tf2 구현의 마지막 예시입니다. # Terminal1 - gazebo $ ros2 launch tf2_world tf2_world.launch.py # Terminal2 - tf2 broadcaster $ ros2 run cpp_tf2_tutorial tf2_broadcast # Terminal3 - tf2 add frame $ ros2 run cpp_tf2_tutorial tf2_add_frame ⇒ tf2 broadcaster와 큰 차이가 없으므로, 구체적인 설명은 생략하겠습니다.\nTF2 Example 이번 시간에는 실제 센서 데이터 ROS 2 패키지에서 tf2가 사용된 모습을 확인해보겠습니다.\n두 센서 패키지를 참고해보려 합니다.\nintel realsense ros2 package my ahrs imu package 우선, my ahrs 코드입니다. publishtf라는 매개변수에 따라 tf2 데이터의 broadcast 여부가 달라집니다. 이렇게 해둔 이유는, 센서 자체를 통한 개발 시에는 tf2의 사용이 필요 없기 때문입니다. // publish tf if (publish_tf_) { geometry_msgs::msg::TransformStamped tf; tf.header.stamp = now; tf.header.frame_id = parent_frame_id_; tf.child_frame_id = frame_id_; tf.transform.translation.x = 0.0; tf.transform.translation.y = 0.0; tf.transform.translation.z = 0.0; tf.transform.rotation = imu_data_msg.orientation; broadcaster_-\u0026gt;sendTransform(tf); } ⇒ link1\n다음으로, realsense-ros 패키지입니다. 이번에도 마찬가지로, 상황에 따라 statics tf / odom tf를 구별하여 구현해둔 모습을 볼 수 있습니다. void BaseRealSenseNode::publish_static_tf(const rclcpp::Time\u0026amp; t, const float3\u0026amp; trans, const tf2::Quaternion\u0026amp; q, const std::string\u0026amp; from, const std::string\u0026amp; to) { geometry_msgs::msg::TransformStamped msg; msg.header.stamp = t; msg.header.frame_id = from; msg.child_frame_id = to; // Convert x,y,z (taken from camera extrinsics) // from optical cooridnates to ros coordinates msg.transform.translation.x = trans.z; msg.transform.translation.y = -trans.x; msg.transform.translation.z = -trans.y; msg.transform.rotation.x = q.getX(); msg.transform.rotation.y = q.getY(); msg.transform.rotation.z = q.getZ(); msg.transform.rotation.w = q.getW(); _static_tf_msgs.push_back(msg); } void BaseRealSenseNode::publishStaticTransforms(std::vector\u0026lt;rs2::stream_profile\u0026gt; profiles) { // Publish static transforms if (_publish_tf) { for (auto \u0026amp;profile : profiles) { calcAndPublishStaticTransform(profile, _base_profile); } if (_static_tf_broadcaster) _static_tf_broadcaster-\u0026gt;sendTransform(_static_tf_msgs); } } ... void BaseRealSenseNode::pose_callback(rs2::frame frame) { ... geometry_msgs::msg::PoseStamped pose_msg; pose_msg.pose.position.x = -pose.translation.z; ... static tf2_ros::TransformBroadcaster br(_node); geometry_msgs::msg::TransformStamped msg; msg.header.stamp = t; msg.header.frame_id = DEFAULT_ODOM_FRAME_ID; msg.child_frame_id = FRAME_ID(POSE); msg.transform.translation.x = pose_msg.pose.position.x; msg.transform.translation.y = pose_msg.pose.position.y; msg.transform.translation.z = pose_msg.pose.position.z; msg.transform.rotation.x = pose_msg.pose.orientation.x; msg.transform.rotation.y = pose_msg.pose.orientation.y; msg.transform.rotation.z = pose_msg.pose.orientation.z; msg.transform.rotation.w = pose_msg.pose.orientation.w; if (_publish_odom_tf) br.sendTransform(msg); ⇒ 참고 링크 1\n⇒ 참고 링크 2\n"
},
{
	"uri": "/kr/ros2_foxy/lecture11/",
	"title": "Lecture11. About Gazebo - 1",
	"tags": [],
	"description": "",
	"content": "URDF와 Robot Description 로봇에 센서를 부착하고, 외형을 정의하기 위해 가장 기본이 되는 것이 바로 URDF입니다. 이번 시간, 실습을 통해 URDF에 대한 개념과 robot desciption을 실습해 보겠습니다.\n일반적으로, 로봇은 Links와 Joints 두가지 요소로 이루어집니다. Description Link 단단하게 고정된 강체(rigid-body)이며, 사람의 골격에 해당합니다. Joint link 사이를 결합해주고 이들 사이 운동을 결정짓습니다. 사람의 관절에 해당합니다. 다양한 종류의 joint들이 존재하지만, 이론적으로 이들은 결국 prismatic + revolute joint의 결합으로 설명될 수 있습니다.\nDescription revolute joint 회전 운동을 갖는 joint prismatic joint 수평 병진 운동을 갖는 joint ⇒ ROS 2에서는 개발 상 편의를 위해 크게 6가지의 joint를 사용하고 있습니다만 그림으로만 보고 넘어가겠습니다.\nLink와 Joint로 결합된 로봇을 결국 텍스트로 표현할 수 있지 않겠냐는 기본 전제 하에, 로봇 공학자들은 **URDF(Unified Robot Description Format)**라는 표준을 만들게 됩니다. 실제로 urdf만 있다면 시뮬레이터 종류에 상관 없이 동일한 로봇 외형을 등장시킬 수 있습니다. image from : Martin Androvich\n⇒ URDF는 XML 문법을 사용하고 있으며 다양한 tag를 통해 로봇을 표현하게 됩니다. 예시를 통해 URDF에 대한 이해도를 가져봅시다.\nURDF Link Example \u0026lt;link name=\u0026#34;base_link\u0026#34;\u0026gt; \u0026lt;inertial\u0026gt; \u0026lt;origin xyz=\u0026#34;0 0 0\u0026#34; rpy=\u0026#34;0 0 0\u0026#34; /\u0026gt; \u0026lt;mass value=\u0026#34;8.3\u0026#34; /\u0026gt; \u0026lt;inertia ixx=\u0026#34;5.249466E+13\u0026#34; ixy=\u0026#34;-1.398065E+12\u0026#34; ixz=\u0026#34;-3.158592E+12\u0026#34; iyy=\u0026#34;5.786727E+13\u0026#34; iyz=\u0026#34;-5.159120E+11\u0026#34; izz=\u0026#34;3.114993E+13\u0026#34; /\u0026gt; \u0026lt;/inertial\u0026gt; \u0026lt;visual\u0026gt; \u0026lt;origin xyz=\u0026#34;0 0 0\u0026#34; rpy=\u0026#34;0 3.1415 3.1415\u0026#34; /\u0026gt; \u0026lt;geometry\u0026gt; \u0026lt;mesh filename=\u0026#34;package://neuronbot2_description/meshes/neuronbot2/base_link.stl\u0026#34; scale=\u0026#34;0.001 0.001 0.001\u0026#34; /\u0026gt; \u0026lt;/geometry\u0026gt; \u0026lt;material name=\u0026#34;black\u0026#34; /\u0026gt; \u0026lt;/visual \u0026lt;collision\u0026gt; \u0026lt;origin xyz=\u0026#34;0 0 0.125\u0026#34; rpy=\u0026#34;0 0 0\u0026#34; /\u0026gt; \u0026lt;geometry\u0026gt; \u0026lt;box size=\u0026#34;0.25 0.25 0.25\u0026#34; /\u0026gt; \u0026lt;/geometry\u0026gt; \u0026lt;material name=\u0026#34;black\u0026#34; /\u0026gt; \u0026lt;/collision\u0026gt; \u0026lt;/link\u0026gt; Description inertial 해당 link의 질량, 관성 모멘트와 같은 물성치를 포함합니다. visual 로봇이 겉으로 보여지는 시각적인 요소를 설정합니다. STL과 같은 3D 모델링 파일을 사용할 수 있습니다. collision visual은 겉으로 보여지는 모습일 뿐, 실제 해당 link가 자치하는 부피는 collision에서 지정됩니다. Visual과 collision을 일치시킬수록 좋기 때문에 3D 모델링 파일을 사용하기도 합니다. (종종 계산 단순화를 위해 간소화된 모델을 사용하기도 합니다.) URDF JointExample \u0026lt;joint name=\u0026#34;r_wheel_joint\u0026#34; type=\u0026#34;continuous\u0026#34;\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34;/\u0026gt; \u0026lt;child link=\u0026#34;wheel_right_link\u0026#34;/\u0026gt; \u0026lt;origin xyz=\u0026#34;0.0 -0.09 0.0415\u0026#34; rpy=\u0026#34;0 0 0\u0026#34;/\u0026gt; \u0026lt;axis xyz=\u0026#34;0 1 0\u0026#34;/\u0026gt; \u0026lt;/joint\u0026gt; \u0026lt;joint name=\u0026#34;l_wheel_joint\u0026#34; type=\u0026#34;continuous\u0026#34;\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34;/\u0026gt; \u0026lt;child link=\u0026#34;wheel_left_link\u0026#34;/\u0026gt; \u0026lt;origin xyz=\u0026#34;0.0 0.109 0.0415\u0026#34; rpy=\u0026#34;0 0 0\u0026#34;/\u0026gt; \u0026lt;axis xyz=\u0026#34;0 1 0\u0026#34;/\u0026gt; \u0026lt;/joint\u0026gt; Description name joint의 이름은 후에 tf publish 시 그대로 사용되기 때문에 혼란을 야기하지 않도록 설정해야 합니다. type 예시에서 사용중인 joint type은 fixed와 continuous로. fixed는 단단히 결합된 joint를, continuous는 무한히 돌아갈 수 있는 joint를 뜻합니다. origin parent link의 원점을 기준으로 한 joint의 위치를 지정하게 되며, 이러한 수치는 모델링 파일을 통해 미리 조사된 이후 URDF로 변환됩니다. axis 회전하는 joint의 경우 어떠한 축을 기준으로 회전되는지 설정이 필요합니다. parent, child 해당 joint의 전, 후 link를 설정합니다. 기타 속성들 limit, dynamics, calibration, mimic, safety_controller등이 있으며, 각종 역학적인 속성을 표현합니다. urdf의 joint는 절대 좌표를 기준으로 하는 extrinsic 체계를 갖습니다.\n기타 속성들 Description origin 해당 요소의 원점을 기준으로, 위치와 방향을 결정합니다. 3축 직교 좌표계를 기준으로 x,y,z 축과 roll pitch yaw 회전각을 사용하고 있습니다. geometry visual과 collision의 기하학적 요소를 결정하는 태그입니다. urdf에서는 box, cylinder, sphere와 같이 단순한 도형을 제공하고 있습니다. 별도 stl 파일을 사용해도 되지만 로봇을 단순화하고 싶은 경우 이를 통해 간소화가 가능합니다. material color, texture등을 지정할 수 있으며, 외향적인 디자인을 위한 요소입니다. Basic Stick URDF를 설명하긴 했는데… 실제로 와닿지 않지요? 이러한 이유로 2가지 예시를 통해 URDF에 대한 개요를 확실히 짚고 넘어가보겠습니다.\nBasic Stick Fusion Bot basic stick 2개의 link로 구성되어 있는 아주 기본적인 모델을 함께 분석해볼 것입니다. launch file을 실행해봅시다. cbp basic_stick \u0026amp;\u0026amp; source install/local_setup.bash ros2 launch basic_stick description.launch.py 전에 배웠던 tf2 기억하시죠?? 까먹으면 안됩니다…\nlauch file 분석 ⇒ launch file은 항상 최하단부터 분석합니다. 지금 2개의 node가 실행되고 있습니다.\nreturn LaunchDescription([ robot_state_publisher, rviz, ]) robot_state_publisher node는 xacro file을 받아 일련의 처리 과정을 거친 결과를 매개변수로 받습니다. # Get URDF via xacro robot_description_content = Command( [ PathJoinSubstitution([FindExecutable(name=\u0026#34;xacro\u0026#34;)]), \u0026#34; \u0026#34;, PathJoinSubstitution( [FindPackageShare(\u0026#34;basic_stick\u0026#34;), \u0026#34;urdf\u0026#34;, \u0026#34;basic_stick_desc.xacro\u0026#34;] ), ] ) robot_description = {\u0026#34;robot_description\u0026#34;: robot_description_content} # Robot State Publisher robot_state_publisher = Node( package=\u0026#39;robot_state_publisher\u0026#39;, executable=\u0026#39;robot_state_publisher\u0026#39;, name=\u0026#39;robot_state_publisher\u0026#39;, output=\u0026#39;screen\u0026#39;, parameters=[robot_description], ) rviz2 launch는 간단하지만 복습을 위해 다시 살펴봅시다. pkg_path = os.path.join(get_package_share_directory(\u0026#39;basic_stick\u0026#39;)) rviz_config_file = os.path.join(pkg_path, \u0026#39;rviz\u0026#39;, \u0026#39;desc.rviz\u0026#39;) # Launch RViz rviz = Node( package=\u0026#39;rviz2\u0026#39;, executable=\u0026#39;rviz2\u0026#39;, name=\u0026#39;rviz2\u0026#39;, output=\u0026#39;screen\u0026#39;, arguments=[\u0026#34;-d\u0026#34;, rviz_config_file], ) robot state publisher robot state publisher는 모든 link와 joint 값을 지속적으로 받아 전체 로봇의 구조를 tf2 형식으로 변환합니다. tf2 예시에서 static/dynamic tf2에 대해서 살펴보았지요? 지금 basic stick은 움직이는 부분이 없기 때문에 모든 파트가 static이라는 점을 안내드립니다.\nrobot state publisher는 URDF file의 joint/link 데이터를 기반으로 tf2 broadcast를 합니다. 때문에 tf2 tree를 살펴보아도 아래와 같은 그림을 볼 수 있습니다. robot state publisher가 도출하는 또 다른 것은 robot_description topic입니다. string만 가득한 topic이지만 이를 사용하여 시각화, Gazebo spawn 등 여러 작업에서 사용됩니다. $ ros2 topic info /robot_description Type: std_msgs/msg/String Publisher count: 1 Subscription count: 0 data: \u0026lt;?xml version=\u0026#34;1.0\u0026#34; ?\u0026gt; \u0026lt;!-- =================================================================================== --\u0026gt; \u0026lt;!-- | Th... --- basic_stick_desc.xacro URDF 스크립트를 사람이 모두 작성하기는 매우 비효율적입니다. 더불어, Gazebo에서만 사용하는 속성을 따로 분리하고 싶은 경우, 파일을 나누어 관리하고 싶을 것입니다. 이러한 욕구를 충족시키기 위해서 ROS 2는 URDF의 작성을 보다 편하게 해주는 XML Macro, Xacro를 지원하고 있습니다.\n특히 xacro는 수식, 조건을 사용 가능하기 때문에 로봇 파일을 다루기 매우 용이하며, 특정 요소를 모듈화 후 재사용하는 등 효율적인 URDF 작성이 가능하도록 도와줍니다.\nbasic_stick_desc.xacro의 초반부를 보면 xacro 변수가 설정되고 있는 것을 확인할 수 있습니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;robot name=\u0026#34;basic_stick\u0026#34; xmlns:xacro=\u0026#34;http://www.ros.org/wiki/xacro\u0026#34;\u0026gt; \u0026lt;xacro:property name=\u0026#34;PI\u0026#34; value=\u0026#34;3.14159\u0026#34;/\u0026gt; \u0026lt;xacro:property name=\u0026#34;mass1\u0026#34; value=\u0026#34;10\u0026#34; /\u0026gt; \u0026lt;xacro:property name=\u0026#34;mass2\u0026#34; value=\u0026#34;1\u0026#34; /\u0026gt; \u0026lt;xacro:property name=\u0026#34;width1\u0026#34; value=\u0026#34;0.1\u0026#34; /\u0026gt; \u0026lt;!--link_1 radius--\u0026gt; \u0026lt;xacro:property name=\u0026#34;width2\u0026#34; value=\u0026#34;0.1\u0026#34; /\u0026gt; \u0026lt;!--link_2 radius--\u0026gt; \u0026lt;xacro:property name=\u0026#34;length0\u0026#34; value=\u0026#34;0.1\u0026#34; /\u0026gt; \u0026lt;!--link_1 length--\u0026gt; \u0026lt;xacro:property name=\u0026#34;length1\u0026#34; value=\u0026#34;1.5\u0026#34; /\u0026gt; \u0026lt;!--link_2 length--\u0026gt; \u0026lt;xacro:property name=\u0026#34;length2\u0026#34; value=\u0026#34;0.1\u0026#34; /\u0026gt; \u0026lt;!--link_3 length--\u0026gt; \u0026lt;xacro:property name=\u0026#34;mass_camera\u0026#34; value=\u0026#34;0.2\u0026#34; /\u0026gt; 본론으로 돌아와 현재 basic stick은 link 3개 joint 2개를 갖는, 모든 joint가 fixed joint인 로봇입니다. \u0026lt;!--Links--\u0026gt; \u0026lt;link name=\u0026#34;world\u0026#34;/\u0026gt; \u0026lt;link name=\u0026#34;link_1\u0026#34;\u0026gt; \u0026lt;link name=\u0026#34;link_2\u0026#34;\u0026gt; 각 링크의 3가지 속성을 통해 물성치와 시각적 특성을 구현하고, Gazebo에서 이를 바탕으로 우리에게 시각화해주게 되는 원리입니다. \u0026lt;link name=\u0026#34;link_1\u0026#34;\u0026gt; \u0026lt;visual\u0026gt; \u0026lt;collision\u0026gt; \u0026lt;inertial\u0026gt; \u0026lt;/link\u0026gt; joint에서는 항상 parent와 child의 연결이 완성되어 있어야 합니다. xacro property를 사용한 모습도 확인 가능합니다. \u0026lt;!--Joints--\u0026gt; \u0026lt;joint name=\u0026#34;fixed_base_joint\u0026#34; type=\u0026#34;fixed\u0026#34;\u0026gt; \u0026lt;parent link=\u0026#34;world\u0026#34;/\u0026gt; \u0026lt;child link=\u0026#34;link_1\u0026#34;/\u0026gt; \u0026lt;origin xyz=\u0026#34;0 0 ${length1/2}\u0026#34; rpy=\u0026#34;0 0 0\u0026#34;/\u0026gt; \u0026lt;/joint\u0026gt; \u0026lt;joint name=\u0026#34;pan_joint\u0026#34; type=\u0026#34;fixed\u0026#34;\u0026gt; \u0026lt;parent link=\u0026#34;link_1\u0026#34;/\u0026gt; \u0026lt;child link=\u0026#34;link_2\u0026#34;/\u0026gt; \u0026lt;!-- \u0026lt;axis xyz=\u0026#34;0 0 1\u0026#34;/\u0026gt; --\u0026gt; \u0026lt;origin xyz=\u0026#34;0 0 ${length1/2+length2/2}\u0026#34; rpy=\u0026#34;0 0 -${pi/2}\u0026#34;/\u0026gt; \u0026lt;/joint\u0026gt; 이렇게 basic stick을 완성해보았습니다. 그럼, Gazebo에서 이를 등장시켜봅시다. Gazebo launch 예시를 실행합니다. ros2 launch basic_stick gz.launch.py ⇒ 색도 없고, 밋밋한 basic stick이 동장할 것입니다.\n이 launch file을 분석해 보면서 gazebo 연동의 개념을 잡아봅시다. return LaunchDescription( [ start_gazebo_server_cmd, start_gazebo_client_cmd, robot_state_publisher, spawn_entity, ] ) start_gazebo_server_cmd / start_gazebo_client_cmd는 각각 gzserver와 client를 실행하는 부분입니다. 더불어, world file을 gzserver에게 전달할 수 있습니다. def generate_launch_description(): pkg_path = os.path.join(get_package_share_directory(\u0026#39;basic_stick\u0026#39;)) pkg_gazebo_ros = FindPackageShare(package=\u0026#39;gazebo_ros\u0026#39;).find(\u0026#39;gazebo_ros\u0026#39;) world_path = os.path.join(pkg_path, \u0026#39;worlds\u0026#39;, \u0026#39;empty_world.world\u0026#39;) # Start Gazebo server start_gazebo_server_cmd = IncludeLaunchDescription( PythonLaunchDescriptionSource(os.path.join(pkg_gazebo_ros, \u0026#39;launch\u0026#39;, \u0026#39;gzserver.launch.py\u0026#39;)), launch_arguments={\u0026#39;world\u0026#39;: world_path}.items() ) # Start Gazebo client start_gazebo_client_cmd = IncludeLaunchDescription( PythonLaunchDescriptionSource(os.path.join(pkg_gazebo_ros, \u0026#39;launch\u0026#39;, \u0026#39;gzclient.launch.py\u0026#39;)) ) 메인 파트인 spawn 부분입니다. spawn node는 robot state publisher의 output인 robot_description topic을 subscribe하여 gazebo 상에 물체를 등장시킵니다. ⇒ 등장시킬 시의 이름, 위치와 방향을 지정할 수 있습니다.\n# Spawn Robot spawn_entity = Node( package=\u0026#39;gazebo_ros\u0026#39;, executable=\u0026#39;spawn_entity.py\u0026#39;, arguments=[ \u0026#39;-topic\u0026#39;, \u0026#39;robot_description\u0026#39;, \u0026#39;-entity\u0026#39;, \u0026#39;sensor_stick\u0026#39;, \u0026#39;-x\u0026#39;, str(0), \u0026#39;-y\u0026#39;, str(0.0), \u0026#39;-Y\u0026#39;, str(0.0), ], output=\u0026#39;screen\u0026#39; ) 방금 전, Gazebo 상에서 sensor stick이 밋밋했지요? 색상을 추가하기 위해서 다른 xacro file을 include 합시다. ⇒ basic_stick.xacro에서 basic_stick.gazebo.xacro를 include 합니다.\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;robot\u0026gt; \u0026lt;!--base_link--\u0026gt; \u0026lt;gazebo reference=\u0026#34;base_link\u0026#34;\u0026gt; \u0026lt;material\u0026gt;Gazebo/White\u0026lt;/material\u0026gt; \u0026lt;/gazebo\u0026gt; ... \u0026lt;/robot\u0026gt; \u0026lt;!--Import gazebo elements--\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find basic_stick)/urdf/basic_stick.gazebo.xacro\u0026#34; /\u0026gt; 색상이 반영된 새로운 xacro file을 다시 gazebo spawn 시켜봅시다. robot_description_content = Command( [ PathJoinSubstitution([FindExecutable(name=\u0026#34;xacro\u0026#34;)]), \u0026#34; \u0026#34;, PathJoinSubstitution( [FindPackageShare(\u0026#34;basic_stick\u0026#34;), \u0026#34;urdf\u0026#34;, \u0026#34;basic_stick.xacro\u0026#34;] ), ] ) Basic Stick을 통해 배운 내용들을 복습하자면\nROS 2에게 로봇의 정보를 전달하기 위해 urdf라는 포멧을 사용했고, 이는 link와 joint로 이루어집니다. robot state publisher는 URDF를 받아 tf2를 broadcast하며 robot_description publish를 합니다. robot_description topic을 통해 gazebo에서 로봇을 등장시킬 수 있었습니다. fusion bot 일전 sensor stick은 움직이는 파츠가 없이 정적인 모델이었습니다. 그래서 이번에는 움직이는 joint를 갖는 모바일 로봇의 예시를 살펴보겠습니다.\n예시를 실행해봅시다. rviz2에 등장하는 joint들을 볼 수 있습니다. cbp fusionbot_description \u0026amp;\u0026amp; source install/local_setup.bash ros2 launch fusionbot_description description.launch.py tf2 tree도 확인해봅시다. $ ros2 run tf2_tools view_frames.py 그리고 함께 등장하는 joint_state_publisher_gui의 슬라이드바를 움직이면, rviz2 상의 tf가 변화하는 것을 볼 수 있습니다. fusionbot_description.urdf을 보면 알 수 있듯이, 이번 로봇은 continuous joint를 갖습니다. 이는 바퀴와 같이 끝없이 돌아갈 수 있는 joint입니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;robot name=\u0026#34;fusionbot\u0026#34; xmlns:xacro=\u0026#34;http://www.ros.org/wiki/xacro\u0026#34;\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find fusionbot_description)/urdf/materials.xacro\u0026#34; /\u0026gt; \u0026lt;!-- \u0026lt;xacro:include filename=\u0026#34;$(find fusionbot_description)/urdf/fusionbot.gazebo\u0026#34; /\u0026gt; --\u0026gt; \u0026lt;link name=\u0026#39;base_footprint\u0026#39; /\u0026gt; \u0026lt;link name=\u0026#34;base_link\u0026#34;\u0026gt; \u0026lt;link name=\u0026#34;right_wheel\u0026#34;\u0026gt; ... \u0026lt;joint name=\u0026#39;base_link_joint\u0026#39; type=\u0026#39;fixed\u0026#39;\u0026gt; \u0026lt;joint name=\u0026#34;right_wheel_joint\u0026#34; type=\u0026#34;continuous\u0026#34;\u0026gt; \u0026lt;joint name=\u0026#34;left_wheel_joint\u0026#34; type=\u0026#34;continuous\u0026#34;\u0026gt; ... \u0026lt;/robot\u0026gt; joint state publisher joint state publisher는 로봇 내 존재하는 다양한 joint 값들을 실시간으로 갱신하여 /joint_states라는 topic으로 publish 하고 tf2 broadcast도 담당합니다.\n/joint_states topic은 sensor_msgs/msg/JointState msg를 사용하며, 각 joint들의 이름, 현재 위치, 속도와 힘을 배열 형태로 담게 됩니다. $ ros2 interface show sensor_msgs/msg/JointState # This is a message that holds data to describe the state of a set of torque controlled joints. # # # The state of each joint (revolute or prismatic) is defined by: # * the position of the joint (rad or m), # * the velocity of the joint (rad/s or m/s) and # * the effort that is applied in the joint (Nm or N). # ... std_msgs/Header header string[] name float64[] position float64[] velocity float64[] effort 예제 실행 시 등장했던 조그만 창은 joint_state_publisher_gui라고 불리며, 로봇 내 조작이 가능한 joint들을 간단하게 제어할 수 있도록 해주는 작은 프로그램입니다. 이를 통해 구성한 URDF의 방향은 알맞게 설정되었는지, 원점은 잘 맞는지 등을 확인 가능합니다. topic echo를 걸어둔 상태에서 gui의 슬라이드바를 움직여봅시다. $ ros2 topic echo /joint_states header: stamp: frame_id: \u0026#39;\u0026#39; name: - right_wheel_joint - left_wheel_joint position: - 1.918884792812646 - -1.409318464400381 velocity: [] effort: [] --- ⇒ 이렇게 joint state publisher는 현재 로봇이 가진 움직일 수 있는 모든 joint들을 예의주시하고 있습니다.\nrviz2 상에서 보시다시피 tf2 frame도 회전하기 때문에, 이는 로봇팔을 포함 움직이는 모든 로봇에게 필수적인 데이터입니다. 그렇다면 robot state publisher, joint state publisher, tf2는 어떠한 관계를 가질까요? rqt_graph를 통해 살펴봅시다. FusionBot Gazebo fusionbot의 gazebo 예시도 실행해봅시다. ros2 launch fusionbot_description gz.launch.py 현재 로봇이 움직일 수는 없습니다. 이는 다음 시간 plugin을 사용하여 구현해보겠습니다.\n이번 launch file의 하단을 보면서 이번 시간 배운 내용들을 다시금 정리해봅시다. return LaunchDescription( [ start_gazebo_server_cmd, start_gazebo_client_cmd, robot_state_publisher, joint_state_publisher, spawn_entity, ] ) 지금까지 배운 내용을 총정리해봅시다.\nROS 2와 소통하기 위해 urdf를 사용했고,이는 link와 joint로 이루어집니다. joint는 joint state publisher가 담당하며, robot state publisher는 joint state와 함께 link를 결합하여 최종 tf를 구성합니다. 이러한 데이터들에 기반하여 gazebo는 시뮬레이션을 합니다. Gazebo Basic Gazebo의 특징과 기본적인 UI, 그리고 사용법을 짚고 넘어가고자 합니다.\nimage from : Open Robotics Gazebo는 로봇공학을 위해 제작된 전용 물리 엔진 기반의 높은 3D 시뮬레이터로 ROS를 관리하는 Open Robotics에서 비롯된 시뮬레이터인 만큼 ROS와 높은 호환성을 자랑합니다. 이후 Gazebo 사용 및 오류 발생 시 디버깅을 위해, Gazebo를 구성하는 요소들을 간단하게 짚고 넘어가겠습니다.\ngzserver \u0026amp; gzclient Gazebo는 Socket-Based Communication을 갖습니다. 따라서 서버와 Client를 분리하여 실행 가능하며 다른 기기에서의 실행 후 연동도 가능합니다.\nGazebo Server gzserver는 Gazebo 동작의 대부분을 수행합니다. 시뮬레이션하려는 장면과 그 안에 있는 개체 파일을 분석하고, 그런 다음 물리 엔진과 센서 엔진을 사용하여 전체 장면을 시뮬레이션합니다. ⇒ 터미널에서 gzserver를 독립적으로 실행할 수 있습니다. $ gzserver Gazebo Client gzclient는 gzserver에 연결하여 대화형 도구와 함께 시뮬레이션을 렌더링하는 Graphic Client를 제공합니다. $ gzserver ⇒ client만 실행하면, 연결되고 명령을 수신할 서버가 없기 때문에 (컴퓨팅 리소스를 소비하는 것을 제외하고) 아무 것도 하지 않습니다.\ngazebo 명령어를 입력하면 내부적으로 server와 client가 순차적으로 실행됩니다. # Terminal1 - gazebo 실행 $ gazebo # Terminal2 - gazebo process check $ ps faux | grep gz ⇒ 이러한 이유로 Gazebo를 종료했다고 생각하지만 gzserver가 깔끔하게 종료되지 않아 정상 동작하던 예시에서 오류를 얻는 상황이 발생합니다.\nWorld File and Model File image from : dronecode World Files ⇒ Gazebo world file에는 로봇 모델, 환경, 조명, 센서, 다른 기타 물체들까지 시뮬레이션 환경의 모든 요소가 포함되어 있으며, 이는 일반적으로 확장자명 .world를 사용합니다. 아래 예시와 같이 Gazebo 실행 시 world 파일을 옵션으로 하여 단독 실행이 가능합니다.\n$ gazebo \u0026lt;yourworld\u0026gt;.world Model Files ⇒ Gazebo의 World는 다양한 Model들로 구성됩니다. 하지만 Model 파일만으로 gazebo를 실행시킬 수는 없습니다.\n⇒ 모델을 별도의 파일로 보관하는 이유는 다른 프로젝트에 재사용하기 위해서이며, 로봇의 모델 파일 또는 다른 모델을 월드 파일 내에 포함하려면 다음과 같이 태그를 통해 import 할 수 있습니다.\n\u0026lt;include\u0026gt;\u0026lt;uri\u0026gt;model://model_file_name\u0026lt;/uri\u0026gt;\u0026lt;/include\u0026gt; Plugins Gazebo의 World, Model에 장착되는 각종 센서와 제어를 위한 다양한 플러그인이 준비되어 있으며, 이러한 플러그인은 커멘드 라인에서 로드하거나 SDF 파일 내부에 추가할 수 있습니다. (자체 Plugin을 개발할 수도 있습니다.)\nUnderstanding Gazebo GUI 이번에는 Gazebo의 기본 조작 방법과 내장 Tool들을 살펴보겠습니다.\nGazebo의 시점 변환은 마우스를 사용하여 손쉽게 조작 가능합니다. 마우스 왼쪽 버튼을 누르고 드래그하면 시점을 이동할 수 있습니다. 마우스 휠을 누른 상태로 이동시키면 회전 시점을 조작할 수 있습니다. 내장 tool들을 살펴보겠습니다. 우선, 최상단에 위치한 Top Toolbar부터 살펴보겠습니다. ⇒ 왼쪽부터 오른쪽 순서대로 각 아이콘 별 기능을 설명해보겠습니다.\nSelect mode Select mode는 가장 일반적으로 사용되는 커서 모드입니다. 장면을 탐색할 수 있습니다.\nTranslate mode 커서 모드를 선택한 다음 이동시키길 원하는 객체를 클릭합니다. 이후 등장하는 3축 중 적절한 축을 사용하여 개체를 원하는 위치로 끌기만 하면 됩니다.\nRotate mode translate mode와 마찬가지로 이 커서 모드를 사용하면 주어진 모델의 방향을 변경할 수 있습니다.\nScale mode Scale mode를 사용하면 객체의 전체 크기를 변경할 수 있습니다.\nUndo/Redo 앞,뒤로 되돌리는 기능입니다.\nSimple shapes 큐브, 구체 또는 실린더와 같은 기본 3D 모델을 환경에 삽입할 수 있습니다.\nLights 스포트라이트, 포인트 라이트 또는 방향이 정해진 조명과 같은 다양한 광원을 환경에 추가합니다.\nCopy/Paste 모델을 복사/붙여넣을 수 있습니다. (Ctrl+C/V를 통해서도 가능합니다.)\nAlign 이 도구를 사용하면 x y z 축 중 하나를 따라 한 모형을 다른 모델과 정렬할 수 있습니다.\n⇒ 또는 두 모델을 특정한 면 기반으로 서로 붙이는 것도 가능합니다.\nChange view 상단 뷰, 측면 뷰, 전면 뷰, 하단 뷰와 같은 다양한 관점에서 장면을 볼 수 있습니다.\n다음으로 Side Panel을 살펴보겠습니다.\nWorld 현재 사용중인 조명 및 모델들이 표시됩니다. 개별 모델을 클릭하여 위치 및 방향과 같은 모델의 기본 파라미터를 보거나 편집할 수 있습니다. 또한 물리 옵션을 통해 중력 및 자기장과 같은 물성치도 변경할 수 있습니다. GUI 옵션을 사용하면 기본 카메라 뷰 각도 및 포즈에 액세스할 수 있습니다.\nInsert 추가할 모델을 찾을 수 있습니다. 환경 변수에 지정된 폴더에서 모델들을 검색한 뒤 배치하는 것이 가능하며, 환경 변수 설정 없이도 Add Path 옵션을 통해 정해진 포맷을 갖는 모델을 가져올 수 있습니다.\nGazebo and ROS 2 Gazebo는 ROS 2와 호환이 가장 좋은 로봇 시뮬레이션 프로그램입니다. gazebo_ros에 대해서 살펴봅시다.\ngazebo_ros 실행 $ ros2 launch gazebo_ros gazebo.launch.py 겉보기에는 일반 gazebo 실행과 차이가 없는 것 같지만, 내부적으로 이는 큰 차이를 갖습니다. =\u0026gt; 바로 ROS 2와 호환할 수 있는 다양한 API를 포함한 Gazebo가 실행된다는 점입니다.\n$ ros2 topic list /clock /parameter_events /performance_metrics /rosout $ ros2 service list /apply_joint_effort /apply_link_wrench /clear_joint_efforts /clear_link_wrenches /delete_entity /gazebo/describe_parameters /gazebo/get_parameter_types /gazebo/get_parameters /gazebo/list_parameters /gazebo/set_parameters /gazebo/set_parameters_atomically /get_model_list /pause_physics /reset_simulation /reset_world /spawn_entity /unpause_physics 지금까지 실행했던 launch file을 살펴보면 모두 gazebo_ros를 실행함을 알 수 있으며, 특히 server와 client를 나누어 실행하고 있음을 확인 가능합니다. # Start Gazebo server start_gazebo_server_cmd = IncludeLaunchDescription( PythonLaunchDescriptionSource(os.path.join(pkg_gazebo_ros, \u0026#39;launch\u0026#39;, \u0026#39;gzserver.launch.py\u0026#39;)), launch_arguments={\u0026#39;world\u0026#39;: world_path}.items() ) # Start Gazebo client start_gazebo_client_cmd = IncludeLaunchDescription( PythonLaunchDescriptionSource(os.path.join(pkg_gazebo_ros, \u0026#39;launch\u0026#39;, \u0026#39;gzclient.launch.py\u0026#39;)) ) ⇒ server와 client를 나눈 이유는 server단에서 world 파일이 전달되기 때문입니다.\ngazebo_ros를 실행한 뒤 조회되었던 topic과 service들 중 의미있는 것들을 다시 한 번 살펴봅시다. (우리에게 익숙한 것도 있습니다.) Topic Name Description /clock Gazebo 자체의 시간으로 시뮬레이션이 시작되는 시점이 0초가 됩니다. Service Name Description /delete_entity 모델을 등장시킵니다. /spawn_entity 존재하는 모델을 제거합니다. /get_model_list 전체 모델 리스트를 조회합니다. /pause_physics 중력, 바람 등 물리량들을 모두 정지시킵니다. /unpause_physics 물리량들을 다시 시작합니다. /reset_simulation World 전체를 Reset /reset_world World내 Model Pose를 Reset Gazebo Building Editor gazebo를 실행시킨 뒤, 상단 Edit 옵션에서 Building Editor를 실행합니다. 상단 모눈종이에 스케치를 통해 건물 벽을 생성할 수 있으며, 하단 view를 통해 실시간으로 업데이트되는 건물을 확인할 수 있습니다. 혹여 실수를 했거나, 보다 정확한 수치를 입력하고 싶은 경우, 모눈종이 위의 검은 선을 더블 클릭하면 사진과 같이 구체적인 설정을 변경할 수 있는 탭이 등장합니다. 수정이 완료되었다면, 왼쪽 탭에서 door, stairs도 사용해보고, Texture도 입혀봅시다. 모든 작업을 마친 뒤, File 탭에서 Save As를 선택하여 완성한 물체를 저장합니다. (저는 wall 이라는 이름으로 저장해보겠습니다.) 저장된 폴더 내부는 다음과 같은 구조를 갖게 됩니다. ├─ wall ├── model.config └── model.sdf Description model.config 해당 model의 이름, 작성자 등 기본적인 정보들이 기입됩니다. model.sdf 실직적인 sdf 형식의 모델이 위치합니다. 이렇게 생성한 물체를 Gazebo에서 두고두고 사용하는 몇가지 방법들이 있습니다.\nGAZEBO_MODEL_PATH에 추가하기 ⇒ ~/.gazebo/gui.ini 파일 내 model_paths에 building 폴더에 절대 경로를 추가합니다. $ gedit ~/.gazebo/gui.ini [geometry] x=0 y=0 [model_paths] filenames=/home/kimsooyoung/\u0026lt;your-folder-location\u0026gt; launch file에서 GAZEBO_MODEL_PATH 수정하기 대신 이 방법을 사용하면, 해당 launch file을 사용해야 GAZEBO_MODEL_PATH가 반영됩니다.\nif \u0026#39;GAZEBO_MODEL_PATH\u0026#39; in os.environ: os.environ[\u0026#39;GAZEBO_MODEL_PATH\u0026#39;] += \u0026#34;:\u0026#34; + gazebo_model_path else: os.environ[\u0026#39;GAZEBO_MODEL_PATH\u0026#39;] = gazebo_model_path 위 방법을 적용한 뒤 다시 Gazebo를 실행시키면, 사진과 같이 Insert 부분에 building이 추가되어있음을 확인 가능합니다. 이를 클릭 후 gazebo 환경으로 커서를 옮기면 원하는 위치에 wall을 위치시킬 수 있습니다. 3D Gems 이번 시간에는 오픈소스 데이터셋 3DGEMS를 사용하여 나만의 World를 꾸미는 예시를 진행해보겠습니다. =\u0026gt; 📁 3DGEMS.zip\n제공되는 3DGEMS 폴더를 압축해제한 뒤, ~/.gazebo/models 폴더에 위치시킵니다. WSL2를 사용하시는 분들께서는 터미널에서 explorer.exe . 를 입력하면 윈도우 파일 탐색기를 실행 가능합니다.\n다시 한 번 Gazebo를 실행시켜 보면 Insert 탭에 추가된 새로운 모델들을 확인할 수 있습니다. 잠시 시간을 갖고 나만의 building과 model을 추가하여 나만의 world를 만들어 봅시다!\n만든 모델은 launch 실습을 위해 gz_ros2_examples ⇒ my_world ⇒ worlds 폴더에 저장해둡니다. File ⇒ Save World As를 클릭하여 완성된 world 파일을 저장합시다. 여러분들이 만든 world 파일과 기본 empty world를 비교해보세요. \u0026lt;sdf version=\u0026#39;1.7\u0026#39;\u0026gt; \u0026lt;world name=\u0026#39;default\u0026#39;\u0026gt; \u0026lt;include\u0026gt; \u0026lt;uri\u0026gt;model://ground_plane\u0026lt;/uri\u0026gt; \u0026lt;/include\u0026gt; \u0026lt;include\u0026gt; \u0026lt;uri\u0026gt;model://sun\u0026lt;/uri\u0026gt; \u0026lt;/include\u0026gt; \u0026lt;/world\u0026gt; \u0026lt;/sdf\u0026gt; ⇒ world 파일은 SDF라는 포멧을 사용하여 작성되었으며, 이는 Gazebo에서 쓰이는 독특한 문법입니다.\n여러분이 만든 launch file을 gazebo_ros를 통해 실행해보세요. pkg_path = os.path.join(get_package_share_directory(\u0026#39;my_world\u0026#39;)) # world_path = os.path.join(pkg_path, \u0026#39;worlds\u0026#39;, \u0026lt;your-world-file\u0026gt;) # Start Gazebo server start_gazebo_server_cmd = IncludeLaunchDescription( PythonLaunchDescriptionSource(os.path.join(pkg_gazebo_ros, \u0026#39;launch\u0026#39;, \u0026#39;gzserver.launch.py\u0026#39;)), launch_arguments={\u0026#39;world\u0026#39;: world_path}.items() ) # Start Gazebo client start_gazebo_client_cmd = IncludeLaunchDescription( PythonLaunchDescriptionSource(os.path.join(pkg_gazebo_ros, \u0026#39;launch\u0026#39;, \u0026#39;gzclient.launch.py\u0026#39;)) ) 새로운 파일이 추가되었으니, package를 빌드하고, launch file을 다시 실행해봅시다. my_world package에 worlds 폴더 추가 worlds 폴더 안에 여러분의 world 파일을 위치시킵니다. 새로운 folder가 추가되었으니 CMakeLists.txt를 수정하고 빌드합니다. launch file 수정 (직접 작성하셔도 좋고, 제가 제공드리는 template을 사용하셔도 됩니다.) ros2 launch를 통해 gazebo_ros에서 여러분의 world를 불러와봅시다! colcon build --packages-select src_gazebo source install/local_setup.bash ros2 launch my_world template.py world 제작 시 사용된 SDF 포멧은 Blender라는 프로그램에서 export 할 수 있어 많은 사람들이 사용하고 있습니다. 우리는 이제 world 파일을 볼 수 있으니 Github에 있는 수많은 예시들을 가져다 쓸 수 있게 된 것입니다!\n"
},
{
	"uri": "/kr/ros2_foxy/lecture12/",
	"title": "Lecture12. About Gazebo - 2",
	"tags": [],
	"description": "",
	"content": "Gazebo Sensor Plugin Description 예시를 통해 URDF에 대해 습득하였다면, 이제 Gazebo에 로봇을 등장시키고, 이동, 센싱을 구현할 차례입니다. sensor stick을 통해 실습을 진행해보고, fusionbot도 함께 분석해 보겠습니다.\n다뤄볼 센서들은 다음과 같습니다.\nMono Camera Depth Camera 2D Lidar 3D Lidar 미리 말하자면 sensor plugin을 사용하는 기본 방법만 알면 gazebo_ros pkg wiki를 통해 얼마든지 응용이 가능합니다. 하지만 적어도 한번은 직접 plugin을 적용해보시기 바랍니다.\n⇒ https://github.com/ros-simulation/gazebo_ros_pkgs/wiki\nSensor Plugin 추가 절차 다음은 일반적으로 제가 Gazebo Model에 센서를 연동할 때 적용하는 절차입니다.\n센서가 부착될 link/joint 추가 기본 plugin xml 연동 plugin parameter 수정 Gazebo를 통해 동작 검증 ⇒ 다시 2로 반복\nbasic_stick을 통해 카메라 센서들을, fusionbot을 통해 나머지를 실습해봅시다!! 센서가 부착될 link/joint 추가 ⇒ link가 하나 추가되면 필연적으로 joint도 추가됩니다. 이를 기본 로봇 xacro에 반영합니다.\n\u0026lt;link name=\u0026#34;camera_rgb_frame\u0026#34; /\u0026gt; \u0026lt;joint name=\u0026#34;camera_rgb_joint\u0026#34; type=\u0026#34;fixed\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0 0.022 0\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;camera_link\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;camera_rgb_frame\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; \u0026lt;link name=\u0026#34;camera_rgb_optical_frame\u0026#34; /\u0026gt; \u0026lt;joint name=\u0026#34;camera_rgb_optical_joint\u0026#34; type=\u0026#34;fixed\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;-1.57079632679 0 -1.57079632679\u0026#34; xyz=\u0026#34;0 0 0\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;camera_rgb_frame\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;camera_rgb_optical_frame\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; \u0026lt;link name=\u0026#34;camera_depth_frame\u0026#34; /\u0026gt; \u0026lt;joint name=\u0026#34;camera_depth_joint\u0026#34; type=\u0026#34;fixed\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0 0.049 0\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;camera_link\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;camera_depth_frame\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; \u0026lt;link name=\u0026#34;camera_depth_optical_frame\u0026#34; /\u0026gt; \u0026lt;joint name=\u0026#34;camera_depth_optical_joint\u0026#34; type=\u0026#34;fixed\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;-1.57079632679 0 -1.57079632679\u0026#34; xyz=\u0026#34;0 0 0\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;camera_depth_frame\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;camera_depth_optical_frame\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; 기본 plugin xml 연동 ⇒ 앞서 제시드린 gazebo_ros pkg wiki 예시를 참고하여 원하는 link에 센서 속성을 부여합니다. 지금은 Mono Camera를 부착해보겠습니다.\n\u0026lt;gazebo reference=\u0026#34;camera_rgb_frame\u0026#34;\u0026gt; \u0026lt;sensor type=\u0026#34;camera\u0026#34; name=\u0026#34;rgb_cam\u0026#34;\u0026gt; \u0026lt;update_rate\u0026gt;60\u0026lt;/update_rate\u0026gt; \u0026lt;visualize\u0026gt;true\u0026lt;/visualize\u0026gt; \u0026lt;always_on\u0026gt;1\u0026lt;/always_on\u0026gt; \u0026lt;camera name=\u0026#34;head\u0026#34;\u0026gt; \u0026lt;horizontal_fov\u0026gt;1.3962634\u0026lt;/horizontal_fov\u0026gt; \u0026lt;image\u0026gt; \u0026lt;width\u0026gt;1280\u0026lt;/width\u0026gt; \u0026lt;height\u0026gt;720\u0026lt;/height\u0026gt; \u0026lt;format\u0026gt;R8G8B8\u0026lt;/format\u0026gt; \u0026lt;!-- \u0026lt;format\u0026gt;B8G8R8\u0026lt;/format\u0026gt; --\u0026gt; \u0026lt;/image\u0026gt; \u0026lt;clip\u0026gt; \u0026lt;near\u0026gt;0.02\u0026lt;/near\u0026gt; \u0026lt;far\u0026gt;300\u0026lt;/far\u0026gt; \u0026lt;/clip\u0026gt; \u0026lt;noise\u0026gt; \u0026lt;type\u0026gt;gaussian\u0026lt;/type\u0026gt; \u0026lt;mean\u0026gt;0.0\u0026lt;/mean\u0026gt; \u0026lt;stddev\u0026gt;0.007\u0026lt;/stddev\u0026gt; \u0026lt;/noise\u0026gt; \u0026lt;/camera\u0026gt; \u0026lt;plugin name=\u0026#34;camera_controller\u0026#34; filename=\u0026#34;libgazebo_ros_camera.so\u0026#34;\u0026gt; \u0026lt;ros\u0026gt; \u0026lt;namespace\u0026gt;rgb_cam\u0026lt;/namespace\u0026gt; \u0026lt;remapping\u0026gt;image_raw:=image_raw\u0026lt;/remapping\u0026gt; \u0026lt;remapping\u0026gt;camera_info:=camera_info\u0026lt;/remapping\u0026gt; \u0026lt;/ros\u0026gt; \u0026lt;!-- camera_name\u0026gt;omit so it defaults to sensor name\u0026lt;/camera_name--\u0026gt; \u0026lt;!-- \u0026lt;frame_name\u0026gt;omit so it defaults to link name\u0026lt;/frame_name\u0026gt; --\u0026gt; \u0026lt;camera_name\u0026gt;front_camera\u0026lt;/camera_name\u0026gt; \u0026lt;frame_name\u0026gt;camera_rgb_frame\u0026lt;/frame_name\u0026gt; \u0026lt;hack_baseline\u0026gt;0.07\u0026lt;/hack_baseline\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/sensor\u0026gt; \u0026lt;/gazebo\u0026gt; Mono Camera plugin의 매개변수들은 다음과 같습니다. 이들을 여러분의 목적에 맞게 수정한 뒤, gazebo에서 실행하여 검증을 합니다.\nParameter Description gazebo reference camera가 장착되는 link update_rate data publish rate visualize 시각화 옵션 horizontal_fov 카메라의 화각 image 화질, 포맷 옵션 noise 센서 노이즈 remapping topic 이름 재설정 camera_name topic의 namespace가 됩니다. frame_name camera가 장착되는 link hack_baseline stereo camera 사용 시 - 카메라 사이 거리 namespace 동일 센서가 여러개 있을 시 namespace를 통해 구분할 수 있습니다. Gazebo를 통해 검증하기 위해서, 일반 Gazebo가 아닌, gazebo_ros를 사용해야 합니다. 그래야 센서 데이터들이 topic publish 되기 때문입니다. 따라서 launch file 수정 후 실행의 절차를 반복합니다. gazebo 실행 후 3DGEMS Model을 등장시켜 rviz2로 확인해보겠습니다.\nros2 launch basic_stick sensor_stick.launch.py Gazebo 연동 후 rqt, topic echo, rviz2, tf2 tree 등 지금까지 배운 모든 기능들을 사용해 검증하고, 디버깅합니다. 위 과정은 반복되므로, 센서 plugin 예시와 매개변수들을 위주로 살펴보겠습니다.\nDepth Camera ⇒ Depth Camera 사용 시 주의해야 할 점이 있습니다. Depth Camera의 좌표계가 ROS 2 좌표계와 일치하지 않아 해당 joint angle을 통해 offset해야 합니다.\n\u0026lt;link name=\u0026#34;camera_rgb_optical_frame\u0026#34; /\u0026gt; \u0026lt;joint name=\u0026#34;camera_rgb_optical_joint\u0026#34; type=\u0026#34;fixed\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;-1.57079632679 0 -1.57079632679\u0026#34; xyz=\u0026#34;0 0 0\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;camera_rgb_frame\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;camera_rgb_optical_frame\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; Depth Camera Parameter는 Mono Camera와 차이나는 부분을 살펴봅시다. \u0026lt;gazebo reference=\u0026#34;depth_camera_link\u0026#34;\u0026gt; \u0026lt;sensor name=\u0026#34;front_depth_camera\u0026#34; type=\u0026#34;depth\u0026#34;\u0026gt; ... \u0026lt;plugin filename=\u0026#34;libgazebo_ros_camera.so\u0026#34; name=\u0026#34;camera_controller\u0026#34;\u0026gt; \u0026lt;ros\u0026gt; \u0026lt;!-- \u0026lt;namespace\u0026gt;custom_ns\u0026lt;/namespace\u0026gt; --\u0026gt; \u0026lt;remapping\u0026gt;front_depth_camera/image_raw:=front_depth_camera/image_raw\u0026lt;/remapping\u0026gt; \u0026lt;remapping\u0026gt;front_depth_camera/image_depth:=front_depth_camera/image_depth\u0026lt;/remapping\u0026gt; \u0026lt;remapping\u0026gt;front_depth_camera/camera_info:=front_depth_camera/camera_info\u0026lt;/remapping\u0026gt; \u0026lt;remapping\u0026gt;front_depth_camera/camera_info_depth:=front_depth_camera/camera_info_depth\u0026lt;/remapping\u0026gt; \u0026lt;remapping\u0026gt;front_depth_camera/points:=front_depth_camera/points\u0026lt;/remapping\u0026gt; \u0026lt;/ros\u0026gt; \u0026lt;camera_name\u0026gt;front_depth_camera\u0026lt;/camera_name\u0026gt; \u0026lt;frame_name\u0026gt;depth_camera_optical_link\u0026lt;/frame_name\u0026gt; \u0026lt;hack_baseline\u0026gt;0.07\u0026lt;/hack_baseline\u0026gt; \u0026lt;min_depth\u0026gt;0.001\u0026lt;/min_depth\u0026gt; \u0026lt;max_depth\u0026gt;300.0\u0026lt;/max_depth\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/sensor\u0026gt; \u0026lt;/gazebo\u0026gt; Parameter Description type=\u0026ldquo;depth\u0026rdquo; min_depth, max_depth depth 최소, 최대 탐지거리 image_depth depth image topic이며, camera_info_depth depth camera의 정보를 담고 있는 topic입니다. points pointcloud data topic으로 XYZ와 RGB가 결합된 데이터를 얻게 됩니다. xacro 파일 변경 후 Gazebo 예제 실행 sensor_stick.xacro의 line 13을 보면 다른 plugin들을 사용하는 추가 xacro file들을 나눠둔 것을 확인할 수 있습니다. sensor_stick_mono ⇒ sensor_stick_depth로 토글링한 뒤 다시 launch 해봅시다.\nros2 launch basic_stick sensor_stick.launch.py 다음으로 2D/3D 라이다 데이터를 연동해봅시다. 라이다는 바퀴를 가진 fusionbot으로 실습해 보겠습니다.\n2D lidar plugin \u0026lt;gazebo reference=\u0026#34;lidar\u0026#34;\u0026gt; \u0026lt;sensor name=\u0026#34;lidar\u0026#34; type=\u0026#34;ray\u0026#34;\u0026gt; \u0026lt;pose\u0026gt;0 0 0 0 0 0\u0026lt;/pose\u0026gt; \u0026lt;always_on\u0026gt;1\u0026lt;/always_on\u0026gt; \u0026lt;visualize\u0026gt;1\u0026lt;/visualize\u0026gt; \u0026lt;update_rate\u0026gt;10\u0026lt;/update_rate\u0026gt; \u0026lt;ray\u0026gt; \u0026lt;scan\u0026gt; \u0026lt;horizontal\u0026gt; \u0026lt;samples\u0026gt;360\u0026lt;/samples\u0026gt; \u0026lt;resolution\u0026gt;1.000000\u0026lt;/resolution\u0026gt; \u0026lt;min_angle\u0026gt;-3.14159\u0026lt;/min_angle\u0026gt; \u0026lt;max_angle\u0026gt;3.14159\u0026lt;/max_angle\u0026gt; \u0026lt;/horizontal\u0026gt; \u0026lt;/scan\u0026gt; \u0026lt;range\u0026gt; \u0026lt;min\u0026gt;0.2\u0026lt;/min\u0026gt; \u0026lt;max\u0026gt;10.0\u0026lt;/max\u0026gt; \u0026lt;resolution\u0026gt;0.05\u0026lt;/resolution\u0026gt; \u0026lt;/range\u0026gt; \u0026lt;noise\u0026gt; \u0026lt;type\u0026gt;gaussian\u0026lt;/type\u0026gt; \u0026lt;mean\u0026gt;0.0\u0026lt;/mean\u0026gt; \u0026lt;stddev\u0026gt;0.01\u0026lt;/stddev\u0026gt; \u0026lt;/noise\u0026gt; \u0026lt;/ray\u0026gt; \u0026lt;plugin filename=\u0026#34;libgazebo_ros_ray_sensor.so\u0026#34; name=\u0026#34;scan\u0026#34;\u0026gt; \u0026lt;ros\u0026gt; \u0026lt;remapping\u0026gt;~/out:=scan\u0026lt;/remapping\u0026gt; \u0026lt;/ros\u0026gt; \u0026lt;output_type\u0026gt;sensor_msgs/LaserScan\u0026lt;/output_type\u0026gt; \u0026lt;frame_name\u0026gt;lidar\u0026lt;/frame_name\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/sensor\u0026gt; \u0026lt;/gazebo\u0026gt; Parameter Description type=\u0026ldquo;ray\u0026rdquo; samples 라이다의 샘플 수를 지정합니다. 지금은 360개의 point를 각 1도씩 매핑해서 360도를 스캔하게 됩니다. resolution 스캔 해상도로 단위는 각도입니다. min_angle / max_angle 최대, 최소 각도이며 지금은 -180 ~ 180 즉 360도를 스캔합니다. range 탐지거리의 범위, 해상도를 정의합니다. scan 라이다의 스캔 결과는 기본적으로 scan이라는 topic으로 publish 됩니다. output_type ROS 2에서 사용하는 2D 라이다 데이터로 기본은 sensor_msgs/msg/LaserScan입니다. 예제 실행 ros2 launch fusionbot_description sensor_gz.launch.py 3D Lidar plugin ⇒ 2D lidar와 plugin은 같지만, vertical이라는 속성이 추가됩니다.\n이 센서는 연산량이 많아 gpu 버전을 별도로 제공하고 있습니다.\n\u0026lt;!-- Gazebo requires the velodyne_gazebo_plugins package --\u0026gt; \u0026lt;gazebo reference=\u0026#34;velodyne\u0026#34;\u0026gt; \u0026lt;sensor type=\u0026#34;gpu_ray\u0026#34; name=\u0026#34;block_laser_sensor\u0026#34;\u0026gt; \u0026lt;ray\u0026gt; \u0026lt;scan\u0026gt; \u0026lt;horizontal\u0026gt; \u0026lt;samples\u0026gt;1200\u0026lt;/samples\u0026gt; \u0026lt;resolution\u0026gt;1\u0026lt;/resolution\u0026gt; \u0026lt;min_angle\u0026gt;-3.141592653589793\u0026lt;/min_angle\u0026gt; \u0026lt;max_angle\u0026gt;3.141592653589793\u0026lt;/max_angle\u0026gt; \u0026lt;/horizontal\u0026gt; \u0026lt;vertical\u0026gt; \u0026lt;samples\u0026gt;64\u0026lt;/samples\u0026gt; \u0026lt;resolution\u0026gt;1\u0026lt;/resolution\u0026gt; \u0026lt;min_angle\u0026gt;-0.436322083\u0026lt;/min_angle\u0026gt; \u0026lt;max_angle\u0026gt;0.2617993877991494\u0026lt;/max_angle\u0026gt; \u0026lt;/vertical\u0026gt; \u0026lt;/scan\u0026gt; \u0026lt;range\u0026gt; \u0026lt;min\u0026gt;0.3\u0026lt;/min\u0026gt; \u0026lt;max\u0026gt;201.0\u0026lt;/max\u0026gt; \u0026lt;resolution\u0026gt;0.001\u0026lt;/resolution\u0026gt; \u0026lt;/range\u0026gt; \u0026lt;!-- Using gazebo\u0026#39;s noise instead of plugin\u0026#39;s --\u0026gt; \u0026lt;noise\u0026gt; \u0026lt;type\u0026gt;gaussian\u0026lt;/type\u0026gt; \u0026lt;mean\u0026gt;0.0\u0026lt;/mean\u0026gt; \u0026lt;stddev\u0026gt;0.0\u0026lt;/stddev\u0026gt; \u0026lt;/noise\u0026gt; \u0026lt;/ray\u0026gt; \u0026lt;!-- Using gazebo\u0026#39;s update rate instead of plugin\u0026#39;s --\u0026gt; \u0026lt;update_rate\u0026gt;30\u0026lt;/update_rate\u0026gt; \u0026lt;plugin name=\u0026#34;gazebo_ros_block_laser_controller\u0026#34; filename=\u0026#34;libgazebo_ros_ray_sensor.so\u0026#34;\u0026gt; \u0026lt;!-- Change namespace and output topic so published topic is /rrbot/laser/pointcloud --\u0026gt; \u0026lt;ros\u0026gt; \u0026lt;!-- \u0026lt;namespace\u0026gt;/rrbot/laser\u0026lt;/namespace\u0026gt; --\u0026gt; \u0026lt;remapping\u0026gt;~/out:=pointcloud\u0026lt;/remapping\u0026gt; \u0026lt;/ros\u0026gt; \u0026lt;!-- Set output to sensor_msgs/PointCloud to get same output type as gazebo_ros_block_laser --\u0026gt; \u0026lt;output_type\u0026gt;sensor_msgs/PointCloud2\u0026lt;/output_type\u0026gt; \u0026lt;!-- \u0026lt;frame_name\u0026gt; ommited, will default to block_laser_link --\u0026gt; \u0026lt;!-- min_intensity instead of hokuyoMinIntensity --\u0026gt; \u0026lt;min_intensity\u0026gt;100.0\u0026lt;/min_intensity\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/sensor\u0026gt; \u0026lt;/gazebo\u0026gt; Parameter Description type=\u0026ldquo;ray\u0026rdquo; horizontal 라이다의 수직 샘플링 속성을 지정합니다. 3D Lidar는 기본적으로 2D lidar를 쌓아둔 것과 유사한 원리를 갖습니다. pointcloud 라이다의 스캔 결과는 topic 이름입니다. sensor_msgs/PointCloud2 ROS 2에서 사용하는 2D 라이다 데이터로 기본은 sensor_msgs/msg/PointCloud입니다. 하지만 foxy 이후부터 PointCloud2를 사용하고 있습니다. min_intensity PointCloud의 특성 중 물체의 성질에 따라 달라지는 intensity가 있습니다. 이에 대한 임계값입니다. xacro 파일 변경 후 Gazebo 예제 실행 ros2 launch fusionbot_description sensor_gz.launch.py 과제를 통해 위 작업을 충분히 연습해보고 넘어가고자 합니다. ⇒ 직접, basic stick을 sensor stick으로 변환해 보세요!\nGazebo Movement Plugin 지금까지 살펴보았던 gazebo 예시들은 모두 정적인 로봇 + 센서였습니다. 사실 로봇 시뮬레이션은 물체의 정확한 위치와 상태를 알 수 있기 때문에 알고리즘의 검증을 위해 사용됩니다. 이번 시간에는 Gazebo상 물체의 움직임과 관련된 plugin들을 살펴봅시다.\nDiff Drive Controller 로봇 청소기와 같이 제자리 회전이 가능하며, 양쪽 바퀴 회전수 차이로 로봇을 이동시키는 타입을 DD Type이라고 부릅니다. 일전 fusionbot이 여기에 해당합니다. 이 모델이 하도 많이 사용되어서 그런지 gazebo_ros 차원에서 plugin을 제공하고 있습니다.\n예시 실행 전 plugin 적용을 위해 fusionbot_description/urdf/fusionbot.urdf.xacro 파일에서 line 5, include line 주석을 해제합니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;robot name=\u0026#34;fusionbot\u0026#34; xmlns:xacro=\u0026#34;http://www.ros.org/wiki/xacro\u0026#34;\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find fusionbot_description)/urdf/materials.xacro\u0026#34; /\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find fusionbot_description)/urdf/fusionbot.gazebo\u0026#34; /\u0026gt; 수정, 저장 후 예시를 다시 실행해봅시다. ros2 launch fusionbot_description gz.launch.py dd controller plugin이 제공하는 topic들을 확인해봅시다. $ ros2 topic list /clock /cmd_vel /front_camera/camera_info /front_camera/image_raw /joint_states /odom /parameter_events /performance_metrics /robot_description /rosout /scan /tf /tf_static Topic Name Description /cmd_vel 로봇 제어를 위한 topic으로 geometry_msgs/msg/Twist 타입을 갖습니다. /odom 로봇의 위치와 속도, 방향을 모두 포함하는 odometry data topic 입니다. /tf tf2 data로 odom 및 fixed tf2들이 publish 됩니다. /joint_states 로봇 바퀴가 굴러감에 따라 변화하는 joint angle들을 publish 합니다. rqt_robot_steering을 통해 로봇을 제어해봅시다. rqt_robot_steering ⇒ 일전 껍데기에 불과했던 fusionbot이 어떻게 제어될 수 있었는지 과정을 설명해보겠습니다.\nurdf 폴더에 2가지 plugin을 추가하고, 매개변수를 맞춰줍니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34; ?\u0026gt; \u0026lt;robot name=\u0026#34;fusionbot\u0026#34; xmlns:xacro=\u0026#34;http://www.ros.org/wiki/xacro\u0026#34; \u0026gt; \u0026lt;gazebo\u0026gt; \u0026lt;plugin name=\u0026#39;fusionbot_joint_state\u0026#39; filename=\u0026#39;libgazebo_ros_joint_state_publisher.so\u0026#39;\u0026gt; \u0026lt;ros\u0026gt; \u0026lt;remapping\u0026gt;~/out:=joint_states\u0026lt;/remapping\u0026gt; \u0026lt;/ros\u0026gt; \u0026lt;update_rate\u0026gt;30\u0026lt;/update_rate\u0026gt; \u0026lt;joint_name\u0026gt;right_wheel_joint\u0026lt;/joint_name\u0026gt; \u0026lt;joint_name\u0026gt;left_wheel_joint\u0026lt;/joint_name\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;gazebo\u0026gt; \u0026lt;plugin name=\u0026#39;differential_drive_controller\u0026#39; filename=\u0026#39;libgazebo_ros_diff_drive.so\u0026#39;\u0026gt; \u0026lt;update_rate\u0026gt;30\u0026lt;/update_rate\u0026gt; \u0026lt;left_joint\u0026gt;left_wheel_joint\u0026lt;/left_joint\u0026gt; \u0026lt;right_joint\u0026gt;right_wheel_joint\u0026lt;/right_joint\u0026gt; \u0026lt;wheel_separation\u0026gt;0.2\u0026lt;/wheel_separation\u0026gt; \u0026lt;wheel_diameter\u0026gt;0.1\u0026lt;/wheel_diameter\u0026gt; \u0026lt;max_wheel_torque\u0026gt;50\u0026lt;/max_wheel_torque\u0026gt; \u0026lt;max_wheel_acceleration\u0026gt;1.0\u0026lt;/max_wheel_acceleration\u0026gt; \u0026lt;command_topic\u0026gt;cmd_vel\u0026lt;/command_topic\u0026gt; \u0026lt;publish_odom\u0026gt;1\u0026lt;/publish_odom\u0026gt; \u0026lt;publish_odom_tf\u0026gt;1\u0026lt;/publish_odom_tf\u0026gt; \u0026lt;publish_wheel_tf\u0026gt;0\u0026lt;/publish_wheel_tf\u0026gt; \u0026lt;odometry_topic\u0026gt;odom\u0026lt;/odometry_topic\u0026gt; \u0026lt;odometry_frame\u0026gt;odom\u0026lt;/odometry_frame\u0026gt; \u0026lt;robot_base_frame\u0026gt;base_footprint\u0026lt;/robot_base_frame\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;/robot\u0026gt; libgazebo_ros_joint_state_publisher Description remapping ?? data type을 갖는 joint state topic 이름을 remapping 합니다. update_rate joint state topic의 publish rate joint_name tracking할 joint들이며 DD robot은 좌-우 2개가 될 것입니다. libgazebo_ros_diff_drive Description update_rate state topic publish rate left_joint, right_joint DD type 로봇 URDF에서 좌-우 joint를 적어줍니다. wheel_separation 좌-우 바퀴 사이의 거리 wheel_diameter 바퀴의 지름 max_\u0026ldquo;value\u0026rdquo; 제어와 관련된 물성치입니다. 정확하게 하고 싶다면 실제 모터 스펙을 통해 맞춰줍니다. command_topic Twist type을 갖는 로봇 제어 topic으로, 기본값은 cmd_vel입니다. publish_odom odometry topic의 publish 여부 publish_odom_tf odometry tf2의 broadcast 여부 (topic과 tf2는 다른 개념입니다!) publish_wheel_tf 양쪽 바퀴의 tf2 publish 여부 odometry_topic odometry topic name odometry_frame odometry tf2 broadcast 시 사용될 이름 robot_base_frame 로봇 tf2가 시작되는 기준 frame rviz2를 통해 odometry topic을 시각화해봅시다. Differential Drive Type은 Gazebo에서 기본 제공하지만, 이는 gazebo_ros가 만들어지기 전, Gazebo 개발자들이 로봇 예시를 위해 만들어둔 것일 뿐입니다. 따라서 좀 더 모던한 ros2_control 사용을 권장합니다.\nGazebo State Plugin 일전 tf2 예시에서 사용되었던, 마치 행성과 위성 같은 시뮬레이션 기억하시나요? ros2 launch tf2_world tf2_world.launch.py 이 예시에서 gazebo_ros의 기본 topic을 통해 매우 정확한 위치 데이터를 사용하였습니다. $ ros2 topic list /clock /link_states /model_states /parameter_events /performance_metrics /rosout 이러한 topic들을 사용하고 싶다면, gazebo world file에 libgazebo_ros_state plugin을 추가하면 됩니다. Multi Object Spawning 여러대의 로봇, 여러개의 동일한 센서를 시뮬레이션하고 싶은 경우를 다뤄봅시다.\n준비된 예시의 역분석을 통해 학습해보고자 합니다. 우선 예시를 실행해봅시다. ros2 launch chess_world chess_world.launch.py 체스보드 양쪽으로 동일한 realsense camera가 등장한 것을 볼 수 있습니다.\n이 예시를 역으르 해석해가면서 multi object 상황에 대한 gazebo환경에 대해 학습해보겠습니다. launch file 분석 urdf 분석 gazebo plugin 분석 launch file 분석 - chess_world.launch.py cam1_spawn = robot_spawn_nodes(0, \u0026#34;camera_left.urdf.xacro\u0026#34;, pkg_path) cam2_spawn = robot_spawn_nodes(1, \u0026#34;camera_right.urdf.xacro\u0026#34;, pkg_path) return LaunchDescription( [ arg_show_rviz, start_gazebo_server_cmd, start_gazebo_client_cmd, static_transform_publisher, *cam1_spawn, *cam2_spawn, rviz_node, ] ) ⇒ 하나의 object 시뮬레이션을 위해 필요한 node들을 묶어 함수화하고, 이를 통해 cam1_spawn, cam2_spawn을 만들었습니다.\n다시 robot_spawn_nodes 함수를 살펴봅시다. return [ robot_state_publisher, spawn_entity, ] 서로 다른 urdf file을 사용하기 때문에 robot_state_publisher가, 로봇을 등장시키는 과정이 반복되어야 하기 때문에 spawn_entity가 포함되어 있습니다.\n사용할 xacro file과 spawn 위치를 매개변수로 받아 실행되는 구조입니다. 더욱이, 여기서 주목해야 할 점은 namespace를 사용하였다는 점입니다. def robot_spawn_nodes(id, xacro_name, pkg_path): # Get URDF via xacro robot_description_content = Command( [ PathJoinSubstitution([FindExecutable(name=\u0026#34;xacro\u0026#34;)]), \u0026#34; \u0026#34;, PathJoinSubstitution( [FindPackageShare(\u0026#34;chess_world\u0026#34;), \u0026#34;urdf\u0026#34;, xacro_name] ), ] ) robot_description = {\u0026#34;robot_description\u0026#34;: robot_description_content} ... # Spawn Robot spawn_entity = Node( package=\u0026#39;gazebo_ros\u0026#39;, executable=\u0026#39;spawn_entity.py\u0026#39;, namespace=f\u0026#39;camera_{id}\u0026#39;, arguments=[ \u0026#39;-topic\u0026#39;, \u0026#39;robot_description\u0026#39;, \u0026#39;-entity\u0026#39;, f\u0026#39;d435_camera_{id}\u0026#39;, \u0026#39;-x\u0026#39;, str(0), \u0026#39;-y\u0026#39;, str(0.0), \u0026#39;-Y\u0026#39;, str(0.0), ], output=\u0026#39;screen\u0026#39; ) camera_right.urdf.xacro \u0026amp; camera_left.urdf.xacro ⇒ 링크를 통해 이 둘을 비교해봅시다. ⇒ camera_right.urdf.xacro / camera_left.urdf.xacro\n⇒ 반복되는 구문을 함수화하고, 기능상의 on/off를 변수화하여 별도 관리하고 있습니다. xacro의 사용이 아주 빛나는 상황입니다.\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;robot xmlns:xacro=\u0026#34;http://ros.org/wiki/xacro\u0026#34; name=\u0026#34;camera_\u0026lt;\u0026gt;\u0026#34;\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find chess_world)/urdf/sensors/_d415.urdf.xacro\u0026#34;/\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find chess_world)/urdf/sensors/cam_holder.urdf.xacro\u0026#34;/\u0026gt; \u0026lt;link name=\u0026#34;chess_frame\u0026#34; /\u0026gt; \u0026lt;!-- sets camera frame w.r.t. to chess frame--\u0026gt; \u0026lt;!-- set only the color camera and a slow frame rate - an image each 5 seconds)--\u0026gt; \u0026lt;xacro:sensor_d415 name=\u0026#34;camera_\u0026lt;\u0026gt;\u0026#34; parent=\u0026#34;chess_frame\u0026#34; flag_color=\u0026#34;1\u0026#34; flag_ir=\u0026#34;0\u0026#34; flag_depth=\u0026#34;0\u0026#34; updaterate=\u0026#34;10\u0026#34;\u0026gt; \u0026lt;origin xyz=\u0026#34;? ? ?\u0026#34; rpy=\u0026#34;? ? ?\u0026#34; /\u0026gt; \u0026lt;/xacro:sensor_d415\u0026gt; \u0026lt;!-- result from calib --\u0026gt; \u0026lt;!-- sets cam holder w.r.t to camera--\u0026gt; \u0026lt;xacro:cam_holder name=\u0026#34;camera_\u0026lt;\u0026gt;_holder\u0026#34; parent=\u0026#34;camera_\u0026lt;\u0026gt;_link\u0026#34;\u0026gt; \u0026lt;origin xyz=\u0026#34;0.0 -0.020 0.0115\u0026#34; rpy=\u0026#34;0 -1.161379 0\u0026#34; /\u0026gt; \u0026lt;/xacro:cam_holder\u0026gt; \u0026lt;/robot\u0026gt; 각각의 xacro file내에는 변화하는 부분을 변수로 두어 상위 xacro에서 매개변수를 전달하기만 하면 언제든 독립된 모델을 만들 수 있도록 설계되었습니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;robot name=\u0026#34;cam_holder\u0026#34; xmlns:xacro=\u0026#34;http://ros.org/wiki/xacro\u0026#34;\u0026gt; \u0026lt;xacro:macro name=\u0026#34;cam_holder\u0026#34; params=\u0026#34;name parent *origin\u0026#34;\u0026gt; ... \u0026lt;robot name=\u0026#34;sensor_d415\u0026#34; xmlns:xacro=\u0026#34;http://ros.org/wiki/xacro\u0026#34;\u0026gt; \u0026lt;xacro:macro name=\u0026#34;sensor_d415\u0026#34; params=\u0026#34;name parent flag_color flag_ir flag_depth updaterate *origin\u0026#34;\u0026gt; ⇒ 이러한 이유에서 xacro의 사용이 권장됩니다.\n실제 에시를 실행하여 topic list를 조회해보아도 겹치는 이름 없이 잘 실행되는 모습을 확인 가능합니다. $ ros2 topic list /camera_0/joint_states /camera_0/robot_description /camera_1/joint_states /camera_1/robot_description /camera_left/color/camera_info /camera_left/color/image_raw /camera_right/color/camera_info /camera_right/color/image_raw /clicked_point /clock /goal_pose /initialpose /parameter_events /performance_metrics /rosout /tf /tf_static 더욱이 tf2 tree도 완벽하게 구성되어 rviz2에서의 시각화도 문제없습니다. 다른 World 가져와서 써보기 이번에는, 오픈소스 프로젝트를 활용하여 나만의 world를 만드는 방법에 대해 학습해보겠습니다.\n예시 실행 $ ros2 launch lidar_world lidar_world.launch.py ⇒ 해당 world는 제가 youtube 검색을 통해 괜찮다고 생각되어 직접 수정해본 것입니다. (물론 라이센스는 지켜야 합니다.) youtube link\nyoutube link를 통해 접근할 수 있는 해당 프로젝트 코드를 분석해봅시다. ⇒ 사용된 패키지는 총 5개 입니다. 이들 중 gazebo와 관련이 깊을 것 같은 robot_gazebo 패키지에서 launch file을 분석합니다.\nrobot_sim.launch.py return LaunchDescription([ IncludeLaunchDescription( PythonLaunchDescriptionSource( os.path.join(pkg_gazebo_ros, \u0026#39;launch\u0026#39;, \u0026#39;gzserver.launch.py\u0026#39;) ), launch_arguments={\u0026#39;world\u0026#39;: world}.items(), ), IncludeLaunchDescription( PythonLaunchDescriptionSource( os.path.join(pkg_gazebo_ros, \u0026#39;launch\u0026#39;, \u0026#39;gzclient.launch.py\u0026#39;) ), ), IncludeLaunchDescription( PythonLaunchDescriptionSource( os.path.join(pkg_cart_pole_control, \u0026#39;launch\u0026#39;, \u0026#39;robot_control.launch.py\u0026#39;) ), ), IncludeLaunchDescription( PythonLaunchDescriptionSource([launch_file_dir, \u0026#39;/robot_state_publisher.launch.py\u0026#39;]), launch_arguments={\u0026#39;use_sim_time\u0026#39;: use_sim_time}.items(), ), Node( package = \u0026#34;joy\u0026#34;, executable = \u0026#34;joy_node\u0026#34; ), ]) 우리가 관심있는 것은 world file의 위치이며, 이렇게 찾은 lio_world.model을 gazebo_ros가 아닌 일반 Gazebo로 로컬 실행시켜봅니다. gazebo lio_world.model ⇒ 아마 실행되지 않을 것입니다. lio_world.model에서는 gazebo 기본 model이 아닌 커스텀 모델들이 사용되고 있는데, 이들을 Gazebo 환경변수에 추가해주어야 하기 때문입니다.\n따라서 나만의 패키지를 구성하고, 이 world를 다시 실행시켜봅니다. 패키지 생성 launch file 생성, world file, models file 복사 CMakeLists.txt 수정 패키지 빌드 후, 실행 이전에 배운 sensor plugin, urdf, sensor stick, moving stick을 모두 활용해서 여러분만의 camera \u0026amp; lidar world를 만들어 보세요!! - 과제입니다.\n⇒ 제가 만든 World를 참고하셔도 좋지만 직접 해보시기를 권장드립니다.\n⇒ object animation은 다음 링크를 참고합니다. link\n"
},
{
	"uri": "/kr/ros2_foxy/lecture13/",
	"title": "Lecture13. Useful ROS 2 Examples (Sensor Part)",
	"tags": [],
	"description": "",
	"content": "Useful ROS 2 Examples (Sensor Part) Topic, Service, Action, Gazebo 예시들을 진행하면서 다양한 센서 데이터들을 다루어보았습니다. 이번 시간에는 예시들과 함께 해당 센서 데이터들의 ROS 2 연동 프로그램을 작성해 보겠습니다.\nCV2 and ROS 2 다양한 컴퓨터 비전 알고리즘을 담고 있는 오픈소스 비전 라이브러리인 OpenCV를 ROS 2와 연동하여 사용해 봅시다.\ncv2 and rclpy 첫번째 시간으로 ROS 2의 이미지 데이터를 OpenCV Python, cv2와 연동하는 방법에 대해 알아보겠습니다.\nImage Publish - Python 우선, 항상 그렇듯이 예시를 실행해 보겠습니다. 온라인상에서 아무 영상 하나를 다운받아 위치를 기억해주세요. img_pub.py 코드의 VIDEO_FILE_ROOT 변수를 해당 위치로 변경해줍니다. # Import the necessary libraries import rclpy # Python Client Library for ROS 2 from rclpy.node import Node # Handles the creation of nodes from sensor_msgs.msg import Image # Image is the message type from cv_bridge import CvBridge # Package to convert between ROS and OpenCV Images import cv2 # OpenCV library VIDEO_FILE_ROOT = \u0026#34;/home/kimsooyoung/ros2_ws/rosbag2/img_pub_test.mp4\u0026#34; 패키지를 빌드한 뒤, 예시를 실행합니다. # Terminal 1 - pkg build and run cbp py_cv_tutorial \u0026amp;\u0026amp; source install/local_setup.bash ros2 run py_cv_tutorial img_pub # Terminal 2 - rqt_image_view ros2 run rqt_image_view rqt_image_view ⇒ rqt image view는 이미지 topic만을 위한 rqt tool로 이미지 데이터를 시각화해줍니다.\n코드 분석 OpenCV에서는 이미지 데이터를 다룰 때 cv::Mat를 사용합니다. 반면 ROS 2는 sensor_msgs/msg/Image를 사용합니다. 따라서 Image \u0026lt;=\u0026gt; Mat 변환을 위해 CV Bridge를 사용합니다. from cv_bridge import CvBridge # Package to convert between ROS and OpenCV Images import cv2 # OpenCV library class ImagePublisher(Node): \u0026#34;\u0026#34;\u0026#34; Create an ImagePublisher class, which is a subclass of the Node class. \u0026#34;\u0026#34;\u0026#34; def __init__(self): ... # Used to convert between ROS and OpenCV images self.br = CvBridge() def timer_callback(self): ... if ret == True: # Publish the image. # The \u0026#39;cv2_to_imgmsg\u0026#39; method converts an OpenCV # image to a ROS 2 image message self.publisher_.publish(self.br.cv2_to_imgmsg(frame, encoding=\u0026#34;bgr8\u0026#34;)) ⇒ CvBridge 객체의 imgmsg_to_cv2를 사용하면 손쉽게 Image data로 변환이 가능합니다.\nImage Subscribe - Python 일전 학습하였던 rosbag2을 사용하여 예시를 실행해보고자 합니다. 제가 미리 준비한 데이터셋을 제공드리니, 기억하기 쉬운 위치에 다운받아 주세요.\n📁 quadrupped_train.zip\nWindows + WSL2 유저의 경우 explorer.exe 명령어를 통해 파일 탐색기를 열 수 있습니다.\n파일을 적당한 위치에 저장하고 replay 해봅시다. # 예제 실행 준비 colcon build --packages-select py_cv_tutorial source install/local_setup.bash # Terminal 1 – 데이터 위치로 이동하여 ros2 bag 실행 cd \u0026lt;데이터를 저장한 위치\u0026gt; ros2 bag play quadrupped_train.bag_0.db3 # Terminal 2 – image_view 실행 ros2 run rqt_image_view rqt_image_view 사진과 같이 기차 선로 모습이 보인다면 성공입니다.\n해당 데이터셋은 기차 선로에서 주행하는 4족 보행 로봇으로부터 취득한 것입니다. 기차 선로는 주기적으로 관리가 필요하며, 길고 긴 선로를 로봇이 자동으로 검사해준다면 아주 유용할 것입니다. 이러한 상상을 해보면서 실습에 임해봅시다.\n다음은 ros2 bag을 재생하면서 생기는 Image topic을 subscribe한 뒤, 이를 cv2.imshow()로 시각화하는 예시입니다. # Terminal 1 $ cd \u0026lt;bag 파일 위치\u0026gt; $ ros2 bag play quadruped_train/quadruped_train.bag_0.db3 [INFO] [1667077909.362223100] [rosbag2_storage]: Opened database \u0026#39;quadrupped_train/quadrupped_train.bag_0.db3\u0026#39; for READ_ONLY. ... # Terminal 2 $ ros2 run py_cv_tutorial img_sub [INFO] [1667077909.613586300] [image_subscriber]: Receiving video frame [INFO] [1667077910.934147000] [image_subscriber]: Receiving video frame ... 이번에는 ROS2 msg를 cv데이터 포멧으로 변환해야 하지요? cv_bridge를 통해 imgmsg_to_cv2 함수를 실행하여 이 작업을 수행합니다. from cv_bridge import CvBridge # Package to convert between ROS and OpenCV Images import cv2 # OpenCV library class ImageSubscriber(Node): def __init__(self): # Used to convert between ROS and OpenCV images self.br = CvBridge() ... def listener_callback(self, data): ... # Convert ROS Image message to OpenCV image current_frame = self.br.imgmsg_to_cv2(data, \u0026#34;bgr8\u0026#34;) edge_frame = self.hough_transform(current_frame) imgmsg_to_cv2를 통해 CV::Mat으로 변환된 이미지 데이터를 OpenCV의 다양한 기능들과 함께 사용할 수 있습니다. 코드의 imshow 부분을 위와 같이 주석 토글하여 이미지 처리를 적용해 봅시다. 예시를 위해 직선검출 알고리즘을 사용해 보았습니다. 직선 검출을 위해 사용된 OpenCV 기능들은 아래와 같습니다. 로직을 업그레이드하여 여러분만의 로직을 만들어 보세요!\ncv2.GaussianBlur cv2.fillPoly / cv2.bitwise_and ROI 설정 cv2.HoughLinesP rosbag2 to seperate image 컴퓨터 비전만으로 완벽한 선로 인식을 구현하기는 너무나 힘듭니다. 딥러닝을 사용해서 이를 극복할 수 있을 것이며, 데이터셋의 제작을 위해 rosbag2 데이터에서 이미지를 추출하는 예시를 준비하였습니다.\n$ ros2 run py_cv_tutorial rosbag2_to_timedimg /home/kimsooyoung/ros2_ws/rosbag2/quadrupped_train/quadrupped_train.bag_0.db3 saved: color_1666796292992515592.png saved: color_1666796293035428479.png saved: color_1666796293079139778.png saved: color_1666796293120768031.png saved: color_1666796293161406687.png ... 예제 실행 전 main 함수에서 bag 파일의 위치를 여러분의 것으로 수정해야 합니다. def main(args=None): # Change below roots to your ros2 bag locations ROOT_DIR = \u0026#34;/home/kimsooyoung/ros2_ws/rosbag2/quadrupped_train\u0026#34; FILENAME = \u0026#34;/quadrupped_train.bag_0.db3\u0026#34; DESCRIPTION = \u0026#34;color_\u0026#34; 예제 실행 후 사진과 같이 생성된 이미지들이 보인다면 성공입니다. wsl을 사용중이신 분들은 아래와 같이 파일 탐색기를 사용하세요 CV2 and rclcpp 파이썬을 통해 ROS 2와 OpenCV를 연동하는 기본적인 맥락은 이해하셨으리라 생각합니다. 동일한작업을 C++에서 작업하면서 몇가지 유의점을 살펴보겠습니다.\n코딩을 시작하기 전에, 제가 사용한 opencv 버전을 확인하고 가겠습니다. $ pkg-config --modversion opencv4 4.2.0 Image Publish - Python 이번에 사용되는 파일은 img_pub.cpp이며, 정상 실행을 위해 VIDEO_FILE_ROOT 변수를 여러분의 영상 경로로 수정합니다. #include \u0026#34;rclcpp/rclcpp.hpp\u0026#34; #include \u0026#34;std_msgs/msg/header.hpp\u0026#34; #include \u0026#34;sensor_msgs/msg/image.hpp\u0026#34; // cv_bridge converts between ROS 2 image messages and OpenCV image representations. #include \u0026lt;cv_bridge/cv_bridge.h\u0026gt; // Using image_transport allows us to publish and subscribe to compressed image streams in ROS2 #include \u0026lt;image_transport/image_transport.hpp\u0026gt; // We include everything about OpenCV as we don\u0026#39;t care much about compilation time at the moment. #include \u0026lt;opencv2/opencv.hpp\u0026gt; const std::string VIDEO_FILE_ROOT = \u0026#34;/home/kimsooyoung/ros2_ws/go1_lidar.mp4\u0026#34;; 예시 자체는 python과 동일합니다. # Terminal 1 - run demo ros2 run cpp_cv_tutorial img_pub # Terminal 2 - rqt_image_view ros2 run rqt_image_view rqt_image_view c++에서는 CvImage 객체를 굳이 생성해야 할 필요 없이 toImageMsg를 사용해 변환합니다. 대신 실제 msg로 사용할 때는 get() 함수를 통한 forwarding이 필요합니다. #include \u0026lt;cv_bridge/cv_bridge.h\u0026gt; #include \u0026lt;image_transport/image_transport.hpp\u0026gt; #include \u0026lt;opencv2/opencv.hpp\u0026gt; ... void timer_callback() { // // Create a new 640x480 image // cv::Mat my_image(cv::Size(640, 480), CV_8UC3); //--- GRAB AND WRITE LOOP cap.read(my_img); if (my_img.empty()){ std::cerr \u0026lt;\u0026lt; \u0026#34;ERROR! blank frame grabbed\\n\u0026#34;; rclcpp::shutdown(); } // Write message to be sent. Member function toImageMsg() converts a CvImage // into a ROS image message img_msg = cv_bridge::CvImage(std_msgs::msg::Header(), \u0026#34;bgr8\u0026#34;, my_img).toImageMsg(); // Publish the image to the topic defined in the publisher image_pub-\u0026gt;publish(*img_msg.get()); } Image Subscribe - Python 예제 실행을 위해 gazebo world를 실행해보겠습니다. ros2 launch chess_world chess_world.launch.py 사용하고 싶은 topic 이름을 img_sub.cpp에 반영한 뒤 예시를 실행합니다. class ImageSubscriber : public rclcpp::Node{ private: rclcpp::Subscription\u0026lt;Image\u0026gt;::SharedPtr m_img_sub; rclcpp::Publisher\u0026lt;Image\u0026gt;::SharedPtr m_img_pub; public: ImageSubscriber(): Node(\u0026#34;image_subscriber\u0026#34;){ std::string topic_name = \u0026#34;video_frames\u0026#34;; m_img_sub = this-\u0026gt;create_subscription\u0026lt;Image\u0026gt;( topic_name, 10, std::bind(\u0026amp;ImageSubscriber::image_cb, this, std::placeholders::_1) ); 예시 실행 - 아마 단순 이미지 프레임만 반복될 것입니다. ros2 run cpp_cv_tutorial img_sub 이번 예시는 일종의 template 처럼 작성해보았습니다. image topic을 받아 프로세싱을 거치고 이 결과를 화면에 보여주는 예시입니다. cv::Mat image_processing(const cv::Mat img_in){ // Create output image cv::Mat img_out; cv::Mat img_small; ... return img_out; } void image_cb(const Image::SharedPtr msg) const{ // Convert ROS Image to CV Image cv::Mat frame = cv_bridge::toCvCopy( msg, sensor_msgs::image_encodings::BGR8 )-\u0026gt;image; // Image processing cv::Mat proced_img = image_processing(frame); } 현 시스템에서 OpenCV는 CMake의 find_package를 사용할 수 있기 때문에 C++ 예시를 빌드할 때 CMakeLists.txt에서 ament_target_dependencies를 명시합니다. find_package(OpenCV REQUIRED) add_executable(img_pub src/img_pub.cpp) ament_target_dependencies(img_pub rclcpp std_msgs sensor_msgs cv_bridge image_transport OpenCV) add_executable(img_sub src/img_sub.cpp) ament_target_dependencies(img_sub rclcpp std_msgs sensor_msgs cv_bridge image_transport OpenCV) PCL and ROS 2 이번 시간부터 3D PointCloud Data 처리를 위한 다양한 기능을 제공하는 PCL(Point Cloud Library)을 실습하고 ROS 2와 연동해보고자 합니다.\n사실 기본적인 PCL에 대한 이해가 있다면 일전 cv2 예시처럼 ROS 2 ⇒ PCL, PCL ⇒ ROS 2의 Mapping 작업만 잘 수행하면 되는데요. 따라서 python, c++에서 pcl을 다루는 방법에 대해 먼저 익숙해진 뒤 ROS 2에서 이를 구현하는 방식으로 진행하겠습니다.\nAbout Point Cloud Point Cloud Data는 수많은 3차원 상의 데이터들이 모인 집합체입니다. ⇒ 하지만 x,y,z를 비롯해서 Point Cloud의 추가 데이터 항목들이 있습니다. 자주 사용되는 point cloud 포멧들을 살펴봅시다.\nPointXYZ 가장 많이 사용하는 기본 데이터 타입으로 xyz 위치 데이터만 담고 있습니다.\nPointXYZI intensity라는 필드가 추가된 형태로 이는 물체로부터 되돌아온 빛의 양을 뜻합니다. 바닥에 고인 물이나 투명한 물체의 경우 이 I 필드를 통해 detection 가능하여 최근 활발히 연구되고 있습니다.\nPointXYZRGB RGB 3색이 포함된 데이터 타입으로 rgbd camera에서 주로 사용됩니다.\nPCD Format Point Cloud는 여러 데이터 포맷으로 사용 가능하지만 가장 자주 사용되는 것은 pcd 포맷입니다. 이는 크게 header/data로 구분되어 있으며 예시를 통해 함께 익숙해져보겠습니다.\nDescription Header 전체 포인트 수, 데이터 타입, 크기 등의 정보 Data x,y,z 또는 x,y,z + 추가정보 example - xyzrgb format # .PCD v0.7 - Point Cloud Data file format VERSION 0.7 FIELDS x y z rgb SIZE 4 4 4 4 TYPE F F F U COUNT 1 1 1 1 WIDTH 4421 HEIGHT 1 VIEWPOINT 0 0 0 1 0 0 0 POINTS 4421 DATA ascii -0.8739934 -1.342802 0.73930842 1577997 -0.86556709 -1.342802 0.73930842 1577997 -0.85433203 -1.3428019 0.73930848 1577997 -0.84450132 -1.3428019 0.73930854 1577997 ROS 2에서 사용하는 PointCloud 데이터 포맷은 크게 두가지가 있습니다. sensor_msgs/msg/PointCloud std_msgs/Header header geometry_msgs/Point32[] points ChannelFloat32[] channels sensor_msgs/msg/PointCloud2 std_msgs/Header header uint32 height uint32 width PointField[] fields bool is_bigendian # Is this data bigendian? uint32 point_step # Length of a point in bytes uint32 row_step # Length of a row in bytes uint8[] data # Actual point data, size is (row_step*height) bool is_dense # True if there are no invalid points PointCloud2가 더욱 풍부한 데이터를 담고 있는데요. ROS 2 Foxy 이상부터 PointCloud2를 지원하며 그 이후 버전부터 PointCloud는 거의 사용하지 않습니다.\nPCL 설치 PCL c++은 ROS 2 설치 시 자동으로 설치되므로 별도 설치는 필요 없습니다. (오히려 잘못 건들면 복잡해지므로 가만히 냅둡시다.) PCL python은 ubuntu 버전에 따라 설치 방법이 다릅니다.\nubuntu ≤ 18.04 $ sudo pip install cython $ sudo apt-get install pcl-tools $ sudo apt install python3-pcl $ sudo add-apt-repository ppa:sweptlaser/python3-pcl $ sudo apt update $ sudo apt install python3-pcl ubuntu ≥ 20.04 $ sudo apt install python3-pcl 설치가 잘 되었는지 확인해봅시다. $ python3 Python 3.8.10 [GCC 9.4.0] on linux Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt; import pcl \u0026gt;\u0026gt;\u0026gt; PCL python 아래 표와 같이 pcl은 다양한 알고리즘을 API 형태로 제공하고 있습니다. 이들에 익숙해지기 위해 python pcl을 사용하여 실습을 해본 뒤, 실제 ROS 2 topic을 처리해보고, c++로도 사용해보겠습니다.\nFuction Description pcl_visualization PointCloud 시각화 도구 pcl_surface 3차원 곡면 복원 pcl_segmentation PointCloud의 Clustering과 Classification 기능 pcl_sample_consensus 선, 평면, 실린더 등 모델 추정을 위한 알고리즘 pcl_kdtree 빠른 처리, 탐색을 위한 자료 구조 pcl_features PointCloud로부터 특징 추출을 위한 자료 구조와 방법들 pcl_registration ICP와 같이 서로 다른 PointCloud를 Align하고 정합하기 위한 방법들 pcl_keypoints Key point 검출 알고리즘 (BRISK, Harris Corner, NARF, SIFT, SUSAN 등) pcl_io 3D 센서로부터 PointCloud 데이터를 직접 읽고 쓰기 위한 인터페이스 PCL IO pcd 포멧의 point cloud 데이터를 읽고, 저장하고, 시각화하는 방법은 아래와 같습니다. cd py_pcl_tutorial/exercise python3 example1_load_and_view.py example1_load_and_view.py import pcl import pcl.pcl_visualization # Load point cloud file cloud = pcl.load_XYZRGB(\u0026#39;./data/pcl_sub_node.pcd\u0026#39;) # Create pcl built-in viewer visual = pcl.pcl_visualization.CloudViewing() ##### Visualize APIs ##### # \u0026#39;ShowColorACloud\u0026#39;, # \u0026#39;ShowColorCloud\u0026#39;, # \u0026#39;ShowGrayCloud\u0026#39;, # \u0026#39;ShowMonochromeCloud\u0026#39;, # \u0026#39;WasStopped\u0026#39; filename = \u0026#39;example_save.pcd\u0026#39; pcl.save(cloud, filename) visual.ShowColorCloud(cloud, b\u0026#39;cloud\u0026#39;) v = True while v: v = not(visual.WasStopped()) pcl_sub_node.pcd는 lidar world에서 제가 미리 추출해 둔 pointcloud 입니다.\nDescription pcl.load_XYZRGB() pcd data를 load합니다. 단, 저장된 유형에 따라 load_XYZ, load_XYZI 등 사용하는 함수가 다릅니다. pcl.pcl_visualization.CloudViewing() 시각화를 위한 뷰어를 생성합니다. pcl.save(, ) 처리한 cloud를 저장합니다. Voxel Grid Sampling 수많은 point cloud들을 모두 각각 처리하는 것은 매우 많은 연산을 요합니다. 따라서 보통 이를 3차원 격자의 Voxel 형태로 Sampling 합니다. Voxel이란, 마치 게임 그래픽처럼 해상도를 낮춘 큐브이며 Voxel 내 점 군 유/무에 따라 중심점을 샘플링합니다.\nexample2_voxelgrid.py # Voxel Grid filter # Create a VoxelGrid filter object for our input point cloud vox = cloud.make_voxel_grid_filter() # Choose a voxel (also known as leaf) size # Note: this (1) is a poor choice of leaf size # Experiment and find the appropriate size! LEAF_SIZE = 0.01 # Set the voxel (or leaf) size vox.set_leaf_size(LEAF_SIZE, LEAF_SIZE, LEAF_SIZE) # Call the filter function to obtain the resultant downsampled point cloud cloud_voxed = vox.filter() LEAF_SIZE = 0.01\nLEAF_SIZE = 0.1\nPass Through Filter ROI(Region of Interest)를 설정하고 원하는 위치의 point cloud들만 추려내보겠습니다. 주로 바닥 지점이나, 테이블 위 물체에서 물체 부분만 추출하는 경우 사용됩니다.\nexample3_roi_filter.py # Pass Through filter passthrough = cloud_voxed.make_passthrough_filter() # Assign axis and range to the passthrough filter object. filter_axis = \u0026#39;z\u0026#39; passthrough.set_filter_field_name(filter_axis) axis_min = -1.1 axis_max = 1.1 passthrough.set_filter_limits(axis_min, axis_max) cloud_filtered = passthrough.filter() ⇒ 현재 z축을 기준으로 -1.1 ~ 1.1 영역을 필터링하였습니다. x y 축에 대해서도 동일 작업이 가능합니다.\nRANSAC Plane Fitting 직선은 2개의 매개변수로, 평면은 3개의 매개변수로 모델링할 수 있습니다. PCL에서는 이런 모델 기반 Consensus를 사용하는 가장 대표적인 예시인 RANSAC을 제공하고 있습니다.\nModel Hypothesis를 통해 매개변수를 구했다면, 해당 모델에 포함되는 inlier와 outlier를 추출할 수 있게 됩니다. 이때 inlier의 임계값으로 허용하는 최대 거리가 max_distance입니다. seg.segment()를 통해 도출한 inlier index 들로 기존 point cloud에서 inliner/outlier들을 추출할 수 있습니다. negative=True ⇒ outlier extraction negative=False ⇒ inlier extraction # RANSAC plane segmentation # Create the segmentation object seg = cloud_filtered.make_segmenter() # Set the model you wish to fit seg.set_model_type(pcl.SACMODEL_PLANE) seg.set_method_type(pcl.SAC_RANSAC) # Max distance for a point to be considered fitting the model # Experiment with different values for max_distance # for segmenting the table max_distance = 0.01 seg.set_distance_threshold(max_distance) # Call the segment function to obtain set of inlier indices and model coefficients inliers, coefficients = seg.segment() # Extract inliers extracted_inliers = cloud_filtered.extract(inliers, negative=True) 목적 자체는 바닥을 제거한다는 점에서 Pass Through Filter와 동일하지만, 사용되는 알고리즘에서 차이를 갖습니다.\nStatistical Outlier Removal Filter 실제 센서를 사용하다보면 사진과 같이 노이즈도 심하고, 의도치 않는 비정상적인 이상치가 발생합니다. PCL에서는 일종의 평균 필터를 통해 이를 제거하는 함수를 갖고 있습니다.\n# Much like the previous filters, we start by creating a filter object: outlier_filter = cloud_filtered.make_statistical_outlier_filter() # Set the number of neighboring points to analyze for any given point outlier_filter.set_mean_k(50) # Set threshold scale factor x = 1.0 # Any point with a mean distance larger than global (mean distance+x*std_dev) will be considered outlier outlier_filter.set_std_dev_mul_thresh(x) # Finally call the filter function for magic cloud_filtered = outlier_filter.filter() ⇒ 현재 우리 예시는 Gazebo에서 추출한지라 이 필터의 영향이 거의 없습니다. 따라서 예제 코드는 생략하겠습니다.\nKD-Tree Search KD-Tree는 Binary Tree를 응용한 K 차원의 자료 구조입니다. x,y,z 3차원에 대한 KD-Tree를 구축하고, 이 안에 모든 point들을 가지런히 추가해두면, 이후 거리 계산 등 연산 시 매우 빠른 탐색이 가능합니다.\n# create kd tree for the search method of extraction tree = extracted_inliers.make_kdtree() ⇒ XYZRGB 데이터는 make_kdtree_flann()이라는 함수를 사용합니다.\nEuclidean Clustering (DBSCAN) Point Cloud들을 분류하여 군집화를 해야 물체 인식과 추정이 가능합니다. 군집과 알고리즘에는 여러 종류가 있지만 이번 실습에서는 밀집도를 기준으로 분류하는 Euclidean Clustering을 사용하겠습니다.\n이 방식은 클러스터 수를 지정하지 않아도 알아서 클러스터 수도 결정하고, 불특정한 형상의 클러스터도 분류할 수 있습니다. 뿐만 아니라 노이즈에도 강인한 알고리즘입니다.\nexample5_clustering.py # Load point cloud file cloud = pcl.load_XYZRGB(\u0026#39;./data/pcl_sub_node.pcd\u0026#39;) # eliminate color from cloud for clustering while_cloud = XYZRGB_to_XYZ(cloud) ... # Create a cluster extraction object ec = extracted_inliers.make_EuclideanClusterExtraction() # Set tolerances for distance threshold # as well as minimum and maximum cluster size (in points) ec.set_ClusterTolerance(0.07) ec.set_MinClusterSize(10) ec.set_MaxClusterSize(25000) # Search the k-d tree for clusters ec.set_SearchMethod(tree) # Extract indices for each of the discovered clusters cluster_indices = ec.Extract() # Create Cluster-Mask Point Cloud to visualize each cluster separately get_color_list.color_list =[] cluster_color = get_color_list(len(cluster_indices)) # Assign a color corresponding to each segmented object in scene color_cluster_point_list = [] for j, indices in enumerate(cluster_indices): for i, indice in enumerate(indices): color_cluster_point_list.append([extracted_inliers[indice][0], extracted_inliers[indice][1], extracted_inliers[indice][2], rgb_to_float(cluster_color[j])]) #Create new cloud containing all clusters, each with unique color cluster_cloud = pcl.PointCloud_PointXYZRGB() cluster_cloud.from_list(color_cluster_point_list) 이전 예시와 달리, clustering을 위해 필요없는 색상 데이터는 제거하였습니다. # Load point cloud file cloud = pcl.load_XYZRGB(\u0026#39;./data/pcl_sub_node.pcd\u0026#39;) # eliminate color from cloud for clustering while_cloud = XYZRGB_to_XYZ(cloud) make_EuclideanClusterExtraction()을 통해 filter를 구성하고 매개변수를 설정합니다. # Create a cluster extraction object ec = extracted_inliers.make_EuclideanClusterExtraction() # Set tolerances for distance threshold # as well as minimum and maximum cluster size (in points) ec.set_ClusterTolerance(0.07) ec.set_MinClusterSize(10) ec.set_MaxClusterSize(25000) Description set_ClusterTolerance point clout 처리 시 cluster로 판단하는 기준 거리 set_MinClusterSize cluster가 되기 위한 최소 point cloud 개수 set_MaxClusterSize cluster가 되기 위한 최대 point cloud 개수 cluster를 판단하기 위해 거리계산이 필요하며, 이는 일전 생성한 KD tree를 사용합니다. ec.set_SearchMethod(tree) clustering의 결과는 point cloud set이 아니라 cluster와 이에 해당하는 point들의 index입니다. 따라서 extract 이후 별도의 후처리 과정이 필요합니다. 현재는 서로 다른 cluster 마다 색상을 부여하여 시각화하고 있습니다. # Extract indices for each of the discovered clusters cluster_indices = ec.Extract() # Create Cluster-Mask Point Cloud to visualize each cluster separately get_color_list.color_list =[] cluster_color = get_color_list(len(cluster_indices)) # Assign a color corresponding to each segmented object in scene color_cluster_point_list = [] for j, indices in enumerate(cluster_indices): for i, indice in enumerate(indices): color_cluster_point_list.append([extracted_inliers[indice][0], extracted_inliers[indice][1], extracted_inliers[indice][2], rgb_to_float(cluster_color[j])]) PCL python ROS 2 연동 지금까지 배운 내용들을 총동원해서 PCL를 ROS 2와 연동해보겠습니다.\n예시 실행 # Terminal 1 - gazebo world launch ros2 launch lidar_world lidar_world.launch.py # Terminal 2 - python node run ros2 run py_pcl_tutorial pcl_cluster_pub [INFO] [1682602819.908146533] [pcl_cluster_node]: PCL Cluster Node has been started rviz2를 통해 /cluster topic을 subscribe 하면, 사진과 같이 물체별로 다른 색상이 적용된 새로운 pointcloud topic을 확인할 수 있습니다.\n코드를 분석하기 전, 전체 시스템을 요약해보았습니다.\nROS 2의 PointCloud2 msg를 PCL 타입으로 변환합니다. PCL data와 일전 예시 코드를 통해 clustering을 구현합니다. 분리한 cluster들에 개별 색상을 부여하고, 다시 ROS 2 PointCloud2 타입으로 변환합니다. topic publish! ROS 2 ⇒ PCL / PCL ⇒ ROS 2 사이의 변환은 pcl_helper라는 별도 코드를 구현해 두었습니다. def ros2_to_pcl(ros_cloud): \u0026#34;\u0026#34;\u0026#34; Converts a ROS PointCloud2 message to a pcl PointXYZRGB Args: ros_cloud (PointCloud2): ROS PointCloud2 message Returns: pcl.PointCloud_PointXYZRGB: PCL XYZRGB point cloud \u0026#34;\u0026#34;\u0026#34; ... def pcl_to_ros2(pcl_array, now=None): \u0026#34;\u0026#34;\u0026#34; Converts a pcl PointXYZRGB to a ROS PointCloud2 message Args: pcl_array (PointCloud_PointXYZRGB): A PCL XYZRGB point cloud now (Time): A ROS 2 time object like self.get_clock().now() Returns: PointCloud2: A ROS point cloud \u0026#34;\u0026#34;\u0026#34; 주의해야 할 점으로, PCL ⇒ ROS 2 변환 시에는 시간에 대한 데이터가 추가되니 Node 내부의 clock에서 now 객체를 전달해야 합니다.\nPCLClusterNode의 생성자에서 subscriber와 publisher를 하나씩 생성합니다. class PCLClusterNode(Node): def __init__(self): super().__init__(\u0026#39;pcl_cluster_node\u0026#39;) self.pc_subscription = self.create_subscription( PointCloud2, \u0026#39;pointcloud\u0026#39;, self.pcl_callback, 10 ) self.cluster_publisher = self.create_publisher( PointCloud2, \u0026#39;cluster\u0026#39;, 10 ) subscription callback에서 대부분의 로직이 구현되어 있습니다. def pcl_callback(self, pcl_msg): # TODO: Convert ROS msg to PCL data pcl_data = ros2_to_pcl(pcl_msg) ... #Create new cloud containing all clusters, each with unique color cluster_cloud = pcl.PointCloud_PointXYZRGB() cluster_cloud.from_list(color_cluster_point_list) ... callback의 마지막에 pcl_to_ros2를 통해 전체 cluster를 PointCloud2 타입으로 변환한 뒤 publish합니다. # Convert PCL data to ROS 2 messages cluster_cloud_msg = pcl_to_ros2(cluster_cloud, now=self.get_clock().now()) self.cluster_publisher.publish(cluster_cloud_msg) "
},
{
	"uri": "/kr/ros2_foxy/lecture14/",
	"title": "Lecture14. Useful ROS 2 Examples (Control Part)",
	"tags": [],
	"description": "",
	"content": "Gazebo ROS 2 Control 지난 fusionbot 예시에서, Differential Drive만 예외적으로 gazebo pluin을 제공한다고 하였습니다. 일반적으로 Gazebo내에서 움직이는 (=모터를 가진) 모델을 구현하기 위해서는 gazebo_ros2_control을 사용합니다.\n다만, ROS 2 Control 전체 시스템을 이해하기 위해서는 상당한 배경 지식과 시간이 필요하므로, 이번 예시에서는 딱 하나, 위치 제어를 하는 가이드를 드리도록 하겠습니다.\n일전 sensor_stick의 URDF에는 tilt_joint라는 joint가 있었습니다. 우리의 목표는 이 tilt_joint를 말 그대로 기울여질 수 있게 해보는 것입니다. \u0026lt;joint name=\u0026#34;tilt_joint\u0026#34; type=\u0026#34;revolute\u0026#34;\u0026gt; \u0026lt;origin xyz=\u0026#34;0.05 0 ${length2/2+0.02}\u0026#34; rpy=\u0026#34;0 0.5 0\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;link_2\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;camera_link\u0026#34; /\u0026gt; \u0026lt;limit lower=\u0026#34;-1.5707\u0026#34; upper=\u0026#34;1.5707\u0026#34; effort=\u0026#34;10\u0026#34; velocity=\u0026#34;100\u0026#34; /\u0026gt; \u0026lt;axis xyz=\u0026#34;0 1 0\u0026#34;/\u0026gt; \u0026lt;/joint\u0026gt; 예시 실행 # Terminal 1 $ ros2 launch basic_stick moving_stick.launch.py \u0026gt; gazebo world 내에 table등 원하는 물체를 추가합니다. # Terminal 2 ros2 topic pub --once /forward_position_controller/commands std_msgs/msg/Float64MultiArray \u0026#34;data: - -0.1\u0026#34; 마지막 data value를 바꿔가면서 원하는 기울기로 조정해보세요!\ngazebo_ros의 ForwardCommandController를 사용하여 제작한 예시이며, ros2 control에 대해 학습하지 않았으므로, 이를 위한 절차만 간단히 설명드리겠습니다.\nURDF 내 움직일 수 있는 joint 추가 gazebo_ros2_control을 정의하는 xacro 추가 gazebo_ros2_control controller 매개변수를 정의하는 yaml file 추가 URDF 내 움직일 수 있는 joint 추가 \u0026lt;joint name=\u0026#34;tilt_joint\u0026#34; type=\u0026#34;revolute\u0026#34;\u0026gt; \u0026lt;origin xyz=\u0026#34;0.05 0 ${length2/2+0.02}\u0026#34; rpy=\u0026#34;0 0.5 0\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;link_2\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;camera_link\u0026#34; /\u0026gt; \u0026lt;limit lower=\u0026#34;-1.5707\u0026#34; upper=\u0026#34;1.5707\u0026#34; effort=\u0026#34;10\u0026#34; velocity=\u0026#34;100\u0026#34; /\u0026gt; \u0026lt;axis xyz=\u0026#34;0 1 0\u0026#34;/\u0026gt; \u0026lt;/joint\u0026gt; Description revolute 문고리와 같이 limit을 갖는 joint 입니다. limit - lower/upper revolute joint의 limit을 설정합니다. effort 최대 토크를 정의합니다. (이론은 모르셔도 됩니다. 지금은 적당히 넉넉히 해두었습니다.) velocity 최대 속도를 정의합니다. axis joint가 움직일 축 방향을 지정합니다. gazebo_ros2_control을 정의하는 xacro 추가 - ros2_control.gazebo.xacro이라는 이름으로 추가하였으며, 최소한의 내용만 짚고 넘어가겠습니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!-- ref github - diffbot_system.ros2_control.xacro --\u0026gt; \u0026lt;robot xmlns:xacro=\u0026#34;http://www.ros.org/wiki/xacro\u0026#34;\u0026gt; \u0026lt;ros2_control name=\u0026#34;GazeboSystem\u0026#34; type=\u0026#34;system\u0026#34;\u0026gt; \u0026lt;!-- Gazebo --\u0026gt; \u0026lt;hardware\u0026gt; \u0026lt;plugin\u0026gt;gazebo_ros2_control/GazeboSystem\u0026lt;/plugin\u0026gt; \u0026lt;/hardware\u0026gt; \u0026lt;joint name=\u0026#34;tilt_joint\u0026#34;\u0026gt; \u0026lt;command_interface name=\u0026#34;position\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;min\u0026#34;\u0026gt;-1.5707\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;max\u0026#34;\u0026gt;1.5707\u0026lt;/param\u0026gt; \u0026lt;/command_interface\u0026gt; \u0026lt;state_interface name=\u0026#34;position\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;initial_value\u0026#34;\u0026gt;0.0\u0026lt;/param\u0026gt; \u0026lt;/state_interface\u0026gt; \u0026lt;state_interface name=\u0026#34;velocity\u0026#34;/\u0026gt; \u0026lt;/joint\u0026gt; \u0026lt;/ros2_control\u0026gt; \u0026lt;gazebo\u0026gt; \u0026lt;plugin name=\u0026#34;gazebo_ros2_control\u0026#34; filename=\u0026#34;libgazebo_ros2_control.so\u0026#34;\u0026gt; \u0026lt;parameters\u0026gt;$(find basic_stick)/config/joint_controller.yaml\u0026lt;/parameters\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;/robot\u0026gt; Description joint name control이 필요한 joint name을 지정합니다. command_interface position 제어를 위해 name=position, 이에 따른 최대, 최소 각도를 지정합니다. state_interface topic을 통해 피드백받을 데이터 종류를 선택합니다. 지금은 위치 피드백을 받을 예정이며, 초기값을 0도로 두었습니다. plugin parameters controller 실행을 위해 추가로 필요한 매개변수들을 yaml file로 전달합니다. 이번 예시에서는 control, state feedback, 총 2개의 plugin이 사용됩니다. 각 pluin들에 대해서 필수로 정의해줘야 하는 매개변수들이 있으며, forward_position_controller의 경우 joints를 필요로 합니다. controller_manager: ros__parameters: update_rate: 100 # Hz joint_state_broadcaster: type: joint_state_broadcaster/JointStateBroadcaster forward_position_controller: type: forward_command_controller/ForwardCommandController forward_position_controller: ros__parameters: joints: - tilt_joint interface_name: position ⇒ 여기까지 한번에 완성되었다면, 매우 순조로운 것입니다. 보통 robot_state_publisher의 실행을 통해 하나씩 검증하며 개발이 이루어집니다.\n마지막으로, launch file을 살펴봅시다. ros2_control을 관리하는 controller_manager에게 필요한 plugin을 전달하면 spawner.py가 이들을 실행해주는 형태를 취하고 있습니다. fp_controller = Node( package=\u0026#34;controller_manager\u0026#34;, executable=\u0026#34;spawner.py\u0026#34;, arguments=[\u0026#34;forward_position_controller\u0026#34;], output=\u0026#34;screen\u0026#34;, ) jsb_controller = Node( package=\u0026#34;controller_manager\u0026#34;, executable=\u0026#34;spawner.py\u0026#34;, arguments=[\u0026#34;joint_state_broadcaster\u0026#34;], output=\u0026#34;screen\u0026#34;, ) 이번 예시와 지난 dataset_gen action 예시, 그리고 take picture service 예시와 my world 생성까지 모두 결합하면, 무궁무진한 여러분들만의 gazebo 센서 환경을 갖추실 수 있을 것입니다.\n"
},
{
	"uri": "/kr/ros2_foxy/lecture15/",
	"title": "Lecture15. Advanced ROS 2, Package Management",
	"tags": [],
	"description": "",
	"content": "ROS 2 Launch 심화 Launch arguments ROS 2 launch file은 파이썬 사용함에 따라 다양한 기능을 직접 구현할 수 있습니다. 다수 모델 사용 시 반복 내용을 함수로 만들 수도 있고, 외부 파일이나 패키지를 import 할 수도 있지요. launch 패키지에서는 자주 사용되는 기능들을 미리 제공하고 있습니다. 이러한 기능을 통해 launch file을 좀 더 풍성하게 만들어 봅시다.\n예제 실행 - use_rviz launch 옵션을 사용해봅시다. ros2 launch src_gazebo empty_world.launch.py use_rviz:=true ros2 launch src_gazebo empty_world.launch.py use_rviz:=false ⇒ use_rviz 값에 따라 rviz2 실행 여부가 결정됩니다.\n이러한 launch argument는 LaunchConfiguration, DeclareLaunchArgument을 사용하여 구현할 수 있습니다. from launch.actions import DeclareLaunchArgument from launch.substitutions import LaunchConfiguration def generate_launch_description(): namespace = LaunchConfiguration(\u0026#39;namespace\u0026#39;) declare_namespace_cmd = DeclareLaunchArgument( \u0026#39;namespace\u0026#39;, default_value=\u0026#39;my_robot\u0026#39;, description=\u0026#39;Top-level namespace\u0026#39; ) return LaunchDescription( [ declare_namespace_cmd, ] ) Description LaunchConfiguration 생성할 argument의 이름을 넣어주면 argument 객체가 반환됩니다. DeclareLaunchArgument default_value를 통해 argument의 기본값을, description을 통해 설명을 적어둡니다. declare_namespace_cmd LaunchDescription에게 생성된 argument 객체를 전달해야 비로소 사용이 가능합니다. declare_namespace_cmd의 값을 보고 싶은 경우가 있습니다. 하지만 이 객체 자체는 str 매직 메소드가 구현되어 있는 것이 아니어 print시 아래와 같은 결과를 얻습니다. print(declare_namespace_cmd) \u0026gt;\u0026gt;\u0026gt; result \u0026lt;launch.actions.declare_launch_argument.DeclareLaunchArgument object at 0x7fc89a164730\u0026gt; 하지만 launch argument의 값을 볼 수 있는 LogInfo라는 기능이 제공되고 있습니다. message_info = LogInfo(msg=LaunchConfiguration(\u0026#39;namespace\u0026#39;)) return LaunchDescription( [ declare_namespace_cmd, message_info, ] ) LaunchDescription에 객체들을 넣어줄 때 순서에 주의합니다.\nLogInfo 결과를 직접 확인해봅시다. $ ros2 launch advanced_tutorial launch_arg_info.launch.py [INFO] [launch]: Default logging verbosity is set to INFO [INFO] [launch.user]: my_robot 실제 오픈소스 프로젝트를 살펴보아도 이러한 Launch argument를 수도 없이 확인할 수 있습니다. 아래 예시는 자율 주행을 위한 메타페키지인 nav2의 launch example입니다. def generate_launch_description(): # Get the launch directory bringup_dir = get_package_share_directory(\u0026#39;nav2_bringup\u0026#39;) launch_dir = os.path.join(bringup_dir, \u0026#39;launch\u0026#39;) # Create the launch configuration variables namespace = LaunchConfiguration(\u0026#39;namespace\u0026#39;) use_namespace = LaunchConfiguration(\u0026#39;use_namespace\u0026#39;) slam = LaunchConfiguration(\u0026#39;slam\u0026#39;) map_yaml_file = LaunchConfiguration(\u0026#39;map\u0026#39;) use_sim_time = LaunchConfiguration(\u0026#39;use_sim_time\u0026#39;) params_file = LaunchConfiguration(\u0026#39;params_file\u0026#39;) autostart = LaunchConfiguration(\u0026#39;autostart\u0026#39;) use_composition = LaunchConfiguration(\u0026#39;use_composition\u0026#39;) use_respawn = LaunchConfiguration(\u0026#39;use_respawn\u0026#39;) log_level = LaunchConfiguration(\u0026#39;log_level\u0026#39;) Timer Action 대규모 gazebo 파일을 불러오거나, urdf에 수많은 mesh가 결합되어 있는 경우, 프로세스 로딩에 상당한 시간이 소요될 수 있습니다. Timer Action은 일정 시간동안 대기 이벤트를 걸 수 있어 이러한 상황을 다루기 용이합니다.\nfrom launch.actions import TimerAction ... # Launch RViz rviz2 = Node( package=\u0026#34;rviz2\u0026#34;, executable=\u0026#34;rviz2\u0026#34;, name=\u0026#34;rviz2\u0026#34;, output=\u0026#34;screen\u0026#34;, arguments=[\u0026#34;-d\u0026#34;, rviz_config_file], ) ... return LaunchDescription([ TimerAction( period=3.0, actions=[rviz2] ), ⇒ urdf 로딩이 끝난 뒤 rviz2를 실행하도록 해둔 예시입니다.\nOnProcessExit node 실행 시 순서를 지켜야 하는 경우 ex - model spawn 후 센서 데이터 처리 등 RegisterEventHandler와 OnProcessExit를 통해 실행 순서 로직을 구현할 수 있습니다.\nfrom launch.actions import RegisterEventHandler from launch.event_handlers import OnProcessExit 저의 경우 ros2_control을 사용할 때 주로 사용하고 있습니다. return LaunchDescription([ declare_use_rviz, RegisterEventHandler( event_handler=OnProcessExit( target_action=spawn_entity, on_exit=[load_joint_state_broadcaster], ) ), RegisterEventHandler( event_handler=OnProcessExit( target_action=load_joint_state_broadcaster, on_exit=[load_forward_position_controller], ) ), Description target_action 먼저 완료되어야 하는 Node on_exit target_action 종료 후 실행되어야 하는 Node IncludeLaunchDescription launch file은 매우 유연한 구현이 가능하도록 지원되며, 하나의 launch file에서 다른 launch file을 추가하는 것도 가능합니다. from launch.actions import IncludeLaunchDescription 예를 들면, gazebo 상의 로봇을 위한 부분과 실제 로봇을 다루는 부분을 별도의 launch file로 분리한 뒤, main launch file에서는 이 둘을 스위칭하는 방식으로 구현할 수 있을 것입니다. def generate_launch_description(): launch_test_pkg = get_package_share_directory(\u0026#39;launch_test_pkg\u0026#39;) robot_spawn = IncludeLaunchDescription( PythonLaunchDescriptionSource( os.path.join(launch_test_pkg, \u0026#39;launch\u0026#39;,\u0026#39;robot_spawn.launch.py\u0026#39;))) rviz_launch = IncludeLaunchDescription( PythonLaunchDescriptionSource( os.path.join(launch_test_pkg, \u0026#39;launch\u0026#39;, \u0026#39;start_rviz.launch.py\u0026#39;))) return LaunchDescription([ robot_spawn, rviz_launch, ]) IfCondition, UnlessCondition 조건문에 따라 정해진 Node가 실행되도록 할 수도 있습니다. 이를 위해 IfCondition과 UnlessCondition을 사용합니다. from launch.conditions import IfCondition, UnlessCondition 아래 예시를 보면, Node =\u0026gt; condition 항목에 execute LaunchConfiguration이 삽입된 모습을 볼 수 있으며, execute 값에 따라 turtlesim_node의 실행 여부를 관리할 수 있게 됩니다. def generate_launch_description(): execute = LaunchConfiguration(\u0026#39;execute\u0026#39;) declare_execute_cmd = DeclareLaunchArgument( \u0026#39;execute\u0026#39;, default_value=\u0026#39;true\u0026#39;, description=\u0026#39;whether to use namespace or not\u0026#39; ) turtlesim_node = Node( package = \u0026#39;turtlesim\u0026#39;, executable = \u0026#39;turtlesim_node\u0026#39;, name = \u0026#39;turtlesim_node\u0026#39;, output=\u0026#39;screen\u0026#39;, condition=IfCondition(execute), ) return LaunchDescription( [ declare_execute_cmd, turtlesim_node, ] ) 실제 예시를 통해 실습해봅시다. $ ros2 launch advanced_tutorial ifcondition.launch.py execute:=false [INFO] [launch]: All log files can be found below /home/kimsooyoung/.ros/log/2023-04-25-15-14-32-373647-kimsooyoung-XPS-13-9370-6088 [INFO] [launch]: Default logging verbosity is set to INFO GroupAction 관련된 Node, launch file들을 한데 묶어 공통된 속성을 부여할 시 GroupAction을 사용하며, 주로 namespace를 지정할 때 많이 사용됩니다. turtle_group = GroupAction([ PushRosNamespace( condition=IfCondition(use_namespace), namespace=namespace ), turtlesim에 namespace를 적용하는 실습을 해보겠습니다. $ ros2 launch advanced_tutorial group_action.launch.py $ ros2 topic list /parameter_events /rosout /turtle1/cmd_vel /turtle1/color_sensor /turtle1/pose ⇒ 별도 namespace 지정이 없으면 위와 같은 rqt_graph를 확인할 수 있습니다.\nlaunch argument를 통해 namespace를 적용시킨 뒤, topic list와 rqt_graph를 살펴봅시다. $ ros2 launch advanced_tutorial group_action.launch.py use_namespace:=true namespace:=my_turtle $ ros2 topic list /my_turtle/turtle1/cmd_vel /my_turtle/turtle1/color_sensor /my_turtle/turtle1/pose /parameter_events /rosout /my_turtle namespace가 적용된 모습을 확인할 수 있습니다. 👍\nExecutor and CallbackGroup 실제 센서, 제어기를 개발 하다보면 기존 코드와 ROS 2 코드를 연동해야 할 일이 많습니다. 기존 코드가 병렬 연산 형태로 개발되었다면 ROS 2의 Spin과 맞물려 Dead Lock이 발생할 수 있습니다. 이러한 경우를 다루기 위해 ROS 2의 Executor와 CallbackGroup에 대해 알아봅시다.\n이번 튜토리얼은 모두 c++로 진행됩니다.\n예시 package를 build하고 sourcing 합시다. cbp cpp_multiproc_tutorial \u0026amp;\u0026amp; source install/local_setup.bash Dead Lock Example 예시를 실행해보면서 발생할 수 있는 문제상황을 고려해봅시다. $ ros2 run cpp_multiproc_tutorial dead_lock [INFO] [1682404393.717961395] [deadlock_example]: timer_cb_1 [INFO] [1682404398.718512552] [deadlock_example]: timer_cb_2 [INFO] [1682404400.719076263] [deadlock_example]: timer_cb_1 [INFO] [1682404405.719559218] [deadlock_example]: timer_cb_2 [INFO] [1682404407.719972272] [deadlock_example]: timer_cb_1 [INFO] [1682404412.720329962] [deadlock_example]: timer_cb_2 [INFO] [1682404414.720709183] [deadlock_example]: timer_cb_1 ⇒ timer_cb_1이 5초 동안 sleep하는 동안 시스템을 독식해버립니다.\n실제 코드는 다음과 같이 5초마다 timer_cb_1을, 2초마다 timer_cb_2를 실행하는 것이 목표였습니다. void timer_cb_1(){ RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;timer_cb_1\u0026#34;); // assume that something logic happens here std::this_thread::sleep_for(5s); } void timer_cb_2(){ RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;timer_cb_2\u0026#34;); // assume that something logic happens here std::this_thread::sleep_for(2s); } 여기에서, 아래와 같이 timer 주기를 5초, 2초라고 수정하면 동작은 잘 됩니다. 하지만, 이는 지금 우리가 원하는 상황을 표현하지 못합니다. 우리가 가정하는 상황은, timer callback안에서, ROS 2가 아닌 다른 무언가의 코드가 시스템을 점유하는 상황입니다. DeadLockNode() : Node(\u0026#34;deadlock_example\u0026#34;){ timer_1 = this-\u0026gt;create_wall_timer( 5s, std::bind(\u0026amp;DeadLockNode::timer_cb_1, this) ); timer_2 = this-\u0026gt;create_wall_timer( 2s, std::bind(\u0026amp;DeadLockNode::timer_cb_2, this) ); } main문은 다음과 같습니다. (rclcpp의 Default Executor인 Single Threaded Executor가 실행될 것입니다. int main(int argc, char **argv){ rclcpp::init(argc, argv); rclcpp::spin(std::make_shared\u0026lt;DeadLockNode\u0026gt;()); rclcpp::shutdown(); return 0; } MultiThreadedExecutor rclcpp의 Executor는 그림과 같이 크게 3종류를 제공합니다. 지금까지는 기본인 SingleThreaded를 사용하였지만, MultThreaded도 사용해보겠습니다. 과연 문제를 해결해 줄 수 있을까요? main 문을 수정하고 다시 컴파일 =\u0026gt; 실행해봅시다. int main(int argc, char * argv[]){ rclcpp::init(argc, argv); std::cout \u0026lt;\u0026lt; \u0026#34;Max CPU Core : \u0026#34; \u0026lt;\u0026lt; std::thread::hardware_concurrency() \u0026lt;\u0026lt; std::endl; rclcpp::executors::MultiThreadedExecutor executor(rclcpp::executor::ExecutorArgs(), 2); auto test_node = std::make_shared\u0026lt;DeadLockNode\u0026gt;(); executor.add_node(test_node); executor.spin(); rclcpp::shutdown(); return 0; } 예시 실행 (8코어 랩탑에서 실행하였습니다.) $ ros2 run cpp_multiproc_tutorial multi_executor Max CPU Core : 8 [INFO] [1682404852.346859530] [deadlock_example]: timer_cb_1 [INFO] [1682404857.348183807] [deadlock_example]: timer_cb_1 [INFO] [1682404862.348802309] [deadlock_example]: timer_cb_1 [INFO] [1682404867.349427033] [deadlock_example]: timer_cb_1 [INFO] [1682404872.349906028] [deadlock_example]: timer_cb_1 [INFO] [1682404877.350774188] [deadlock_example]: timer_cb_1 [INFO] [1682404882.351478568] [deadlock_example]: timer_cb_1 [INFO] [1682404887.352284317] [deadlock_example]: timer_cb_1 [INFO] [1682404892.352806238] [deadlock_example]: timer_cb_1 ⇒ 여전히 timer_cb_1이 시스템을 독식하고 있습니다.\n이렇게 되는 이유가 무엇일까요??\n현재 상황을 그림으로 표현해보면 다음과 같습니다. 비록 multi-threaded executor가 실행되어 작업자가 3명이 있더라도 작업 라인이 1개밖에 없어 효율적이지 못한 것이지요. Callback Group 이를 해결하는 방법은 각각의 timer 마다 독립적인 작업 라인을 구축하는 것입니다. 그리고 이를 위해 rclcpp에서는 Callback Group이라는 API를 제공하고 있습니다. class DeadLockNode : public rclcpp::Node{ private: rclcpp::TimerBase::SharedPtr timer_1; rclcpp::TimerBase::SharedPtr timer_2; rclcpp::CallbackGroup::SharedPtr cb_group_1; rclcpp::CallbackGroup::SharedPtr cb_group_2; 각각의 Callback에 독립적인(MutuallyExclusive) Group을 구축하여 Executor들이 개별 Group을 다루도록 해봅시다. cb_group_1 = this-\u0026gt;create_callback_group( rclcpp::CallbackGroupType::MutuallyExclusive ); cb_group_2 = this-\u0026gt;create_callback_group( rclcpp::CallbackGroupType::MutuallyExclusive ); timer_1 = this-\u0026gt;create_wall_timer( 200ms, std::bind(\u0026amp;DeadLockNode::timer_cb_1, this), cb_group_1 ); timer_2 = this-\u0026gt;create_wall_timer( 200ms, std::bind(\u0026amp;DeadLockNode::timer_cb_2, this), cb_group_2 ); 사용하는 CPU 코어는 2개로 맞춰주겠습니다. ... rclcpp::executors::MultiThreadedExecutor executor( rclcpp::executor::ExecutorArgs(), 2 ); auto test_node = std::make_shared\u0026lt;DeadLockNode\u0026gt;(); 실행 결과, timer_cb_1은 5초마다, timer_cb_2는 2초마다 잘 실행되는 것이 확인됩니다! 계속 실행되면서 약간의 오차가 있지만 이는 timer call 주기 때문입니다. $ ros2 run cpp_multiproc_tutorial callback_group Max CPU Core : 8 [INFO] [1682405209.687586816] [deadlock_example]: timer_cb_1 [INFO] [1682405209.687668485] [deadlock_example]: timer_cb_2 [INFO] [1682405211.688211586] [deadlock_example]: timer_cb_2 [INFO] [1682405213.688626203] [deadlock_example]: timer_cb_2 [INFO] [1682405214.689019990] [deadlock_example]: timer_cb_1 [INFO] [1682405215.690033260] [deadlock_example]: timer_cb_2 [INFO] [1682405217.690549333] [deadlock_example]: timer_cb_2 [INFO] [1682405219.689435329] [deadlock_example]: timer_cb_1 [INFO] [1682405219.691070145] [deadlock_example]: timer_cb_2 ... 지금 상황을 아까의 그림에 다시 비유해봅시다. Task들이 독자적인 Callback Group에서 실행되고, 각 Callback Group을 담당하는 Process가 있기 때문에 Delay 없이 모든 작업이 수월하게 실행됩니다. ReentrantCallbackGroup rclcpp에서 제공하는 또다른 Callback Group Option, Reentrant가 있습니다. 이를 사용해봅시다.\nreference : https://docs.ros2.org/eloquent/api/rclcpp/namespacerclcpp_1_1callback__group.html\nReentrant CallbackGroupType은 이름과 같이 Process와 Callback을 조율하여 가장 효율적인 실행을 제공합니다. 때문에 여러 callback이 같은 Group Option을 공유해도 문제 없습니다. public: DeadLockNode() : Node(\u0026#34;deadlock_example\u0026#34;){ cb_group_1 = this-\u0026gt;create_callback_group( rclcpp::CallbackGroupType::Reentrant ); cb_group_2 = cb_group_1; 예시를 실행해봅시다. 별도 Group이 아니더라도 모든 Callback이 잘 실행됩니다. $ ros2 run cpp_multiproc_tutorial reentrant_callback_group Max CPU Core : 8 [INFO] [1682405497.174734254] [deadlock_example]: timer_cb_1 [INFO] [1682405497.174845897] [deadlock_example]: timer_cb_2 [INFO] [1682405499.175241117] [deadlock_example]: timer_cb_2 [INFO] [1682405501.175422765] [deadlock_example]: timer_cb_2 [INFO] [1682405502.175086294] [deadlock_example]: timer_cb_1 [INFO] [1682405503.175637456] [deadlock_example]: timer_cb_2 [INFO] [1682405505.175894939] [deadlock_example]: timer_cb_2 ... 하지만, Reentrant CallbackGroupType도 사용하는 프로세서 자체가 적으면 Dead lock에 빠집니다. class ReentrantNode : public rclcpp::Node{ private: rclcpp::TimerBase::SharedPtr timer_1; rclcpp::TimerBase::SharedPtr timer_2; rclcpp::TimerBase::SharedPtr timer_3; rclcpp::CallbackGroup::SharedPtr cb_group_1; rclcpp::CallbackGroup::SharedPtr cb_group_2; rclcpp::CallbackGroup::SharedPtr cb_group_3; void timer_cb_3(){ RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;timer_cb_3\u0026#34;); // assume that something logic happens here std::this_thread::sleep_for(1s); } ... rclcpp::executors::MultiThreadedExecutor executor( rclcpp::executor::ExecutorArgs(), 1 ); 예시 실행 결과 $ ros2 run cpp_multiproc_tutorial reentrant_limited Max CPU Core : 8 [INFO] [1682405732.583538668] [deadlock_example]: timer_cb_1 [INFO] [1682405737.584007252] [deadlock_example]: timer_cb_2 [INFO] [1682405739.584306750] [deadlock_example]: timer_cb_3 [INFO] [1682405740.585280574] [deadlock_example]: timer_cb_1 [INFO] [1682405745.585707617] [deadlock_example]: timer_cb_2 [INFO] [1682405747.586083455] [deadlock_example]: timer_cb_3 [INFO] [1682405748.586534268] [deadlock_example]: timer_cb_1 ... ⇒ 본디 timer_cb_3는 1초마다 실행되어야 하는데 Dead Lock에 빠짐을 볼 수 있습니다.\nCore 3개로 늘려주면 정상 작동하는지 확인해봅시다. rclcpp::executors::MultiThreadedExecutor executor( rclcpp::executor::ExecutorArgs(), 3 ); 예시 실행 결과 $ ros2 run cpp_multiproc_tutorial reentrant_limited Max CPU Core : 8 [INFO] [1682405809.551428499] [deadlock_example]: timer_cb_1 [INFO] [1682405809.551649918] [deadlock_example]: timer_cb_2 [INFO] [1682405809.551742931] [deadlock_example]: timer_cb_3 [INFO] [1682405810.552612691] [deadlock_example]: timer_cb_3 [INFO] [1682405811.552408971] [deadlock_example]: timer_cb_2 [INFO] [1682405811.552878292] [deadlock_example]: timer_cb_3 [INFO] [1682405812.553239899] [deadlock_example]: timer_cb_3 [INFO] [1682405813.552785030] [deadlock_example]: timer_cb_2 [INFO] [1682405813.553579643] [deadlock_example]: timer_cb_3 [INFO] [1682405814.552104332] [deadlock_example]: timer_cb_1 [INFO] [1682405814.553891457] [deadlock_example]: timer_cb_3 Intra-process communication and Node Composition ROS 2 개발을 일반적으로 Node의 결합으로 이루어집니다.이를 통해 모듈화, 코드 재사용이 가능하지만 성능 저하가 초래되는 경우가 많습니다. ROS 1에서는 Nodelet이라는 것으로 이를 해결하고자 하였는데, 이는 기본적으로 하나의 프로세스에서 다수의 Node를 구현하고자 하는 작업입니다.\n이러한 작업을 통해 메모리 최적화와 동적 Node load / unload가 가능한 것이지요. 그리고 이를 이어받은 ROS 2에서는 Node Composition이라는 이름으로 같은 기능을 제공하고 있습니다.\n예시를 통해 Node Composition이 왜 필요한지 살펴봅시다. ros2 run composition_tutorial image_pipeline_all_in_one ⇒ 현재 3개의 Node가 실행중에 있습니다. 각각의 Node로 Image data가 전송되고 있지요.\n⇒ 이미지에 찍힌 데이터 주소에 주목합시다.\n이번에는 다른 상황을 실행해보겠습니다. ros2 launch composition_tutorial image_pipeline_extra.launch.py Node를 거치면서 메모리 생성, 복사가 반복되기 때문에 주소가 모두 다른 것을 확인할 수 있습니다.\n실제 top을 통해 메모리 효율을 비교해보겠습니다. PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 927 kimsooy+ 20 0 625328 86892 47116 S 17.9 0.5 1:18.92 Xorg 1217 kimsooy+ 20 0 4604400 269984 111132 S 13.6 1.7 1:45.35 gnome-shell 4095 kimsooy+ 20 0 1565920 102108 73140 S 11.9 0.6 0:01.13 image_pipeline_ PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 927 kimsooy+ 20 0 607300 86892 47116 R 18.8 0.5 1:11.38 Xorg 2332 kimsooy+ 20 0 1130.9g 258892 126436 S 16.8 1.6 1:15.52 chrome 1217 kimsooy+ 20 0 4595376 269984 111132 R 15.2 1.7 1:36.03 gnome-shell 4030 kimsooy+ 20 0 1034768 77124 58520 S 8.3 0.5 0:01.99 camera_node 4034 kimsooy+ 20 0 1341172 98136 70164 S 5.6 0.6 0:01.71 image_view_node 4032 kimsooy+ 20 0 811272 74320 55924 S 4.6 0.5 0:01.21 watermark_node 이 둘의 차이는 Intra-process communication의 사용 유무입니다. Node ⇒ Node로 메모리가 전달되면서 불필요한 복사가 반복되면 메모리 효율이 저하됩니다.\nIntra-process communication Programming image_pipeline_all_in_one 코드와 예시를 통해 이를 어떻게 구현할 수 있는지 확인해봅시다.\n생성자 Option에서 use_intra_process_comms을 사용하였습니다. CameraNode( const std::string \u0026amp; output, const std::string \u0026amp; node_name = \u0026#34;camera_node\u0026#34;, bool watermark = true, int device = 0, int width = 320, int height = 240) : Node(node_name, rclcpp::NodeOptions().use_intra_process_comms(true)), WatermarkNode( const std::string \u0026amp; input, const std::string \u0026amp; output, const std::string \u0026amp; text, const std::string \u0026amp; node_name = \u0026#34;watermark_node\u0026#34;) : Node(node_name, rclcpp::NodeOptions().use_intra_process_comms(true)){ // Node which receives sensor_msgs/Image messages and renders them using OpenCV. class ImageViewNode : public rclcpp::Node{ public: explicit ImageViewNode(const std::string \u0026amp; input, const std::string \u0026amp; node_name = \u0026#34;image_view_node\u0026#34;, bool watermark = true) : Node(node_name, rclcpp::NodeOptions().use_intra_process_comms(true)){ Topic data 생성 시 unique_ptr, weak_ptr, SharedPtr을 사용한 모습도 보입니다. // Create a new unique_ptr to an Image message for storage. sensor_msgs::msg::Image::UniquePtr msg(new sensor_msgs::msg::Image()); msg-\u0026gt;step = static_cast\u0026lt;sensor_msgs::msg::Image::_step_type\u0026gt;(frame_.step); // Create a publisher on the input topic. pub_ = this-\u0026gt;create_publisher\u0026lt;sensor_msgs::msg::Image\u0026gt;(output, qos); std::weak_ptr\u0026lt;std::remove_pointer\u0026lt;decltype(pub_.get())\u0026gt;::type\u0026gt; captured_pub = pub_; // Create a subscription on the input topic. sub_ = this-\u0026gt;create_subscription\u0026lt;sensor_msgs::msg::Image\u0026gt;( input, rclcpp::SensorDataQoS(),[node_name, watermark](const sensor_msgs::msg::Image::SharedPtr msg) { 메모리 복사가 아닌 소유권 이전으로 최적화를 구현한 것입니다.\n이번 예시에서는 SingleThreadedExecutor를 사용하여 Executor에 3개의 Node를 직접 추가하였습니다. int main(int argc, char * argv[]){ rclcpp::init(argc, argv); rclcpp::executors::SingleThreadedExecutor executor; ... executor.add_node(camera_node); executor.add_node(watermark_node); executor.add_node(image_view_node); executor.spin(); 지금 시점에서 Intra-comm이 필요한 이유는 모두 이해하셨으리라 생각합니다. 비록 이러한 구현이 가능은 하지만, ROS 개발자들은 이를 좀 더 쉽고 동적으로 할 수는 없을지 고민하였습니다.\nROS 2 Node Composition Node Composition의 기본 개념은 각 Node를 런타임에 로드되는 공유 라이브러리인 \u0026ldquo;Composition\u0026quot;로 작성한다는 것입니다. 이러한 방식으로, 다음과 같은 것이 가능합니다\n각각의 Composition을 개별 프로세스에서 실행 단일 프로세스에서 여러 노드를 실행하여 오버헤드를 낮추고 통신 효율성을 높이기 Composition 예시 실행을 위한 준비를 해봅시다. sudo apt install ros-foxy-ros2cli* -y sudo apt install ros-foxy-composition -y 다음으로, 기본 예시를 통해 Composition을 다루기 위한 CLI를 살펴보겠습니다.\n현재 사용 가능한 모든 components 조회 $ ros2 component types (... components of other packages here) composition composition::Talker composition::Listener composition::NodeLikeListener composition::Server composition::Client composition cli example - 순서는 다음과 같습니다. component container 실행 component load component unload # Terminal 1 - execute component_container ros2 run rclcpp_components component_container # Terminal 2 - check available container ros2 component list /ComponentManager component를 load 해봅시다. # Terminal 1 - load built-in publisher component ros2 component load /ComponentManager composition composition::Talker \u0026gt; Loaded component 1 into \u0026#39;/ComponentManager\u0026#39; container node as \u0026#39;/talker\u0026#39; # Container 실행 terminal 확인 [INFO] [1682422159.067057665] [talker]: Publishing: \u0026#39;Hello World: 1\u0026#39; [INFO] [1682422160.066962102] [talker]: Publishing: \u0026#39;Hello World: 2\u0026#39; [INFO] [1682422161.066817081] [talker]: Publishing: \u0026#39;Hello World: 3\u0026#39; [INFO] [1682422162.066801139] [talker]: Publishing: \u0026#39;Hello World: 4\u0026#39; ... # Terminal 2 - load built-in subscriber component ros2 component load /ComponentManager composition composition::Listener \u0026gt; Loaded component 2 into \u0026#39;/ComponentManager\u0026#39; container node as \u0026#39;/listener\u0026#39; # Container 실행 terminal 확인 [INFO] [1682422159.067057665] [talker]: Publishing: \u0026#39;Hello World: 1\u0026#39; [INFO] [1682422160.066962102] [talker]: Publishing: \u0026#39;Hello World: 2\u0026#39; [INFO] [1682422161.066817081] [talker]: Publishing: \u0026#39;Hello World: 3\u0026#39; [INFO] [1682422162.066801139] [talker]: Publishing: \u0026#39;Hello World: 4\u0026#39; ... ComponentManager의 하위 component로 talker와 listener가 등록되어 있는 것을 확인할 수 있습니다. ros2 component list /ComponentManager 1 /talker 2 /listene component의 unload는 다음과 같습니다. 지금은 1개의 component 밖에 없기 때문에 id는 1이 됩니다. ros2 component unload /ComponentManager \u0026lt;id\u0026gt; Composition Programming Composition은 내용이 까다롭고 디버깅도 쉽지 않습니다. 때문에 절차를 나누어 차근차근 작은 부분부터 함께 프로그래밍 실습을 해보도록 하겠습니다.\n기본 구조와 Export Data Forwarding Composition Container ComposableNodeContainer를 통한 launch 실 사용 사례 ⇒ ZED Stereo Camera 기본 구조와 Export - 아주 간단한 코드를 통해 Node Composition의 기초부터 익혀봅시다. Node 생성 CMakeLists.txt 수정 후 Export Component 생성 및 실행 확인 basic_component.cpp - 필수로 구현해야 하는 부분들을 살펴봅시다. #include \u0026#34;rclcpp/rclcpp.hpp\u0026#34; #include \u0026#34;std_msgs/msg/string.hpp\u0026#34; using namespace std::chrono_literals; namespace composition_tutorial { class BasicComponent : public rclcpp::Node { public: explicit BasicComponent(const rclcpp::NodeOptions \u0026amp; options) : Node(\u0026#34;BasicComponent\u0026#34;, options), count_(0){ // Create a publisher of \u0026#34;std_mgs/String\u0026#34; messages on the \u0026#34;chatter\u0026#34; topic. pub_ = create_publisher\u0026lt;std_msgs::msg::String\u0026gt;(\u0026#34;chatter\u0026#34;, 10); // Use a timer to schedule periodic message publishing. timer_ = create_wall_timer(1s, std::bind(\u0026amp;BasicComponent::on_timer, this)); } protected: void on_timer(){ auto msg = std::make_unique\u0026lt;std_msgs::msg::String\u0026gt;(); msg-\u0026gt;data = \u0026#34;Hello World: \u0026#34; + std::to_string(++count_); RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;Publishing: \u0026#39;%s\u0026#39;\u0026#34;, msg-\u0026gt;data.c_str()); std::flush(std::cout); // Put the message into a queue to be processed by the middleware. // This call is non-blocking. pub_-\u0026gt;publish(std::move(msg)); } private: size_t count_; rclcpp::Publisher\u0026lt;std_msgs::msg::String\u0026gt;::SharedPtr pub_; rclcpp::TimerBase::SharedPtr timer_; }; } // namespace composition #include \u0026#34;rclcpp_components/register_node_macro.hpp\u0026#34; // Register the component with class_loader. // This acts as a sort of entry point, allowing the component to be discoverable when its library // is being loaded into a running process. RCLCPP_COMPONENTS_REGISTER_NODE(composition_tutorial::BasicComponent) 요점들을 정리하면 다음과 같습니다. Description namespace 지정 패키지 이름으로 설정하는 것이 일반적입니다. explicit 생성자 일반 Node가 아닌 Component로의 사용을 위해 생성자 explicit 키워드를 사용합니다. smart_pointer on_timer에서 사용되는 msg 데이터가 shared_ptr 타입인 것을 볼 수 있었습니다. 메모리 최적화를 위해 다음 Component에게 pointer를 전달합니다. register_node_macro component register 매크로를 통해 구현한 Component를 ROS 2 시스템에 등록합니다. 이 기능은 Foxy기준 C++ 패키지만 지원합니다. CMakeLists.txt 수정 후 Export - 아래의 template에 맞추어 Component를 빌드하고 export합니다. Component 자체는 shared library이며 때문에 Container 실행 후 런타임에 load / unload가 가능합니다. add_library target_compile_definitions ament_target_dependencies rclcpp_components_register_nodes install add_library(basic_component SHARED src/basic_component.cpp) target_compile_definitions(basic_component PRIVATE \u0026#34;COMPOSITION_TUTORIAL_BUILDING_DLL\u0026#34;) ament_target_dependencies(basic_component \u0026#34;rclcpp\u0026#34; \u0026#34;rclcpp_components\u0026#34; \u0026#34;std_msgs\u0026#34; ) rclcpp_components_register_nodes(basic_component \u0026#34;composition_tutorial::BasicComponent\u0026#34;) set(node_plugins \u0026#34;${node_plugins}composition_tutorial::BasicComponent;$\u0026lt;TARGET_FILE:basic_component\u0026gt;\\n\u0026#34;) install(TARGETS basic_component ARCHIVE DESTINATION lib LIBRARY DESTINATION lib RUNTIME DESTINATION bin ) Description add_library 현재 실행 파일을 만드는 것이 아니라 라이브러리를 생성하는 것이므로 add_executable이 아닌 add_library를 사용합니다. target_compile_definitions basic_component는 라이브러리이므로 특정 타겟에만 해당하는 컴파일 옵션을 정의합니다. ament_target_dependencies 일반적인 종속석 linking입니다. rclcpp_components_register_nodes 이 부분이 새롭게 등장한 내용인데요, 사실 main 함수가 없어도 실행 가능한 Node를 만들 수 있습니다. 지금은 라이브러리를 빌드하기 위한 커멘드로 사용되었지만 이는 이후에 다시 살펴보겠습니다. set node_plugins에 새롭게 컴파일한 basic_component를 추가합니다. install build 폴더에 위치시켜 ros2 component 커멘드 라인을 사용할 수 있도록 합니다. Component 생성 및 실행 확인 - component cli를 통해 생성된 Component를 확인하고 실행해봅시다. # Component 생성 확인 $ ros2 component types composition_tutorial composition_tutorial::BasicComponent # Container 실행 $ ros2 run rclcpp_components component_container # 실행 중인 Container 확인 후 component load $ ros2 component list /ComponentManager $ ros2 component load /ComponentManager composition_tutorial composition_tutorial::BasicComponent # Container 실행 Terminal에서 로그 확인 \u0026gt; [INFO] [1682466495.013826879] [BasicComponent]: Publishing: \u0026#39;Hello World: 1\u0026#39; ⇒ 지금은 cpp 파일에 최소한의 구현을 했지만 보통 헤더를 분리하고 visibility control을 통해 외부에서 접근할 수 있는 범위를 제한합니다.\n⇒ 실제 제품 개발 시 보안이 적용되어야 하는 부분이라면 Node코드 대신 Component를 제공하는 방법도 있습니다.\nCompile-time composition component로 동적 load / unload가 가능하지만 시스템 통합을 위해 manual 통합 코드를 작성하거나, launch file을 사용할 수 있습니다.\n직접 component들을 실행시키는 main 코드를 작성하는 경우입니다. 일전 image_pipeline_all_in_one을 통해 예시를 살펴봅시다. int main(int argc, char * argv[]) { rclcpp::init(argc, argv); rclcpp::executors::SingleThreadedExecutor executor; // Connect the nodes as a pipeline: camera_node -\u0026gt; watermark_node -\u0026gt; image_view_node std::shared_ptr\u0026lt;CameraNode\u0026gt; camera_node = nullptr; try { camera_node = std::make_shared\u0026lt;CameraNode\u0026gt;(\u0026#34;image\u0026#34;); } catch (const std::exception \u0026amp; e) { fprintf(stderr, \u0026#34;%s Exiting ..\\n\u0026#34;, e.what()); return 1; } auto watermark_node = std::make_shared\u0026lt;WatermarkNode\u0026gt;(\u0026#34;image\u0026#34;, \u0026#34;watermarked_image\u0026#34;, \u0026#34;Hello world!\u0026#34;); auto image_view_node = std::make_shared\u0026lt;ImageViewNode\u0026gt;(\u0026#34;watermarked_image\u0026#34;); executor.add_node(camera_node); executor.add_node(watermark_node); executor.add_node(image_view_node); Composition using launch actions composition container와 실행될 component들을 명시하는 launch action도 사용할 수 있습니다. (talker와 listener, Component Manager를 함께 실행하는 launch file을 작성해보았습니다.) ros2 launch composition_tutorial talk_listen.launch.py import launch from launch_ros.actions import ComposableNodeContainer from launch_ros.descriptions import ComposableNode def generate_launch_description(): \u0026#34;\u0026#34;\u0026#34;Generate launch description with multiple components.\u0026#34;\u0026#34;\u0026#34; container = ComposableNodeContainer( name=\u0026#39;my_container\u0026#39;, namespace=\u0026#39;\u0026#39;, package=\u0026#39;rclcpp_components\u0026#39;, executable=\u0026#39;component_container\u0026#39;, composable_node_descriptions=[ ComposableNode( package=\u0026#39;composition\u0026#39;, plugin=\u0026#39;composition::Talker\u0026#39;, name=\u0026#39;talker\u0026#39;), ComposableNode( package=\u0026#39;composition\u0026#39;, plugin=\u0026#39;composition::Listener\u0026#39;, name=\u0026#39;listener\u0026#39;) ], output=\u0026#39;screen\u0026#39;, ) return launch.LaunchDescription([container]) Component Manager는 rqt_graph를 통해 구별하기 쉽지 않습니다. 따라서 적절한 이름을 부여하는 것이 디버깅에 용이합니다. 기본 Container 이름은 /ComponentManager 이지만, remapping을 통해 namespace를 지정하거나 이 이름을 바꿀 수 있습니다. # container remapping ros2 run rclcpp_components component_container --ros-args -r __node:=MyContainer -r __ns:=/ns ros2 component list \u0026gt; /ns/MyContainer # Remap node name ros2 component load /ns/MyContainer composition composition::Talker --node-name talker3 --node-namespace /ns2 ros2 component list /ns/MyContainer 1 /ns2/talker3 component에게 매개변수도 전달할 수 있습니다. use_intra_process_comms 옵션을 매개변수로 제어해 보겠습니다. ros2 component load /ComponentManager composition composition::Talker -e use_intra_process_comms:=true 구현과 사용에 대해서는 이정도 설명하고, 추가 자료는 링크로 남기겠습니다.\nComponent를 shared library로 export하고 다른 package에서 import하여 사용하기 - Ament best practice for sharing libraries\n실 사용 사례 - ZED ros2 composition composition의 중요성과 사용에 대해 좀 더 확실히 알 수 있는 예시를 가져와 보았습니다.\nStereo Labs의 ZED Camera는 Composition을 사용하여 보다 효율적인 rgb convert, format conversion을 제공하고 있습니다. 코드를 통해 함께 살펴봅시다.⇒ 출처 : https://www.stereolabs.com/docs/ros2/ros2-composition/\nzed_rgb_convert_component.hpp - composition인 ZedRgbCvtComponent가 구현되어 있습니다. namespace stereolabs { class ZedRgbCvtComponent : public rclcpp::Node { public: ZED_CVT_COMPONENT_PUBLIC explicit ZedRgbCvtComponent(const rclcpp::NodeOptions \u0026amp; options); virtual ~ZedRgbCvtComponent() {} protected: void camera_callback( const sensor_msgs::msg::Image::ConstSharedPtr \u0026amp; img, const sensor_msgs::msg::CameraInfo::ConstSharedPtr \u0026amp; cam_info); private: // Publisher image_transport::CameraPublisher mPubBgr; // Subscriber image_transport::CameraSubscriber mSubBgra; // QoS parameters rclcpp::QoS mVideoQos; }; } // namespace stereolabs #endif // ZED_RGB_CONVERT_COMPONENT_HPP_ zed_rgb_convert_component.cpp - 메모리 최적화를 위해 ConstSharedPtr 타입 input, output을 사용하고 있는 모습을 확인할 수 있습니다. void ZedRgbCvtComponent::camera_callback( const sensor_msgs::msg::Image::ConstSharedPtr \u0026amp; img, const sensor_msgs::msg::CameraInfo::ConstSharedPtr \u0026amp; cam_info) { // Check for correct input image encoding if (img-\u0026gt;encoding != sensor_msgs::image_encodings::BGRA8) { RCLCPP_ERROR(get_logger(), \u0026#34;The input topic image requires \u0026#39;BGRA8\u0026#39; encoding\u0026#34;); exit(EXIT_FAILURE); } // Convert BGRA to BGR using OpenCV void * data = const_cast\u0026lt;void *\u0026gt;(reinterpret_cast\u0026lt;const void *\u0026gt;(\u0026amp;img-\u0026gt;data[0])); cv::Mat bgra(img-\u0026gt;height, img-\u0026gt;width, CV_8UC4, data); cv::Mat bgr; cv::cvtColor(bgra, bgr, cv::COLOR_BGRA2BGR); // Create the output message and copy coverted data std::shared_ptr\u0026lt;sensor_msgs::msg::Image\u0026gt; out_bgr = std::make_shared\u0026lt;sensor_msgs::msg::Image\u0026gt;(); out_bgr-\u0026gt;header.stamp = img-\u0026gt;header.stamp; out_bgr-\u0026gt;header.frame_id = img-\u0026gt;header.frame_id; out_bgr-\u0026gt;height = bgr.rows; out_bgr-\u0026gt;width = bgr.cols; int num = 1; // for endianness detection out_bgr-\u0026gt;is_bigendian = !(*reinterpret_cast\u0026lt;char *\u0026gt;(\u0026amp;num) == 1); out_bgr-\u0026gt;step = bgr.step; size_t size = out_bgr-\u0026gt;step * out_bgr-\u0026gt;height; out_bgr-\u0026gt;data.resize(size); out_bgr-\u0026gt;encoding = sensor_msgs::image_encodings::BGR8; memcpy(reinterpret_cast\u0026lt;char *\u0026gt;((\u0026amp;out_bgr-\u0026gt;data[0])), \u0026amp;bgr.data[0], size); // Publish the new image message coupled with camera info from the original message mPubBgr.publish(out_bgr, cam_info); } camera_callback의 목표는 cv::cvtColor를 통해 BGRA (CV_8UC4)을 BGR (CV_8UC4) 타입으로 변환하는 것입니다.\nZedCamera Composition과 ZedRgbCvtComponent Composition을 함께 사용하는 별도 Executor를 만들어 제공하고 있습니다. int main(int argc, char * argv[]){ setvbuf(stdout, NULL, _IONBF, BUFSIZ); rclcpp::init(argc, argv); rclcpp::executors::MultiThreadedExecutor exec; rclcpp::NodeOptions options; // Enable intraprocess communication options.use_intra_process_comms(true); // Add ZedCamera node auto zed_node = std::make_shared\u0026lt;stereolabs::ZedCamera\u0026gt;(options); exec.add_node(zed_node); // Add ZedRgbCvtComponent node auto zed_cvt_node = std::make_shared\u0026lt;stereolabs::ZedRgbCvtComponent\u0026gt;(options); exec.add_node(zed_cvt_node); exec.spin(); rclcpp::shutdown(); return 0; } 이는 물론 launch file로도 가능할 것입니다. 😁\n"
},
{
	"uri": "/kr/ros2_foxy/lecture16/",
	"title": "Lecture16. Useful ROS 2 Examples (Misc)",
	"tags": [],
	"description": "",
	"content": "ROS 1 Bridge 단순 개발을 위해서는 최신 스택을 사용하면 좋지만, 제품 개발을 생각하면 이전 버전의 소스들도 유지보수할 줄 알아야 합니다. ROS 개발은 특히 오픈소스에 기반하기 때문에 어느 정도 레벨에 오르면 레거시를 읽고 새로운 버전으로 관리도 할 줄 알아야 합니다.\n⇒ 그런 의미에서 이번 시간에는 코드 작업이 전혀 없어도 ROS와 ROS 2를 연동시킬 수 있는 ROS bridge라는 것을 실습해 보겠습니다.\nimage from : swri.org\n강의 초반 저의 설정을 잘 따라오셨다면 여러분의 시스템에는 이미 ROS noetic이 설치되어 있습니다. ****************************************************** * Usage: To set ROS env to be auto-loaded, please * * assign ros_option in ros_menu/config.yaml * ****************************************************** 0) Do nothing 1) ROS 1 noetic 2) ROS 2 foxy 3) ROS2/ROS1_bridge **Please choose an opt**ion: 2 ------------------------------------------------------ * ROS_DOMAIN_ID = 30 ------------------------------------------------------ 실습을 위해 husky ROS package를 실행하고 topic을 조회해봅시다. sudo apt-get install ros-noetic-husky-desktop -y sudo apt-get install ros-noetic-husky-simulator -y sudo apt-get install ros-noetic-husky-gazebo -y # 새로운 터미널을 실행시킨 뒤 1번을 선택하여 ROS 1 noetic 터미널로 전환합니다. 0) Do nothing 1) ROS 1 noetic 2) ROS 2 foxy 3) ROS 2 galactic 4) ROS2/ROS1_bridge h) Help Please choose an option: 1 # 동일 터미널에서 아래 명령어를 입력합니다. roslaunch husky_gazebo empty_world.launch # 두번째 터미널도 ROS 1 noetic 터미널로 전환합니다. $ rostopic list # Terminal 2 $ rostopic list /clock /cmd_vel /diagnostics /e_stop /gazebo/link_states /gazebo/model_states /gazebo/parameter_descriptions /gazebo/parameter_updates /gazebo/performance_metrics /gazebo/set_link_state /gazebo/set_model_state ... 우리의 목표는 지금 보이는 cmd_vel에게 topic publish를 하여 ROS 2가 아닌, ROS 상의 로봇을 제어해보는 것입니다.\nhusky_gazebo를 종료한 뒤, 새로운 터미널을 열고 초기 옵션 선택에서 (ROS2/ROS1_bridge)를 선택하면 ros1 bridge가 실행됩니다. (아마 실행 시 오류가 등장할 것입니다.) ****************************************************** * Usage: To set ROS env to be auto-loaded, please * * assign ros_option in ros_menu/config.yaml * ****************************************************** 0) Do nothing 1) ROS 1 noetic 2) ROS 2 foxy 3) ROS2/ROS1_bridge Please choose an option: 3 ------------------------------------------------------ * ROS_IP=172.24.55.124 * ROS_MASTER_URI 172.24.55.124 ------------------------------------------------------ * ROS_DOMAIN_ID = 30 ------------------------------------------------------ ROS_DISTRO was set to \u0026#39;noetic\u0026#39; before. Please make sure that the environment does not mix paths from different distributions. source /home/kimsooyoung/.ros_menu/plugins_bashrc/dds_bashrc 1 Source Eclipse Cyclone DDS successfully! [ERROR] [1682250552.661762864]: [registerPublisher] Failed to contact master at [172.24.55.124:11311]. Retrying... ROS1의 Node들끼리 데이터를 주고받기 위해서는 어떤 노드가 존재하는지, id는 몇번인지 등의 정보가 공유되어야 합니다. 아래 그림의 ROS Master가 이를 관리해주는 것이라고 이해하시면 되며, ROS 2는 DDS가 이를 알아서 해주기 때문에 편하게 사용할 수 있는 것입니다. 참고로 roslaunch를 사용하면 기본적으로 roscore도 함께 실행됩니다.\nimage from : clearpathrobotics\n다시 한 번, rosmaster를 실행시킨 뒤, cmd_vel 제어를 해봅시다. # Terminal 1 =\u0026gt; ROS 1 noetic 선택 후 roslaunch husky_gazebo empty_world.launch # Terminal 2 - ros bridge 선택 Created 2 to 1 bridge for service /ekf_localization/enable Created 2 to 1 bridge for service /gazebo/clear_body_wrenches Created 2 to 1 bridge for service /gazebo/clear_joint_forces ... # Terminal 3 - ROS 2 Foxy 선택 후 cmd_vel control ros2 run teleop_twist_keyboard teleop_twist_keyboard ROS 2로 설정된 터미널에서 ROS 1으로 구동되고 있는 로봇을 조종할 수 있습니다. ros bridge가 있으니 ROS 2 개발을 굳이 하지 않아도 된다고 생각할 수 있습니다. 하지만 보안, 지연과 같은 ROS 1의 고질적인 문제들은 여전히 남아있게 되므로 프로젝트를 시작하는 단계라면, 처음부터 ROS 2로 모든 개발을 진행하시길 추천드립니다.\n참고로, /opt/ros/\u0026lt;ros-version\u0026gt;/setup.bash는 ROS 시스템을 사용하기 위해서 필요한 설정이 담긴 파일입니다. 혹여나 galactic, humble과 같이 최신 버전을 사용하고 싶을 때 참고하시기 바랍니다.\nAbout DDS ROS 1과 대두되는 가장 큰 차이점으로, ROS 2는 DDS를 미들웨어로 기반하여 개편되었습니다. 따라서 DDS에 대한 개요와 기능을 이해하는 것은 ROS 2의 성질을 파악하는 데 많은 도움이 됩니다.\nWhat is DDS? DDS - Data Distribution Service는 OMG에서 정의한 Publish-Subscribe 방식의 실시간 데이터 분배 서비스 표준입니다. Pub-Sub이라는 용어는 ROS 개발자에게 무척 익숙한 단어이지요? DDS의 기본 통신 개념은 ROS의 Topic과 매우 유사합니다. 이러한 결론을 머리속에 잘 담아두고 계속해서 진행해 보겠습니다.\nOMG(Object Management Group)는 분산 객체 컴퓨팅(Distributed Object Computing) 영역의 표준을 제정하는 국제 비영리 컨소시엄으로 영향력 있는 각종 세계 표준을 정의하고 있습니다.\nimage from : 분산이동컴퓨팅 연구실\nOMG DDS는 통신 프로토콜이 아닌 기능적 표준으로, 위 그림과 같이 TCP/UDP 같은 통신 프로토콜 위에서 정의되는 객체입니다. 그림의 아래에서부터 OMG DDS의 구조를 간단히 살펴보겠습니다.\nRTPS(Real-Time Publish-Subscribe Wire Protocol) Layer RTPS Layer는 네트워크 내, 참여자 정보를 유지하고, 네트워크 참여자에 대한 정보를 기반으로 자동 검색을 해줍니다. (같은 네트워크를 사용하는 ROS 2 시스템은 서로 통신이 가능합니다.) 더불어, 참여자의 동적 추가와 이탈에 대응하는 기능을 합니다.\nRTPS는 OMG에 의해 표준화된, 데이터 분산 시스템을 위한 프로토콜로써 Pub-Sub 구조의 통신 모델을 지원합니다. UDP와 같이 신뢰성 없는 계층 위에서도 동작 가능하도록 설계되었으며, 4가지 모듈로 구성되어 있습니다.\nStructure Module : 데이터 교환 시, 통신에 참여하게 되는 개체들에 대해 정의합니다. Message Module : Writer와 Reader간 정보 교환을 위해 사용되는 메시지에 대해 정의합니다. Behavior Module : Writer와 Reader간 상태, 시간 조건에 따라 수행되어야 할 메시지 전송 절차에 대해 정의합니다. Discovery Module : 같은 도메인 상에 존재하는 개체에 대한 정보를 탐색하는 기능을 수행합니다. Discovery Module은 다음과 같이 두 가지의 RTPS 프로토콜을 사용합니다. PDP(Participant Discovery Protocol) : 서로 다른 네트워크 상에서의 Participant탐색을 위한 프로토콜 EDP(Endpoint Discovery Protocol) : Writer, Reader와 같이 서로 다른 종단점 간의 탐색 정보 교환에 사용되는 프로토콜 image from : OMG DDS(Data Distrubution Service) 기술 개요\nDDS Discovery ROS 2를 사용하는 두 디바이스는 같은 네트워크를 사용하고 있다면 자동으로 서로를 인식할 수 있습니다. 어떻게 이러한 동작이 가능하며, 이를 위한 필요조건은 무엇인지 살펴보겠습니다.\nDiscovery를 위해 필요한 정보들 - DDS 미들웨어 통신을 위해 아래 4가지 정보를 사전에 교환해야 합니다.\nWho : Topic Publish 혹은 Subscribe 대상 Where : DDS 표준에서 생성한 Locator 정보 What : Publish하거나 Subscribe하려는 Topic How : Topic Publisher인지 Subscriber인지에 대한 정보 DDS RTPS도 결국 UDP나 TCP 네트워크 레이어를 사용하며, 이를 위해서 실질적으로 IP와 PORT등의 정보가 필요합니다. 하지만, DDS는 사용자가 주소를 지정하지 않아도 “Topic”만으로 통신이 가능합니다. 이를 가능하게 해주는 것이 Locator이며, 이는 Middle Ware단에서 능동적으로 통신에 필요한 정보를 포함하는 새로운 개념을 별도로 생성하는 것입니다.\nDDS 표준에서는 Discovery를 수행하는 절차를 PDP 와 EDP로 구분하고 있습니다.\nPDP - Participant Discovery Protocol : 같은 도메인에 존재하는 서로 다른 Participant를 검색하는 절차로, Participant에 포함되어 있는 endpoint 의 정보를 검색합니다. EDP - Endpoint Discovery Protocol : PDP를 통해 Participant가 서로를 탐지하고 나면, EDP가 수행됩니다. 표준에서는 각 프로토콜이 지원해야할 최소한의 기능을 만족하는 SPDP와 SEDP에 대해 설명하고 있습니다. vendor에 따라 다양한 PDP와 EDP를 지원할 수 있지만, 호환성을 위해 모든 RTPS는 SPDP(Simple Participant Discovery Protocol)와 SEDP(Simple Endpoint Discovery Protocol)를 필수로 지원해야합니다. 서로 다른 vendor를 가진 머신 사이에 통신이 가능한 이유이기도 합니다.\n그림을 통해 SPDP와 SEDP를 활용한 Discovery 절차에 대해 알아봅시다.\n같은 Domain을 사용하는 Participant는 생성 시, Discovery를 수행하는 3쌍의 builtin Writer와 builtin Reader, 그리고 pre-defined topic를 포함하게 됩니다. DDS가 구동되면, Participant는 Multicast로 PDP(Participant Discovery Protocol) 메시지를 주기적으로 전송하기 시작합니다.\n각 Participant의 builtinParticipantWriter와 builtinPariticpantReader 사이 SPDP 교환이 이루어집니다. 전달되는 정보에는 Participant에 포함된 builtinPublicationWriter와 builtinPublicationReader의 Locator 정보가 담겨 있습니다.\nSPDP 교환 이후, 상대방 Participant의 정보를 통해 양측 Participant들은 서로 연결됩니다.\n이후, Topic 수행을 위해 각 Participant에 Endpoint에 해당하는 Publisher와 Datawriter가 하나씩 생성됩니다.\nSPDP에서 교환했던 Locator정보를 바탕으로 builtinPublicationWriter는 builtiinPublicationReader에게, builtinSubscriptionWriter는 SubscriptionReader에게 Unicast를 통해 정보를 전달합니다.(SEDP를 교환하는 것입니다.) 전달되는 정보에는 topic, data type, Qos등의 정보가 포함되어 있습니다.\nSEDP의 결과로 Participant에 포함된 Endpoint들이 연결되고, 연결된 두 Endpoint는 동일 Topic으로 통신을 시작합니다.\nDiscovery 과정을 한번에 정리한 그림입니다. 다시 한 번 의미를 이해하면서 과정을 복기해봅시다.\nDCPS(Data-Centric Publish-Subscribe) Layer DCPS Layer는 RTPS Layer와 Application 사이의 인터페이스 역할을 합니다. 이후 다뤄지는 Participant, Domain, Topic 등을 정의하고, Publish-Subscribe를 수행합니다. 더불어, DDS의 중요한 기능 중 하나인 QoS(Quality of Service)도 담당하고 있습니다.\n구현 측면에서, DCPS는 Data read/write API를 제공함으로 응용 프로그램들 사이 데이터를 교환할 상대에 대한 인지 없이 원하는 데이터의 송수신이 가능하게 합니다.\nimage from : OMG DDS(Data Distrubution Service) 기술 개요\nDataWriter / DataReader DataWriter는 송신자, DataReader는 수신자의 역할을 합니다. DataWriter는 Sample(실제 데이터)을 생성하고 전송하는 역할을 하며, DataReader는 Sample을 수신하는 기능을 합니다. 단일 DataWriter와 DataReader는 단일 Topic만을 보유할 수 있습니다.\nPublisher 데이터 Publish를 담당하는 객체로, 하나의 Publisher는 다수의 DataWriter를 가질 수 있습니다. 때문에, 각 Publisher들은 여러 Topic 데이터를 Publish 할 수 있습니다. Publish하고자 하는 데이터 객체의 값이 Publisher에게 전해지면 Publisher는 자신에게 설정된 QoS값에 따라 연관된 Subscriber에게 전달합니다.\nSubscriber 데이터 Subscribe를 담당하는 객체로, Publisher와 유사하게 다수의 DataReader를 가질 수 있으며 여러 Topic 데이터를 수신할 수 있습니다. Subscriber가 데이터를 수신한 이후, 응용 프로그램은 DataReader를 통해 실제 데이터로 접근하는 방식입니다.\nDDS Pub-Sub의 기본 구성 요소 image from : MDS 테크\nTopic Topic은 Publish-Subscribe의 관계를 정의하는 Key입니다. topic은 데이터 타입과 해당 데이터의 QoS에 대한 정보를 담고 있습니다. QoS를 Topic 데이터에 추가하고, Topic과 연관된 DataWriter, Datawriter에 연관된 QoS를 설정하는 식으로 제어됩니다. (Subscriber 측도 동일합니다.)\nTopic의 이름은 Domain 내에서 유일해야 합니다.\nParticipant Participant는 DDS Publisher와 Subscriber를 담게 되는 객체입니다. ROS 2의 Node안에 다수의 Publisher와 Subscriber와 공존할 수 있는 것처럼, Participant도 다수의 DataWriter와 DataReader를 가질 수 있습니다.\nDomain Domain은 Participant들이 활동하는 영역으로, 같은 Domain을 갖는 Participant내에서만 정보전달을 할 수 있습니다. ROS 2 터미널의 실행 시 ROS_DOMAIN_ID라는 콘솔 출력이 나왔던 것을 기억하시나요?\n*************** Startup Menu for ROS *************** * Usage: To set ROS env to be auto-loaded, please * * assign ros_option in ros_menu/config.yaml * ****************************************************** 0) Do nothing 1) ROS 1 noetic 2) ROS 2 foxy 3) ROS2/ROS1_bridge Please choose an option: 2 ------------------------------------------------------ * ROS_DOMAIN_ID = 30 ------------------------------------------------------ 이렇게 DDS의 통신 구조에 대해서 알아보았습니다. 위 구조에서 실제 사용자는 Topic, Publisher, Subscriber만 구현하면 되며, DataWriter, DataReader와 RTPS, DCPS는 DDS가 알아서 처리하게 됩니다. 이러한 DDS의 장점에 기반하여 ROS 2 시스템이 올라가게 되는 것이지요.\nDDS QoS TCPROS/UDPROS라는 자체 프로토콜을 사용했던 기존 ROS 1과는 달리, ROS 2에서는 QoS 옵션을 통해 원하는 기능을 선택적으로 사용할 수 있습니다. 이는 DDS의 QoS를 도입하였기 때문으로, Publisher, Subscriber를 선언할 때, QoS를 매개변수형태로 지정하는 방식이 사용됩니다.\n상황에 따라 데이터의 신뢰성이 중요할 수도 있고, 버퍼의 크기를 크게 하여 Topic의 안정성을 높여야 할 수도 있습니다. 이러한 통신의 품질을 옵션화하기 위해서, DDS에서는 아래와 같은 22가지의 QoS를 정의하고 있습니다.\n각각의 QoS 옵션은 연관된 조합으로 Topic, DataWriter, DataReader, Publisher, Subscriber, Domain, Participant에 적용되며, 본 세션에서는 주로 사용되는 QoS를 위주로 살펴보고자 합니다.\nRELIABILITY: 데이터 통신의 신뢰성 레벨(재전송 여부)을 결정하며 두 가지 속성을 설정 할 수 있습니다. RELIABLE : DataWriter History에 있는 모든 샘플들이 DataReader에 전달되는 것을 보장합니다. BEST_EFFORT : 통신 시 손실된 데이터 샘플을 재전송 하지 않고, 전달된 데이터의 순서는 유지 합니다. 알파벳은 다음과 같은 의미를 갖습니다. T : TOPIC, DR : DataReader, DW : DataWriter, P : Publisher, S:Subscriber\nRxO는 Requested/Offered의 약자로 QoS가 적용되는 대상을 Publisher(발간/송신) 측과 Subscriber(구독/수신) 측으로 구분해서 서로의 상관관계를 표현하는 방법입니다.\n‘YES’ : Publisher 측과 Subscriber 측 모두 QoS가 적용되어야 하고, 설정된 QoS 값이 호환되어야 한다. ‘NO’ : Publisher 측과 Subscriber 측 모두 QoS 가 적용되어야 하지만, 설정된 QoS 값은 서로 독립적이다. ‘N/A’ : Publisher 측과 Subscriber 측 중 한 측에만 적용되어야 한다. Changeable이 ‘YES’ 일 경우에는, 동작하면서도 QoS 의 값이 변경될 수 있지만, ‘NO’일 경우에는 처음 생성된 이후에는 변경할 수 없습니다.\nHISTORY : 데이터의 재전송을 위해 HistoryCache내 데이터 보관 방법을 결정하며 두 가지 속성을 설정 할 수 있습니다. KEEP_LAST : Depth(History Cache안에 유지하고 있을 데이터 개수) 크기 만큼 최신 데이터를 유지 합니다. KEEP_ALL : DataReader에게 인스턴스의 모든 값들을 유지하고 전송 합니다. DURABILITY : 나중에 참여한 DataReader에게 이전 데이터를 전송할지 여부를 결정 하며 네 가지 속성을 설정 할 수 있습니다. VOLATILE : 연결이 설정 된 이후의 데이터만 제공 합니다. TRANSIENT LOCAL : DataWriter 생명주기와 일치 일치합니다. TRANSIENT : DataReader에 과거 데이터를 제공 합니다. PERSISTENT : Permanent-Storage에 과거 데이터를 저장하며, 데이터의 유효성은 System 보다 오래 지속 됩니다. OWNERSHIP : 다수의 DataWriter가 동일한 인스턴스를 갱신하게 허용할지를 결정합니다. SHARED : 다수의 DataWriter들이 동일한 데이터 인스턴스 업데이트가 가능합니다. EXCLUSIVE : 데이터 객체의 각 인스턴스는 하나의 DataWriter에 의해서만 수정 가능합니다. PARTITION : Domain 내부에서 Node들을 분리하는 방법을 결정 합니다. (Domain 내에서 별도의 논리적인 통신 채널 형성) - Partition Name이 같은 DataWriter/DataReader간 데이터 배포 가 가능합니다. Partition과 Domain의 차이 - 다른 Domain들에 속하는 개체들은 완전히 서로 독립 된 상태입니다. Entity는 다수의 Partition에 있을 수 있지만 하나의 Domain에만 속할 수 있습니다.\nDEADLINE : 데이터 샘플 사이의 최대 도착 시간을 정의할 수 있습니다. DataWriter는 DEADLINE(period:Duration_t)이 설정된 시간 안에 적어도 한번 이상의 데이터를 전송합니다. DataReader는 DEADLINE(period:Duration_t) 시간 안에 DataWriter로부터 데이터를 받지 못하면 DDS로부터 위반 통보를 받습니다. TIME_BASED_FILTER : DataReader 가 데이터를 필터링 하는 시간을 결정 합니다. Minimum_separation: Duation_t 값을 설정하여 DataReader는 이 값 이내에 수신한 데이터는 삭제 합니다. ROS 2에서는 자주 사용되는 QoS 조합을 묶어 RMW QoS Profile이라는 이름으로 제공하고 있습니다. 지금까지 우리가 queue_size만을 전달하고 있었지만, 사실은 아래 사진의 Default에서 Depth만 바꿔주고 있었던 것입니다.\nimage from : 오로카\nQoS Programming ros2 프로그래밍에서 QoS를 설정하는 방법은 매우 간단합니다. Publisher, Subscriber 클래스를 생성하면서 QoS 옵션을 매개변수로 전달하면 됩니다.\npython example - RMW QoS Profile 사용 시 from rclpy.qos import qos_profile_sensor_data self.string_publisher = self.create_publisher(String, \u0026#39;qos_test_topic\u0026#39;, qos_profile_sensor_data) python example - 직접 Profile 설정 시 from rclpy.qos import QoSDurabilityPolicy from rclpy.qos import QoSHistoryPolicy from rclpy.qos import QoSProfile from rclpy.qos import QoSReliabilityPolicy my_profile = QoSProfile( reliability=QoSReliabilityPolicy.BEST_EFFORT, history=QoSHistoryPolicy.KEEP_LAST, depth=10, durability=QoSDurabilityPolicy.VOLATILE ) self.string_publisher = self.create_publisher(String, \u0026#39;qos_test_topic\u0026#39;, my_profile) 참고 링크 : rclpy/qos.py\ntopic 통신이 이루어지고 있는 상황에서, QoS 옵션을 보고 싶다면 Topic 커멘드에 verbose 옵션을 추가하면 됩니다. # Terminal 1 - publisher $ ros2 run py_topic_tutorial qos_example_publisher # Terminal 2 - subscriber $ ros2 run py_topic_tutorial qos_example_subscriber # Terminal 3 - topic info $ ros2 topic info /qos_test_topic --verbose Type: std_msgs/msg/String Publisher count: 1 Node name: twist_pub_node Node namespace: / Topic type: std_msgs/msg/String Endpoint type: PUBLISHER GID: 60.77.10.01.f3.67.78.3d.6b.0c.cc.7b.00.00.14.03.00.00.00.00.00.00.00.00 QoS profile: Reliability: RMW_QOS_POLICY_RELIABILITY_BEST_EFFORT Durability: RMW_QOS_POLICY_DURABILITY_VOLATILE Lifespan: 9223372036854775807 nanoseconds Deadline: 9223372036854775807 nanoseconds Liveliness: RMW_QOS_POLICY_LIVELINESS_AUTOMATIC Liveliness lease duration: 9223372036854775807 nanoseconds Subscription count: 1 Node name: string_sub_node Node namespace: / Topic type: std_msgs/msg/String Endpoint type: SUBSCRIPTION GID: d2.03.10.01.d5.6b.69.e0.be.3f.b5.a2.00.00.14.04.00.00.00.00.00.00.00.00 QoS profile: Reliability: RMW_QOS_POLICY_RELIABILITY_BEST_EFFORT Durability: RMW_QOS_POLICY_DURABILITY_VOLATILE Lifespan: 9223372036854775807 nanoseconds Deadline: 9223372036854775807 nanoseconds Liveliness: RMW_QOS_POLICY_LIVELINESS_AUTOMATIC Liveliness lease duration: 9223372036854775807 nanoseconds DDS QoS는 RxO (requested by offered) 특성을 갖고 있어 서로 양립할 수 없는 조합이 존재합니다. 예를 들어, Publish의 Reliability가 BEST_EFFORT일때, Subscriber의 Reliability가 RELIABLE라면, Topic 통신이 발생할 수 없습니다.\n코드 수정을 통해 서로 다른 QoS 통신이 가능한지 직접 실습해봅시다. 코드 내 qos_profile_sensor_data / my_profile을 변경한 뒤 실행해보고 topic 통신이 잘 이루어지는지 확인해보세요! # qos_example_publisher.py my_profile = QoSProfile( reliability=QoSReliabilityPolicy.BEST_EFFORT, history=QoSHistoryPolicy.KEEP_LAST, depth=10, durability=QoSDurabilityPolicy.VOLATILE ) ... self.string_publisher = self.create_publisher(String, \u0026#39;qos_test_topic\u0026#39;, qos_profile_sensor_data) # qos_example_subscriber.py my_profile = QoSProfile( reliability=QoSReliabilityPolicy.RELIABLE, history=QoSHistoryPolicy.KEEP_LAST, depth=10, durability=QoSDurabilityPolicy.VOLATILE ) ... self.pose_subscriber = self.create_subscription( String, \u0026#39;qos_test_topic\u0026#39;, self.sub_callback, my_profile ) 코드 변경 후 실행 $ ros2 run py_topic_tutorial qos_example_publisher [WARN] [1673945160.449603592] [twist_pub_node]: New subscription discovered on this topic, requesting incompatible QoS. No messages will be sent to it. Last incompatible policy: RELIABILITY_QOS_POLICY $ ros2 run py_topic_tutorial qos_example_subscriber [WARN] [1673945160.455319911] [string_sub_node]: New publisher discovered on this topic, offering incompatible QoS. No messages will be received from it. Last incompatible policy: RELIABILITY_QOS_POLICY Warning과 함께 Subscriber가 동작하지 않음을 알 수 있습니다.\nC++에서는 아래와 같이 프로그래밍 합니다.\ncpp example - RMW QoS Profile 사용 시 rclcpp::SensorDataQoS qos; twist_sub_ = this-\u0026gt;create_subscription\u0026lt;geometry_msgs::msg::Twist\u0026gt;(input, qos, callback); odom_sub_ = node-\u0026gt;create_subscription\u0026lt;nav_msgs::msg::Odometry\u0026gt;( odom_topic, rclcpp::SystemDefaultsQoS(), obom_callback ); cpp example - 직접 Profile 설정 시 (사실 여러 방식이 구현 가능하여 정답이 있는 것은 아닙니다. 자주 사용되는 패턴들을 정리해보았습니다.) // Pattern 1 rclcpp::QoS map_qos(10); if (map_subscribe_transient_local_) { map_qos.transient_local(); map_qos.reliable(); map_qos.keep_last(1); } // Pattern 2 auto custom_qos = rclcpp::QoS(rclcpp::KeepLast(1)).transient_local().reliable(); costmap_pub_ = node-\u0026gt;create_publisher\u0026lt;nav_msgs::msg::OccupancyGrid\u0026gt;(topic_name, custom_qos); // Pattern 3 filter_info_sub_ = node-\u0026gt;create_subscription\u0026lt;nav2_msgs::msg::CostmapFilterInfo\u0026gt;( filter_info_topic_, rclcpp::QoS(rclcpp::KeepLast(1)).transient_local().reliable(), std::bind(\u0026amp;BinaryFilter::filterInfoCallback, this, std::placeholders::_1)); QoS를 통해 원하는 도메인에서의 성능을 끌어올리고 안정성을 갖춘 시스템을 구축합시다.\nDDS의 IDL DDS에서는 특정 언어에 의존적이지 않는 데이터 통신을 위해 IDL을 사용합니다.\nIDL(Interface Description Language 또는 Interface Definition Language)는 어느 한 언어에 국한되지 않는 언어중립적인 방법으로 인터페이스를 표현함으로써, 같은 언어를 사용하지 않는 컴포넌트 사이의 통신을 가능하게 합니다.\nOMG의 Interface Definition Language Version 3.5에 따른 사용 가능한 키워드들은 아래와 같습니다.\nimage from : MDS 테크\nROS 2에서는 interface라는 이름으로 topic message, service srv, action action이 사용되었지요. 이들이 모두 IDL 타입을 갖기 때문에 rclpy, rclcpp, rcljava 모두에서 사용할 수 있는 것입니다.\ncustom interface를 빌드하게 되면, 해당 패키지 내부에 생성된 IDL들을 확인할 수 있습니다. build 폴더 내부 패키지 폴더에 진입하면 사진과 같이 다양한 언어를 지원하기 위한 설정 파일들이 위치하는 것을 확인 가능합니다.\nrosidl_generator_py__arguments.json { \u0026#34;package_name\u0026#34;: \u0026#34;custom_interfaces\u0026#34;, \u0026#34;output_dir\u0026#34;: \u0026#34;/home/kimsooyoung/ros2_ws/build/custom_interfaces/rosidl_generator_py/custom_interfaces\u0026#34;, \u0026#34;template_dir\u0026#34;: \u0026#34;/opt/ros/foxy/share/rosidl_generator_py/cmake/../resource\u0026#34;, \u0026#34;idl_tuples\u0026#34;: [ \u0026#34;/home/kimsooyoung/ros2_ws/build/custom_interfaces/rosidl_adapter/custom_interfaces:action/Parking.idl\u0026#34;, \u0026#34;/home/kimsooyoung/ros2_ws/build/custom_interfaces/rosidl_adapter/custom_interfaces:srv/CircleTurtle.idl\u0026#34;, \u0026#34;/home/kimsooyoung/ros2_ws/build/custom_interfaces/rosidl_adapter/custom_interfaces:srv/TurtleJail.idl\u0026#34; ], \u0026#34;ros_interface_dependencies\u0026#34;: [ \u0026#34;action_msgs:/opt/ros/foxy/share/action_msgs/msg/GoalInfo.idl\u0026#34;, \u0026#34;action_msgs:/opt/ros/foxy/share/action_msgs/msg/GoalStatus.idl\u0026#34;, \u0026#34;action_msgs:/opt/ros/foxy/share/action_msgs/msg/GoalStatusArray.idl\u0026#34;, \u0026#34;action_msgs:/opt/ros/foxy/share/action_msgs/srv/CancelGoal.idl\u0026#34;, \u0026#34;builtin_interfaces:/opt/ros/foxy/share/builtin_interfaces/msg/Duration.idl\u0026#34;, \u0026#34;builtin_interfaces:/opt/ros/foxy/share/builtin_interfaces/msg/Time.idl\u0026#34;, \u0026#34;unique_identifier_msgs:/opt/ros/foxy/share/unique_identifier_msgs/msg/UUID.idl\u0026#34; ], ... 생성된 IDL 파일 내부를 함께 살펴봅시다. custom_interfaces ⇒ rosidl_adapter ⇒ custom_interfaces ⇒ action 폴더 내부에 위치한 Parking.idl은 아래와 같은 IDL 형태를 띄고 있습니다.\nParking.idl // generated from rosidl_adapter/resource/action.idl.em // with input from custom_interfaces/action/Parking.action // generated code does not contain a copyright notice module custom_interfaces { module action { @verbatim (language=\u0026#34;comment\u0026#34;, text= \u0026#34;goal definition\u0026#34;) struct Parking_Goal { boolean start_flag; }; struct Parking_Result { @verbatim (language=\u0026#34;comment\u0026#34;, text= \u0026#34;result definition\u0026#34;) string message; }; struct Parking_Feedback { @verbatim (language=\u0026#34;comment\u0026#34;, text= \u0026#34;feedback definition\u0026#34;) float distance; }; }; }; ROS 2 Domain ID DDS 시간 살펴본 바와 같이 각 DDS Participant들은 특정 Domain에 속하게 됩니다. 기본적으로 ROS 2에서는 Domain ID 0을 사용하고 있으며, 같은 Domain ID를 사용하는 Participant들 사이에서만 Discovery와 통신이 가능합니다.\n이번 시간에는 ROS 2의 Domain ID를 수정해보고, Domain ID를 설정할 시 주의해야 할 점들에 대해서도 알아보겠습니다.\n우선, 예시를 통해 서로 다른 Domain ID를 갖는 Participant들을 실행해봅시다. # Ternimal 1 ros2 topic pub -r 1 /string_topic std_msgs/String \u0026#34;{data: \\\u0026#34;Hello from my 2ND domain\\\u0026#34;}\u0026#34; # Terminal 2 ROS_DOMAIN_ID=1 ros2 topic list # Terminal 3 ros2 topic list 예시 결과에서 알 수 있듯이 통신을 위해서는 같은 Domain ID를 갖는 조건이 필수적입니다. $ ros2 topic list /parameter_events /rosout /string_topic Domain ID는 환경변수를 통해 변경할 수 있습니다. 터미널의 실행 시 Domain ID를 자동 적용하기 위해 ~/.bashrc를 수정하거나 config.yaml을 수정하시면 됩니다. export ROS_DOMAIN_ID=\u0026lt;your_domain_id\u0026gt; or # edit ~/ros_menu/config.yaml Config: menu_enable: true ros_option: menu default_ros_domain_id: 30 Menu: ... ROS 2 foxy: option_num: 2 ROS_version: 2 distro_name: foxy ros2_path: /opt/ros/foxy domain_id: # set if you don\u0026#39;t want to use default domain id cmds: DDS는 Domain ID를 사용하여 Participant들이 사용할 UDP Port를 지정합니다. Port가 계산되는 방법은 아래와 같으며, 링크를 참고합니다. - 추가 링크 ROS 2 공식 문서에서는 Domain ID와 Participant 순서에 따라 사용되는 포트 번호를 계산해주는 계산기를 제공하고 있습니다. 이를 통해 최대 가질 수 있는 Domain ID와 Participant 수를 확인해 보겠습니다. - 공식 문서 링크 Domain ID 설정 시 고려해야 할 요소들은 다음과 같습니다.\n각 OS 별로 침범하면 안되는 포트 영역이 있습니다. (Linux - 32768-60999 / Windows \u0026amp; macOS - 49152-65535) 각 Participant당 2개의 Unicast Port를 사용합니다. 따라서, 하나의 Domain ID에서 사용할 수 있는 최대 Participant의 수는 120개 입니다. (ROS 2는 하나의 프로세스에서 여러 Node를 실행할 수 있기 때문에 Node를 120개까지 사용할 수 있는 것은 아닙니다.) 이러한 이유로 ROS 2 공식 문서에서는 0-101 사이의 Domain ID를 사용하기를 권장하고 있습니다.\nament_general (C++ \u0026amp; Python) ROS 2 개발 시 C++와 Python을 모두 사용할 수 있다는 것은 큰 장점이지만, 패키지 생성 시 사용할 언어를 정해야 하기 때문에 불편한 상황들도 많이 있습니다. 이번 시간에는 하나의 패키지에서 C++와 파이썬을 동시에 사용할 수 있는 방법에 대해서 알아봅시다.\n이번 예시는 직접 패키지를 생성해보면서 따라와보시기를 권장합니다!\nC++와 python 모두를 사용하는 의미에서 ament_general이라는 패키지를 생성하였습니다. ros2 pkg create --build-type ament_cmake ament_general 일반적인 C++ 패키지였다면 다음과 같은 작업들이 이어졌을 것입니다.\nheader 파일 추가 - ament_general/include/ament_general/my_node.hpp #ifndef AMENT_GENERAL__MY_NODE_HPP_ #define AMENT_GENERAL__MY_NODE_HPP_ #include \u0026#34;rclcpp/rclcpp.hpp\u0026#34; using namespace std::chrono_literals; class MyNode: public rclcpp::Node { private: size_t count; rclcpp::TimerBase::SharedPtr timer; public: MyNode(); void timer_callback(); }; #endif header에 대한 구현을 포함하는 cpp 파일 추가 - ament_general/src/my_node.hpp #include \u0026#34;ament_general/my_node.hpp\u0026#34; MyNode::MyNode() : Node(\u0026#34;example_node\u0026#34;) { timer = this-\u0026gt;create_wall_timer( 200ms, std::bind(\u0026amp;MyNode::timer_callback, this) ); } void MyNode::timer_callback() { RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 : %d ====\u0026#34;, count); count++; } rclcpp main 함수가 포함된 main.cpp 추가 #include \u0026#34;ament_general/my_node.hpp\u0026#34; int main(int argc, char **argv) { rclcpp::init(argc, argv); auto node = std::make_shared\u0026lt;MyNode\u0026gt;(); rclcpp::spin(node); rclcpp::shutdown(); return 0; } CMakeLists.txt 수정 include_directories(include) add_executable(my_node src/main.cpp src/my_node.cpp) ament_target_dependencies(my_node rclcpp) install( TARGETS my_node DESTINATION lib/${PROJECT_NAME} ) 빌드 후 실행 # package build cbp ament_general \u0026amp;\u0026amp; source install/local_setup.bash # package run ros2 run ament_general my_node [INFO] [1682942433.465392502] [example_node]: ==== Hello ROS 2 : 0 ==== [INFO] [1682942433.665303331] [example_node]: ==== Hello ROS 2 : 1 ==== [INFO] [1682942433.865330372] [example_node]: ==== Hello ROS 2 : 2 ==== ... 이제 ament_general에 파이썬 코드를 추가하고, ros2 run을 통해 파이썬 코드도 실행할 수 있도록 작업을 진행해봅시다.\nAdd Python node 우리의 궁극적인 목표는 아래와 같은 파일 구조를 생성하는 것입니다. 제시되는 과정을 함께 따라와주세요!\nament_general 폴더 생성 ament_general 내부 init.py 생성 ( 이 파일은 빈 파일입니다.) ament_general 내부에 module이 되는 helper.py 파일을 생성 main 함수를 포함하는 rclpy code 생성 주의할 점이 있습니다. main rclpy 코드는 반드시 Shebang line을 포함해야 합니다!\nmy_py_node.py #!/usr/bin/env python3 import rclpy from rclpy.node import Node from ament_general.helper import * package.xml에 ament_python에 대한 종속성을 포함합니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;?xml-model href=\u0026#34;http://download.ros.org/schema/package_format3.xsd\u0026#34; schematypens=\u0026#34;http://www.w3.org/2001/XMLSchema\u0026#34;?\u0026gt; \u0026lt;package format=\u0026#34;3\u0026#34;\u0026gt; \u0026lt;name\u0026gt;ament_general\u0026lt;/name\u0026gt; \u0026lt;version\u0026gt;0.0.0\u0026lt;/version\u0026gt; \u0026lt;description\u0026gt;TODO: Package description\u0026lt;/description\u0026gt; \u0026lt;maintainer email=\u0026#34;tge1375@naver.com\u0026#34;\u0026gt;kimsooyoung\u0026lt;/maintainer\u0026gt; \u0026lt;license\u0026gt;TODO: License declaration\u0026lt;/license\u0026gt; \u0026lt;!-- python part --\u0026gt; \u0026lt;buildtool_depend\u0026gt;ament_cmake_python\u0026lt;/buildtool_depend\u0026gt; \u0026lt;depend\u0026gt;rclpy\u0026lt;/depend\u0026gt; \u0026lt;!-- python part --\u0026gt; ... CMakeLists.txt에 아래와 같은 라인을 추가합니다. (python 코드 이름은 여러분의 것으로 변경해야 합니다.) ###### Python Part ##### # Install Python modules ament_python_install_package(${PROJECT_NAME}) # Install Python executables install(PROGRAMS ament_general/my_py_node.py DESTINATION lib/${PROJECT_NAME} ) 기존 파이썬 코드들은 수정 후 별도 빌드가 없어도 실행 시 해당 내용이 반영되었지요? 이러한 symlink install 동작을 위해선 파이썬 파일에 권한을 추가해주어야 합니다. chmod +x my_py_node.py 새로운 사용자가 코드를 clone하면 매번 이 작업을 반복해야 합니다. 따라서 실제 개발에 이러한 방법이 자주 사용되지는 않습니다.\n최종 build와 실행입니다. cbp ament_general \u0026amp;\u0026amp; source install/local_setup.bash ros2 run ament_general my_py_node.py "
},
{
	"uri": "/kr/ros2_foxy/lecture17/",
	"title": "Lecture17. Real Hardware Examples",
	"tags": [],
	"description": "",
	"content": " 이번 시간에는 실제 센서 하드웨어를 실행하는 ROS 2 package들을 실행해보고, 코드 분석을 진행해보려합니다. 준비된 예시들은 다음과 같습니다.\nIntel Realsense2 D455 Camera Velodyne VLP16 3D lidar Orbbec Astra+ Camera Intel realsense2 camera ROS 2 real hardware 강의의 두번째 시간으로 Intel의 realsense2 카메라 패키지를 실행하고, 분석해 보겠습니다.\n예제 실행을 위해 필요한 종속성들을 설치하고 realsense sdk인 librealsense를 설치합니다. sudo apt-get update \u0026amp;\u0026amp; sudo apt-get upgrade # Register the server\u0026#39;s public key sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-key F6E65AC044F831AC80A06380C8B3A55A6F3EFCDE || sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-key F6E65AC044F831AC80A06380C8B3A55A6F3EFCDE \u0026gt; gpg: Total number processed: 1 # Add the server to the list of repositories sudo add-apt-repository \u0026#34;deb https://librealsense.intel.com/Debian/apt-repo $(lsb_release -cs) main\u0026#34; -u # Install the libraries (see section below if upgrading packages) sudo apt-get install librealsense2-dkms -y sudo apt-get install librealsense2-utils -y 실제 카메라 연결을 통해 realsense2 패키지 설치를 검증해봅시다. # Reconnect the Intel RealSense depth camera and run realsense-viewer modinfo uvcvideo | grep \u0026#34;version:\u0026#34; # should include realsense string ⇒ 위와 같은 이미지 출력을 얻었다면 성공입니다.\n사실, realsense camera는 intel이 개발한 만큼 ubuntu 배포판 패키지로 ros2를 지원하고 있습니다. 사용만 하고 싶다면 아래와 같이 손쉽게 설치가 가능합니다. # Install Dependencies sudo apt-get install ros-foxy-cv-bridge ros-foxy-librealsense2 ros-foxy-message-filters ros-foxy-image-transport -y sudo apt install ros-foxy-diagnostic-updater -y sudo apt-get install -y libssl-dev libusb-1.0-0-dev pkg-config libgtk-3-dev sudo apt-get install -y libglfw3-dev libgl1-mesa-dev libglu1-mesa-dev ⇒ 하지만 우리는 패키지 분석이 목적이므로 직접 소스코드 빌드와 분석을 해보겠습니다. 아래 링크를 통해 release version을 다운받고 ros2 workspace에 압축을 해제합니다.\nhttps://github.com/IntelRealSense/realsense-ros/releases\n폴더 이동 후 빌드는 아래 순서대로 해주세요! cbp realsense2_camera_msgs \u0026amp;\u0026amp; source install/local_setup.bash cbp realsense2_description \u0026amp;\u0026amp; source install/local_setup.bash cbp realsense2_camera \u0026amp;\u0026amp; source install/local_setup.bash 우선 빌드가 잘 되었는지 예시부터 실행해봅시다. ros2 launch realsense2_camera rs_launch.py topic list, rviz2를 통해 정상 동작을 확인합니다. $ ros2 topic list /camera/color/camera_info /camera/color/image_raw /camera/color/metadata /camera/depth/camera_info /camera/depth/image_rect_raw /camera/depth/metadata /camera/extrinsics/depth_to_color /camera/extrinsics/depth_to_depth /camera/imu /parameter_events /rosout /tf_static point cloud topic을 활성화하기 위해선 아래와 같은 launch가 필요합니다. ros2 launch realsense2_camera rs_launch.py pointcloud.enable:=true rviz2를 통해 pointcloud를 시각화해봅시다. (메가커피에서 강의를 제작해서 손흥민 선수 얼굴이 보이네요 ㅎㅎ) rviz2에서 tf2 data도 확인할 수 있습니다. fixed frame은 camera_link로 두시면 됩니다. tf2 tree도 확인해봅시다. Composition launch realsense ros2 package는 Intra-communication을 사용하여 메모리 최적화를 적용한 composition launch도 지원하고 있습니다. 이를 사용하기 위해서는 패키지 빌드를 다시 해야 하며, 이러한 이유로 저는 realsense_ws라는 별도의 workspace를 만들었습니다.\ncd ~/ mkdir -p realsense_ws/src cd realsense_ws # locate packages \u0026amp; build again colcon build --cmake-args \u0026#39;-DBUILD_TOOLS=ON\u0026#39; Composition 예시를 실행해봅시다! $ ros2 launch realsense2_camera rs_intra_process_demo_launch.py ... [component_container-1] [INFO] [1682508794.621382739] [frame_latency]: Got msg with address 0x7fe51c6cb570 with latency of 0.0597926 [sec] [component_container-1] [INFO] [1682508794.689360200] [frame_latency]: Got msg with address 0x7fe51c6cb570 with latency of 0.0610729 [sec] [component_container-1] [INFO] [1682508794.755558725] [frame_latency]: Got msg with address 0x7fe51c6cb570 with latency of 0.0605604 [sec] [component_container-1] [INFO] [1682508794.822757399] [frame_latency]: Got msg with address 0x7fe51c6cb570 with latency of 0.0610629 [sec] [component_container-1] [INFO] [1682508794.889473916] [frame_latency]: Got msg with address 0x7fe51c6cb570 with latency of 0.0610784 [sec] [component_container-1] [INFO] [1682508794.955772739] [frame_latency]: Got msg with address 0x7fe51c6cb570 with latency of 0.0606767 [sec] [component_container-1] [INFO] [1682508795.022029595] [frame_latency]: Got msg with address 0x7fe51c6cb570 with latency of 0.0602304 [sec] [component_container-1] [INFO] [1682508795.088818104] [frame_latency]: Got msg with address 0x7fe51c6cb570 with latency of 0.0603308 [sec] [component_container-1] [INFO] [1682508795.156870084] [frame_latency]: Got msg with address 0x7fe51c6cb570 with latency of 0.0616579 [sec] [component_container-1] [INFO] [1682508795.223072425] [frame_latency]: rqt_image_view를 통해 이미지도 확인해 보겠습니다. $ ros2 run rqt_image_view rqt_image_view 실제 일반 node 실행과 composition 사용 시 점유하는 메모리를 비교해 보았습니다. PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2530 kimsooy+ 20 0 897252 82312 50300 R 12.3 0.5 1:09.80 x-terminal-emul 1247 kimsooy+ 20 0 6284836 344712 109988 S 11.3 2.1 7:17.14 gnome-shell 41892 kimsooy+ 20 0 1183960 85788 57140 S 5.3 0.5 0:03.28 component_conta PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1247 kimsooy+ 20 0 6333092 344816 109988 S 11.6 2.1 8:00.07 gnome-shell 2530 kimsooy+ 20 0 897252 82664 50300 S 10.9 0.5 1:33.14 x-terminal-emul 42240 kimsooy+ 20 0 1457552 92104 57096 S 8.9 0.6 0:03.88 realsense2_came 노트북 환경이어 겉보기에 큰 차이는 없지만, 실제 edge device에서 실행 + 다중 Node들이 결합되는 경우 Composition 사용 여부가 큰 차이를 가질 것입니다.\nrealsense2 Launch file 분석 launch file과 소스코드 일부 분석을 통해 센서 패키지 개발의 흐름을 이해해봅시다.\nrs_launch.py의 시작은 수많은 launch configuration들로 시작됩니다. (DeclareLaunchArgument, LaunchConfiguration을 별도의 함수로 구현해 두고 재사용하고 있습니다.) configurable_parameters = [{\u0026#39;name\u0026#39;: \u0026#39;camera_name\u0026#39;, \u0026#39;default\u0026#39;: \u0026#39;camera\u0026#39;, \u0026#39;description\u0026#39;: \u0026#39;camera unique name\u0026#39;}, {\u0026#39;name\u0026#39;: \u0026#39;serial_no\u0026#39;, \u0026#39;default\u0026#39;: \u0026#34;\u0026#39;\u0026#39;\u0026#34;, \u0026#39;description\u0026#39;: \u0026#39;choose device by serial number\u0026#39;}, {\u0026#39;name\u0026#39;: \u0026#39;usb_port_id\u0026#39;, \u0026#39;default\u0026#39;: \u0026#34;\u0026#39;\u0026#39;\u0026#34;, \u0026#39;description\u0026#39;: \u0026#39;choose device by usb port id\u0026#39;}, {\u0026#39;name\u0026#39;: \u0026#39;device_type\u0026#39;, \u0026#39;default\u0026#39;: \u0026#34;\u0026#39;\u0026#39;\u0026#34;, \u0026#39;description\u0026#39;: \u0026#39;choose device by type\u0026#39;}, ... def declare_configurable_parameters(parameters): return [DeclareLaunchArgument(param[\u0026#39;name\u0026#39;], default_value=param[\u0026#39;default\u0026#39;], description=param[\u0026#39;description\u0026#39;]) for param in parameters] def set_configurable_parameters(parameters): return dict([(param[\u0026#39;name\u0026#39;], LaunchConfiguration(param[\u0026#39;name\u0026#39;])) for param in parameters]) ROS 2 dashing, eloquent, foxy / 별도 user config file이 있는지 등 각종 조건에 따른 조건 분리도 설정해 두었습니다. def generate_launch_description(): log_level = \u0026#39;info\u0026#39; if (os.getenv(\u0026#39;ROS_DISTRO\u0026#39;) == \u0026#34;dashing\u0026#34;) or (os.getenv(\u0026#39;ROS_DISTRO\u0026#39;) == \u0026#34;eloquent\u0026#34;): ... else: return LaunchDescription(declare_configurable_parameters(configurable_parameters) + [ # Realsense launch_ros.actions.Node( condition=IfCondition(PythonExpression([LaunchConfiguration(\u0026#39;config_file\u0026#39;), \u0026#34; == \u0026#39;\u0026#39;\u0026#34;])), ... launch_ros.actions.Node( condition=IfCondition(PythonExpression([LaunchConfiguration(\u0026#39;config_file\u0026#39;), \u0026#34; != \u0026#39;\u0026#39;\u0026#34;])), 실제 실행되는 것은 realsense2_camera_node이며, 다음으로 이 node에 대해서 파헤쳐보겠습니다. launch_ros.actions.Node( package=\u0026#39;realsense2_camera\u0026#39;, namespace=LaunchConfiguration(\u0026#34;camera_name\u0026#34;), name=LaunchConfiguration(\u0026#34;camera_name\u0026#34;), executable=\u0026#39;realsense2_camera_node\u0026#39;, parameters=[set_configurable_parameters(configurable_parameters) , PythonExpression([LaunchConfiguration(\u0026#34;config_file\u0026#34;)]) ], output=\u0026#39;screen\u0026#39;, arguments=[\u0026#39;--ros-args\u0026#39;, \u0026#39;--log-level\u0026#39;, LaunchConfiguration(\u0026#39;log_level\u0026#39;)], emulate_tty=True, ) 코드 분석 CMakeLists.txt를 살펴보면 realsense2_camera_node이 어떻게 빌드된 결과물인지 확인할 수 있습니다. rclcpp_components_register_node(${PROJECT_NAME} PLUGIN \u0026#34;realsense2_camera::RealSenseNodeFactory\u0026#34; EXECUTABLE realsense2_camera_node ) 그런데, 일반적으로 executable을 빌드하는 방식이 아닌 rclcpp_components_register_node라는 옵션을 사용하고 있습니다. rclcpp_components_register_node은 라이브러리, 실행 파일을 모두 생성할 수 있는 rclcpp의 CMake tools입니다. https://docs.ros2.org/latest/api/rclcpp_components/\nrealsense2 ROS 2 package는 ROS 1 때부터의 레거시가 잔존하고 구조상으로 깔끔하다고 말하기는 어려운 코드입니다. 분석은 하겠지만 이러한 형태가 일반적이라고 할 수 없음을 인지하시기 바랍니다! (저라면 싹다 처음부터 짤 것 같습니다.)\nrealsense2_camera_node를 구성하는 composition인 RealSenseNodeFactory는 realsense_node_factory.h에 구현되어 있습니다. 디자인 패턴을 따랐다고 말할 수는 없지만, 일종의 팩토리이며 _realSenseNode가 Node에 해당합니다. namespace realsense2_camera { class RealSenseNodeFactory : public rclcpp::Node { public: explicit RealSenseNodeFactory(const rclcpp::NodeOptions \u0026amp; node_options = rclcpp::NodeOptions()); RealSenseNodeFactory( const std::string \u0026amp; node_name, const std::string \u0026amp; ns, const rclcpp::NodeOptions \u0026amp; node_options = rclcpp::NodeOptions()); virtual ~RealSenseNodeFactory(); private: void init(); void closeDevice(); void startDevice(); void changeDeviceCallback(rs2::event_information\u0026amp; info); void getDevice(rs2::device_list list); void tryGetLogSeverity(rs2_log_severity\u0026amp; severity) const; static std::string parseUsbPort(std::string line); rclcpp::Node::SharedPtr _node; rs2::device _device; std::unique_ptr\u0026lt;BaseRealSenseNode\u0026gt; _realSenseNode; rs2::context _ctx; std::string _serial_no; std::string _usb_port_id; std::string _device_type; double _wait_for_device_timeout; double _reconnect_timeout; bool _initial_reset; std::thread _query_thread; bool _is_alive; rclcpp::Logger _logger; std::shared_ptr\u0026lt;Parameters\u0026gt; _parameters; }; }//end namespace 우선 여기서 몇가지 주요 함수들을 분석하고 더 깊이 들어가보겠습니다.\nrealsense_node_factory.cpp - startDevice() void RealSenseNodeFactory::startDevice() { if (_realSenseNode) _realSenseNode.reset(); std::string pid_str(_device.get_info(RS2_CAMERA_INFO_PRODUCT_ID)); uint16_t pid = std::stoi(pid_str, 0, 16); try { switch(pid) { case SR300_PID: case SR300v2_PID: case RS400_PID: case RS405_PID: case RS410_PID: case RS460_PID: case RS415_PID: case RS420_PID: case RS420_MM_PID: case RS430_PID: case RS430_MM_PID: case RS430_MM_RGB_PID: case RS435_RGB_PID: case RS435i_RGB_PID: case RS455_PID: case RS465_PID: case RS_USB2_PID: case RS_L515_PID_PRE_PRQ: case RS_L515_PID: case RS_L535_PID: _realSenseNode = std::unique_ptr\u0026lt;BaseRealSenseNode\u0026gt;(new BaseRealSenseNode(*this, _device, _parameters, this-\u0026gt;get_node_options().use_intra_process_comms())); break; case RS_T265_PID: _realSenseNode = std::unique_ptr\u0026lt;T265RealsenseNode\u0026gt;(new T265RealsenseNode(*this, _device, _parameters, this-\u0026gt;get_node_options().use_intra_process_comms())); break; default: ROS_FATAL_STREAM(\u0026#34;Unsupported device!\u0026#34; \u0026lt;\u0026lt; \u0026#34; Product ID: 0x\u0026#34; \u0026lt;\u0026lt; pid_str); rclcpp::shutdown(); exit(1); } _realSenseNode-\u0026gt;publishTopics(); } catch(const rs2::backend_error\u0026amp; e) { std::cerr \u0026lt;\u0026lt; \u0026#34;Failed to start device: \u0026#34; \u0026lt;\u0026lt; e.what() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; _device.hardware_reset(); _device = rs2::device(); } } main Node인 _realSenseNode를 정의하고 있으며, 이는 사용하는 카메라 모델에 따라 차이를 갖습니다.\n_realSenseNode를 생성한 이후, publishTopics 메소드가 호출됩니다. base_realsense_node.cpp - publishTopics() void BaseRealSenseNode::publishTopics() { getParameters(); setup(); ROS_INFO_STREAM(\u0026#34;RealSense Node Is Up!\u0026#34;); } ⇒ getParameters()에서는 말 그대로 각종 ROS 2 매개변수들의 파싱이 이루어집니다.\nsetup() 메소드에서 주요 기능들이 실행되며 여기로 한단계 더 진입해보겠습니다. BaseRealSenseNode::setup() void BaseRealSenseNode::setup() { setDynamicParams(); startDiagnosticsUpdater(); setAvailableSensors(); SetBaseStream(); setupFilters(); setupFiltersPublishers(); setCallbackFunctions(); monitoringProfileChanges(); updateSensors(); publishServices(); } 이렇게 복잡한 구조를 갖게 된 까닭은 유추하건데 ROS 1의 레거시에서 시작했기 때문일겁니다. ⇒ ROS 1 코드에서 주요 기능들을 모두 모듈화하고 ROS 2에서는 setup()이라는 이름으로 모조리 때려넣은 것이지요. 다시 말하지만, 구조적으로 잘 구현된 코드는 아닙니다.\n위 함수들 대부분은 이름을 통해 기능을 유추할 수 있으며 중요한 함수들만 몇가지 파헤쳐보겠습니다.\nsetAvailableSensors std::function\u0026lt;void(rs2::frame)\u0026gt; frame_callback_function = [this](rs2::frame frame){ bool is_filter(_filters.end() != find_if(_filters.begin(), _filters.end(), [](std::shared_ptr\u0026lt;NamedFilter\u0026gt; f){return (f-\u0026gt;is_enabled()); })); if (_sync_frames || is_filter) this-\u0026gt;_asyncer.invoke(frame); else frame_callback(frame); }; std::function\u0026lt;void(rs2::frame)\u0026gt; imu_callback_function = [this](rs2::frame frame){ imu_callback(frame); if (_imu_sync_method != imu_sync_method::NONE) imu_callback_sync(frame); }; std::function\u0026lt;void(rs2::frame)\u0026gt; multiple_message_callback_function = [this](rs2::frame frame){multiple_message_callback(frame, _imu_sync_method);}; std::function\u0026lt;void()\u0026gt; update_sensor_func = [this](){ { std::lock_guard\u0026lt;std::mutex\u0026gt; lock_guard(_profile_changes_mutex); _is_profile_changed = true; } _cv_mpc.notify_one(); }; 각종 callback들이 구현됩니다. 현재 callback안에서 다시 callback이 실행되기도 하고, lock guard가 호출되고도 있지만, 결국 해당 callback들이 subscriber, service server의 callback으로 사용됩니다.\n더불어, setAvailableSensors에서 librealsense와, ROS 2의 연동이 동작합니다. 이를 RosSensor라는 패턴으로 구현하여 앞서 구현한 callback들과 binding합니다. for(auto\u0026amp;\u0026amp; sensor : _dev_sensors) { const std::string module_name(sensor.get_info(RS2_CAMERA_INFO_NAME)); std::unique_ptr\u0026lt;RosSensor\u0026gt; rosSensor; if (sensor.is\u0026lt;rs2::depth_sensor\u0026gt;() || sensor.is\u0026lt;rs2::color_sensor\u0026gt;() || sensor.is\u0026lt;rs2::fisheye_sensor\u0026gt;()) { ROS_DEBUG_STREAM(\u0026#34;Set \u0026#34; \u0026lt;\u0026lt; module_name \u0026lt;\u0026lt; \u0026#34; as VideoSensor.\u0026#34;); rosSensor = std::make_unique\u0026lt;RosSensor\u0026gt;(sensor, _parameters, frame_callback_function, update_sensor_func, hardware_reset_func, _diagnostics_updater, _logger, _use_intra_process, _dev.is\u0026lt;playback\u0026gt;()); } else if (sensor.is\u0026lt;rs2::motion_sensor\u0026gt;()) { ROS_DEBUG_STREAM(\u0026#34;Set \u0026#34; \u0026lt;\u0026lt; module_name \u0026lt;\u0026lt; \u0026#34; as ImuSensor.\u0026#34;); rosSensor = std::make_unique\u0026lt;RosSensor\u0026gt;(sensor, _parameters, imu_callback_function, update_sensor_func, hardware_reset_func, _diagnostics_updater, _logger, false, _dev.is\u0026lt;playback\u0026gt;()); } else if (sensor.is\u0026lt;rs2::pose_sensor\u0026gt;()) { ROS_DEBUG_STREAM(\u0026#34;Set \u0026#34; \u0026lt;\u0026lt; module_name \u0026lt;\u0026lt; \u0026#34; as PoseSensor.\u0026#34;); rosSensor = std::make_unique\u0026lt;RosSensor\u0026gt;(sensor, _parameters, multiple_message_callback_function, update_sensor_func, hardware_reset_func, _diagnostics_updater, _logger, false, _dev.is\u0026lt;playback\u0026gt;()); } else { ROS_ERROR_STREAM(\u0026#34;Module Name \\\u0026#34;\u0026#34; \u0026lt;\u0026lt; module_name \u0026lt;\u0026lt; \u0026#34;\\\u0026#34; does not define a callback.\u0026#34;); throw(\u0026#34;Error: Module not supported\u0026#34;); } _available_ros_sensors.push_back(std::move(rosSensor)); } 생성된 rosSensor들은 _available_ros_sensors에 push_back된 후, updateSensors에서 소비됩니다. void BaseRealSenseNode::updateSensors() { std::lock_guard\u0026lt;std::mutex\u0026gt; lock_guard(_update_sensor_mutex); try{ for(auto\u0026amp;\u0026amp; sensor : _available_ros_sensors) { if(is_profile_changed) { // Start/stop sensors only if profile was changed // No need to start/stop sensors if align_depth was changed ROS_INFO_STREAM(\u0026#34;Stopping Sensor: \u0026#34; \u0026lt;\u0026lt; module_name); sensor-\u0026gt;stop(); } stopPublishers(active_profiles); if (!wanted_profiles.empty()) { if(is_profile_changed) { ROS_INFO_STREAM(\u0026#34;Starting Sensor: \u0026#34; \u0026lt;\u0026lt; module_name); sensor-\u0026gt;start(wanted_profiles); } ... RosSensor의 start 메소드에서 드디어 realsense sdk와의 연동이 동작하며, \\_frame_callback이라는 메모리 전달이 구현되어 있습니다. // base_realsense_node.h std::vector\u0026lt;std::unique_ptr\u0026lt;RosSensor\u0026gt;\u0026gt; _available_ros_sensors; bool RosSensor::start(const std::vector\u0026lt;stream_profile\u0026gt;\u0026amp; profiles) { if (get_active_streams().size() \u0026gt; 0) return false; setupErrorCallback(); rs2::sensor::open(profiles); for (auto\u0026amp; profile : profiles) ROS_INFO_STREAM(\u0026#34;Open profile: \u0026#34; \u0026lt;\u0026lt; ProfilesManager::profile_string(profile)); rs2::sensor::start(_frame_callback); ... return true; } ... _frame_callback = [this](rs2::frame frame) { runFirstFrameInitialization(); auto stream_type = frame.get_profile().stream_type(); auto stream_index = frame.get_profile().stream_index(); stream_index_pair sip{stream_type, stream_index}; try { _origin_frame_callback(frame); if (_frequency_diagnostics.find(sip) != _frequency_diagnostics.end()) _frequency_diagnostics.at(sip).Tick(); } catch(const std::exception\u0026amp; ex) ... }; Publish 분석 실제 image topic이 publish 되는 부분을 추가로 분석해 보겠습니다.\nstartPublishers 내부에서 image_rcl_publisher 타입의 클래스 포인터가 할당됩니다. void BaseRealSenseNode::startPublishers(const std::vector\u0026lt;stream_profile\u0026gt;\u0026amp; profiles, const RosSensor\u0026amp; sensor) { const std::string module_name(create_graph_resource_name(rs2_to_ros(sensor.get_info(RS2_CAMERA_INFO_NAME)))); for (auto\u0026amp; profile : profiles) { ... // We can use 2 types of publishers: // Native RCL publisher that support intra-process zero-copy comunication // image-transport package publisher that adds a commpressed image topic if package is found installed if (_use_intra_process) { _image_publishers[sip] = std::make_shared\u0026lt;image_rcl_publisher\u0026gt;(_node, image_raw.str(), qos); } else { _image_publishers[sip] = std::make_shared\u0026lt;image_transport_publisher\u0026gt;(_node, image_raw.str(), qos); ROS_DEBUG_STREAM(\u0026#34;image transport publisher was created for topic\u0026#34; \u0026lt;\u0026lt; image_raw.str()); } ... if (_use_intra_process) { _depth_aligned_image_publishers[sip] = std::make_shared\u0026lt;image_rcl_publisher\u0026gt;(_node, aligned_image_raw.str(), qos); } else { _depth_aligned_image_publishers[sip] = std::make_shared\u0026lt;image_transport_publisher\u0026gt;(_node, aligned_image_raw.str(), qos); ROS_DEBUG_STREAM(\u0026#34;image transport publisher was created for topic\u0026#34; \u0026lt;\u0026lt; image_raw.str()); } _depth_aligned_info_publisher[sip] = _node.create_publisher\u0026lt;sensor_msgs::msg::CameraInfo\u0026gt;(aligned_camera_info.str(), rclcpp::QoS(rclcpp::QoSInitialization::from_rmw(info_qos), info_qos)); } 참고로, _image_publishers는 아래와 같이 std::map 타입의 클래스 변수이며 index_pair와 image_publisher 포인터를 담고 있습니다. std::map\u0026lt;stream_index_pair, std::shared_ptr\u0026lt;image_publisher\u0026gt;\u0026gt; _image_publishers; image_publisher.cpp - image_rcl_publisher image_rcl_publisher의 publish 메소드에서 드디어 실질적인 publish가 이루어집니다. 더불어 std::move를 통해 소유권을 이전하고 있습니다. (intra-processing에 대비한 것으로 보입니다.) image_rcl_publisher::image_rcl_publisher( rclcpp::Node \u0026amp; node, const std::string \u0026amp; topic_name, const rmw_qos_profile_t \u0026amp; qos ) { image_publisher_impl = node.create_publisher\u0026lt; sensor_msgs::msg::Image \u0026gt;( topic_name, rclcpp::QoS( rclcpp::QoSInitialization::from_rmw( qos ), qos ) ); } void image_rcl_publisher::publish( sensor_msgs::msg::Image::UniquePtr image_ptr ) { image_publisher_impl-\u0026gt;publish( std::move( image_ptr ) ); } ... image_transport_publisher::image_transport_publisher( rclcpp::Node \u0026amp; node, const std::string \u0026amp; topic_name, const rmw_qos_profile_t \u0026amp; qos ) { image_publisher_impl = std::make_shared\u0026lt; image_transport::Publisher \u0026gt;( image_transport::create_publisher( \u0026amp;node, topic_name, qos ) ); } void image_transport_publisher::publish( sensor_msgs::msg::Image::UniquePtr image_ptr ) { image_publisher_impl-\u0026gt;publish( *image_ptr ); } image_rcl_publisher가 사용되는 부분을 추적해 보겠습니다. BaseRealSenseNode의 frame_callback에서 다시 publishFrame callback을 호출하여 _image_publishers를 전달하고 있습니다. void BaseRealSenseNode::frame_callback(rs2::frame frame) { ... publishFrame(f, t, sip, _image, _info_publisher, _image_publishers); ... publishFrame(frame_to_send, t, DEPTH, _image, _info_publisher, _image_publishers); 전달된 _image_publishers는 std::map type이기 때문에 rgb, depth, infra camera 중에서 indexing하여 최종 publish가 진행됩니다. void BaseRealSenseNode::publishFrame(rs2::frame f, const rclcpp::Time\u0026amp; t, const stream_index_pair\u0026amp; stream, std::map\u0026lt;stream_index_pair, cv::Mat\u0026gt;\u0026amp; images, const std::map\u0026lt;stream_index_pair, rclcpp::Publisher\u0026lt;sensor_msgs::msg::CameraInfo\u0026gt;::SharedPtr\u0026gt;\u0026amp; info_publishers, const std::map\u0026lt;stream_index_pair, std::shared_ptr\u0026lt;image_publisher\u0026gt;\u0026gt;\u0026amp; image_publishers, const bool is_publishMetadata){ auto\u0026amp; image_publisher = image_publishers.at(stream); ... image_publisher-\u0026gt;publish(std::move(img)); 다시 말하지만, realsense2 ros2 코드가 완성도가 높은 것은 아닙니다. 하지만, 적어도 ROS 2시스템 차원에서 코드를 분석할 수 있는 예시가 되기에 같이 파헤쳐 보았습니다.\nrs_intra_process_demo_launch.py Composition 예시에서 살펴본 바와 같이 launch file에서 ComposableNodeContainer를 통해 composition container를 실행하고, RealSenseNodeFactory/FrameLatencyNode composition을 load하고 있습니다. rs_node_class= \u0026#39;RealSenseNodeFactory\u0026#39; rs_latency_tool_class = \u0026#39;FrameLatencyNode\u0026#39; ... def generate_launch_description(): return LaunchDescription(declare_configurable_parameters(configurable_parameters) + [ ComposableNodeContainer( name=\u0026#39;my_container\u0026#39;, namespace=\u0026#39;\u0026#39;, package=\u0026#39;rclcpp_components\u0026#39;, executable=\u0026#39;component_container\u0026#39;, composable_node_descriptions=[ ComposableNode( package=\u0026#39;realsense2_camera\u0026#39;, namespace=\u0026#39;\u0026#39;, plugin=\u0026#39;realsense2_camera::\u0026#39; + rs_node_class, name=\u0026#34;camera\u0026#34;, parameters=[set_configurable_parameters(configurable_parameters)], extra_arguments=[{\u0026#39;use_intra_process_comms\u0026#39;: LaunchConfiguration(\u0026#34;intra_process_comms\u0026#34;)}]) , ComposableNode( package=\u0026#39;realsense2_camera\u0026#39;, namespace=\u0026#39;\u0026#39;, plugin=\u0026#39;rs2_ros::tools::frame_latency::\u0026#39; + rs_latency_tool_class, name=\u0026#39;frame_latency\u0026#39;, parameters=[set_configurable_parameters(configurable_parameters)], extra_arguments=[{\u0026#39;use_intra_process_comms\u0026#39;: LaunchConfiguration(\u0026#34;intra_process_comms\u0026#34;)}]) , ], output=\u0026#39;screen\u0026#39;, emulate_tty=True, # needed for display of logs arguments=[\u0026#39;--ros-args\u0026#39;, \u0026#39;--log-level\u0026#39;, LaunchConfiguration(\u0026#39;log_level\u0026#39;)], )]) RealSenseNodeFactory는 애초에 composition 형태로 개발되었으므로 실제 코드를 살펴보아도 로그를 남기는 것외에 추가 작업은 없습니다. BaseRealSenseNode::BaseRealSenseNode(rclcpp::Node\u0026amp; node, rs2::device dev, std::shared_ptr\u0026lt;Parameters\u0026gt; parameters, bool use_intra_process) : ... _use_intra_process(use_intra_process), ... { if ( use_intra_process ) { ROS_INFO(\u0026#34;Intra-Process communication enabled\u0026#34;); } FrameLatencyNode는 tools ⇒ frame_latency에 구현되어 있으며, 단순히 topic publish의 지연 시간을 계산하여 콘솔 출력합니다. FrameLatencyNode::FrameLatencyNode( const rclcpp::NodeOptions \u0026amp; node_options ) : Node( \u0026#34;frame_latency\u0026#34;, \u0026#34;/\u0026#34;, node_options ) , _logger( this-\u0026gt;get_logger() ) { ROS_INFO_STREAM( \u0026#34;frame_latency node is UP!\u0026#34; ); ROS_INFO_STREAM( \u0026#34;Intra-Process is \u0026#34; \u0026lt;\u0026lt; ( this-\u0026gt;get_node_options().use_intra_process_comms() ? \u0026#34;ON\u0026#34; : \u0026#34;OFF\u0026#34; ) ); // Create a subscription on the input topic. _sub = this-\u0026gt;create_subscription\u0026lt; sensor_msgs::msg::Image \u0026gt;( \u0026#34;/color/image_raw\u0026#34;, // TODO Currently color only, we can declare and accept the required // streams as ros parameters rclcpp::QoS( rclcpp::QoSInitialization::from_rmw( rmw_qos_profile_default ), rmw_qos_profile_default ), [\u0026amp;, this]( const sensor_msgs::msg::Image::SharedPtr msg ) { rclcpp::Time curr_time = this-\u0026gt;get_clock()-\u0026gt;now(); auto latency = ( curr_time - msg-\u0026gt;header.stamp ).seconds(); ROS_INFO_STREAM( \u0026#34;Got msg with address 0x\u0026#34; \u0026lt;\u0026lt; std::hex \u0026lt;\u0026lt; reinterpret_cast\u0026lt; std::uintptr_t \u0026gt;( msg.get() ) \u0026lt;\u0026lt; std::dec \u0026lt;\u0026lt; \u0026#34; with latency of \u0026#34; \u0026lt;\u0026lt; latency \u0026lt;\u0026lt; \u0026#34; [sec]\u0026#34; ); } ); } rs_multi_camera_launch.py rs_multi_camera_launch에서는 namespace가 지정된 rs_launch.py 2개가 실행되며, rviz2 시각화를 위해 별도로 static_transform_publisher가 실행됩니다. local_parameters = [{\u0026#39;name\u0026#39;: \u0026#39;camera_name1\u0026#39;, \u0026#39;default\u0026#39;: \u0026#39;camera1\u0026#39;, \u0026#39;description\u0026#39;: \u0026#39;camera unique name\u0026#39;}, {\u0026#39;name\u0026#39;: \u0026#39;camera_name2\u0026#39;, \u0026#39;default\u0026#39;: \u0026#39;camera2\u0026#39;, \u0026#39;description\u0026#39;: \u0026#39;camera unique name\u0026#39;}, ] ... def generate_launch_description(): params1 = duplicate_params(rs_launch.configurable_parameters, \u0026#39;1\u0026#39;) params2 = duplicate_params(rs_launch.configurable_parameters, \u0026#39;2\u0026#39;) return LaunchDescription( rs_launch.declare_configurable_parameters(local_parameters) + rs_launch.declare_configurable_parameters(params1) + rs_launch.declare_configurable_parameters(params2) + [ IncludeLaunchDescription( PythonLaunchDescriptionSource([ThisLaunchFileDir(), \u0026#39;/rs_launch.py\u0026#39;]), launch_arguments=set_configurable_parameters(params1).items(), ), IncludeLaunchDescription( PythonLaunchDescriptionSource([ThisLaunchFileDir(), \u0026#39;/rs_launch.py\u0026#39;]), launch_arguments=set_configurable_parameters(params2).items(), ), # dummy static transformation from camera1 to camera2 launch_ros.actions.Node( package = \u0026#34;tf2_ros\u0026#34;, executable = \u0026#34;static_transform_publisher\u0026#34;, arguments = [\u0026#34;0\u0026#34;, \u0026#34;0\u0026#34;, \u0026#34;0\u0026#34;, \u0026#34;0\u0026#34;, \u0026#34;0\u0026#34;, \u0026#34;0\u0026#34;, \u0026#34;camera1_link\u0026#34;, \u0026#34;camera2_link\u0026#34;] ), ]) rs_multi_camera_launch.py에서 선언된 camera_name launch argument는 rs_launch.py로 전달되어 namespace 옵션에 추가됨과 더불어 Composotion에게 전달됩니다. return LaunchDescription(declare_configurable_parameters(configurable_parameters) + [ # Realsense launch_ros.actions.Node( condition=IfCondition(PythonExpression([LaunchConfiguration(\u0026#39;config_file\u0026#39;), \u0026#34; == \u0026#39;\u0026#39;\u0026#34;])), package=\u0026#39;realsense2_camera\u0026#39;, namespace=LaunchConfiguration(\u0026#34;camera_name\u0026#34;), name=LaunchConfiguration(\u0026#34;camera_name\u0026#34;), executable=\u0026#39;realsense2_camera_node\u0026#39;, parameters=[set_configurable_parameters(configurable_parameters)], output=\u0026#39;screen\u0026#39;, arguments=[\u0026#39;--ros-args\u0026#39;, \u0026#39;--log-level\u0026#39;, LaunchConfiguration(\u0026#39;log_level\u0026#39;)], emulate_tty=True, ), parameter를 모두 관리하는 parameters.cpp에서 camera_name의 파싱을 확인할 수 있습니다. void BaseRealSenseNode::getParameters() { ROS_INFO(\u0026#34;getParameters...\u0026#34;); std::string param_name; param_name = std::string(\u0026#34;camera_name\u0026#34;); _camera_name = _parameters-\u0026gt;setParam\u0026lt;std::string\u0026gt;(param_name, \u0026#34;camera\u0026#34;); _parameters_names.push_back(param_name); realsense2 Description description이라는 이름을 가진 패키지는 CAD, URDF 파일과 같은 물성치, 외관에 대한 데이터를 담고 있습니다. realsense의 description package를 분석해봅시다.\n기본 launch file을 실행해 보겠으며, d455 옵션으로 실행해보겠습니다. ros2 launch realsense2_description view_model.launch.py model:=\u0026lt;sth\u0026gt; ros2 launch realsense2_description view_model.launch.py model:=test_d455_camera.urdf.xacro ⇒ 센서 외관을 비롯하여 다양한 내장 센서들에 대한 tf2도 확인할 수 있습니다.\ntf2 tree를 통해 이에 대한 자세한 구조를 파악할 수 있으며, d455는 카메라 뿐만 아니라 가속도 센서, 자이로 센서를 포함하고 있어 아래와 같이 복잡한 구조를 갖게 됩니다. 지금 tf2 tree에서는 base_link가 최상위 Node인데요. 실제 로봇 시스템에 장착 시 로봇의 base_link가 이미 존재한다면 의도치 않은 tf2 error가 발생할 수 있습니다.\n실제 test_d455_camera.urdf.xacro 파일에서도 이를 손쉽게 제거할 수 있도록 아래와 같이 base_link를 별도 분리해둔 모습을 볼 수 있습니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;robot name=\u0026#34;realsense2_camera\u0026#34; xmlns:xacro=\u0026#34;http://ros.org/wiki/xacro\u0026#34;\u0026gt; \u0026lt;xacro:arg name=\u0026#34;use_nominal_extrinsics\u0026#34; default=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find realsense2_description)/urdf/_d455.urdf.xacro\u0026#34; /\u0026gt; \u0026lt;link name=\u0026#34;base_link\u0026#34; /\u0026gt; \u0026lt;xacro:sensor_d455 parent=\u0026#34;base_link\u0026#34; use_nominal_extrinsics=\u0026#34;$(arg use_nominal_extrinsics)\u0026#34;\u0026gt; \u0026lt;origin xyz=\u0026#34;0 0 0\u0026#34; rpy=\u0026#34;0 0 0\u0026#34;/\u0026gt; \u0026lt;/xacro:sensor_d455\u0026gt; \u0026lt;/robot\u0026gt; Description Launch file 분석 view_model.launch.py - 실제 실행되는 Node는 robot_state_publisher와 rviz2 입니다. (센서는 움직이는 파츠가 없으니 joint_state_publisher는 굳이 필요 없겠지요?) rviz_node = Node( package=\u0026#39;rviz2\u0026#39;, executable=\u0026#39;rviz2\u0026#39;, node_name=\u0026#39;rviz2\u0026#39;, output = \u0026#39;screen\u0026#39;, arguments=[\u0026#39;-d\u0026#39;, rviz_config_dir], parameters=[{\u0026#39;use_sim_time\u0026#39;: False}] ) model_node = Node( node_name=\u0026#39;model_node\u0026#39;, package=\u0026#39;robot_state_publisher\u0026#39;, executable=\u0026#39;robot_state_publisher\u0026#39;, namespace=\u0026#39;\u0026#39;, output=\u0026#39;screen\u0026#39;, arguments = [urdf] ) return launch.LaunchDescription([rviz_node, model_node]) robot_state_publisher의 argument로 urdf 파일들이 전달되며, 사용자로부터 mode:= 값을 받아 해당 urdf file이 실행되는 형식입니다. (저라면 Launch Argument를 사용했을 것 같습니다.)\nurdf 폴더를 살펴보면, 모든 모델에 대한 기본 urdf file과, description launch를 위해 base_link가 결합된 test urdf들이 자동생성되어있는 모습을 확인할 수 있습니다. 마지막으로 카메라 센서의 tf2 사용 시 주의할 점이 있는데요. 일반적으로 컴퓨터 비전 도메인에서 사용하는 좌표계와, ROS 2에서 사용하는 좌표계는 아래와 같이 차이를 갖습니다. gazebo plugin 시간에 살펴보았던 것처럼 rviz2를 통해 검증을 한 뒤 사용하기를 추천드립니다. Custom Message 대부분 센서 패키지들은 sdk에서 정의된 자료구조와 ROS 2의 연동을 위해 custom interface를 구현합니다. realsense2에서도 IMUInfo를 비롯한 Custom Interface들을 제공하고 있습니다. $ ros2 interface show realsense2_camera_msgs/msg/IMUInfo # header.frame_id is either set to \u0026#34;imu_accel\u0026#34; or \u0026#34;imu_gyro\u0026#34; # to distinguish between \u0026#34;accel\u0026#34; and \u0026#34;gyro\u0026#34; info. std_msgs/Header header float64[12] data float64[3] noise_variances float64[3] bias_variances ⇒ 이렇게 custom interface가 있다면, 다른 패키지의 종속성이 될 확률이 높이 때문에 먼저 빌드해줘야 합니다.\n⇒ 더불어 custom interface는 해당 workspace에만 적용되기 때문에 workspace가 바뀌면 적용되지 않습니다.\nCMakeLists.txt를 통해 빌드되는 모든 IDL들을 확인할 수 있습니다. set(msg_files \u0026#34;msg/IMUInfo.msg\u0026#34; \u0026#34;msg/Extrinsics.msg\u0026#34; \u0026#34;msg/Metadata.msg\u0026#34; ) rosidl_generate_interfaces(${PROJECT_NAME} ${msg_files} \u0026#34;srv/DeviceInfo.srv\u0026#34; DEPENDENCIES builtin_interfaces std_msgs ADD_LINTER_TESTS ) 일전 이야기한 것과 같이 다른 소스코드에서 custom interface를 사용하고 있어 선행 빌드 후 소싱이 꼭 필요합니다. #pragma once #include \u0026lt;librealsense2/rs.hpp\u0026gt; #include \u0026lt;librealsense2/rsutil.h\u0026gt; #include \u0026#34;constants.h\u0026#34; #include \u0026lt;cv_bridge/cv_bridge.h\u0026gt; #include \u0026lt;diagnostic_updater/diagnostic_updater.hpp\u0026gt; #include \u0026lt;diagnostic_updater/publisher.hpp\u0026gt; #include \u0026#34;realsense2_camera_msgs/msg/imu_info.hpp\u0026#34; #include \u0026#34;realsense2_camera_msgs/msg/extrinsics.hpp\u0026#34; #include \u0026#34;realsense2_camera_msgs/msg/metadata.hpp\u0026#34; #include \u0026#34;realsense2_camera_msgs/srv/device_info.hpp\u0026#34; velodyne Lidar ROS 2 실행 이번에는 point cloud 데이터를 센싱할 수 있는 3D Lidar 중 가장 보편적으로 사용되는 VLP-16의 ROS 2 패키지를 분석해보겠습니다.\nvelodyne lidar 또한 ubuntu package를 제공하고 있으며 자체적인 Gazebo package와 driver 패키지를 모두 제공합니다. $ sudo apt install ros-foxy-velodyne- ros-foxy-velodyne-description ros-foxy-velodyne-laserscan-dbgsym ros-foxy-velodyne-driver ros-foxy-velodyne-msgs ros-foxy-velodyne-driver-dbgsym ros-foxy-velodyne-msgs-dbgsym ros-foxy-velodyne-gazebo-plugins ros-foxy-velodyne-pointcloud ros-foxy-velodyne-gazebo-plugins-dbgsym ros-foxy-velodyne-pointcloud-dbgsym ros-foxy-velodyne-laserscan ros-foxy-velodyne-simulator 이번에도 우리는 학습을 위해 소스코드 빌드를 진행하겠습니다. cd ~/ros2_ws/src # package clone git clone -b foxy-devel https://github.com/ros-drivers/velodyne.git # dependencies install sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install libpcap-dev # source code build cbp velodyne_msgs \u0026amp;\u0026amp; source install/local_setup.bash cbp velodyne_laserscan \u0026amp;\u0026amp; source install/local_setup.bash cbp velodyne_pointcloud \u0026amp;\u0026amp; source install/local_setup.bash cbp velodyne_driver \u0026amp;\u0026amp; source install/local_setup.bash cbp velodyne \u0026amp;\u0026amp; source install/local_setup.bash velodyne lidar는 Ethernet 인터페이스를 제공합니다. 따라서 Ubuntu의 네트워크 설정에서 고정 IP 설정을 해주며, VLP-16의 기본 IP는 192.168.1.100입니다. 설정 이후 launch는 다음과 같습니다. ros2 launch velodyne velodyne-all-nodes-VLP16-launch.py launch rviz2를 통한 시각화를 해봅시다. fixed frame을 velodyne으로 설정해야 합니다. tf2 tree를 살펴보면 아무것도 조회되지 않습니다. velodyne tf2만 broadcast되고 있기 때문에 확인할 수 없는 것입니다. 저였다면 stasic transform broadcaster를 통해 world \u0026gt; velodyne tf2를 하나 생성했을 것 같습니다.\nvelodyne lidar 또한 composed-launch라는 comspoition 기반 실행을 지원합니다. $ ros2 launch velodyne velodyne-all-nodes-VLP16-composed-launch.py [INFO] [launch_ros.actions.load_composable_nodes]: Loaded node \u0026#39;/velodyne_driver_node\u0026#39; in container \u0026#39;/velodyne_container\u0026#39; [component_container-1] [INFO] [1682566114.537928654] [velodyne_container]: Load Library: /home/kimsooyoung/ros2_ws/install/velodyne_pointcloud/lib/libconvert.so [component_container-1] [INFO] [1682566114.540579179] [velodyne_container]: Found class: rclcpp_components::NodeFactoryTemplate\u0026lt;velodyne_pointcloud::Convert\u0026gt; [component_container-1] [INFO] [1682566114.540601962] [velodyne_container]: Instantiate class: rclcpp_components::NodeFactoryTemplate\u0026lt;velodyne_pointcloud::Convert\u0026gt; [component_container-1] [INFO] [1682566114.542606795] [velodyne_convert_node]: correction angles: /home/kimsooyoung/ros2_ws/install/velodyne_pointcloud/share/velodyne_pointcloud/params/VLP16db.yaml [INFO] [launch_ros.actions.load_composable_nodes]: Loaded node \u0026#39;/velodyne_convert_node\u0026#39; in container \u0026#39;/velodyne_container\u0026#39; [component_container-1] [INFO] [1682566114.548422161] [velodyne_container]: Load Library: /home/kimsooyoung/ros2_ws/install/velodyne_laserscan/lib/libvelodyne_laserscan.so [component_container-1] [INFO] [1682566114.549147973] [velodyne_container]: Found class: rclcpp_components::NodeFactoryTemplate\u0026lt;velodyne_laserscan::VelodyneLaserScan\u0026gt; [component_container-1] [INFO] [1682566114.549171818] [velodyne_container]: Instantiate class: rclcpp_components::NodeFactoryTemplate\u0026lt;velodyne_laserscan::VelodyneLaserScan\u0026gt; [INFO] [launch_ros.actions.load_composable_nodes]: Loaded node \u0026#39;/velodyne_laserscan_node\u0026#39; in container \u0026#39;/velodyne_container\u0026#39; [component_container-1] [INFO] [1682566114.597621115] [velodyne_laserscan_node]: Latched ring count of 16 [component_container-1] [WARN] [1682566114.597755427] [velodyne_laserscan_node]: PointCloud2 fields in unexpected order. Using slower generic method. composed-launch와 일반 launch 시 차이점을 rqt_graph로 확인해봅시다. Launch file 분석 velodyne-all-nodes-VLP16-launch.py를 분석해봅시다. velodyne_driver_node, velodyne_convert_node, velodyne_laserscan_node이 실행되며 velodyne_driver_node의 종료 시 launch 자체가 종료되도록 Event를 걸어주었습니다. return launch.LaunchDescription([ velodyne_driver_node, velodyne_convert_node, velodyne_laserscan_node, launch.actions.RegisterEventHandler( event_handler=launch.event_handlers.OnProcessExit( target_action=velodyne_driver_node, on_exit=[launch.actions.EmitEvent( event=launch.events.Shutdown())], )), ]) velodyne-all-nodes-VLP16-composed-launch.py에서는 component_container와 velodyne_driver::VelodyneDriver, velodyne_pointcloud::Convert, velodyne_laserscan::VelodyneLaserScan 3개의 composition이 동작합니다. container = ComposableNodeContainer( name=\u0026#39;velodyne_container\u0026#39;, namespace=\u0026#39;\u0026#39;, package=\u0026#39;rclcpp_components\u0026#39;, executable=\u0026#39;component_container\u0026#39;, composable_node_descriptions=[ ComposableNode( package=\u0026#39;velodyne_driver\u0026#39;, plugin=\u0026#39;velodyne_driver::VelodyneDriver\u0026#39;, name=\u0026#39;velodyne_driver_node\u0026#39;, parameters=[driver_params]), ComposableNode( package=\u0026#39;velodyne_pointcloud\u0026#39;, plugin=\u0026#39;velodyne_pointcloud::Convert\u0026#39;, name=\u0026#39;velodyne_convert_node\u0026#39;, parameters=[convert_params]), ComposableNode( package=\u0026#39;velodyne_laserscan\u0026#39;, plugin=\u0026#39;velodyne_laserscan::VelodyneLaserScan\u0026#39;, name=\u0026#39;velodyne_laserscan_node\u0026#39;, parameters=[laserscan_params]), ], output=\u0026#39;both\u0026#39;, ) return LaunchDescription([container]) 이제 방금 전의 실행 코드들(velodyne_driver_node, velodyne_convert_node, velodyne_laserscan_node)을 분석해 봅시다.\nvelodyne_driver_node velodyne package의 CMakeLists.txt에서 velodyne_driver_node의 코드를 확인할 수 있습니다. add_executable(velodyne_driver_node src/driver/velodyne_node.cpp) ament_target_dependencies(velodyne_driver_node rclcpp) target_link_libraries(velodyne_driver_node velodyne_driver) install(TARGETS velodyne_driver_node DESTINATION lib/${PROJECT_NAME}) velodyne_node.cpp 자체는 일반적인 rclcpp node programming이 구현되어 있습니다. (대신 NodeOptions을 매개변수로 전달하는데 이는 VelodyneDriver가 Composition형태로 구현되어 있기 때문입니다.) #include \u0026lt;rclcpp/rclcpp.hpp\u0026gt; #include \u0026lt;memory\u0026gt; #include \u0026#34;velodyne_driver/driver.hpp\u0026#34; int main(int argc, char ** argv) { // Force flush of the stdout buffer. setvbuf(stdout, nullptr, _IONBF, BUFSIZ); rclcpp::init(argc, argv); rclcpp::spin(std::make_shared\u0026lt;velodyne_driver::VelodyneDriver\u0026gt;(rclcpp::NodeOptions())); rclcpp::shutdown(); return 0; } VelodyneDriver::VelodyneDriver에서는 velodyne sdk =\u0026gt; ROS 2로의 형태 변환이 이루어집니다. Composition을 고려한 형태로 Node 프로그래밍 되어있습니다. namespace velodyne_driver { class VelodyneDriver final : public rclcpp::Node { public: explicit VelodyneDriver(const rclcpp::NodeOptions \u0026amp; options); ~VelodyneDriver() override; ... private: bool poll(); void pollThread(); // configuration parameters struct config_; ... std::unique_ptr\u0026lt;Input\u0026gt; input_; rclcpp::Publisher\u0026lt;velodyne_msgs::msg::VelodyneScan\u0026gt;::SharedPtr output_; int last_azimuth_; ... }; } // namespace velodyne_driver #endif // VELODYNE_DRIVER__DRIVER_HPP_ velodyne sdk =\u0026gt; ROS 2로의 데이터 형태 변환은 std::thread 통해 구현되어 있습니다. ROS 2와의 충돌을 막기 위해 소멸자에서 join하는 방식을 사용하였습니다. 사실 이렇게 하면 이벤트 발생 시 다시 deadlock 문제가 발생합니다. 저라면 일전의 callback group \u0026amp; executor를 사용했을 것 같습니다.\nstd::thread poll_thread_; // node 생성자에서 thread 시작 VelodyneDriver::VelodyneDriver(const rclcpp::NodeOptions \u0026amp; options) : rclcpp::Node(\u0026#34;velodyne_driver_node\u0026#34;, options), diagnostics_(this, 0.2) { poll_thread_ = std::thread(\u0026amp;VelodyneDriver::pollThread, this); } // thread 함수에서 무한 poll 호출 void VelodyneDriver::pollThread() { std::future_status status; do { poll(); status = future_.wait_for(std::chrono::seconds(0)); } while (status == std::future_status::timeout); } // poll 함수가 마치 ROS 2 callback 처럼 동작 bool VelodyneDriver::poll() velodyne_driver =\u0026gt; ROS 2로의 데이터 변환을 정리해보았습니다. (poll 함수의 내용입니다.) velodyne driver 데이터를 std::unique_ptr input으로 파싱 input에서 config으로 데이터 변환 config_에서 std::unique_ptr\u0026lt;velodyne_msgs::msg::VelodyneScan\u0026gt; scan으로 데이터 변환 output_-\u0026gt;publish(std::move(scan)); ⇒ 상당히 메모리 형변환이 잦은데 이전 코드에서의 레거시가 있는 것 같습니다.\ndiagnostic_updater ⇒ 중간중간 보이는 diagnostic 관련 코드들은 ROS 2의 diagnostic_updater API로 device drivers의 여러 상태를 topic 형태로 publish할 수 있는 기능입니다. diagnostic_updater::Updater diagnostics_; std::unique_ptr\u0026lt;diagnostic_updater::TopicDiagnostic\u0026gt; diag_topic_; velodyne_convert_node rviz2에서 보았던 것처럼 제대로 된 Pointcloud topic을 위해서 velodyne_driver에서의 raw data들을 누적하고, 다시 sensor_msgs/msg/PointCloud2로 변환하는 작업이 필요합니다. velodyne_convert_node에서 이 내용이 구현되어 있습니다.\nvelodyne_pointcloud package의 CMakeLists.txt에서 velodyne_convert_node의 코드를 확인할 수 있습니다. add_executable(velodyne_convert_node src/conversions/convert_node.cpp) ament_target_dependencies(velodyne_convert_node rclcpp) target_link_libraries(velodyne_convert_node convert) install(TARGETS velodyne_convert_node DESTINATION lib/${PROJECT_NAME} ) convert_node.cpp 자체는 단순 Node 생성 후 spin을 담고 있습니다. int main(int argc, char ** argv) { // Force flush of the stdout buffer. setvbuf(stdout, nullptr, _IONBF, BUFSIZ); rclcpp::init(argc, argv); // handle callbacks until shut down rclcpp::spin( std::make_shared\u0026lt;velodyne_pointcloud::Convert\u0026gt;( rclcpp::NodeOptions())); rclcpp::shutdown(); return 0; } Convert 클래스는 velodyne_msgs::msg::VelodyneScan topic을 subscribe하여 누적하고, sensor_msgs::msg::PointCloud2 topic으로 다시 publish합니다. namespace velodyne_pointcloud { class Convert final : public rclcpp::Node { public: explicit Convert(const rclcpp::NodeOptions \u0026amp; options); ... private: void processScan(const velodyne_msgs::msg::VelodyneScan::SharedPtr scanMsg); std::unique_ptr\u0026lt;velodyne_rawdata::RawData\u0026gt; data_; rclcpp::Subscription\u0026lt;velodyne_msgs::msg::VelodyneScan\u0026gt;::SharedPtr velodyne_scan_; rclcpp::Publisher\u0026lt;sensor_msgs::msg::PointCloud2\u0026gt;::SharedPtr output_; tf2_ros::Buffer tf_buffer_; std::unique_ptr\u0026lt;velodyne_rawdata::DataContainerBase\u0026gt; container_ptr_; ... }; } // namespace velodyne_pointcloud velodyne_packets의 subscribe callback으로 processScan이 바인딩되어있으며, processScan에서는 일전 언급한 데이터 누적과 publish가 이루어집니다. // subscribe to VelodyneScan packets velodyne_scan_ = this-\u0026gt;create_subscription\u0026lt;velodyne_msgs::msg::VelodyneScan\u0026gt;( \u0026#34;velodyne_packets\u0026#34;, rclcpp::QoS(10), std::bind(\u0026amp;Convert::processScan, this, std::placeholders::_1)); void Convert::processScan(const velodyne_msgs::msg::VelodyneScan::SharedPtr scanMsg) { ... // allocate a point cloud with same time and frame ID as raw data container_ptr_-\u0026gt;setup(scanMsg); // process each packet provided by the driver for (size_t i = 0; i \u0026lt; scanMsg-\u0026gt;packets.size(); ++i) { data_-\u0026gt;unpack(scanMsg-\u0026gt;packets[i], *container_ptr_); } // publish the accumulated cloud message diag_topic_-\u0026gt;tick(scanMsg-\u0026gt;header.stamp); output_-\u0026gt;publish(container_ptr_-\u0026gt;finishCloud()); } velodyne_convert_node에서 tf2 데이터를 다루는 부분이 구현되어 있습니다. 하지만 편의를 위해 별도의 컨테이너를 만들고 구현은 추상화해둔 모습을 확인할 수 있습니다. tf2_ros::Buffer tf_buffer_; if (organize_cloud) { container_ptr_ = std::make_unique\u0026lt;OrganizedCloudXYZIR\u0026gt;( min_range, max_range, target_frame, fixed_frame, data_-\u0026gt;numLasers(), data_-\u0026gt;scansPerPacket(), tf_buffer_); } else { container_ptr_ = std::make_unique\u0026lt;PointcloudXYZIR\u0026gt;( min_range, max_range, target_frame, fixed_frame, data_-\u0026gt;scansPerPacket(), tf_buffer_); } DataContainerBase 클래스에서는 tf2 lookupTransform을 통해 scan data의 좌표를 미리 계산해둡니다. std::unique_ptr\u0026lt;velodyne_rawdata::DataContainerBase\u0026gt; container_ptr_; class DataContainerBase { public: ... void computeTransformation(const rclcpp::Time \u0026amp; time) { geometry_msgs::msg::TransformStamped transform; try { const std::chrono::nanoseconds dur(time.nanoseconds()); std::chrono::time_point\u0026lt;std::chrono::system_clock, std::chrono::nanoseconds\u0026gt; time(dur); transform = tf_buffer_.lookupTransform(config_.target_frame, cloud.header.frame_id, time); } catch (tf2::LookupException \u0026amp; e) { return; } catch (tf2::ExtrapolationException \u0026amp; e) { return; } tf2::Quaternion quaternion( transform.transform.rotation.x, transform.transform.rotation.y, transform.transform.rotation.z, transform.transform.rotation.w); Eigen::Quaternionf rotation(quaternion.w(), quaternion.x(), quaternion.y(), quaternion.z()); Eigen::Vector3f eigen_origin; tf2::Vector3 origin( transform.transform.translation.x, transform.transform.translation.y, transform.transform.translation.z); vectorTfToEigen(origin, eigen_origin); Eigen::Translation3f translation(eigen_origin); transformation = translation * rotation; } velodyne_laserscan_node velodyne_laserscan_node는 sensor_msgs::msg::PointCloud2 data를 sensor_msgs::msg::LaserScan로 변환 후 /scan topic으로 publish 하는 node입니다. 3D pointcloud만 사용한다면 일반적으로 필요 없는 기능입니다.\n클래스 header file을 통해 간단히 기능만 리뷰해봅시다. namespace velodyne_laserscan { class VelodyneLaserScan final : public rclcpp::Node { public: explicit VelodyneLaserScan(const rclcpp::NodeOptions \u0026amp; options); ... private: void recvCallback(const sensor_msgs::msg::PointCloud2::SharedPtr msg); rclcpp::Subscription\u0026lt;sensor_msgs::msg::PointCloud2\u0026gt;::SharedPtr sub_; rclcpp::Publisher\u0026lt;sensor_msgs::msg::LaserScan\u0026gt;::SharedPtr pub_; uint16_t ring_count_{0}; int ring_; double resolution_; }; } // namespace velodyne_laserscan PointCloud2 topic을 subscribe 받고 이 데이터를 LaserScan으로 변환합니다. (subscribe callback) 마지막으로 변환된 데이터를 scan topic으로 다시 publish합니다. 코드를 분석하면서 보시다시피 모든 Node 구현은 Composition을 고려하여 만들어졌습니다. 따라서 CMakeLists.txt를 보면 아래와 같이 rclcpp_components_register_nodes 키워드들을 통해 같은 코드로 Composition을 생성할 수 있습니다. target_link_libraries(velodyne_driver velodyne_input) # install runtime and library files install(TARGETS velodyne_driver ARCHIVE DESTINATION lib LIBRARY DESTINATION lib RUNTIME DESTINATION bin ) rclcpp_components_register_nodes(velodyne_driver \u0026#34;velodyne_driver::VelodyneDriver\u0026#34;) velodyne_msgs velodyne_msgs 패키지에는 VelodynePacket, VelodyneScan라는 두 종류의 custom message를 정의하고 있습니다. 이는 주로 velodyne 자체의 프로토콜 패킷을 다루기 위한 것으로 ROS 2 데이터 변환 시 중간 데이터 구조로 사용됩니다.\n\u0026gt; VelodynePacket.msg # Raw Velodyne LIDAR packet. builtin_interfaces/Time stamp # packet timestamp uint8[1206] data # packet contents \u0026gt; VelodyneScan.msg # Velodyne LIDAR scan packets. std_msgs/Header header # standard ROS message header VelodynePacket[] packets # vector of raw packets orbbec astra camera ROS 2 패키지 분석 이번 시간에는 Orbbec Astra+ Development Kit의 ROS 2 실행과 분석을 진행해보겠습니다. 실제 사용될 카메라와 코드이므로 좀 더 자세하게 분석해보려 합니다. 이전 센서 패키지들과 비교하면서 따라와 주세요!\n개발환경 설정 필요한 apt package들과 ROS 2 package들을 설치합니다. sudo apt install libgflags-dev nlohmann-json3-dev sudo apt install ros-foxy-image-transport ros-foxy-image-publisher 빌드 종속성인 glog을 설치합니다. wget -c https://github.com/google/glog/archive/refs/tags/v0.6.0.tar.gz -O glog-0.6.0.tar.gz tar -xzvf glog-0.6.0.tar.gz cd glog-0.6.0 mkdir build \u0026amp;\u0026amp; cd build cmake .. \u0026amp;\u0026amp; make -j4 sudo make install sudo ldconfig # Refreshing the link library 다음으로, 빌드 종속성인 magic_enum을 설치합니다. wget -c https://github.com/Neargye/magic_enum/archive/refs/tags/v0.8.0.tar.gz -O magic_enum-0.8.0.tar.gz tar -xzvf magic_enum-0.8.0.tar.gz cd magic_enum-0.8.0 mkdir build \u0026amp;\u0026amp; cd build cmake .. \u0026amp;\u0026amp; make -j4 sudo make install sudo ldconfig # Refreshing the link library 이번 실습을 위해 사용된 코드는 2022-07-15 버전 Orbbec SDK Beta for ROS입니다. ( 이후 업데이트 시 코드 변경이 있을 수 있어 명확히 명시하겠습니다. ⇒ download link)\n다운로드 받은 source code를 원하는 workspace에 위치시킨 뒤, 개발문서에서 요구하는 usb rule 추가 작업을 진행합니다. cd orbbec_camera/scripts sudo bash install.sh sudo udevadm control --reload-rules \u0026amp;\u0026amp; sudo udevadm trigger 해당 작업 후 혹시 모를 오류를 방지하기 위해 재부팅을 권장드리며, 카메라를 연결한 뒤 장치 인식이 되는지 확인해봅시다. $ ls /dev | grep Astra Astra+ Astra+_rgb 소스코드를 빌드하며, 공식 문서에서는 Release build를 제시하고 있어 그대로 진행해 보겠습니다. cd ~/ros2_ws/src colcon build --event-handlers console_direct+ --cmake-args -DCMAKE_BUILD_TYPE=Release 빌드 중 오류가 발생했다면 패키지를 하나하나씩 빌드하며 원인을 분석해봅니다.\ncolcon build --packages-select orbbec_camera_msgs --event-handlers console_direct+ --cmake-args -DCMAKE_BUILD_TYPE=Release source install/local_setup.bash colcon build --packages-select orbbec_camera --event-handlers console_direct+ --cmake-args -DCMAKE_BUILD_TYPE=Release source install/local_setup.bash Getting started 빌드가 완료되었다면 기본 예시를 사용해봅시다.\n제공되는 초기 코드 parameter가 아닌, default parameter를 사용하겠습니다. launch file에서 아래와 같이 parameter를 설정을 제거하고 실행합시다. from launch import LaunchDescription from launch_ros.actions import Node from ament_index_python import get_package_share_directory def generate_launch_description(): ob_params_file = ( get_package_share_directory(\u0026#34;orbbec_camera\u0026#34;) + \u0026#34;/params/astra_plus_params.yaml\u0026#34; ) return LaunchDescription( [ Node( package=\u0026#34;orbbec_camera\u0026#34;, namespace=\u0026#34;camera\u0026#34;, name=\u0026#34;camera\u0026#34;, executable=\u0026#34;orbbec_camera_node\u0026#34;, output=\u0026#34;screen\u0026#34;, # parameters=[ob_params_file], ), ] ) astra_plus.launch 예제를 실행해봅시다. cd \u0026lt;my_ws\u0026gt; source install/local_setup.bash ros2 launch orbbec_camera astra_plus.launch.py ... [orbbec_camera_node-1] [WARN] [1683197732.405664220] [camera.camera]: Using default profile instead. [orbbec_camera_node-1] [WARN] [1683197732.405680938] [camera.camera]: default FPS 15 [orbbec_camera_node-1] [INFO] [1683197732.413525012] [camera.camera]: stream color is enabled - width: 2048, height: 1536, fps: 30, Format: OB_FORMAT_MJPG [orbbec_camera_node-1] [WARN] [1683197732.427355527] [camera.camera]: Publishing dynamic camera transforms (/tf) at 10 Hz custom interface들을 사용하기 때문에 workspace sourcing이 반드시 필요합니다.\npublish되고 있는 topic들은 다음과 같습니다. $ ros2 topic list /camera/color/camera_info /camera/color/image_raw /camera/depth/camera_info /camera/depth/color/points /camera/depth/image_raw /camera/depth/points /camera/extrinsic/depth_to_color /camera/ir/camera_info /camera/ir/image_raw /clicked_point /goal_pose /initialpose /parameter_events /rosout /tf /tf_static 특이한 점으로, 카메라 사이 좌표계 값을 depth_to_color라는 이름의 topic으로 publish하고 있습니다. $ ros2 topic echo --qos-durability=transient_local /camera/extrinsic/depth_to_color --qos-profile=services_default header: stamp: sec: 0 nanosec: 0 frame_id: depth_to_color_extrinsics rotation: - 0.9999811053276062 - -0.006122155115008354 - -0.0005165112670511007 - 0.006124507170170546 - 0.9999702572822571 - 0.004682439845055342 - 0.0004878292966168374 - -0.004685514606535435 - 0.9999889135360718 translation: - -25.19551658630371 - -0.30450138449668884 - 1.0939441919326782 --- rviz2를 통해 데이터를 시각화해봅시다. 주의해야 할 점으로, pointcloud2 topic의 DDS QoS를 아래와 같이 잘 맞춰주어야 합니다.\n더불어, color pointcloud2 topic의 색상을 확인하기 위해서는 rviz2 옵션을 아래와 같이 맞춰주어야 합니다.\n혹은, 제가 제공드리는 rviz파일을 사용하여 configuration 하셔도 좋습니다. ⇒ astra rviz download\n카메라 센서인 만큼 tf2를 다룰 시 조심해야 할 부분이 있습니다. tf2 tree는 다음과 같습니다. rviz2를 통해 확인해보면, optical frame들은 회전된 camera 좌표 체계를 갖는 것을 확인 가능합니다. 마지막으로, astra node의 parameter들을 조회해봅시다. $ ros2 param list /camera/camera: camera_link_frame_id color_format color_fps color_frame_id color_height color_optical_frame_id color_width d2c_mode ... $ ros2 param get /camera/camera color_format String value is: YUYV 해당 parameter들에 따라 코드 실행에 어떤 변화가 있는지 분석을 통해 살펴보겠습니다.\n코드 분석 launch file을 통해 확인했던 orbbec_camera_node가 어떻게 생성되었는지 추적해봅시다. Node( package=\u0026#34;orbbec_camera\u0026#34;, namespace=\u0026#34;camera\u0026#34;, name=\u0026#34;camera\u0026#34;, executable=\u0026#34;orbbec_camera_node\u0026#34;, output=\u0026#34;screen\u0026#34;, # parameters=[ob_params_file], ), CMakeLists.txt를 살펴보면 rclcpp_components_register_node를 통해 생성되는 orbbec_camera_node를 확인할 수 있습니다. (component와 executable을 모두 빌드하기 위함입니다.) ament_target_dependencies(${PROJECT_NAME} ${dependencies} ) rclcpp_components_register_node(${PROJECT_NAME} PLUGIN \u0026#34;orbbec_camera::OBCameraNodeFactory\u0026#34; EXECUTABLE orbbec_camera_node ) orbbec_camera_node을 구성하는 코드들은 다음과 같습니다. add_library(${PROJECT_NAME} SHARED src/dynamic_params.cpp src/ob_camera_node_factory.cpp src/ob_camera_node.cpp src/ros_param_backend.cpp src/ros_service.cpp src/utils.cpp ) File별 기능을 분석하면 다음과 같습니다. Code Description ros_param_backend parameter 변경 시 특정 callback이 실행되도록 binding 해주는 decorator입니다. dynamic_params ROS 2에서 제공되는 기본적인 set_parameter와 유사한 역할을 수행하는 각종 setParameter API들을 구현한 부분입니다. (아마도 별도의 parameter 변경 reject 로직을 구현하고 싶었던 것 같습니다.) ob_camera_node 일반적인 ROS 2 Node의 로직과, orbbec sdk의 pipeline을 융합하여 구현한 코드입니다. 실질적인 topic publish, service server들이 구현되어 있습니다. ros_service service server들에 대한 cpp 구현을 별도로 분리한 코드입니다. ob_camera_node_factory ob_camera_node에서 구현한 OBCameraNode node를 포인터로 갖는 별도의 Component를 구현하였습니다. (이 부분은 ROS 2 구현 측면에서 다소 미숙한 부분이라고 볼 수 있습니다.) 주요 구현은 ob_camera_node에 작성되어 있습니다. 해당 파일 내 메소드들을 호출 계층 구조에 따라 정리하면 아래와 같습니다.\nob_camera_node\nConstructor setupTopics getParameters setupDevices setupProfiles setupDefaultStreamCalibData findDefaultCameraParam updateStreamCalibData setupCameraCtrlServices setupPublishers publishStaticTransforms startPipeline ob::Pipeline 실행 frameSetCallback publishColorFrame publishDepthFrame publishIRFrame publishPointCloud publishColorPointCloud publishDepthPointCloud setupTopics에서 호출되는 함수들은 다음과 같은 역할을 갖습니다.\nFunction Description getParameters dynamic_params에 구현된 setParam를 사용하여 각종 매개변수들을 파싱하고, 세팅합니다. setupDevices orbbec sdk를 사용하여 camera profile, stream data등에 대한 정보를 조회하고 저장합니다. setupProfiles getParameters와 setupDevices에서 얻은 정보를 바탕으로 orbbec 카메라를 셋업합니다. d2c_mode등 orbbec만의 고유 설정들을 셋업하는 코드가 구현되어 있습니다. setupDefaultStreamCalibData 내부적으로 findDefaultCameraParam / updateStreamCalibData라는 메소드를 호출하며, 카메라 calibration data를 받아 셋업하는 부분입니다. setupCameraCtrlServices topic이 아닌 service server들에 대한 선언과 callback mapping들이 이루어집니다. setupPublishers depth/color/points, depth/points, camera_info, extrinsic/depth_to_color, image_raw 등의 topic publisher들이 선언되고 세팅됩니다. publishStaticTransforms dynamictf_broadcaster와 statictf_broadcaster라는 두개의 tf2 broadcast가 구현되어 있습니다. dynamictf_broadcaster의 경우 publishDynamicTransforms라는 메소드를 별도 thread로 실행합니다. (하지만 실제 카메라 내부에서 동적으로 변화하는 tf2는 없습니다.) 대부분 설정과 관련된 구현이지만, ROS 2 구현 측면에서 setupPublishers를 살펴보겠습니다. QoS profile을 적용한 topic publisher들과 tf broadcaster가 생성되고 있습니다.\nvoid OBCameraNode::setupPublishers() { static_tf_broadcaster_ = std::make_shared\u0026lt;tf2_ros::StaticTransformBroadcaster\u0026gt;(node_); using PointCloud2 = sensor_msgs::msg::PointCloud2; using CameraInfo = sensor_msgs::msg::CameraInfo; point_cloud_publisher_ = node_-\u0026gt;create_publisher\u0026lt;PointCloud2\u0026gt;( \u0026#34;depth/color/points\u0026#34;, rclcpp::QoS{1}.best_effort().keep_last(1)); depth_point_cloud_publisher_ = node_-\u0026gt;create_publisher\u0026lt;PointCloud2\u0026gt;( \u0026#34;depth/points\u0026#34;, rclcpp::QoS{1}.best_effort().keep_last(1)); for (const auto\u0026amp; stream_index : IMAGE_STREAMS) { std::string name = stream_name_[stream_index.first]; std::string topic = name + \u0026#34;/image_raw\u0026#34;; image_publishers_[stream_index] = image_transport::create_publisher(node_, topic); topic = name + \u0026#34;/camera_info\u0026#34;; camera_info_publishers_[stream_index] = node_-\u0026gt;create_publisher\u0026lt;CameraInfo\u0026gt;(topic, rclcpp::QoS{1}.best_effort()); } extrinsics_publisher_ = node_-\u0026gt;create_publisher\u0026lt;orbbec_camera_msgs::msg::Extrinsics\u0026gt;( \u0026#34;extrinsic/depth_to_color\u0026#34;, rclcpp::QoS{1}.transient_local()); } publishStaticTransforms 메소드는 다음과 같습니다. dynamic transform이라는 구현이 보이는데, 사실 카메라 내부적으로는 움직이는 부분이 없습니다. void OBCameraNode::publishStaticTransforms() { calcAndPublishStaticTransform(); if (tf_publish_rate_ \u0026gt; 0) { tf_thread_ = std::make_shared\u0026lt;std::thread\u0026gt;([this]() { publishDynamicTransforms(); }); } else { static_tf_broadcaster_-\u0026gt;sendTransform(static_tf_msgs_); } } 코드 확인 결과, transform의 의미보다 시간 동기화를 위해 구현해둔 것으로 보입니다. void OBCameraNode::publishDynamicTransforms() { RCLCPP_WARN(logger_, \u0026#34;Publishing dynamic camera transforms (/tf) at %g Hz\u0026#34;, tf_publish_rate_); std::mutex mu; std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mu); while (rclcpp::ok() \u0026amp;\u0026amp; is_running_) { tf_cv_.wait_for(lock, std::chrono::milliseconds((int)(1000.0 / tf_publish_rate_)), [this] { return (!(is_running_)); }); { rclcpp::Time t = node_-\u0026gt;now(); for (auto\u0026amp; msg : static_tf_msgs_) { msg.header.stamp = t; } dynamic_tf_broadcaster_-\u0026gt;sendTransform(static_tf_msgs_); } } } startPipeline에서 호출되는 함수들은 다음과 같은 역할을 갖습니다. Function Description ob::Pipeline 실행 orbbec sdk로부터 pipeline을 다루는 핸들러를 받아 image stream을 시작합니다. frameSetCallback setupPublishers에서 설정한 각종 topic publisher들이 실질적인 topic publish를 수행하는 부분입니다. 코드를 확인해보면, orbbec SDK의 pipeline을 실행한 뒤, frame callback과 binding하고 있는 모습을 확인 가능합니다. void OBCameraNode::startPipeline() { if (pipeline_ != nullptr) { pipeline_.reset(); } pipeline_ = std::make_unique\u0026lt;ob::Pipeline\u0026gt;(device_); pipeline_-\u0026gt;start(config_, [this](std::shared_ptr\u0026lt;ob::FrameSet\u0026gt; frame_set) { frameSetCallback(std::move(frame_set)); }); } frame이 갱신될 떄마다 실행되는 frameSetCallback에서는 갱신된 이미지 데이터를 사용하여 각종 topic publish를 진행합니다. void OBCameraNode::frameSetCallback(std::shared_ptr\u0026lt;ob::FrameSet\u0026gt; frame_set) { auto color_frame = frame_set-\u0026gt;colorFrame(); auto depth_frame = frame_set-\u0026gt;depthFrame(); auto ir_frame = frame_set-\u0026gt;irFrame(); if (color_frame \u0026amp;\u0026amp; enable_[COLOR]) { publishColorFrame(color_frame); } if (depth_frame \u0026amp;\u0026amp; enable_[DEPTH]) { publishDepthFrame(depth_frame); } if (ir_frame \u0026amp;\u0026amp; enable_[INFRA0]) { publishIRFrame(ir_frame); } publishPointCloud(frame_set); } publishColorFrame / publishDepthFrame / publishIRFrame에서는 cv::Mat 형식의 데이터를 ROS 2 Image msg로 변환하여 publish하고 있습니다. void OBCameraNode::publishColorFrame(std::shared_ptr\u0026lt;ob::ColorFrame\u0026gt; frame) { ... sensor_msgs::msg::Image::SharedPtr img; img = cv_bridge::CvImage(std_msgs::msg::Header(), encoding_.at(stream), image).toImageMsg(); img-\u0026gt;width = width; img-\u0026gt;height = height; img-\u0026gt;is_bigendian = false; img-\u0026gt;step = width * unit_step_size_[stream]; img-\u0026gt;header.frame_id = optical_frame_id_[COLOR]; img-\u0026gt;header.stamp = timestamp; auto\u0026amp; image_publisher = image_publishers_.at(stream); image_publisher.publish(img); } publishPointCloud에서는 특정 조건에 따라 color pointcloud, depth point cloud를 준비시킵니다. 이 부분 때문에 parameter설정이 중요합니다. void OBCameraNode::publishPointCloud(std::shared_ptr\u0026lt;ob::FrameSet\u0026gt; frame_set) { try { if (align_depth_ \u0026amp;\u0026amp; (format_[COLOR] == OB_FORMAT_YUYV || format_[COLOR] == OB_FORMAT_I420)) { if (frame_set-\u0026gt;depthFrame() != nullptr \u0026amp;\u0026amp; frame_set-\u0026gt;colorFrame() != nullptr) { publishColorPointCloud(frame_set); } } if (frame_set-\u0026gt;depthFrame() != nullptr) { publishDepthPointCloud(frame_set); } pointcloud를 publish하는 로직을 살펴보면 공통적으로 아래와 같은 iterator 구현을 확인할 수 있습니다. 이는 ROS 2의 PointCloud2 type에서 제공하는 API로 손쉽게 각 point data를 append 할 수 있습니다. ... sensor_msgs::PointCloud2Iterator\u0026lt;float\u0026gt; iter_x(point_cloud_msg_, \u0026#34;x\u0026#34;); sensor_msgs::PointCloud2Iterator\u0026lt;float\u0026gt; iter_y(point_cloud_msg_, \u0026#34;y\u0026#34;); sensor_msgs::PointCloud2Iterator\u0026lt;float\u0026gt; iter_z(point_cloud_msg_, \u0026#34;z\u0026#34;); size_t valid_count = 0; for (size_t point_idx = 0; point_idx \u0026lt; point_size; point_idx++, points++) { bool valid_pixel(points-\u0026gt;z \u0026gt; 0); if (valid_pixel) { *iter_x = static_cast\u0026lt;float\u0026gt;(points-\u0026gt;x / 1000.0); *iter_y = -static_cast\u0026lt;float\u0026gt;(points-\u0026gt;y / 1000.0); *iter_z = static_cast\u0026lt;float\u0026gt;(points-\u0026gt;z / 1000.0); ++iter_x; ++iter_y; ++iter_z; ++valid_count; } } 마지막으로 ros_service.cpp 코드에는 각종 설정을 service로 제어할 수 있는 로직이 구현되어 있습니다. 자세한 내용을 살펴보지는 않겠지만, service server를 설정하고 binding되는 callback을 구현하는 부분이 반복됩니다. service_name = \u0026#34;set_\u0026#34; + stream_name + \u0026#34;_exposure\u0026#34;; set_exposure_srv_[stream_index] = node_-\u0026gt;create_service\u0026lt;SetInt32\u0026gt;( service_name, [this, stream_index = stream_index](const std::shared_ptr\u0026lt;SetInt32::Request\u0026gt; request, std::shared_ptr\u0026lt;SetInt32::Response\u0026gt; response) { setExposureCallback(request, response, stream_index); }); ... void OBCameraNode::setExposureCallback(const std::shared_ptr\u0026lt;SetInt32::Request\u0026gt;\u0026amp; request, std::shared_ptr\u0026lt;SetInt32::Response\u0026gt;\u0026amp; response, const stream_index_pair\u0026amp; stream_index) { auto stream = stream_index.first; ... OBCameraNodeFactory는 OBCameraNode, ob::Device, ob::DeviceInfo 인스턴스를 스마트 포인터로 포함하고 있습니다. 대부분의 구현들도 해당 스마트 포인터 내부의 메소드를 호출하는 식으로 구성됩니다. void init(); void startDevice(); void getDevice(const std::shared_ptr\u0026lt;ob::DeviceList\u0026gt;\u0026amp; list); void updateDeviceInfo(); void deviceConnectCallback(const std::shared_ptr\u0026lt;ob::DeviceList\u0026gt;\u0026amp; device_list); void deviceDisconnectCallback(const std::shared_ptr\u0026lt;ob::DeviceList\u0026gt;\u0026amp; device_list); void printDeviceInfo(const std::shared_ptr\u0026lt;ob::DeviceInfo\u0026gt;\u0026amp; device_info); std::unique_ptr\u0026lt;OBCameraNode\u0026gt; ob_camera_node_; std::shared_ptr\u0026lt;ob::Device\u0026gt; device_; std::shared_ptr\u0026lt;ob::DeviceInfo\u0026gt; device_info_; 이 부분은 구조적으로 다소 비효율적이라고 생각합니다. orbbec 관련 인스턴스를 클래스 변수로 갖는 것은 이해가 되지만, 저라면 Node를 스마트 포인터로 갖지 않고, Composition 형태로 바로 구현했을 것 같습니다.\norbbec astra plus model의 ROS 2 패키지 분석을 끝으로 모든 예시 분석을 마쳤습니다. 실제 ROS 2 package 개발에 대한 안목이 생기셨으리라 생각합니다.\norbbec gemini 2 ROS 2 패키지 분석 이번에는 Orbbec의 또다른 rgbd camera인 Gemini 2를 ROS 2 연동해보겠습니다.\n일전 Astra Plus를 분석하며 종속성 설치 등 많은 부분을 이미 해두었으므로 중복되는 설정은 제외하였습니다.\nAstra Plus package와 Gemini 2 package의 이름이 동일합니다! 따라서 새로운 Workspace를 생성한 뒤 별도 빌드를 해주겠습니다. cd ~/ mkdir -p gemini_ws/src cd ~/gemini_ws colon build 만약 두 package를 같은 workspace에서 사용하고 싶다면 소스코드에서 패키지 이름을 모조리 찾아내 변경하면 됩니다.\nGemini2의 인식을 위해 udev-rules를 다시 수정해야 합니다. udev-rules에 대한 설명은 링크로 대체하겠으며, 여러분들께서는 하단 터미널 명령어를 따라하시기만 하면 됩니다. cd /etc/udev/rules.d sudo rm -rf 99-obsensor-libusb.rules 이제 새로운 udev-rules를 추가해야 합니다. 하지만 Orbbec에서 제공하는 rule이 적절치 않아 이번 예시를 위해 일부 제가 수정하였습니다. ⇒ OrbbecSDK_ROS2/orbbec_camera/scripts99-obsensor-libusb.rules 수정 # UVC Modules ... SUBSYSTEMS==\u0026#34;usb\u0026#34;, ATTRS{idVendor}==\u0026#34;2bc5\u0026#34;, ATTRS{idProduct}==\u0026#34;0670\u0026#34;, MODE:=\u0026#34;0666\u0026#34;, OWNER:=\u0026#34;root\u0026#34;, GROUP:=\u0026#34;video\u0026#34;, SYMLINK+=\u0026#34;orbbec_gemini_2\u0026#34; 새로운 rule을 로컬 환경에 적용합시다. cd \u0026lt;your-ws\u0026gt;/OrbbecSDK_ROS2/orbbec_camera/scripts sudo bash install.sh sudo udevadm control --reload-rules \u0026amp;\u0026amp; sudo udevadm trigger 이제 Gemini2를 연결하면 아래와 같이 인식되는 모습을 볼 수 있습니다. cd /dev ls | grep gem \u0026gt;\u0026gt; result orbbec_gemini_2 예시 실행 전, color point cloud를 보고 싶다면 gemini2.launch.xml 파일의 parameter를 아래와 같이 수정해야 합니다. \u0026lt;launch\u0026gt; \u0026lt;!-- unique camera name--\u0026gt; \u0026lt;arg name=\u0026#34;camera_name\u0026#34; default=\u0026#34;camera\u0026#34;/\u0026gt; \u0026lt;!-- Hardware depth registration --\u0026gt; \u0026lt;arg name=\u0026#34;depth_registration\u0026#34; default=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;serial_number\u0026#34; default=\u0026#34;\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;device_num\u0026#34; default=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;vendor_id\u0026#34; default=\u0026#34;0x2bc5\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;product_id\u0026#34; default=\u0026#34;\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;enable_point_cloud\u0026#34; default=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;!-- from --\u0026gt; \u0026lt;!-- \u0026lt;arg name=\u0026#34;enable_colored_point_cloud\u0026#34; default=\u0026#34;false\u0026#34;/\u0026gt; --\u0026gt; \u0026lt;!-- to --\u0026gt; \u0026lt;arg name=\u0026#34;enable_colored_point_cloud\u0026#34; default=\u0026#34;True\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;point_cloud_qos\u0026#34; default=\u0026#34;default\u0026#34;/\u0026gt; 패키지를 빌드하고 소싱합시다. colcon build --event-handlers console_direct+ --cmake-args -DCMAKE_BUILD_TYPE=Release source install/local_setup.bash gemini2 launch를 실행하고, rviz2로 시각화해봅시다. # Terminal 1 ros2 launch orbbec_camera gemini2.launch.xml # Terminal 2 rviz2 여러분들이 직접 rviz2 구성을 해보셔도 좋고, 제가 제공드리는 파일을 사용하셔도 됩니다!\n📁gemini2.rviz\n노트북, Edge Device 사용 시, color point cloud 시각화를 실행하면 급격히 성능이 저하될 수 있습니다. (우측 하단 frame rate를 확인해보세요!)\n예제 실행 시 동작하는 topic list, tf2 tree는 다음과 같습니다. $ ros2 topic list /color/camera_info /color/image_raw /depth/camera_info /depth/color/points /depth/image_raw /depth/points /ir/camera_info /ir/image_raw /parameter_events /rosout /tf /tf_static IMU에 대한 tf2와 topic이 없는 점은 많이 아쉽습니다.\n혹시나 parameter로 IMU on/off를 제어하는가 싶었지만 param list 결과 없었습니다. $ ros2 param list /camera: camera_link_frame_id color_camera_info_qos color_format color_fps color_frame_id color_height color_info_url color_optical_frame_id color_qos color_width depth_camera_info_qos depth_format depth_fps depth_frame_id depth_height depth_optical_frame_id depth_qos depth_registration depth_width device_num enable_color enable_colored_point_cloud enable_depth enable_ir enable_point_cloud enable_publish_extrinsic ir_camera_info_qos ir_format ir_fps ir_frame_id ir_height ir_info_url ir_optical_frame_id ir_qos ir_width log_level point_cloud_qos publish_tf serial_number tf_publish_rate use_sim_time 코드 분석 코드 분석에 앞서, launch file을 먼저 언급하자면, 일전 astra plus package와 두드러진 차이를 보이고 있습니다. 이러한 xml 문법은 ROS 1 시절 사용되었던 문법으로 사실 자주 사용되지는 않습니다.\n\u0026lt;launch\u0026gt; \u0026lt;!-- unique camera name--\u0026gt; \u0026lt;arg name=\u0026#34;camera_name\u0026#34; default=\u0026#34;camera\u0026#34;/\u0026gt; ... \u0026lt;group\u0026gt; \u0026lt;node name=\u0026#34;camera\u0026#34; pkg=\u0026#34;orbbec_camera\u0026#34; exec=\u0026#34;orbbec_camera_node\u0026#34; output=\u0026#34;screen\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;camera_name\u0026#34; value=\u0026#34;$(var camera_name)\u0026#34;/\u0026gt; ... \u0026lt;remap from=\u0026#34;/$(var camera_name)/depth/color/points\u0026#34; to=\u0026#34;/$(var camera_name)/depth_registered/points\u0026#34;/\u0026gt; \u0026lt;/node\u0026gt; \u0026lt;/group\u0026gt; \u0026lt;/launch\u0026gt; 더불어 한눈에 보아도 parameter들이 지저분하게 나열되어 있는 모습이 확인됩니다. 저라면 yaml file로 분리했을 것 같습니다!\n대부분의 코드들은 이미 분석하였기 때문에 이번에는 새롭게 추가되거나 변경된 내용을 위주로 분석해보겠습니다.\n각 File별 기능은 다음과 같습니다. Code Description list_devices_node.cpp 실행중인 모든 디바이스들을 조회합니다. multi camera를 위한 디버깅 툴로 유추됩니다. main.cpp 일반적인 Node / Spin 구조의 main문으로 사실 ob_camera_node_factory를 통해 Composition으로 구현해두었기 때문에 불필요하다고 생각합니다. ob_cleanup_shm.cpp Astra에서 Node / SDK 사이 프로세싱을 thread로 처리한 것과 달리 Gemini에서는 세마포어를 사용합니다. 이에 따른 유틸리티 코드입니다. ob_camera_node.cpp 실질적인 topic publish, service server들이 구현되어 있던 코드입니다. 기능은 동일하지만 구조에서 차이가 발생하였습니다. ob_camera_node_factory.cpp 세마포어를 사용함에 따른 구현상의 작은 변화가 발생하였습니다. list_devices_node.cpp의 빌드 결과물인 list_devices_node의 실행 결과입니다.\nros2 run orbbec_camera list_devices_node ... [I20230510 19:48:22.675072 28664 DeviceManager.cpp:375] Orbbec Gemini 2 Depth Camera [I20230510 19:48:22.675125 28664 DeviceManager.cpp:375] Orbbec Gemini 2 IR Camera [I20230510 19:48:22.675169 28664 DeviceManager.cpp:375] Orbbec Gemini 2 RGB Camera [I20230510 19:48:22.675212 28664 DeviceManager.cpp:375] Orbbec Gemini Data Channel [I20230510 19:48:22.675287 28664 DeviceManager.cpp:375] Orbbec Gemini 2 IMU ob_camera_node.cpp의 구조를 분석해보겠습니다. 대부분의 구조는 동일하며 이름의 변경과 구현상의 차이만 있을 뿐 Astra plus와 일맥상통합니다.\nOBCameraNode\nsetupDefaultImageFormat setupTopics getParameters (몇가지 parameter가 추가되었습니다.) setupDevices setupProfiles setupDefaultStreamCalibData setupCameraCtrlServices setupPublishers publishStaticTransforms startPipeline ⇒ startStreams setupPipelineConfig onNewFrameSetCallback color_frame depth_frame ir_frame publishPointCloud onNewFrameSetCallback에서 구현상 변경이 발생하였으며, Orbbec SDK와 ROS 2 Topic을 연동하는 onNewFrameCallback 매핑이 이루어졌습니다.\nauto color_frame = std::dynamic_pointer_cast\u0026lt;ob::Frame\u0026gt;(frame_set-\u0026gt;colorFrame()); auto depth_frame = std::dynamic_pointer_cast\u0026lt;ob::Frame\u0026gt;(frame_set-\u0026gt;depthFrame()); auto ir_frame = std::dynamic_pointer_cast\u0026lt;ob::Frame\u0026gt;(frame_set-\u0026gt;irFrame()); onNewFrameCallback(color_frame, COLOR); onNewFrameCallback(depth_frame, DEPTH); onNewFrameCallback(ir_frame, INFRA0); publishPointCloud(frame_set); "
},
{
	"uri": "/kr/ros2_foxy/lecture18/",
	"title": "Lecture18. Point Cloud Deep Learning Example (PointNet)",
	"tags": [],
	"description": "",
	"content": "Special Part - Point Cloud Deep Learning Example (PointNet) 이번 시간에는 ROS 2와 딥러닝 모델을 결합하여 Application을 구현해보는 예시를 준비했습니다. 사실 제가 딥러닝 분야에 지식은 매우 얕은지라 모델에 대한 설명은 불가합니다. PyTorch를 통해 구현된 오픈소스에 기반하여 동작하는 ROS 2 코드를 개발하는 맥락에 집중해주시면 감사하겠습니다!\n이번 시간 사용할 모델은 스탠포드의 PointNet으로, 3D PointCloud의 feature를 추출하는 가장 대표적인 네트워크입니다. reference : PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\npointnet 오픈소스에서 제공하는 기능은 classification과 segmentation으로 이번 예시에서는 classification에 집중해 보겠습니다. Model Training 참고로, Anaconda와 같이 파이썬 가상환경을 사용하고 있다면 ROS 2 python 시스템과 호환이 불가할 수 있습니다. 파이썬 가상환경에 ROS 2 관련 패키지를 설치하시거나, ROS 2 python 환경에 torch 등 필요 패키지를 설치하시기 바랍니다.\nModel 코드를 clone하고 학습을 위해 필요한 dataset을 다운로드합니다. shapenet dataset의 일부가 다운로드됩니다. git clone https://github.com/fxia22/pointnet.pytorch cd pointnet.pytorch pip install -e . cd scripts # build C++ code for visualization bash build.sh # download dataset bash download.sh 현재 데모에서 사용하는 dataset은 약 1.1GB로 매우 적은 종류의 물체를 담고 있습니다. 단지 빠른 데모를 위해 이렇게 적용하는 점에 유의하세요!\nPointNet을 학습 시켜봅시다. segmentation과 classification 중 원하는 상황에 맞추어 training을 진행합니다. dataset이 약 1GB이기 때문에 epoch을 25로 하여도 시간은 오래 걸리지 않습니다. cd utils python train_classification.py --dataset \u0026lt;dataset path\u0026gt; --nepoch=\u0026lt;number epochs\u0026gt; --dataset_type \u0026lt;modelnet40 | shapenet\u0026gt; python train_segmentation.py --dataset \u0026lt;dataset path\u0026gt; --nepoch=\u0026lt;number epochs\u0026gt; # example python3 train_segmentation.py --dataset /home/kimsooyoung/Downloads/pointnet.pytorch/shapenetcore_partanno_segmentation_benchmark_v0 --nepoch=24 python3 train_classification.py --dataset /home/kimsooyoung/Downloads/pointnet.pytorch/shapenetcore_partanno_segmentation_benchmark_v0 --nepoch=24 --dataset_type shapenet Training 결과로 cls, seg 폴더 내 pth 파일이 생성됩니다. Confirm Trained Parameters ROS 2 연동 전 학습된 pth 모델을 검증해봅시다. 별도의 clone은 필요 없으며 오픈 소스의 수정으로 제가 미리 준비한 코드를 사용하겠습니다.\n해당 코드는 isl-org의 오픈소스에 기반하였습니다. ⇒ https://github.com/isl-org/Open3D-PointNet\n검증 프로그램을 실행하기 위한 추가 패키지를 다운로드 받습니다. pip install torchvision pip install open3d pip install --upgrade numpy 제공된 검증 코드 내부 모델 경로와 dataset 경로를 수정한 뒤, 예시 프로그램을 실행합니다. cd Open3D-PointNet pip install -r requirements.txt # 코드 중 아래 내용 수정 NUM_POINTS = 10000 MODEL_PATH = \u0026#39;/home/kimsooyoung/Downloads/pointnet.pytorch/utils/cls/cls_model_23.pth\u0026#39; DATA_FOLDER = \u0026#39;/home/kimsooyoung/Downloads/pointnet.pytorch/shapenetcore_partanno_segmentation_benchmark_v0\u0026#39; # 데모 실행 python3 pointnet_test.py prediction 결과 vector와 pointcloud 데이터를 시각화해서 보여줍니다.\n현재 dataset으로 구분할 수 있는 항목들은 다음과 같습니다. 계속해서 이야기하지만 dataset 자체의 한계로 검출할 수 있는 객체가 많지는 않습니다. 😅 # Problem ontology classes_dict = {\u0026#39;Airplane\u0026#39;: 0, \u0026#39;Bag\u0026#39;: 1, \u0026#39;Cap\u0026#39;: 2, \u0026#39;Car\u0026#39;: 3, \u0026#39;Chair\u0026#39;: 4, \u0026#39;Earphone\u0026#39;: 5, \u0026#39;Guitar\u0026#39;: 6, \u0026#39;Knife\u0026#39;: 7, \u0026#39;Lamp\u0026#39;: 8, \u0026#39;Laptop\u0026#39;: 9, \u0026#39;Motorbike\u0026#39;: 10, \u0026#39;Mug\u0026#39;: 11, \u0026#39;Pistol\u0026#39;: 12, \u0026#39;Rocket\u0026#39;: 13, \u0026#39;Skateboard\u0026#39;: 14, \u0026#39;Table\u0026#39;: 15} PointNet ROS 2 연동 드디어 ROS 2와 PointNet을 연동시켜보려 합니다. 개발의 시작 전, 항상 어떠한 기능을 구현해야 하는지, 이미 개발 가능한 것을 무엇이고 새롭게 구현해야 하는 것은 무엇인지 습관적으로 구체화시키시길 바랍니다.\nshapenet dataset이 아닌, Gazebo로부터의 Raw PointCloud를 subscribe하여 물체 인식을 하고자 합니다. 이를 위한 Gazebo 환경은 일전의 rgbd world를 사용하겠습니다. 센서로부터의 raw Point Cloud에서 바닥을 제거하고 물체별로 clustering을 하는 작업 또한 일전 구현한 바 있습니다. 따라서 우리는 약간의 수정과 마지막 Node, Clustering된 pointcloud를 받아 어떤 물체인지 판단하는 기능만 구현하면 됩니다. 앞선 내용들을 잘 생각하면서, 예시부터 실행해봅시다. # Terminal 1 - gazebo launch ros2 launch rgbd_world pointnet_world.launch.py # Terminal 2 - object spawn ros2 run py_service_tutorial pointnet_object_wo_gravity # Terminal 3 - clustering ros2 run py_pcl_tutorial pointnet_cluster_pub # Terminal 4 - torch classification ros2 run pointnet_torch pointnet_torch 마지막 터미널에서 검출된 물체와 정확도를 확인할 수 있습니다.\n예제 실행 시 gpu 메모리 제한에 따른 오류가 발생할 수 있습니다. 아래 명령어를 통해 gpu 점유율을 확인하며 실행을 추천드립니다. nvidia-smi -l 1 코드 분석 학습된 dataset과 3DGEMS를 통해 확보한 gazebo model 중 겹치는 것들을 먼저 확인해보았습니다. 확인된 모델들이 등장하도록 Model spawn service client의 코드를 수정합니다 def send_spawn_req(self): # model_name = \u0026#34;beer\u0026#34; model_id = input(\u0026#34;\u0026#34;\u0026#34;Enter Model name Among Below List 1.chair_1 \\t2.chair_2 \\t3.chair_3 4.labtop_mac_1 \\t5.labtop_mac_2 \\t6.labtop_mac_3 7.cup_green \\t8.cup_blue \\t9.cup_yellow 10.cup_paper \\t11.lamp_table_large \\t12.lamp_table_small 13.side_table_1 \\t14.side_table_3 \\t15.side_table_set_1 16.side_table_set_2 \\t17.table_dining \\t18.cafe_table [Type your choice]: \u0026#34;\u0026#34;\u0026#34;) 다음으로 Clustering 코드를 수정해보겠습니다. Topic 이름 변경과 더불어 전처리 과정 중 Voxel grid와 RANSAC만 적용하도록 수정했습니다. # RANSAC plane segmentation # Create the segmentation object seg = cloud_voxed.make_segmenter() ... # Extract inliers extracted_inliers = cloud_voxed.extract(inliers, negative=True) # inliers into list for ROS 2 Conversion color_cluster_point_list = [] # cloud size color generator color = size_color_gen(extracted_inliers) for i, indices in enumerate(extracted_inliers): color_cluster_point_list.append([extracted_inliers[i][0], extracted_inliers[i][1], extracted_inliers[i][2], rgb_to_float(color)]) 카메라가 한쪽 방향만을 인지하여 아래와 같이 객체가 분리되는 상황이 발생하기 때문에 알고리즘을 간소화하였습니다.\n마지막으로 PointCloud2 topic을 통해 Inference를 실행하는 코드입니다.\n생성자에서 Tuning된 parameter를 upload하여 classifier를 생성합니다. class PointNetNode(Node): def __init__(self): super().__init__(\u0026#39;pointnet_cls_node\u0026#39;) self.declare_parameter(\u0026#39;model_path\u0026#39;, \u0026#39;/home/kimsooyoung/Downloads/pointnet/pointnet.pytorch/utils/cls/cls_model_23.pth\u0026#39;) self.declare_parameter(\u0026#39;num_points\u0026#39;, 10000) MODEL_PATH = self.get_parameter(\u0026#39;model_path\u0026#39;).value NUM_POINTS = self.get_parameter(\u0026#39;num_points\u0026#39;).value # Create the classification network from pre-trained model self.classifier = PointNetCls(k=len(classes_dict.items()), num_points=NUM_POINTS) if torch.cuda.is_available(): self.classifier.cuda() self.classifier.load_state_dict(torch.load(MODEL_PATH)) else: self.classifier.load_state_dict(torch.load(MODEL_PATH, map_location=\u0026#39;cpu\u0026#39;)) self.classifier.eval() callback에서는 PointCloud2 형식의 데이터를 subscribe 한 뒤 numpy.asarray로 변형하여 pytorch에게 넘길 준비를 합니다. def obj_callback(self, msg): # 1. Convert PointCloud2 message to numpy array points_list = [] for data in pc2.read_points(msg, skip_nans=True): points_list.append([data[0], data[1], data[2]]) points = np.asarray(points_list, dtype=np.float32) # 2. numpy resample m, n = points.shape choice = np.random.choice(m, 10000, replace=True) point_set = points[choice, :] # 3. numpy to torch point_set = torch.from_numpy(point_set) classifier를 통한 Interence후 검출 결과는 다시 cpu로 넘어온 뒤 콘솔 출력됩니다. # 4. perform inference in GPU if self.cb_flag == True: points = Variable(point_set.unsqueeze(0)) points = points.transpose(2, 1) if torch.cuda.is_available(): points = points.cuda() pred_logsoft, _ = self.classifier(points) # move data back to cpu pred_logsoft_cpu = pred_logsoft.data.cpu().numpy().squeeze() pred_soft_cpu = np.exp(pred_logsoft_cpu) pred_class = np.argmax(pred_soft_cpu) self.get_logger().info(f\u0026#39;Your object is a [{list(classes_dict.keys())[pred_class]}]\u0026#39;) self.get_logger().info(\u0026#39;Probability is a [{:0.3}]\u0026#39;.format(pred_soft_cpu[pred_class])) 전체 시스템을 rqt graph로 살펴보면 다음과 같습니다. 앞서 개요로 설명했던 Node들에 유의하며 차근차근 분석해보세요!! "
},
{
	"uri": "/kr/ros2_foxy/lecture19/",
	"title": "Lecture19. Orbbec ROS 2 Package - Final",
	"tags": [],
	"description": "",
	"content": " 강의 도중 (2022년 5월) Orbbec ROS 2 SDK가 업데이트됨에 따라 새롭게 분석을 진행해보았습니다.\n강의에서 사용되는 패키지 버전은 아래 사진과 같이 2023-05-15 버전입니다.\n새롭게 분석한다는 마음으로 launch file부터 차근차근 분석해나가겠습니다. 😂\ngemini2.launch.xml - xml 문법으로 구성된 launch file로 실질적으로 실행시키는 것은 orbbec_camera_node라는 이름의 단일 Node입니다. \u0026lt;node name=\u0026#34;camera\u0026#34; pkg=\u0026#34;orbbec_camera\u0026#34; exec=\u0026#34;orbbec_camera_node\u0026#34; output=\u0026#34;screen\u0026#34;\u0026gt; orbbec_camera_node가 생성되는 코드를 분석하기 위해 CMakeLists.txt를 살펴봅시다. main.cpp를 사용하고 있음이 확인 가능합니다. add_executable(${PROJECT_NAME}_node src/main.cpp ) main.cpp에서는 SingleThreaded Executor와 OBCameraNodeDriver라는 Node를 spin하고 있습니다. #include \u0026lt;rclcpp/rclcpp.hpp\u0026gt; #include \u0026lt;orbbec_camera/ob_camera_node_driver.h\u0026gt; int main(int argc, char** argv) { rclcpp::init(argc, argv); rclcpp::NodeOptions options; using namespace orbbec_camera; auto node = std::make_shared\u0026lt;OBCameraNodeDriver\u0026gt;(options); rclcpp::spin(node); rclcpp::shutdown(); return 0; } OBCameraNodeDriver를 분석해보기 위해 해당 구현을 담고 있는 ob_camera_node_driver.cpp 파일을 살펴봅시다. config file을 Node내에서 직접 불러오는 모습과, init() 메소드를 호출하고 있음이 확인됩니다.\nnamespace orbbec_camera { OBCameraNodeDriver::OBCameraNodeDriver(const rclcpp::NodeOptions \u0026amp;node_options) : Node(\u0026#34;orbbec_camera_node\u0026#34;, \u0026#34;/\u0026#34;, node_options), config_path_(ament_index_cpp::get_package_share_directory(\u0026#34;orbbec_camera\u0026#34;) + \u0026#34;/config/OrbbecSDKConfig_v1.0.xml\u0026#34;), ctx_(std::make_unique\u0026lt;ob::Context\u0026gt;(config_path_.c_str())), logger_(this-\u0026gt;get_logger()) { init(); } OrbbecSDKConfig_v1.0.xml은 중국어로 주석이 되어있어 정확히 분석할 수는 없었지만, 각종 카메라들의 기본 설정값을 담고 있는 파일로 추측됩니다. \u0026lt;Gemini\u0026gt; \u0026lt;Depth\u0026gt; \u0026lt;!--默认分辨率的宽，int类型--\u0026gt; \u0026lt;Width\u0026gt;640\u0026lt;/Width\u0026gt; \u0026lt;!--默认分辨率的高，int类型--\u0026gt; \u0026lt;Height\u0026gt;400\u0026lt;/Height\u0026gt; \u0026lt;!--默认帧率，int类型--\u0026gt; \u0026lt;FPS\u0026gt;30\u0026lt;/FPS\u0026gt; \u0026lt;!--默认帧格式--\u0026gt; \u0026lt;Format\u0026gt;Y11\u0026lt;/Format\u0026gt; \u0026lt;!--开流失败后是否需要进行重试，0-不重试，\u0026gt;=1-重试并重试多少次--\u0026gt; \u0026lt;StreamFailedRetry\u0026gt;0\u0026lt;/StreamFailedRetry\u0026gt; \u0026lt;/Depth\u0026gt; \u0026lt;Color\u0026gt; \u0026lt;!--默认分辨率的宽，int类型--\u0026gt; \u0026lt;Width\u0026gt;640\u0026lt;/Width\u0026gt; \u0026lt;!--默认分辨率的高，int类型--\u0026gt; \u0026lt;Height\u0026gt;480\u0026lt;/Height\u0026gt; \u0026lt;!--默认帧率，int类型--\u0026gt; \u0026lt;FPS\u0026gt;30\u0026lt;/FPS\u0026gt; \u0026lt;!--默认帧格式--\u0026gt; \u0026lt;Format\u0026gt;MJPG\u0026lt;/Format\u0026gt; \u0026lt;!--开流失败后是否需要进行重试，0-不重试，\u0026gt;=1-重试并重试多少次--\u0026gt; \u0026lt;StreamFailedRetry\u0026gt;0\u0026lt;/StreamFailedRetry\u0026gt; \u0026lt;/Color\u0026gt; \u0026lt;IR\u0026gt; \u0026lt;!--默认分辨率的宽，int类型--\u0026gt; \u0026lt;Width\u0026gt;640\u0026lt;/Width\u0026gt; \u0026lt;!--默认分辨率的高，int类型--\u0026gt; \u0026lt;Height\u0026gt;400\u0026lt;/Height\u0026gt; \u0026lt;!--默认帧率，int类型--\u0026gt; \u0026lt;FPS\u0026gt;30\u0026lt;/FPS\u0026gt; \u0026lt;!--默认帧格式--\u0026gt; \u0026lt;Format\u0026gt;Y10\u0026lt;/Format\u0026gt; \u0026lt;!--开流失败后是否需要进行重试，0-不重试，\u0026gt;=1-重试并重试多少次--\u0026gt; \u0026lt;StreamFailedRetry\u0026gt;0\u0026lt;/StreamFailedRetry\u0026gt; \u0026lt;/IR\u0026gt; \u0026lt;/Gemini\u0026gt; init()으로 부터 시작되는 OBCameraNodeDriver의 로직은 아래와 같습니다.\nOBCameraNodeDriver init()\nsetDeviceChangedCallback - orbbec 디바이스의 연결, 해제 시 실행되는 callback을 binding합니다. 디바이스의 연결을 지속 탐지하는 checkconnect_timer를 생성하고 checkConnectTimer callback을 binding합니다. 다음으로, 디바이스의 연결 확인 시 실행되는 두개의 callback을 추가로 실행하는데요. 이는 ROS 2가 아닌 thread를 사용하고 있습니다.\nqueryDevice thread - thead를 통해 디바이스 연결 상태와 ROS 2 실행 상태를 지속 확인합니다. 디바이스 연결 시 onDeviceConnected 메소드가 실행되며 내부에서는 try-catch로 예외처리를 구현하였습니다. startDevice - 어떠한 디바이스가 연결되었는지, 인식한 숫자와 일치하는 디바이스가 존재하는지를 검사한 뒤, 디바이스를 초기화합니다. initializeDevice - 각종 디바이스의 정보를 조회하고 사용자에게 콘솔 출력으로 알려줌과 동시에 OBCameraNode를 생성합니다. ⇒ OBCameraNode는 다음 분석할 파일인 ob_camera_node에서 살펴봅시다. deviceCountUpdate thread updateConnectedDeviceCount - 연결되어 있는 디바이스의 개수를 갱신하고 이 값은 일전 분석했던 예외처리에서 사용됩니다. init() 메소드부터 상세하게 살펴봅시다.\nstd::unique_ptr\u0026lt;ob::Context\u0026gt; ctx_ = nullptr; ... ctx_-\u0026gt;setDeviceChangedCallback([this](std::shared_ptr\u0026lt;ob::DeviceList\u0026gt; removed_list, std::shared_ptr\u0026lt;ob::DeviceList\u0026gt; added_list) { (void)added_list; onDeviceDisconnected(removed_list); }); check_connect_timer_ = this-\u0026gt;create_wall_timer(std::chrono::milliseconds(1000), [this]() { checkConnectTimer(); }); CHECK_NOTNULL(check_connect_timer_); query_thread_ = std::make_shared\u0026lt;std::thread\u0026gt;([this]() { queryDevice(); }); device_count_update_thread_ = std::make_shared\u0026lt;std::thread\u0026gt;([this]() { deviceCountUpdate(); }); CHECK_NOTNULL(device_count_update_thread_); checkConnectTimer void OBCameraNodeDriver::checkConnectTimer() { if (!device_connected_.load()) { RCLCPP_ERROR_STREAM(logger_, \u0026#34;checkConnectTimer: device \u0026#34; \u0026lt;\u0026lt; serial_number_ \u0026lt;\u0026lt; \u0026#34; not connected\u0026#34;); return; } else if (!ob_camera_node_) { device_connected_.store(false); } } queryDevice void OBCameraNodeDriver::queryDevice() { while (is_alive_ \u0026amp;\u0026amp; rclcpp::ok()) { if (!device_connected_.load()) { RCLCPP_INFO_STREAM_THROTTLE(logger_, *get_clock(), 1000, \u0026#34;Waiting for device connection...\u0026#34;); auto device_list = ctx_-\u0026gt;queryDeviceList(); if (device_list-\u0026gt;deviceCount() == 0) { std::this_thread::sleep_for(std::chrono::milliseconds(10)); continue; } onDeviceConnected(device_list); } else { std::this_thread::sleep_for(std::chrono::milliseconds(1000)); } } } onDeviceConnected void OBCameraNodeDriver::onDeviceConnected(const std::shared_ptr\u0026lt;ob::DeviceList\u0026gt; \u0026amp;device_list) { CHECK_NOTNULL(device_list); if (device_list-\u0026gt;deviceCount() == 0) { return; } RCLCPP_INFO_STREAM_THROTTLE(logger_, *get_clock(), 1000, \u0026#34;onDeviceConnected\u0026#34;); if (!device_) { try { startDevice(device_list); } catch (ob::Error \u0026amp;e) { RCLCPP_ERROR_STREAM(logger_, \u0026#34;startDevice failed: \u0026#34; \u0026lt;\u0026lt; e.getMessage()); } catch (const std::exception \u0026amp;e) { RCLCPP_ERROR_STREAM(logger_, \u0026#34;startDevice failed: \u0026#34; \u0026lt;\u0026lt; e.what()); } catch (...) { RCLCPP_ERROR_STREAM(logger_, \u0026#34;startDevice failed\u0026#34;); } } } startDevice void OBCameraNodeDriver::startDevice(const std::shared_ptr\u0026lt;ob::DeviceList\u0026gt; \u0026amp;list) { std::scoped_lock\u0026lt;decltype(device_lock_)\u0026gt; lock(device_lock_); if (device_connected_) { return; } if (list-\u0026gt;deviceCount() == 0) { RCLCPP_WARN(logger_, \u0026#34;No device found\u0026#34;); return; } if (device_) { device_.reset(); } auto device = selectDevice(list); if (device == nullptr) { RCLCPP_WARN_THROTTLE(logger_, *get_clock(), 1000, \u0026#34;Device with serial number %s not found\u0026#34;, serial_number_.c_str()); device_connected_ = false; return; } initializeDevice(device); } initializeDevice void OBCameraNodeDriver::initializeDevice(const std::shared_ptr\u0026lt;ob::Device\u0026gt; \u0026amp;device) { device_ = device; CHECK_NOTNULL(device_); CHECK_NOTNULL(device_.get()); if (ob_camera_node_) { ob_camera_node_.reset(); } ob_camera_node_ = std::make_unique\u0026lt;OBCameraNode\u0026gt;(this, device_, parameters_); device_connected_ = true; device_info_ = device_-\u0026gt;getDeviceInfo(); CHECK_NOTNULL(device_info_.get()); device_unique_id_ = device_info_-\u0026gt;uid(); RCLCPP_INFO_STREAM(logger_, \u0026#34;Device \u0026#34; \u0026lt;\u0026lt; device_info_-\u0026gt;name() \u0026lt;\u0026lt; \u0026#34; connected\u0026#34;); RCLCPP_INFO_STREAM(logger_, \u0026#34;Serial number: \u0026#34; \u0026lt;\u0026lt; device_info_-\u0026gt;serialNumber()); RCLCPP_INFO_STREAM(logger_, \u0026#34;Firmware version: \u0026#34; \u0026lt;\u0026lt; device_info_-\u0026gt;firmwareVersion()); RCLCPP_INFO_STREAM(logger_, \u0026#34;Hardware version: \u0026#34; \u0026lt;\u0026lt; device_info_-\u0026gt;hardwareVersion()); RCLCPP_INFO_STREAM(logger_, \u0026#34;device type: \u0026#34; \u0026lt;\u0026lt; ObDeviceTypeToString(device_info_-\u0026gt;deviceType())); RCLCPP_INFO_STREAM(logger_, \u0026#34;device unique id: \u0026#34; \u0026lt;\u0026lt; device_unique_id_); } 다음으로, initializeDevice에서 생성되었던 OBCameraNode에 대해 분석해보았습니다.\nOBCameraNode OBCameraNode\nsetupDefaultImageFormat setupTopics getParameters - 각종 매개변수들이 잔뜩 선언, 초기화되고 있습니다. setupDevices - getParameters에서 설정한 parameter에 따라 Orbbec device를 셋업하면서 다시금 오류 상황에 대한 처리를 진행합니다. setupProfiles - data stream의 구체적인 profile을 조회하면서 올바른 설정을 확인합니다. setupCameraCtrlServices - ros_service.cpp 파일에 각종 service들이 구현되어 있는데요. 이에 대한 초기화를 담당합니다. setupPublishers - color image, depth image, imu, ir 등 각종 publisher들에 대한 초기화를 진행합니다. publishStaticTransforms - static_tf_broadcaster_와 dynamic_tf_broadcaster_ 설정합니다. calcAndPublishStaticTransform - imu, camera, optical frame 등 orbbec camera 내부의 센서들간 위치 offset를 고려하여 각종 tf frame을 계산합니다. publishStaticTF - std::vector 타입의 클래스 변수인 static_tf_msgs_에 tf data들을 push_back 합니다. publishDynamicTransforms - 실제 sendTransform이 동작하는 부분인데요. 그렇지만 사실상 static broadcast가 실행됩니다. startStreams - ob::Pipeline 타입의 클래스 변수를 초기화한 뒤, pipeline을 시작시키고 onNewFrameSetCallback를 callback으로 binding 합니다. setupPipelineConfig - 사전 정의된 parameter들에 따라 orbbec SDK에 구현된 setAlignMode, enableStream 등의 메소드를 호출합니다. onNewFrameSetCallback - pipeline으로부터 새로운 data가 유입될 때마다 실행되는 callback입니다. publishPointCloud - depth_frame과 color_frame data를 받아 ob::PointCloudFilter를 통해 필터링하고 상황에 맞는 topic data를 준비한 뒤, 최종 publish합니다. publishColoredPointCloud publishDepthPointCloud onNewFrameCallback - pointcloud가 아닌 rgb, depth, ir 카메라 publisher들에 대해 ROS 2 Conversion을 적용한 뒤 publish합니다. startIMU onNewIMUFrameCallback setDefaultIMUMessage publish OBCameraNode 생성자부터 상세 분석을 해봅시다.\n이 부분에서 사용된 is_running_과 같은 클래스 변수는 atomic type인데요. 아마 Thread간 상태 변환 로직에 사용되는 것 같습니다. 저였다면 Thread가 아닌, Composition을 사용하여 여러 코드로 나누고, 이런 복잡한 구현을 피하려고 하지 않았을까 생각해봅니다.\nOBCameraNode::OBCameraNode(rclcpp::Node* node, std::shared_ptr\u0026lt;ob::Device\u0026gt; device, std::shared_ptr\u0026lt;Parameters\u0026gt; parameters) : node_(node), device_(std::move(device)), parameters_(std::move(parameters)), logger_(node-\u0026gt;get_logger()) { is_running_.store(true); stream_name_[COLOR] = \u0026#34;color\u0026#34;; stream_name_[DEPTH] = \u0026#34;depth\u0026#34;; stream_name_[INFRA0] = \u0026#34;ir\u0026#34;; stream_name_[INFRA1] = \u0026#34;ir2\u0026#34;; stream_name_[ACCEL] = \u0026#34;accel\u0026#34;; stream_name_[GYRO] = \u0026#34;gyro\u0026#34;; compression_params_.push_back(cv::IMWRITE_PNG_COMPRESSION); compression_params_.push_back(0); compression_params_.push_back(cv::IMWRITE_PNG_STRATEGY); compression_params_.push_back(cv::IMWRITE_PNG_STRATEGY_DEFAULT); setupDefaultImageFormat(); setupTopics(); startStreams(); if (enable_d2c_viewer_) { auto rgb_qos = getRMWQosProfileFromString(image_qos_[COLOR]); auto depth_qos = getRMWQosProfileFromString(image_qos_[DEPTH]); d2c_viewer_ = std::make_unique\u0026lt;D2CViewer\u0026gt;(node_, rgb_qos, depth_qos); } } OBCameraNode에서 정의된 ROS 2 메커니즘들은 다음과 같습니다. // Topic publisher std::map\u0026lt;stream_index_pair, image_transport::Publisher\u0026gt; image_publishers_; std::map\u0026lt;stream_index_pair, rclcpp::Publisher\u0026lt;sensor_msgs::msg::CameraInfo\u0026gt;::SharedPtr\u0026gt; camera_info_publishers_; ... rclcpp::Publisher\u0026lt;sensor_msgs::msg::PointCloud2\u0026gt;::SharedPtr depth_registration_cloud_pub_; rclcpp::Publisher\u0026lt;sensor_msgs::msg::PointCloud2\u0026gt;::SharedPtr depth_cloud_pub_; ... rclcpp::Publisher\u0026lt;Extrinsics\u0026gt;::SharedPtr extrinsics_publisher_; ... std::map\u0026lt;stream_index_pair, rclcpp::Publisher\u0026lt;sensor_msgs::msg::Imu\u0026gt;::SharedPtr\u0026gt; imu_publishers_; ... // TF broadcaster std::shared_ptr\u0026lt;tf2_ros::StaticTransformBroadcaster\u0026gt; static_tf_broadcaster_ = nullptr; std::shared_ptr\u0026lt;tf2_ros::TransformBroadcaster\u0026gt; dynamic_tf_broadcaster_ = nullptr; setupDefaultImageFormat void OBCameraNode::setupDefaultImageFormat() { format_[DEPTH] = OB_FORMAT_Y16; format_str_[DEPTH] = \u0026#34;Y16\u0026#34;; image_format_[DEPTH] = CV_16UC1; encoding_[DEPTH] = sensor_msgs::image_encodings::TYPE_16UC1; unit_step_size_[DEPTH] = sizeof(uint16_t); format_[INFRA0] = OB_FORMAT_Y16; format_str_[INFRA0] = \u0026#34;Y16\u0026#34;; image_format_[INFRA0] = CV_16UC1; encoding_[INFRA0] = sensor_msgs::image_encodings::MONO16; unit_step_size_[INFRA0] = sizeof(uint8_t); image_format_[COLOR] = CV_8UC3; encoding_[COLOR] = sensor_msgs::image_encodings::RGB8; unit_step_size_[COLOR] = 3 * sizeof(uint8_t); } setupTopics void OBCameraNode::setupTopics() { getParameters(); setupDevices(); setupProfiles(); setupCameraCtrlServices(); setupPublishers(); publishStaticTransforms(); } getParameters void OBCameraNode::getParameters() { setAndGetNodeParameter\u0026lt;std::string\u0026gt;(camera_name_, \u0026#34;camera_name\u0026#34;, \u0026#34;camera\u0026#34;); for (auto stream_index : IMAGE_STREAMS) { std::string param_name = stream_name_[stream_index] + \u0026#34;_width\u0026#34;; setAndGetNodeParameter(width_[stream_index], param_name, IMAGE_WIDTH); param_name = stream_name_[stream_index] + \u0026#34;_height\u0026#34;; setAndGetNodeParameter(height_[stream_index], param_name, IMAGE_HEIGHT); param_name = stream_name_[stream_index] + \u0026#34;_fps\u0026#34;; ... setAndGetNodeParameter(publish_tf_, \u0026#34;publish_tf\u0026#34;, true); setAndGetNodeParameter(tf_publish_rate_, \u0026#34;tf_publish_rate\u0026#34;, 10.0); setAndGetNodeParameter(depth_registration_, \u0026#34;depth_registration\u0026#34;, false); setAndGetNodeParameter(enable_point_cloud_, \u0026#34;enable_point_cloud\u0026#34;, true); setAndGetNodeParameter\u0026lt;std::string\u0026gt;(ir_info_url_, \u0026#34;ir_info_url\u0026#34;, \u0026#34;\u0026#34;); setAndGetNodeParameter\u0026lt;std::string\u0026gt;(color_info_url_, \u0026#34;color_info_url\u0026#34;, \u0026#34;\u0026#34;); ... setupDevices void OBCameraNode::setupDevices() { auto sensor_list = device_-\u0026gt;getSensorList(); for (size_t i = 0; i \u0026lt; sensor_list-\u0026gt;count(); i++) { auto sensor = sensor_list-\u0026gt;getSensor(i); auto profiles = sensor-\u0026gt;getStreamProfileList(); for (size_t j = 0; j \u0026lt; profiles-\u0026gt;count(); j++) { auto profile = profiles-\u0026gt;getProfile(j); stream_index_pair sip{profile-\u0026gt;type(), 0}; if (sensors_.find(sip) != sensors_.end()) { continue; } sensors_[sip] = sensor; } } ... device_-\u0026gt;setBoolProperty(OB_PROP_DEPTH_SOFT_FILTER_BOOL, enable_soft_filter_); device_-\u0026gt;setBoolProperty(OB_PROP_COLOR_AUTO_EXPOSURE_BOOL, enable_color_auto_exposure_); device_-\u0026gt;setBoolProperty(OB_PROP_IR_AUTO_EXPOSURE_BOOL, enable_ir_auto_exposure_); auto default_soft_filter_max_diff = device_-\u0026gt;getIntProperty(OB_PROP_DEPTH_MAX_DIFF_INT); if (soft_filter_max_diff_ != -1 \u0026amp;\u0026amp; default_soft_filter_max_diff != soft_filter_max_diff_) { device_-\u0026gt;setIntProperty(OB_PROP_DEPTH_MAX_DIFF_INT, soft_filter_max_diff_); } auto default_soft_filter_speckle_size = device_-\u0026gt;getIntProperty(OB_PROP_DEPTH_MAX_SPECKLE_SIZE_INT); if (soft_filter_speckle_size_ != -1 \u0026amp;\u0026amp; default_soft_filter_speckle_size != soft_filter_speckle_size_) { device_-\u0026gt;setIntProperty(OB_PROP_DEPTH_MAX_SPECKLE_SIZE_INT, soft_filter_speckle_size_); } } catch (const ob::Error\u0026amp; e) { RCLCPP_ERROR_STREAM(logger_, \u0026#34;Failed to setup devices: \u0026#34; \u0026lt;\u0026lt; e.getMessage()); } catch (const std::exception\u0026amp; e) { RCLCPP_ERROR_STREAM(logger_, \u0026#34;Failed to setup devices: \u0026#34; \u0026lt;\u0026lt; e.what()); } setupProfiles void OBCameraNode::setupProfiles() { for (const auto\u0026amp; elem : IMAGE_STREAMS) { if (enable_stream_[elem]) { const auto\u0026amp; sensor = sensors_[elem]; CHECK_NOTNULL(sensor.get()); auto profiles = sensor-\u0026gt;getStreamProfileList(); CHECK_NOTNULL(profiles.get()); CHECK(profiles-\u0026gt;count() \u0026gt; 0); for (size_t i = 0; i \u0026lt; profiles-\u0026gt;count(); i++) { auto profile = profiles-\u0026gt;getProfile(i)-\u0026gt;as\u0026lt;ob::VideoStreamProfile\u0026gt;(); RCLCPP_DEBUG_STREAM( logger_, \u0026#34;Sensor profile: \u0026#34; \u0026lt;\u0026lt; \u0026#34;stream_type: \u0026#34; \u0026lt;\u0026lt; magic_enum::enum_name(profile-\u0026gt;type()) \u0026lt;\u0026lt; \u0026#34;Format: \u0026#34; \u0026lt;\u0026lt; profile-\u0026gt;format() \u0026lt;\u0026lt; \u0026#34;, Width: \u0026#34; \u0026lt;\u0026lt; profile-\u0026gt;width() \u0026lt;\u0026lt; \u0026#34;, Height: \u0026#34; \u0026lt;\u0026lt; profile-\u0026gt;height() \u0026lt;\u0026lt; \u0026#34;, FPS: \u0026#34; \u0026lt;\u0026lt; profile-\u0026gt;fps()); supported_profiles_[elem].emplace_back(profile); } setupPublisher void OBCameraNode::setupPublishers() { using PointCloud2 = sensor_msgs::msg::PointCloud2; using CameraInfo = sensor_msgs::msg::CameraInfo; auto point_cloud_qos_profile = getRMWQosProfileFromString(point_cloud_qos_); if (enable_colored_point_cloud_) { depth_registration_cloud_pub_ = node_-\u0026gt;create_publisher\u0026lt;PointCloud2\u0026gt;( \u0026#34;depth/color/points\u0026#34;, rclcpp::QoS(rclcpp::QoSInitialization::from_rmw(point_cloud_qos_profile), point_cloud_qos_profile)); } if (enable_point_cloud_) { depth_cloud_pub_ = node_-\u0026gt;create_publisher\u0026lt;PointCloud2\u0026gt;( \u0026#34;depth/points\u0026#34;, rclcpp::QoS(rclcpp::QoSInitialization::from_rmw(point_cloud_qos_profile), point_cloud_qos_profile)); } for (const auto\u0026amp; stream_index : IMAGE_STREAMS) { if (!enable_stream_[stream_index]) { continue; } std::string name = stream_name_[stream_index]; std::string topic = name + \u0026#34;/image_raw\u0026#34;; auto image_qos = image_qos_[stream_index]; auto image_qos_profile = getRMWQosProfileFromString(image_qos); image_publishers_[stream_index] = image_transport::create_publisher(node_, topic, image_qos_profile); topic = name + \u0026#34;/camera_info\u0026#34;; auto camera_info_qos = camera_info_qos_[stream_index]; auto camera_info_qos_profile = getRMWQosProfileFromString(camera_info_qos); camera_info_publishers_[stream_index] = node_-\u0026gt;create_publisher\u0026lt;CameraInfo\u0026gt;( topic, rclcpp::QoS(rclcpp::QoSInitialization::from_rmw(camera_info_qos_profile), camera_info_qos_profile)); } if (enable_publish_extrinsic_) { extrinsics_publisher_ = node_-\u0026gt;create_publisher\u0026lt;orbbec_camera_msgs::msg::Extrinsics\u0026gt;( \u0026#34;extrinsic/depth_to_color\u0026#34;, rclcpp::QoS{1}.transient_local()); } } publishStaticTransforms void OBCameraNode::publishStaticTransforms() { if (!publish_tf_) { return; } static_tf_broadcaster_ = std::make_shared\u0026lt;tf2_ros::StaticTransformBroadcaster\u0026gt;(node_); dynamic_tf_broadcaster_ = std::make_shared\u0026lt;tf2_ros::TransformBroadcaster\u0026gt;(node_); calcAndPublishStaticTransform(); if (tf_publish_rate_ \u0026gt; 0) { tf_thread_ = std::make_shared\u0026lt;std::thread\u0026gt;([this]() { publishDynamicTransforms(); }); } else { static_tf_broadcaster_-\u0026gt;sendTransform(static_tf_msgs_); } } calcAndPublishStaticTransform void OBCameraNode::calcAndPublishStaticTransform() { tf2::Quaternion quaternion_optical, zero_rot, Q; std::vector\u0026lt;float\u0026gt; trans(3, 0); zero_rot.setRPY(0.0, 0.0, 0.0); quaternion_optical.setRPY(-M_PI / 2, 0.0, -M_PI / 2); std::vector\u0026lt;float\u0026gt; zero_trans = {0, 0, 0}; auto camera_param = findDefaultCameraParam(); if (enable_publish_extrinsic_ \u0026amp;\u0026amp; extrinsics_publisher_ \u0026amp;\u0026amp; camera_param.has_value()) { auto ex = camera_param-\u0026gt;transform; Q = rotationMatrixToQuaternion(ex.rot); Q = quaternion_optical * Q * quaternion_optical.inverse(); extrinsics_publisher_-\u0026gt;publish(obExtrinsicsToMsg(ex, \u0026#34;depth_to_color_extrinsics\u0026#34;)); } else { Q.setRPY(0, 0, 0); } rclcpp::Time tf_timestamp = node_-\u0026gt;now(); publishStaticTF(tf_timestamp, trans, Q, frame_id_[DEPTH], frame_id_[COLOR]); publishStaticTF(tf_timestamp, trans, Q, camera_link_frame_id_, frame_id_[COLOR]); publishStaticTF(tf_timestamp, zero_trans, quaternion_optical, frame_id_[COLOR], optical_frame_id_[COLOR]); publishStaticTF(tf_timestamp, zero_trans, quaternion_optical, frame_id_[DEPTH], optical_frame_id_[DEPTH]); publishStaticTF(tf_timestamp, zero_trans, zero_rot, camera_link_frame_id_, frame_id_[DEPTH]); publishStaticTF(tf_timestamp, zero_trans, zero_rot, camera_link_frame_id_, frame_id_[ACCEL]); publishStaticTF(tf_timestamp, zero_trans, zero_rot, camera_link_frame_id_, frame_id_[GYRO]); } publishStaticTF void OBCameraNode::publishStaticTF(const rclcpp::Time\u0026amp; t, const std::vector\u0026lt;float\u0026gt;\u0026amp; trans, const tf2::Quaternion\u0026amp; q, const std::string\u0026amp; from, const std::string\u0026amp; to) { CHECK_EQ(trans.size(), 3u); geometry_msgs::msg::TransformStamped msg; msg.header.stamp = t; msg.header.frame_id = from; msg.child_frame_id = to; msg.transform.translation.x = trans.at(2) / 1000.0; msg.transform.translation.y = -trans.at(0) / 1000.0; msg.transform.translation.z = -trans.at(1) / 1000.0; msg.transform.rotation.x = q.getX(); msg.transform.rotation.y = q.getY(); msg.transform.rotation.z = q.getZ(); msg.transform.rotation.w = q.getW(); static_tf_msgs_.push_back(msg); } publishDynamicTransforms void OBCameraNode::publishDynamicTransforms() { RCLCPP_WARN(logger_, \u0026#34;Publishing dynamic camera transforms (/tf) at %g Hz\u0026#34;, tf_publish_rate_); std::mutex mu; std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mu); while (rclcpp::ok() \u0026amp;\u0026amp; is_running_) { tf_cv_.wait_for(lock, std::chrono::milliseconds((int)(1000.0 / tf_publish_rate_)), [this] { return (!(is_running_)); }); { rclcpp::Time t = node_-\u0026gt;now(); for (auto\u0026amp; msg : static_tf_msgs_) { msg.header.stamp = t; } dynamic_tf_broadcaster_-\u0026gt;sendTransform(static_tf_msgs_); } } } startStreams void OBCameraNode::startStreams() { if (pipeline_ != nullptr) { pipeline_.reset(); } pipeline_ = std::make_unique\u0026lt;ob::Pipeline\u0026gt;(device_); try { setupPipelineConfig(); pipeline_-\u0026gt;start(pipeline_config_, [this](std::shared_ptr\u0026lt;ob::FrameSet\u0026gt; frame_set) { onNewFrameSetCallback(frame_set); }); } catch (const ob::Error\u0026amp; e) { RCLCPP_ERROR_STREAM(logger_, \u0026#34;Failed to start pipeline: \u0026#34; \u0026lt;\u0026lt; e.getMessage()); RCLCPP_INFO_STREAM(logger_, \u0026#34;try to disable ir stream and try again\u0026#34;); enable_stream_[INFRA0] = false; setupPipelineConfig(); pipeline_-\u0026gt;start(pipeline_config_, [this](std::shared_ptr\u0026lt;ob::FrameSet\u0026gt; frame_set) { onNewFrameSetCallback(frame_set); }); } pipeline_started_.store(true); // startIMU(); } setupPipelineConfig void OBCameraNode::setupPipelineConfig() { if (pipeline_config_) { pipeline_config_.reset(); } pipeline_config_ = std::make_shared\u0026lt;ob::Config\u0026gt;(); if (depth_registration_ \u0026amp;\u0026amp; enable_stream_[COLOR] \u0026amp;\u0026amp; enable_stream_[DEPTH]) { pipeline_config_-\u0026gt;setAlignMode(ALIGN_D2C_HW_MODE); } for (const auto\u0026amp; stream_index : IMAGE_STREAMS) { if (enable_stream_[stream_index]) { RCLCPP_INFO_STREAM(logger_, \u0026#34;Enable \u0026#34; \u0026lt;\u0026lt; stream_name_[stream_index] \u0026lt;\u0026lt; \u0026#34; stream\u0026#34;); RCLCPP_INFO_STREAM( logger_, \u0026#34;Stream \u0026#34; \u0026lt;\u0026lt; stream_name_[stream_index] \u0026lt;\u0026lt; \u0026#34; width: \u0026#34; \u0026lt;\u0026lt; width_[stream_index] \u0026lt;\u0026lt; \u0026#34; height: \u0026#34; \u0026lt;\u0026lt; height_[stream_index] \u0026lt;\u0026lt; \u0026#34; fps: \u0026#34; \u0026lt;\u0026lt; fps_[stream_index] \u0026lt;\u0026lt; \u0026#34; format: \u0026#34; \u0026lt;\u0026lt; format_str_[stream_index]); pipeline_config_-\u0026gt;enableStream(stream_profile_[stream_index]); } } } onNewFrameSetCallback void OBCameraNode::onNewFrameSetCallback(const std::shared_ptr\u0026lt;ob::FrameSet\u0026gt;\u0026amp; frame_set) { if (frame_set == nullptr) { return; } try { publishPointCloud(frame_set); auto color_frame = std::dynamic_pointer_cast\u0026lt;ob::Frame\u0026gt;(frame_set-\u0026gt;colorFrame()); auto depth_frame = std::dynamic_pointer_cast\u0026lt;ob::Frame\u0026gt;(frame_set-\u0026gt;depthFrame()); auto ir_frame = std::dynamic_pointer_cast\u0026lt;ob::Frame\u0026gt;(frame_set-\u0026gt;irFrame()); onNewFrameCallback(color_frame, COLOR); onNewFrameCallback(depth_frame, DEPTH); onNewFrameCallback(ir_frame, INFRA0); } catch (const ob::Error\u0026amp; e) { RCLCPP_ERROR_STREAM(logger_, \u0026#34;onNewFrameSetCallback error: \u0026#34; \u0026lt;\u0026lt; e.getMessage()); } catch (const std::exception\u0026amp; e) { RCLCPP_ERROR_STREAM(logger_, \u0026#34;onNewFrameSetCallback error: \u0026#34; \u0026lt;\u0026lt; e.what()); } catch (...) { RCLCPP_ERROR_STREAM(logger_, \u0026#34;onNewFrameSetCallback error: unknown error\u0026#34;); } } startIMU void OBCameraNode::startIMU() { for (const auto\u0026amp; stream_index : HID_STREAMS) { if (enable_stream_[stream_index]) { CHECK(sensors_.count(stream_index)); auto profile_list = sensors_[stream_index]-\u0026gt;getStreamProfileList(); for (size_t i = 0; i \u0026lt; profile_list-\u0026gt;count(); i++) { auto item = profile_list-\u0026gt;getProfile(i); if (stream_index == ACCEL) { auto profile = item-\u0026gt;as\u0026lt;ob::AccelStreamProfile\u0026gt;(); auto accel_rate = sampleRateFromString(imu_rate_[stream_index]); auto accel_range = fullAccelScaleRangeFromString(imu_range_[stream_index]); if (profile-\u0026gt;fullScaleRange() == accel_range \u0026amp;\u0026amp; profile-\u0026gt;sampleRate() == accel_rate) { sensors_[stream_index]-\u0026gt;start(profile, [this, stream_index](std::shared_ptr\u0026lt;ob::Frame\u0026gt; frame) { onNewIMUFrameCallback(frame, stream_index); }); imu_started_[stream_index] = true; RCLCPP_INFO_STREAM(logger_, \u0026#34;start accel stream with \u0026#34; \u0026lt;\u0026lt; magic_enum::enum_name(accel_range) \u0026lt;\u0026lt; \u0026#34; range and \u0026#34; \u0026lt;\u0026lt; magic_enum::enum_name(accel_rate) \u0026lt;\u0026lt; \u0026#34; rate\u0026#34;); } IMU Test?! 소스 코드 확인 시, 주석되어 있는 IMU publisher와 관련된 부분들을 확인할 수 있는데요. 과연 IMU data를 사용할 수 있는지 확인해보겠습니다.\n주석 해제 - ob_camera_node.cpp void OBCameraNode::startStreams() { ... // 주석 해제 pipeline_started_.store(true); startIMU(); } void OBCameraNode::setupPublishers() { ... // 주석 해제 for (const auto\u0026amp; stream_index : HID_STREAMS) { if (!enable_stream_[stream_index]) { continue; } std::string data_topic_name = stream_name_[stream_index] + \u0026#34;/sample\u0026#34;; auto data_qos = getRMWQosProfileFromString(imu_qos_[stream_index]); imu_publishers_[stream_index] = node_-\u0026gt;create_publisher\u0026lt;sensor_msgs::msg::Imu\u0026gt;( data_topic_name, rclcpp::QoS(rclcpp::QoSInitialization::from_rmw(data_qos), data_qos)); RCLCPP_INFO_STREAM(logger_, \u0026#34;IMU Publisher created\u0026#34;); } if (enable_publish_extrinsic_) { extrinsics_publisher_ = node_-\u0026gt;create_publisher\u0026lt;orbbec_camera_msgs::msg::Extrinsics\u0026gt;( \u0026#34;extrinsic/depth_to_color\u0026#34;, rclcpp::QoS{1}.transient_local()); } } 주석 해제 - gemini2.launch.xml \u0026lt;!-- imu --\u0026gt; \u0026lt;arg name=\u0026#34;enable_accel\u0026#34; default=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;accel_rate\u0026#34; default=\u0026#34;100hz\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;accel_range\u0026#34; default=\u0026#34;4g\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;enable_gyro\u0026#34; default=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;gyro_rate\u0026#34; default=\u0026#34;100hz\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;gyro_range\u0026#34; default=\u0026#34;1000dps\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;liner_accel_cov\u0026#34; default=\u0026#34;0.01\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;angular_vel_cov\u0026#34; default=\u0026#34;0.01\u0026#34;/\u0026gt; \u0026lt;group\u0026gt; \u0026lt;push-ros-namespace namespace=\u0026#34;$(var camera_name)\u0026#34;/\u0026gt; \u0026lt;node name=\u0026#34;camera\u0026#34; pkg=\u0026#34;orbbec_camera\u0026#34; exec=\u0026#34;orbbec_camera_node\u0026#34; output=\u0026#34;screen\u0026#34;\u0026gt; ... \u0026lt;!-- imu --\u0026gt; \u0026lt;param name=\u0026#34;enable_accel\u0026#34; value=\u0026#34;$(var enable_accel)\u0026#34; /\u0026gt; \u0026lt;param name=\u0026#34;accel_rate\u0026#34; value=\u0026#34;$(var accel_rate)\u0026#34; /\u0026gt; \u0026lt;param name=\u0026#34;accel_range\u0026#34; value=\u0026#34;$(var accel_range)\u0026#34; /\u0026gt; \u0026lt;param name=\u0026#34;enable_gyro\u0026#34; value=\u0026#34;$(var enable_gyro)\u0026#34; /\u0026gt; \u0026lt;param name=\u0026#34;gyro_rate\u0026#34; value=\u0026#34;$(var gyro_rate)\u0026#34; /\u0026gt; \u0026lt;param name=\u0026#34;gyro_range\u0026#34; value=\u0026#34;$(var gyro_range)\u0026#34; /\u0026gt; \u0026lt;param name=\u0026#34;liner_accel_cov\u0026#34; value=\u0026#34;$(var liner_accel_cov)\u0026#34;/\u0026gt; \u0026lt;param name=\u0026#34;angular_vel_cov\u0026#34; value=\u0026#34;$(var angular_vel_cov)\u0026#34;/\u0026gt; 마지막으로 imu data의 시각화를 위해 rviz2 plugin을 설치합니다. sudo apt install ros-foxy-rviz-imu-plugin -y launch file을 다시 실행시킨 뒤 rviz2를 확인해보면 다음과 같이 /gyro/sample/imu라는 데이터를 확인할 수 있습니다. 하지만 Topic 시각화를 추가하면 아래와 같이 tf2관련 에러들이 확인됩니다. topic은 만들어두고, tf2는 broadcast하고 있지 않기 때문입니다. [INFO] [1685265445.144163057] [rviz]: Message Filter dropping message: frame \u0026#39;camera_gyro_optical_frame\u0026#39; at time 1685265444.622 for reason \u0026#39;Unknown\u0026#39; [INFO] [1685265445.179582316] [rviz]: Message Filter dropping message: frame \u0026#39;camera_gyro_optical_frame\u0026#39; at time 1685265444.652 for reason \u0026#39;Unknown\u0026#39; [INFO] [1685265445.214360819] [rviz]: Message Filter dropping message: frame \u0026#39;camera_gyro_optical_frame\u0026#39; at time 1685265444.712 for reason \u0026#39;Unknown\u0026#39; [INFO] [1685265445.244405298] [rviz]: Message Filter dropping message: frame \u0026#39;camera_gyro_optical_frame\u0026#39; at time 1685265444.751 for reason \u0026#39;Unknown\u0026#39; 실제 topic data를 살펴보아도 frame*id는 camera_gyro_optical_frame로 되어있는 반면, tf2 tree에서 해당 tf2는 확인되지 않습니다. 더불어 angular_velocity만 갱신될 뿐 제일 중요한 orientation data를 얻을 수 없습니다. *(orbbec측의 빠른 업데이트를 기대해봅시다.)_ --- header: stamp: sec: 1685265428 nanosec: 750000128 frame_id: camera_gyro_optical_frame orientation: x: 0.0 y: 0.0 z: 0.0 w: 0.0 orientation_covariance: - -1.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 angular_velocity: x: 0.002128450432792306 y: -0.006385351065546274 z: 0.0026605629827827215 angular_velocity_covariance: "
},
{
	"uri": "/kr/ros2_foxy/lecture20/",
	"title": "Lecture20. NVIDIA Jetson Platform",
	"tags": [],
	"description": "",
	"content": "데모 시연 이번 시간에는 지금까지 학습한 내용들을 다시 한 번 되짚어보면서 ROS 2를 사용하고자 하는 고객들 측면에서의 개발, 기능들을 이야기해보겠습니다.\nGazebo 시뮬레이션 데모 Real World와 시뮬레이션 연동 실물 센서의 ROS 2 연동 소형 로봇 데모를 통해 살펴보는 로봇 시스템 Gazebo 시뮬레이션 데모 - Fusionbot SLAM 지금까지 학습한 내용들을 통해 구현할 수 있는 Application을 데모해보고자 합니다.\nGazebo World 생성 URDF를 통한 로봇 Structure 구성 Gazebo Control Plugin과 Sensor Plugin 처음 마주친 환경에서, 우리는 현재 자신의 위치와 주변 환경의 Mapping을 동시에 진행합니다. 이와 같이 SLAM이란, Localization과 Mapping을 Simultaneously 실행하는 것으로 로봇의 자율주행에 사용되는 지도 생성에 주로 사용됩니다.\n2D Lidar를 통해 Gazebo 상의 Fusionbot을 통해 환경의 지도를 생성해보는 실습을 진행해보겠습니다.\nSLAM은 사용하는 센서, 방식에 따라 여러 종류의 구현이 가능합니다. 반드시 2D Lidar SLAM만 존재하는 것이 아님을 밝힙니다.\nFusionbot SLAM # Terminal 1 - gazebo world launch ros2 launch fusionbot_description office_construction.launch.py # Terminal 2 - slam toolbox launch cbp fusionbot_slam \u0026amp;\u0026amp; source install/local_setup.bash ros2 launch fusionbot_slam online_async_launch.py # Terminal 2 - control node rqt_robot_steering ⇒ rqt_robot_steering을 통해 로봇을 움직임에 따라 rviz2 상에서 완성되는 지도를 확인할 수 있습니다.\n생성된 지도를 저장하고 싶다면 rviz2에서 경로를 입력한 뒤, Save Map 버튼을 클릭합니다. ⇒ 이렇게 생성된 지도는 이후 자율주행, world 생성, 3D reconstruction등 다양한 Application에 사용됩니다.\nReal World와 시뮬레이션 연동 이번 데모는 SLAMTEC의 Rplidar를 사용하여 사무실을 Mapping하고, 이를 바탕으로 Gazebo World를 만들어보겠습니다.\nrplidar a3 2D 라이다 제품군 중 비교적 저렴한 가격에 최대 25m라는 합리적인 탐지거리와 해상도를 갖고 있어 로봇 프로젝트에서 널리 사용되는 제품 중 하나입니다.\n실제 실외 배송로봇에 이러한 형태의 라이다가 사용된 바 있습니다. rplidar a3를 통해 실제 사무실을 SLAM 해보겠습니다. (하단 로그는 제가 데모하기 위한 명령어입니다.) # rplidar a3 cd /dev sudo chmod 777 ttyUSB0 ros2 launch rplidar_ros view_rplidar_a3_launch.py # Terminal 2 ros2 launch demo_pkg rf2o_odom.launch.py # Terminal 3 ros2 launch demo_pkg online_async_launch_real.py 실시간으로 그려지는 지도를 볼 수 있습니다. 지도 작성을 마쳤다면, 이제 Gazebo에서 이 지도를 활용해 Building을 만들어 보겠습니다. SLAM map은 pgm 포맷을 가지므로 png로 변환이 필요합니다. https://convertio.co/pgm-png/\n이제 Gazebo의 building Editor를 사용하여 사무실과 동일한 크기의 시뮬레이션 환경을 제작합니다. ⇒ 지금까지 학습한 내용을 바탕으로 이제 여러분만의 로봇, Object를 추가하여 풍성한 시뮬레이션을 만들 수 있을 것입니다.\n실물 센서의 ROS 2 연동 아무리 시뮬레이션에서 완벽하게 동작하더라도 실제 센서를 사용하는 것과는 큰 차이를 갖습니다. 이번 데모에서는 다양한 센서들을 ROS 2 연동하여 실행해보고, 성능을 비교해보겠습니다. (하단 로그는 제가 데모하기 위한 명령어입니다.)\nOrbbec Astra+ cd ~/gemini_ws/ source install/local_setup.bash ros2 launch orbbec_camera astra_pro_plus.launch.xml rviz2 \u0026amp; rqt top Orbbec Gemini2 ros2 launch orbbec_camera gemini2.launch.xml Intel Realsense2 D455 cd ~/realsense_ws/ source install/local_setup.bash ros2 launch realsense2_camera rs_launch.py pointcloud.enable:=true 소형 로봇 데모를 통해 살펴보는 로봇 시스템 nanosaur 소개 Nanosaur는 탱크 타입의 로봇으로 NVIDIA의 개발자 Raffaello Bonghi가 배포한 오픈소스에 기반하여 Road Balance가 교육용 키트로 재설계한 로봇입니다. 자세한 스펙과 기능은 링크를 통해 확인할 수 있습니다. - link\nnanosaur 제어 ROS_DOMAIN_ID=30 ros2 run nanosaur_hardware nanosaur rqt_robot_steering nanosaur 카메라 ROS_DOMAIN_ID=30 ros2 run nanosaur_camera nanosaur_camera ros2 run rqt_image_view rqt_image_view 이번 데모를 통해 ROS 2의 장점을 엿볼 수 있는데요. ROS 2는 DDS라는 표준 프로토콜을 사용하기 때문에 동일한 네트워크를 사용하는 시스템 내부에서 동작하는 시스템들끼리는 자동으로 상호 인지가 가능합니다. 이러한 장점을 가진 ROS 2는 로봇 뿐만 아니라 자율주행 분야로 확대되어 현재 다양한 도메인에서 수요가 많은 상황입니다. 비롯 지금은 매우 작은 Nanosaur를 살펴보았지만 실제 로봇을 만들기까지 로봇 공학자들은 다양한 과정을 거치고 수정, 검증을 반복합니다. 설계와 검증까지 구현하기도 벅찬 와중, 센서 연동까지 개발하는 것은 매우 힘들기에 대부분 ROS 개발자들은 검증된 코드와 예시를 제공하는 제품들을 사용합니다.\nIntel Realsense ZED Stereo Camera Oak-D AI Camera Livox 3D Lidar 단순 ROS 2 패키지가 존재하는 것 뿐만 아니라, 카메라와 같이 메모리와 처리 속도에 민감한 센서는 효율적인 코드를 제공하는지 여부가 무척 중요합니다.\nNVIDIA에서 제공하는 ROS 2 카메라 코드 페이지를 살펴보면 예시와 함께 사용된 환경, 해상도 별 성능을 제시하고 있습니다.\n따라서 센서를 개발하거나, 로봇을 개발하는 입장 모두 사용자 호환성을 고려하여 설계하고, 수많은 시행착오를 통해 올바른 제품에 대한 척도를 깨우쳐야 합니다.\n"
},
{
	"uri": "/kr/ros2_basic_foxy/lecture1/",
	"title": "Lecture1 - Introduction to ROS 2",
	"tags": [],
	"description": "",
	"content": "About ROS 2 image from : foxglove.dev ROS의 시작은 연구실이었습니다. 구글의 핵심 개발자였던 Scott Hassan은 2006년 Willow Garage를 설립하였고, 여기서 처음으로 ROS가 탄생하였습니다. 이후 Willow Garage는 여러 Spin-off를 거친 뒤 OSRF와 OSRC등으로 나뉘게 되었고, 현재 Gazebo와 ROS는 이들에 의해 관리되고 있습니다.\n2022년 12월 기준 구글의 자회사인 Alphabet의 Intrinsic이 OSRF를 품게 되었으며, Ubuntu Linux를 관리하는 Canonical에서 ROS의 공식 서포트를 약속하고, Jetson 보드와 Issac Sim들을 개발하고 있는 Nvidia에서도 ROS를 공식 지원하고 있습니다.\n이렇게 많은 기업들이 ROS에 거는 기대가 큰 만큼 로봇 시장의 성장성도 기대가 됩니다. 하지만, 로봇이 상용화되기 위해서는 여러 난관이 있습니다.\n보안 안정성 실시간성 개발 용이성 기술 지원 하드웨어 연동 etc… 연구용으로 설계된 기존 ROS를 통해서는 이러한 모든 조건을 충족할 수 없다는 결론을 내렸고, Open Robotics는 ROS 2를 새롭게 선보이게 됩니다.\nROS 1 vs ROS 2 기존 언급되었던 ROS 1의 모든 문제들이 ROS 2에서 해결되었다고 할 수는 없지만 적어도 해결을 고려하여 설계되었다고 말하고 싶습니다.\nROS 1과 비교하여 ROS 2의 장점들을 간단히 살펴봅시다.\nimage from : maker.pro 상용화를 고려한 가장 큰 변화로 패킷 통신에 TCPROS/UPDROS가 아닌 DDS(Data Distribution Service)를 도입하였다는 것입니다.\nimage from : omg.org 뿐만 아니라, 임베디드 시스템을 위한 micro-ros와 같은 멋진 프로젝트들도 ROS 2에서 새롭게 등장하였습니다.\nimage from : freertos 이렇게 멋진 ROS 2를 지금부터 함께 배워보겠습니다.\nAbout this lecture ROS 1 강의에서는 ROS Noetic 버전을 사용하였으며, 동일한 Ubuntu 20.04 버전에서 구동되는 ROS 2 Foxy를 사용할 예정입니다.\nROS 설정을 잘 따라오셨다면 별도의 설치 과정은 필요 없으며, 리눅스 커멘드 사용법, 패키지 설치 등 기본적인 내용은 알고 있다는 가정 하에 강의를 진행해보겠습니다.\nimage from : docs.ros.org ROS 1강의를 통해 탄탄하게 다진 기본기를 바탕으로 아래와 같은 내용들을 다뤄봅니다.\nROS 2 기본 커멘드 C++ ROS 프로그래밍 Nav 2를 사용한 자율주행 실제 로봇 데이터 활용해보기 과제를 통한 ROS 2 응용 프로그래밍 더불어, 이번 강의를 통해 실제 로봇이 어떻게 개발되는지 바닥부터 살펴보고자 합니다.\n로봇 설계 시뮬레이션 제작과 실습 실제 로봇을 만들기 위해 필요한 요소들 유지 보수와 로봇 제품 개발 Road Balance의 차량형 교육 로봇, SRC를 통해 실습해보겠습니다.\n강의를 수강하기 위해 필요한 선수지식 ROS 2는 Python 3와 C++ 11이상의 버전을 지원합니다. 따라서 최소한의 프로그래밍 지식이 있다는 가정 하에 강의가 진행되며, 환경 설정, ROS 개념 등 ROS 1 강의를 모두 수강했다는 전제 하에 진행됩니다.\nimage from : docs.ros.org 이번 강의에서는 좀 더 실질적인 ROS 2 개발을 맛보고자 C++를 활용한 프로그래밍도 준비해 보았으니 이번 기회에 C++를 공부해 보는 것도 좋은 기회가 되실 겁니다.\nROS 2 Workspace 생성 ROS 1에서 catkin build system을 사용한 것과 유사하게, ROS 2에서는 colcon이라는 빌드 시스템을 사용하고 있습니다. colcon을 사용하기 위해서 Workspace가 필요하며, ROS 1과 ROS 2를 모두 사용하는 현재 시스템 같은 경우, 혼란스럽지 않도록 이름을 달리 설정하겠습니다.\ncd ~/ mkdir -p ros2_ws/src cd ros2_ws colcon build 아래와 같은 폴더 구조가 생성되었을 것입니다. build : 컴파일 된 C++ 프로그램, custom interface 등이 위치하게 됩니다. install : ros2 launch와 ros2 run 등의 명령어는 프로그램의 실행 시 이 install 폴더 내 파일들을 조회합니다. 일종의 바로가기들의 모임이라고 생각하면 됩니다. log : colcon build 시 발생하는 로드들이 위치하게 됩니다. src : 모든 소스 코드들이 위치하게 됩니다. Package를 지우고 싶은 경우 ⇒ build와 install 폴더에서 해당 package에 해당하는 내용들을 삭제합니다.\ncolcon을 사용하여 package를 빌드하는 방법들을 간단히 소개합니다.\ncolcon build : src 폴더 내부에 존재하는 모든 package들을 빌드합니다. colcon build \u0026ndash;packages-up-to : 해당 package의 종속성이 존재할 시, 이들을 먼저 빌드하고 pkg-name을 빌드합니다. colcon build \u0026ndash;packages-select : 해당 package만을 빌드합니다. 새로운 Package를 빌드한 다음 ROS 2에서도 setup.bash를 source 해주어야 합니다. 이 작업에는 크게 두가지가 존재합니다.\nsource install/setup.bash ⇒ workspace를 source하고 ROS 2시스템 전체를 갱신합니다. source install/local_setup.bash ⇒ workspace만을 sources합니다. (여러 ROS 2 workspace가 있는 경우 local_setup.bash를 사용합시다.) # source chained prefixes # setting COLCON_CURRENT_PREFIX avoids determining the prefix in the sourced script COLCON_CURRENT_PREFIX=\u0026#34;/opt/ros/foxy\u0026#34; _colcon_prefix_chain_bash_source_script \u0026#34;$COLCON_CURRENT_PREFIX/local_setup.bash\u0026#34; # source this prefix # setting COLCON_CURRENT_PREFIX avoids determining the prefix in the sourced script COLCON_CURRENT_PREFIX=\u0026#34;$(builtin cd \u0026#34;`dirname \u0026#34;${BASH_SOURCE[0]}\u0026#34;`\u0026#34; \u0026gt; /dev/null \u0026amp;\u0026amp; pwd)\u0026#34; _colcon_prefix_chain_bash_source_script \u0026#34;$COLCON_CURRENT_PREFIX/local_setup.bash\u0026#34; unset COLCON_CURRENT_PREFIX unset _colcon_prefix_chain_bash_source_script 마지막으로, 이번 실습에 필요한 소스 코드를 clone 하고, apt 패키지를 설치하면서, 강의를 마치겠습니다.\ncd ~/ros2_ws/src git clone https://github.com/RB2023ROS/du2023-ros2.git cd du2023-ros2 ./setup_scripts.sh 참고자료\nhttps://www.theconstructsim.com/infographic-ros-1-vs-ros-2-one-better-2/ https://rsl.ethz.ch/education-students/lectures/ros.html https://velog.io/@hwang-chaewon/ROS2006 "
},
{
	"uri": "/kr/ros2_basic_foxy/lecture2/",
	"title": "Lecture2 - ROS 2 Node, Package",
	"tags": [],
	"description": "",
	"content": " ROS Noetic 강의를 이미 학습하였기 때문에, Node, Package, launch file, Topic, Message, Service와 같은 개념은 이미 알고 계실 것이라 생각합니다. (맞죠?)\n혹시나 잊어버리셨을 수 있으니 강의 중간중간 제가 간단히 리뷰를 하면서 진행하겠습니다.\nROS 2 Node image from : docs.rog.org ROS에서의 Node는 하나의 실행 가능한 프로그램을 이야기하며, 각각의 Node는 본인 고유의 기능을 담당합니다.\n서로 다른 역할을 담당하는 Node들이 각자의 동작을 수행하고 서로 간의 데이터를 주고받게 됨으로 시스템을 형성하게 되고, 따라서, ROS를 통한 로봇 개발은 곧, 적절한 Node들의 개발이라고도 말할 수 있습니다.\nROS 2 Node 실행 - ROS 2에서 Node의 실행은 ros2 run \u0026lt;pkg-name\u0026gt; \u0026lt;executable-name\u0026gt;입니다. sudo apt install ros-foxy-turtlesim -y ros2 run turtlesim turtlesim_node ROS 2의 Node를 다루는 명령어는 ROS 1과 크게 다르지 않습니다. $ ros2 node list /teleop_turtle /turtlesim $ ros2 node info /turtlesim /turtlesim Subscribers: /parameter_events: rcl_interfaces/msg/ParameterEvent /turtle1/cmd_vel: geometry_msgs/msg/Twist Publishers: /parameter_events: rcl_interfaces/msg/ParameterEvent /rosout: rcl_interfaces/msg/Log /turtle1/color_sensor: turtlesim/msg/Color /turtle1/pose: turtlesim/msg/Pose Service Servers: /clear: std_srvs/srv/Empty … rqt_graph도 동일하게 사용 가능합니다. $ rqt_graph ROS 2 Package ROS의 Package는 파일 관점에서 관련된 소스코드, 라이브러리, 모델링 파일들, 설정 파일들을 한데 모아둔 폴더로 생각할 수 있으며, 기능 관점에서 시뮬레이션, 하드웨어 제어, 센서 다루기 등으로 분리시킨 모듈로 생각할 수 있습니다.\nimage from : packthub 새로운 패키지를 생성하는 과정에서, ROS 2는 ROS 1과 차이점이 있습니다.\nROS 1에서 catkin_create_package를 사용했던 것처럼, ROS 2에서는 colcon을 사용하여 새로운 package를 생성합니다. 하지만, ROS 2에서는 사용하는 프로그래밍 언어(python/c++)에 따라 다른 build type을 지정할 수 있습니다.\nROS 2 Python Package 파이썬 패키지의 생성은 다음과 같습니다. $ ros2 pkg create --build-type ament_python \u0026lt;package_name\u0026gt; $ ros2 pkg create --build-type ament_python my_first_pkg going to create a new package package name: my_first_pkg destination directory: /home/kimsooyoung/ros2_ws/src package format: 3 version: 0.0.0 ... 그리고, 다음과 같은 폴더 구조가 자동 생성됩니다. my_first_pkg/ ├── my_first_pkg │ └── __init__.py ├── package.xml ├── resource │ └── my_first_pkg ├── setup.cfg ├── setup.py └── test ├── test_copyright.py ├── test_flake8.py └── test_pep257.py 새롭게 만든 패키지를 빌드해봅시다. $ cd ~/ros2_ws $ colcon build --packages-select my_first_pkg Starting \u0026gt;\u0026gt;\u0026gt; my_first_pkg Finished \u0026lt;\u0026lt;\u0026lt; my_first_pkg [1.56s] Summary: 1 package finished [1.96s] $ source install/local_setup.bash 생성한 파이썬 코드 패키지에서, 실제 파이썬 코드는 어디에 위치할까요?\n새로운 패키지를 생성하면 해당 패키지 폴더 안에 패키지 이름과 동일한 폴더가 하나 위치하게 됩니다. 이 폴더 안에는 init.py 파일이 기본적으로 위치합니다. 참고로, wsl에서 파일 탐색기를 열기 위해서는 explorer.exe . 를 입력하시면 됩니다.\n강의 예시 소스코드를 하나 끌어와 빌드해보겠습니다. 아주 간단한 파이썬 예시가 실행될 것입니다. $ cd ~/ros2_sw $ colcon build --packages-select py_node_tutorial Starting \u0026gt;\u0026gt;\u0026gt; py_node_tutorial Finished \u0026lt;\u0026lt;\u0026lt; py_node_tutorial [1.85s] Summary: 1 package finished [2.14s] $ source install/local_setup.bash $ ros2 run py_node_tutorial example_node_1 [INFO] [1672462290.252773294] [example_node_1]: ==== Hello ROS 2 ==== 여기서 주목할 점은, node의 실행 시 roscore가 없어도 된다는 점입니다. DDS를 사용함으로 각각의 node가 분산 처리가 가능하기 때문에 가능한 것입니다.\nimage from : design.ros2.org ROS 2 C++ Package 대부분의 오픈소스 패키지들은 C++로 개발되어 있는 경우가 많습니다. turtlesim의 소스코드를 확인해봅시다.\nhttps://github.com/ros/ros_tutorials\n모두 C++로 개발되어 있습니다. 따라서, 실제 작업 시 파이썬을 위주로 사용하더라도 적어도 C++ 패키지의 구조는 파악하고 있어야 오류 상황에 대처할 수 있습니다.\nC++ 패키지의 생성은 다음과 같습니다. $ ros2 pkg create --build-type ament_cmake \u0026lt;package_name\u0026gt; $ ros2 pkg create --build-type ament_cmake my_first_cpp_pkg going to create a new package package name: my_first_cpp_pkg destination directory: /home/kimsooyoung/ros2_ws/src package format: 3 version: 0.0.0 ... C++ 패키지는 다음과 같은 구조를 갖습니다. 파이썬과 달리, C++는 컴파일 언어이기 때문에 CMake를 위한 CMakeLists.txt 파일이 추가되어 있습니다. my_first_cpp_pkg ├── CMakeLists.txt ├── include │ └── my_first_cpp_pkg ├── package.xml └── src 일반적으로 C++ 개발을 하다보면 header와 source의 분리를 시키곤 합니다.\n이를 위해 보통 include 폴더 안에 헤더 파일을 위치시키고, src 폴더 안에 소스 코드를 위치시킵니다.\n빌드와 실행은 C++ 패키지도 동일한 커멘드 라인을 사용합니다. $ colcon build --packages-select cpp_node_tutorial $ source install/local_setup.bash Starting \u0026gt;\u0026gt;\u0026gt; cpp_node_tutorial Finished \u0026lt;\u0026lt;\u0026lt; cpp_node_tutorial [0.42s] Summary: 1 package finished [0.64s] $ ros2 run cpp_node_tutorial example_node_1 [INFO] [1672462275.581606122] [example_node_1]: ==== Hello ROS 2 ==== apt를 통한 패키지 사용하기 널리 사용되고 검증된 패키지들은 소스 코드 빌드 없이 명령어 하나만으로 사용할 수 있습니다. 다만, ROS 1과 ROS 2, 그리고 같은 ROS 2일지라도 버전에 따라 재설치를 해줘야 합니다.\n$ sudo apt install ros-\u0026lt;DISTRO\u0026gt;-\u0026lt;pkg-name\u0026gt; $ sudo apt install ros-foxy-turtlesim 지금까지 우리가 사용했던 turtlesim, turtle_teleop_key는 모두 apt install turtlesim을 통해 설치가 가능하였기에 코드에 대한 고려 없이 바로 실행할 수 있던 것입니다.\n이를 사용하여 ROS 개발 초기에는 바로 설치 가능한 패키지들을 조합하여 빠르게 검증을 하고, 이후 직접 Customizing해야 하는 부분은 별도 소스코드 빌드를 통해 업그레이드를 하곤 합니다.\nROS 2 Launch ROS 2의 launch파일은 기본적으로 Python 문법을 사용합니다. 기존 ROS 1에서 xml 문법을 사용하던 것에서 비교하면, 보다 손쉽게 접근할 수 있어졌습니다.\n예제를 통해 기본 구조에 대해 짚고 넘어가겠습니다. $ cd ~/ros2_ws $ colcon build --packages-select src_description $ source install/local_setup.bash $ ros2 launch src_description src_description.launch.py 사진과 같이 RViz2와 joint state publisher gui가 등장할 것입니다. joint state publisher gui의 슬라이드바를 이리저리 옮겨보세요.\nROS 1 강의에서 배워보았던 tf에 대해서도 복습할 수 있는 기회입니다.\nros2의 launch 명령어는 다음과 같이 구성되어 있습니다. $ ros2 launch \u0026lt;package-name\u0026gt; \u0026lt;launch-file-name\u0026gt; 패키지 내에 존재하는 특정 launch 파일을 실행해라, 라는 뜻이 됩니다.\n예제 launch file을 살펴봅시다. ros2의 launch file은 python과 xml을 지원합니다. python 파일의 경우 .launch.py로 이름짓는 것이 일반적입니다.\n항상 launch file의 분석은 가장 하단부터 시작합니다. return LaunchDescription([ TimerAction( period=3.0, actions=[rviz2] ), robot_state_publisher, joint_state_publisher_gui, ]) LaunchDescription[] 안에 위치한 프로그램들을 동시에 실행하는 것이 launch file을 작성하는 이유입니다.\n상단 옵션을 하나씩 살피겠습니다. launch file에서 특정 폴더, 파일에 접근하기 위해 package에 기반하여 경로를 탐색합니다. def generate_launch_description(): pkg_path = os.path.join(get_package_share_directory(\u0026#34;src_description\u0026#34;)) rviz_config_file = os.path.join(pkg_path, \u0026#34;rviz\u0026#34;, \u0026#34;description.rviz\u0026#34;) urdf_file = os.path.join(pkg_path, \u0026#34;urdf\u0026#34;, \u0026#34;src_body.urdf\u0026#34;) urdf - Unified Robotics Description Format란 로봇의 형상을 파일로 표현하는 일종의 포멧입니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34; ?\u0026gt; \u0026lt;!-- =================================================================================== --\u0026gt; \u0026lt;!-- | This document was autogenerated by xacro from /home/kimsooyoung/ros2_ws/src/du2023-ros2/src_gazebo/urdf/src_body.urdf.xacro | --\u0026gt; \u0026lt;!-- | EDITING THIS FILE BY HAND IS NOT RECOMMENDED | --\u0026gt; \u0026lt;!-- =================================================================================== --\u0026gt; \u0026lt;robot name=\u0026#34;src_body\u0026#34;\u0026gt; \u0026lt;material name=\u0026#34;silver\u0026#34;\u0026gt; \u0026lt;color rgba=\u0026#34;0.700 0.700 0.700 1.000\u0026#34;/\u0026gt; \u0026lt;/material\u0026gt; \u0026lt;material name=\u0026#34;black\u0026#34;\u0026gt; \u0026lt;color rgba=\u0026#34;1.000 1.000 1.000 1.000\u0026#34;/\u0026gt; \u0026lt;/material\u0026gt; \u0026lt;material name=\u0026#34;blue\u0026#34;\u0026gt; \u0026lt;color rgba=\u0026#34;0.0 0.0 0.8 1.0\u0026#34;/\u0026gt; \u0026lt;/material\u0026gt; \u0026lt;material name=\u0026#34;green\u0026#34;\u0026gt; \u0026lt;color rgba=\u0026#34;0.0 0.8 0.0 1.0\u0026#34;/\u0026gt; \u0026lt;/material\u0026gt; \u0026lt;material name=\u0026#34;grey\u0026#34;\u0026gt; \u0026lt;color rgba=\u0026#34;0.2 0.2 0.2 1.0\u0026#34;/\u0026gt; \u0026lt;/material\u0026gt; ... image from : http://library.isr.ist.utl.pt/ src의 urdf와 description 결과를 함께 살펴보면서 urdf에 대한 개념을 익혀봅시다.\nurdf를 생성하는 여러 방법들이 있습니다.\nxacro와 함께 직접 텍스트를 작성하기 CAD 프로그램을 사용하기 SOLIDWORKS Fusion 360 blender 시뮬레이션 프로그램 내 model builder 사용하기 Gazebo Colleliasim 저의 경우, Fusion 360에서 사용할 수 있는 오픈소스 urdf exporter를 통해 시뮬레이션을 개발하였습니다.\nhttps://github.com/syuntoku14/fusion2urdf\nurdf를 사용하여 ROS에게 로봇에 대한 정보를 전달하고 지속 주시하는 것이 아래 두 Node의 역할입니다. joint_state_publisher_gui = Node( package=\u0026#34;joint_state_publisher_gui\u0026#34;, executable=\u0026#34;joint_state_publisher_gui\u0026#34;, name=\u0026#34;joint_state_publisher_gui\u0026#34;, ) robot_state_publisher = Node( package=\u0026#39;robot_state_publisher\u0026#39;, executable=\u0026#39;robot_state_publisher\u0026#39;, name=\u0026#39;robot_state_publisher\u0026#39;, output=\u0026#39;screen\u0026#39;, parameters=[{\u0026#39;use_sim_time\u0026#39;: True}], arguments=[urdf_file], ) launch file 분석의 마지막으로 Rviz2 실행입니다. Rviz와 동일하게 launch file에서 config option을 줄 수 있으며, TimerAction을 통해 3초의 여유를 갖고 실행하도록 하였습니다. # Launch RViz rviz2 = Node( package=\u0026#34;rviz2\u0026#34;, executable=\u0026#34;rviz2\u0026#34;, name=\u0026#34;rviz2\u0026#34;, output=\u0026#34;screen\u0026#34;, arguments=[\u0026#34;-d\u0026#34;, rviz_config_file], ) return LaunchDescription([ TimerAction( period=3.0, actions=[rviz2] ), ROS 2의 launch file 작성법을 간단하게 설명하고 넘어가겠습니다. robot_state_publisher = Node( package=\u0026#39;robot_state_publisher\u0026#39;, executable=\u0026#39;robot_state_publisher\u0026#39;, output=\u0026#39;screen\u0026#39;, parameters=[robot_description] ) Node : Node 하나를 실행시킬 수 있는 옵션입니다. package : 실행시킬 Node가 포함된 package를 선택해줍니다. executable : c++ Node의 경우, colcon build를 하면 실행 가능한 프로그램이 생성됩니다. python의 경우도 스크립트를 실행 시키게 되며, 추후 코딩 실습을 거치면 완벽히 이해하실 수 있을 것입니다. parameters : 실행시킬 Node의 추가 매개변수가 있다면 이 부분에 추가됩니다. 이렇게 launch file 하나를 분석해 보았습니다. 하지만, 제가 보여드린 것은 하나의 예시일 뿐이며, launch file은 여러 형식으로 사용되고 있습니다.\n일례로, 자율 주행 시 사용되는 nav2 패키지의 lanuch file은 다음과 같은 형태를 갖습니다.\ndeclare_namespace_cmd = DeclareLaunchArgument( \u0026#39;namespace\u0026#39;, default_value=\u0026#39;\u0026#39;, description=\u0026#39;Top-level namespace\u0026#39;) ... # Create the launch description and populate ld = LaunchDescription() # Set environment variables ld.add_action(stdout_linebuf_envvar) # Declare the launch options ld.add_action(declare_namespace_cmd) ld.add_action(declare_use_namespace_cmd) ld.add_action(declare_slam_cmd) ld.add_action(declare_map_yaml_cmd) ld.add_action(declare_use_sim_time_cmd) ld.add_action(declare_params_file_cmd) ld.add_action(declare_autostart_cmd) ld.add_action(declare_bt_xml_cmd) # Add the actions to launch all of the navigation nodes ld.add_action(bringup_cmd_group) return ld 아직 프로그래밍을 시작하지도 않았기 때문에, launch file에 대해서 모두 이해하려 하지는 않으셔도 됩니다. 남은 강의들에서 계속해서 살펴보겠습니다.\n"
},
{
	"uri": "/kr/ros2_basic_foxy/lecture3/",
	"title": "Lecture3 - ROS 2 Node Programming, ROS 2 parameter",
	"tags": [],
	"description": "",
	"content": " Python을 사용하여 Node Programming을 실습해봅시다. 강의 마지막에는 간단히 C++ 코딩에 대해서도 다뤄보겠습니다.\nexample 1 - Hello ROS 2 강의를 위해 준비된 예제 코드 패키지를 실습하고 분석하겠습니다.\n$ colcon build --packages-select cbp py_node_tutorial $ source install/local_setup.bash $ ros2 run py_node_tutorial example_node_1 [INFO] [1672463872.778216198] [example_node_1]: ==== Hello ROS 2 ==== 모든 예제 코드는 아래 링크에서 확인할 수 있습니다. https://github.com/RB2023ROS/du2023-ros2/tree/main/py_node_tutorial/py_node_tutorial\n코드 분석을 차근차근 함께 해보겠습니다.\nrcl은 ROS Client Libraries의 약자로 ROS 2에서는 rclc, rclcpp, rclpy, rcljs와 같은 다양한 언어를 지원하고 있습니다. 파이썬에서 ROS 2 개발을 하기 위해서는 필수적으로 rclpy의 import가 필요하며 Node의 사용을 위해서는 Node class를 import 해야 합니다.\n# !/usr/bin/env python3 import rclpy from rclpy.node import Node rclpy 코딩 규칙 ROS 2에서 파이썬 파일을 조회하고 실행하는 과정이 있어 아래와 같이 main()부분을 항상 따로 분리하여 작성하도록 합니다.\nif __name__ == \u0026#39;__main__\u0026#39;: \u0026#34;\u0026#34;\u0026#34;main function\u0026#34;\u0026#34;\u0026#34; main() Node 생성 def main(args=None): \u0026#34;\u0026#34;\u0026#34;Do enter into this main function first.\u0026#34;\u0026#34;\u0026#34; rclpy.init(args=args) node = Node(\u0026#39;node_name\u0026#39;) node.get_logger().info(\u0026#39;\\n==== Hello ROS 2 ====\u0026#39;) node.destroy_node() rclpy.shutdown() 실제 동작을 수행하는 main 함수를 살펴보면 다음과 같은 과정을 거치고 있습니다.\nrclpy.init을 통해 initialization, 즉 초기화를 하고 있습니다. node = Node(\u0026rsquo;node_name\u0026rsquo;) : Node를 생성하는 부분으로 앞서 import한 Node class를 사용하고 있습니다. 매개변수로 node의 이름이 들어갑니다. node.destroy_node() : Node를 생성하고 원하는 작업을 모두 수행했다면, 이제 사용했던 Node를 제거해야 할 것입니다. 그래야 불필요한 자원의 낭비를 줄일 수 있겠지요. rclpy.shutdown() : 이번 예제의 제일 첫 부분에 rclpy.init을 통하여 초기화를 해주었습니다. 이제 rclpy를 통한 작업이 모두 끝났으므로 안전하게 종료시켜줍니다. 위 과정이 Python에서 rclpy를 통해 Node를 다루는 기본 절차입니다.\n1과 4, 2와 3이 짝꿍처럼 보이지요?\nsetup.py 수정 파이썬 파일을 ros2 run 으로 실행하기 위해서 패키지 내 setup.py 파일에 entry_points를 추가해 주어야 합니다.\nentry_points={ \u0026#39;console_scripts\u0026#39;: [ \u0026#39;example_node_1 = py_node_tutorial.node_example_1:main\u0026#39;, \u0026#39;example_node_2 = py_node_tutorial.node_example_2:main\u0026#39;, \u0026#39;example_node_3 = py_node_tutorial.node_example_3:main\u0026#39;, \u0026#39;example_node_4 = py_node_tutorial.node_example_4:main\u0026#39;, \u0026#39;example_node_5 = py_node_tutorial.node_example_5:main\u0026#39;, ], }, 작성하는 방법은 다음과 같습니다. ⇒ 실행 시 사용될 이름 = \u0026lt;패키지 이름\u0026gt;.\u0026lt;파일 이름\u0026gt;.main\nexample 2 - timer 로봇은 실행된 이후 계속해서 작업을 수행해야 하기에 주기적으로 무언가를 실행하는 일이 잦습니다. 이를 구현하는 Timer를 살펴봅시다. $ ros2 run py_node_tutorial example_node_2 ==== Hello ROS 2 : 1==== ==== Hello ROS 2 : 2==== ==== Hello ROS 2 : 3==== ==== Hello ROS 2 : 4==== ==== Hello ROS 2 : 5==== main문에 추가된 create_timer와 timer_callback 함수를 확인할 수 있습니다. def timer_callback(): \u0026#34;\u0026#34;\u0026#34;Timer will run this function periodically.\u0026#34;\u0026#34;\u0026#34; global count count += 1 print(f\u0026#39;==== Hello ROS 2 : {count}====\u0026#39;) def main(args=None): \u0026#34;\u0026#34;\u0026#34;Do enter into this main function first.\u0026#34;\u0026#34;\u0026#34; rclpy.init(args=args) node = Node(\u0026#39;node_name\u0026#39;) node.create_timer(0.2, timer_callback) rclpy.spin(node) node.destroy_node() rclpy.shutdown() timer를 생성하기 위해서 create_timer 함수가 사용됩니다.\ntimer_period_sec : 실행 주기 (초) callback : 해당 주기마다 실행될 함수 image from : docs.ros2.org\nexample 3 - spin_once, spin Node의 상태를 살피면서 반복 실행시키는 spin 함수에 대해 좀 더 자세하게 살펴봅니다.\n예제 실행 $ ros2 run py_node_tutorial example_node_3 ==== Hello ROS 2 : 1==== ==== Hello ROS 2 : 2==== ==== Hello ROS 2 : 3==== ... 주요 코드를 분석해 보겠습니다. Node는 상태를 지속 유지하면서 변경된 내용에 따라 지정된 동작을 수행해야 합니다. 이는 로봇 프로그램에서 매우 보편적인 작업으로, ROS 2에서는 **spin()**이라는 이름의 함수로 기능을 제공하고 있습니다.\ndef main(args=None): \u0026#34;\u0026#34;\u0026#34;Do enter into this main function first.\u0026#34;\u0026#34;\u0026#34; rclpy.init(args=args) node = Node(\u0026#39;node_name\u0026#39;) node.create_timer(0.2, timer_callback) while True: rclpy.spin_once(node, timeout_sec=10) node.destroy_node() rclpy.shutdown() spin을 비롯하여 spin_once, spin_until_future_complete와 같이 프로그램의 실행을 관리하기 위한 다양한 추가 함수들이 존재합니다.\ntimer_callback과 OOP의 필요성 def timer_callback(): \u0026#34;\u0026#34;\u0026#34;Timer will run this function periodically.\u0026#34;\u0026#34;\u0026#34; global count count += 1 print(f\u0026#39;==== Hello ROS 2 : {count}====\u0026#39;) # How can I use logger without globalization ? # node.get_logger().info(\u0026#39;\\n==== Hello ROS 2 ====\u0026#39;) callback 함수가 사용되면 필연적으로 두 함수 간 공유되는 count와 같은 자원이 생기며, 이 count를 다루면서 예기치 못한 실수가 발생할 수 있습니다.\n지금은 모두 전역 변수로 작업하고 있었는데, 이것을 어떻게 효율적으로 처리할 수 있을까요?\nexample 4 - OOP Node 예제 실행의 결과는 이전과 같습니다. 하지만 구현에서 차이를 갖습니다. $ ros2 run py_node_tutorial example_node_5 [INFO] [1657348011.971419700] [composition_example_node]: ==== Hello ROS 2 : 1==== [INFO] [1657348012.163466100] [composition_example_node]: ==== Hello ROS 2 : 2==== [INFO] [1657348012.363590700] [composition_example_node]: ==== Hello ROS 2 : 3==== class를 사용하여 Node를 구현한 모습을 확인할 수 있습니다. class NodeClass(Node): \u0026#34;\u0026#34;\u0026#34;Second Node Class. Just print log periodically. \u0026#34;\u0026#34;\u0026#34; def __init__(self): \u0026#34;\u0026#34;\u0026#34;Node Initialization. You must type name of the node in inheritanced initializer. \u0026#34;\u0026#34;\u0026#34; super().__init__(\u0026#39;composition_example_node\u0026#39;) self.create_timer(0.2, self.timer_callback) self._count = 1 def timer_callback(self): \u0026#34;\u0026#34;\u0026#34;Timer will run this function periodically.\u0026#34;\u0026#34;\u0026#34; self.get_logger().info(f\u0026#39;==== Hello ROS 2 : {self._count}====\u0026#39;) self._count += 1 ROS 1과 달리, ROS 2의 OOP 구현은 Node를 상속받습니다. (때문에 생성 시, Node이름을 super().__init__()안에 넣어주어야 합니다.)\n이렇게 객체지향을 사용하면 Node의 기능들을 적극 활용하여 더욱 쉽고 강력한 ROS 2 개발이 가능해집니다. 앞으로의 예시에서는 모두 객체 지향을 사용하겠습니다.\nrclpy logger super().__init__(\u0026#39;node_name\u0026#39;) ... node.get_logger().info(\u0026#39;\\n==== Hello ROS 2 ====\u0026#39;) rospy.loginfo()와 같이 rclpy에서도 get_logger라는 logging API를 제공합니다. 다만, rclpy의 logger는 Node에 종속되는 개념입니다. (ROS 2에서는 여러 Node가 하나의 프로세스 안에서 실행될 수 있기 때문입니다.)\nget_logger()를 사용하면 일반적인 print 콘솔 출력과는 달리, 실행중인 Node이름, 시간, 위험성 등을 디버깅할 수 있어 이후 복잡한 시스템에서 큰 도움이 됩니다.\nexample 5 - Logger Level 기본 node 프로그래밍의 마지막 예시입니다. $ ros2 run py_node_tutorial example_node_5 [INFO] [1657348108.163389800] [node_name]: ==== Hello ROS 2 : 1==== [WARN] [1657348108.163810900] [node_name]: ==== Hello ROS 2 : 1==== [ERROR] [1657348108.164126200] [node_name]: ==== Hello ROS 2 : 1==== [FATAL] [1657348108.164514300] [node_name]: ==== Hello ROS 2 : 1==== ... ROS 1에서와 유사하게 ROS 2에서도 위험도에 따라서 다른 logger level을 적용할 수 있습니다.\ninfo를 기준으로 아래로 갈수록 높은 레벨의 log이며, 제일 심각한 error와 fatal의 경우, 콘솔 출력시에도 빨간 글씨로 보이는 것을 확인할 수 있습니다.\nimage from : 51CTO debug의 경우 실제 콘솔 출력으로는 나타나지 않으며, 효과적인 Tracking을 위해 ROS 1 강의에서 배운 rqt console 사용을 권장합니다.\nROS 2 Parameter ROS 1에서와 마찬가지로, ROS 2에서도 각종 매개변수를 다룰 수 있는 커멘드 명령어와 코드 API를 제공합니다.\n예제 Package 빌드와 실행 $ colcon build --packages-select py_param_tutorial $ source install/local_setup.bash $ ros2 run py_param_tutorial param_example [INFO] [1672390971.030532687] [param_ex_node]: string_param: world int_param: 119 float_param: 3.1415 arr_param: [1, 2, 3] nested_param.string_param: Wee Woo param_ex_node에서 5종류의 매개변수가 선언되었습니다. 이들을 확인하는 커멘드 라인을 배워봅시다.\nros2 param list $ ros2 param list /param_ex_node: arr_param float_param int_param nested_param.string_param string_param use_sim_time ros2 param get/set - node 이름과 매개변수 이름을 모두 필요로 함에 주의합니다. $ ros2 param get /param_ex_node arr_param Integer values are: array(\u0026#39;q\u0026#39;, [1, 2, 3]) $ ros2 param set /param_ex_node arr_param \u0026#39;[1,2,3,4]\u0026#39; Set parameter successful $ ros2 param get /param_ex_node arr_param Integer values are: array(\u0026#39;q\u0026#39;, [1, 2, 3, 4]) 이제, 파이썬 코드를 분석해봅시다.\nparameter의 생성은 node 내에서 이루어지며, declare_parameter를 통해 생성합니다. 함수의 두번째 인자는 기본값입니다. nested_param과 같이, parameter는 계층 구조를 가질 수 있으며 . 을 통해 구분할 수 있습니다. string_param이라는 이름을 가진 parameter가 두 종류 존재하지만 서로 소속된 계층이 달라 공존할 수 있는 것입니다.\nclass ParamExNode(rclpy.node.Node): def __init__(self): super().__init__(\u0026#39;param_ex_node\u0026#39;) self.declare_parameter(\u0026#39;string_param\u0026#39;, \u0026#39;world\u0026#39;) self.declare_parameter(\u0026#39;int_param\u0026#39;, 119) self.declare_parameter(\u0026#39;float_param\u0026#39;, 3.1415) self.declare_parameter(\u0026#39;arr_param\u0026#39;, [1,2,3]) self.declare_parameter(\u0026#39;nested_param.string_param\u0026#39;, \u0026#39;Wee Woo\u0026#39;) 선언된 매개변수의 값은 get_parameter를 통해 확인 가능합니다. get_parameter 자체는 Object이고, value 속성이 실제 값을 갖고 있습니다. string_param = self.get_parameter(\u0026#39;string_param\u0026#39;) int_param = self.get_parameter(\u0026#39;int_param\u0026#39;) float_param = self.get_parameter(\u0026#39;float_param\u0026#39;) arr_param = self.get_parameter(\u0026#39;arr_param\u0026#39;) nested_param = self.get_parameter(\u0026#39;nested_param.string_param\u0026#39;) self.get_logger().info(f\u0026#34;\\nstring_param: {string_param.value} \\ \\nint_param: {int_param.value} \\ \\nfloat_param: {float_param.value} \\ \\narr_param: {arr_param.value} \\ \\nnested_param.string_param: {nested_param.value}\u0026#34; ) parameter는 launch file에서도 설정할 수 있습니다. - Hello, 112로 변경된 값을 확인해봅시다. $ ros2 launch py_param_tutorial launch_with_param.launch.py ... [param_example-1] [INFO] [1672387864.135213913] [param_example]: [param_example-1] string_param: Hello [param_example-1] int_param: 112 [param_example-1] float_param: 3.1415 [param_example-1] arr_param: [1, 2, 3] launch file의 parameters 옵션을 사용하여 이러한 작업이 가능합니다. def generate_launch_description(): param_ex_node = Node( package=\u0026#39;py_param_tutorial\u0026#39;, executable=\u0026#39;param_example\u0026#39;, name=\u0026#39;param_example\u0026#39;, output=\u0026#39;screen\u0026#39;, parameters=[ {\u0026#39;string_param\u0026#39;: \u0026#39;Hello\u0026#39;}, {\u0026#39;int_param\u0026#39;: 112}, ], ) parameter가 매우 많은 경우에는 ROS 1에서와 같이 yaml 파일을 사용해 관리할 수 있습니다. launch file의 주석된 부분을 해제하고 다시 실행해봅시다. config = os.path.join( get_package_share_directory(\u0026#39;py_param_tutorial\u0026#39;), \u0026#39;config\u0026#39;, \u0026#39;params.yaml\u0026#39; ) param_ex_node = Node( package = \u0026#39;py_param_tutorial\u0026#39;, executable = \u0026#39;param_example\u0026#39;, name = \u0026#39;param_example\u0026#39;, output=\u0026#39;screen\u0026#39;, parameters = [config] ) 모든 매개변수들이 변경된 것을 확인 가능합니다.\n$ ros2 launch py_param_tutorial launch_with_param.launch.py ... [param_example-1] [INFO] [1672391557.995024614] [param_example]: [param_example-1] string_param: Yaml Yaml [param_example-1] int_param: 5 [param_example-1] float_param: 3.14 [param_example-1] arr_param: [\u0026#39;I\u0026#39;, \u0026#39;love\u0026#39;, \u0026#39;ROS 2\u0026#39;] [param_example-1] nested_param.string_param: Ooh Wee yaml 파일은 config/params.yaml에 위치하고 있습니다. parameter 관리 용도로 사용하기 위해서 yaml 파일은 일정한 규칙을 갖춰야 합니다. param_example: ros__parameters: string_param: \u0026#34;Yaml Yaml\u0026#34; int_param: 5 float_param: 3.14 arr_param: [\u0026#39;I\u0026#39;, \u0026#39;love\u0026#39;, \u0026#39;ROS 2\u0026#39;] nested_param: string_param: \u0026#34;Ooh Wee\u0026#34; \u0026lt;node-name\u0026gt;: ros__parameters: \u0026lt;param-name\u0026gt;: \u0026lt;param-value\u0026gt; ... \u0026lt;nested-layer-name\u0026gt;: \u0026lt;param-name\u0026gt;: \u0026lt;param-value\u0026gt; 이렇게 새로운 폴더와 파일을 추가한 경우, python 패키지의 setup.py를 수정해주어야 하며 패키지 빌드도 새로 해주어야 합니다. import os from glob import glob from setuptools import setup package_name = \u0026#39;py_param_tutorial\u0026#39; setup( name=package_name, version=\u0026#39;0.0.0\u0026#39;, packages=[package_name], data_files=[ (\u0026#39;share/ament_index/resource_index/packages\u0026#39;, [\u0026#39;resource/\u0026#39; + package_name]), (\u0026#39;share/\u0026#39; + package_name, [\u0026#39;package.xml\u0026#39;]), (os.path.join(\u0026#39;share\u0026#39;, package_name, \u0026#39;config\u0026#39;), glob(\u0026#39;config/*.yaml\u0026#39;)), (os.path.join(\u0026#39;share\u0026#39;, package_name, \u0026#39;launch\u0026#39;), glob(\u0026#39;launch/*.launch.py\u0026#39;)), ], launch file에 추가된 내용을 다시 살펴보면, 방금 전의 yaml 파일을 불러와서 node의 실행 option에 전달하고 있습니다. config = os.path.join( get_package_share_directory(\u0026#39;py_param_tutorial\u0026#39;), \u0026#39;config\u0026#39;, \u0026#39;params.yaml\u0026#39; ) param_ex_node = Node( package = \u0026#39;py_param_tutorial\u0026#39;, executable = \u0026#39;param_example\u0026#39;, name = \u0026#39;param_example\u0026#39;, output=\u0026#39;screen\u0026#39;, parameters = [config] ) 아래 예시에서 보이듯이 로봇의 초기 속도, 최대/최소 값들, 하드웨어와 관련된 튜닝값 등 수많은 매개변수들이 사용되며 모두 지금 배운 parameter를 사용하게 됩니다.\nhttps://github.com/ros-planning/navigation2/blob/main/nav2_bt_navigator/src/bt_navigator.cpp\n"
},
{
	"uri": "/kr/ros2_basic_foxy/lecture4/",
	"title": "Lecture4 - ROS 2 Node C++ Programming",
	"tags": [],
	"description": "",
	"content": " 실제 로봇 개발에서 Python만 사용되지는 않습니다. tensorflow, pytorch와 같은 딥러닝 프레임워크들이 모두 Python을 사용하고 있고, 상대적으로 개발 과정이 쉬워 많은 사람들이 Python을 사용하고 있지만, 제어, 센싱을 위해서는 C++를 대부분 사용한다고 보시면 됩니다.\nimage from : wikipedia 따라서 앞선 node 프로그래밍 예시들을 모두 C++로 구현해 볼 예정입니다. 아래와 같은 C++ 지식이 필요하지만 필수는 아닙니다.\n클래스 생성 (OOP) 스마트 포인터 헤더 분리 람다 함수 std::bind와 placeholders C++ 빌드 시스템 (CMake) 코드 설명에 앞서 ROS 2 C++ 패키지를 개발하는 절차에 대해 빠르게 훑어보겠습니다.\n패키지 생성 후 src \u0026amp; include 폴더에서 코드 작성 ros2 pkg create --build-type ament_cmake \u0026lt;package_name\u0026gt; CMakeLists.txt \u0026amp; package.xml 수정 add_executable(example_node_1 src/node_example_1.cpp) ament_target_dependencies(example_node_1 rclcpp) install( TARGETS example_node_1 DESTINATION lib/${PROJECT_NAME} ) 코드 빌드와 디버깅 colcon build --packages-select \u0026lt;package_name\u0026gt; source install/local_setup.bash 코드 실행 ros2 run \u0026lt;pkg-name\u0026gt; \u0026lt;executable-name\u0026gt; 개발 과정 자체는 파이썬 package와 크게 다르지 않습니다.\n하지만, C++ 개발은 코드를 빌드하는 과정에서 각종 컴파일 에러와 링크 에러, 런타임 에러까지 발생하기 때문에 개발에 여러움이 생길 수 있습니다.\n⇒ 이를 해결하기 위해서, 학생 라이센스로 무료 사용 가능한 IDE를 소개하고, 함께 셋업해보고자 합니다.\nCLion 설치와 ROS 2 개발환경 설정 CLion은 IDE의 명가 Jetbrains에서 만든 C/C++용 통합 개발 환경입니다. C++ 개발자를 힘들게 하는 각종 에러들의 디버깅을 편리하게 해줄 뿐더러 ROS 2 개발을 위한 솔루션도 제공하고 있습니다.\nimage from : wikipedia CLion은 오픈소스가 아닌 판매되고 있는 소프트웨어입니다.\n하지만 학생에게는 무료 라이센스를 제공하고 있습니다. 아래 링크를 통해서 회원가입과 학생인증을 진행한 다음, CLion을 설치합시다.\nhttps://www.jetbrains.com/clion/\nhttps://www.jetbrains.com/community/education/#students\n이메일 인증을 거치면 어렵지 않게 학생인증이 완료됩니다. 이 과정은 생략하겠습니다.\n학생 라이센스를 통해 CLion을 비롯하여 IntelliJ, PyCharm, WebStorm과 같은 다양한 언어의 IDE를 무료로 사용 가능합니다. snapcraft를 통해 CLion을 설치하고 실행 해봅시다. $ sudo snap install clion --classic [sudo] password for kimsooyoung: clion 2022.3.1 from jetbrains✓ installed $ clion 약관 동의 및 로그인을 통한 학생 인증을 거치면 모든 설치 절차가 완료됩니다. colcon build를 통해 빌드했던 cpp_node_tutorial package를 clion 프로젝트로 열어보겠습니다. clion에서 File ⇒ Open을 실행한 뒤 cpp_node_tutorial의 CMakeLists.txt를 선택합니다. build target를 지정하고 실행하면 CLion상에서 ROS 2 프로그램을 실행시킬 수 있습니다. CLion에서의 장점을 직접 살펴보기 위해 프로그램 개발을 함께 해보겠습니다. 라이브 코딩 Time!!\n모든 설정이 완료되었다면, 이제 본격적으로 C++ 예제 코드를 살펴봅시다.\nexample 1 - Hello ROS 2 파이썬에서 한차례 살펴본 바 있기에 자세한 로직들은 생략합니다.\n예제 실행 $ ros2 run cpp_node_tutorial example_node_1 [INFO] [1666431282.586519100] [example_node_1]: ==== Hello ROS 2 ==== 코드 분석 #include \u0026lt;rclcpp/rclcpp.hpp\u0026gt; int main(int argc, char **argv) { rclcpp::init(argc, argv); auto node = rclcpp::Node::make_shared(\u0026#34;example_node_1\u0026#34;); RCLCPP_INFO(node-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 ====\u0026#34;); rclcpp::shutdown(); return 0; } rclcpp은 ROS 2를 C++에서 사용하기 위해 필요한 코드의 집합입니다.\nNode 생성 시 주의하셔야 할 점은 “모든 Node가 포인터의 형식을 갖는다”는 것입니다. shared_ptr를 사용하여 메모리 누수를 막기 위해 파생된 모든 데이터들을 추적하고 있습니다.\nrclcpp에서 로그의 실행은 RCLCPP_INFO와 get_logger() 메소드를 통해 실행할 수 있으며, 로그는 Node에서 실행된다는 점을 기억합시다.\nCMakeLists.txt 수정\n# find_package를 통해 종속성들을 추가합니다. find_package(\u0026lt;depends\u0026gt; REQUIRED) # 실행 프로그램 빌드 설정 add_executable(\u0026lt;program_name\u0026gt; include/\u0026lt;header\u0026gt;.hpp src/\u0026lt;code\u0026gt;.cpp ...) ament_target_dependencies(\u0026lt;program_name\u0026gt; \u0026lt;dependency1\u0026gt; \u0026lt;dependency2\u0026gt; ...) install( TARGETS \u0026lt;program_name\u0026gt; DESTINATION lib/${PROJECT_NAME} ) 패키지 빌드 \u0026amp; 실행 colcon build --packages-select cpp_node_tutorial source install/local_setup.bash ros2 run cpp_node_tutorial example_node_1 예제 소스 코드를 조금이라도 수정하여 여러분들만의 코드를 작성해보고 CLion을 통한 빌드까지 스스로 한 번 해봅시다.\nexample 2 - Timer 예제 실행 $ ros2 run cpp_node_tutorial example_node_2 ==== Hello ROS 2 : 0 ==== ==== Hello ROS 2 : 1 ==== ==== Hello ROS 2 : 2 ==== ==== Hello ROS 2 : 3 ==== ==== Hello ROS 2 : 4 ==== ... rclcpp에서 timer는 create_wall_timer를 사용합니다. #include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; #include \u0026#34;rclcpp/rclcpp.hpp\u0026#34; static int count = 0; void timer_callback(){ std::cout \u0026lt;\u0026lt; \u0026#34;==== Hello ROS 2 : \u0026#34; \u0026lt;\u0026lt; count \u0026lt;\u0026lt; \u0026#34; ====\u0026#34; \u0026lt;\u0026lt; std::endl; count++; } int main(int argc, char **argv) { rclcpp::init(argc, argv); auto node = rclcpp::Node::make_shared(\u0026#34;example_node_2\u0026#34;); auto timer = node-\u0026gt;create_wall_timer(std::chrono::milliseconds(200), timer_callback); rclcpp::spin(node); rclcpp::shutdown(); return 0; } example 3 - OOP Node 기능 자체는 큰 의미가 없으므로 코드를 위주로 설명하겠습니다. #include \u0026lt;memory\u0026gt; #include \u0026#34;rclcpp/rclcpp.hpp\u0026#34; class NodeClass: public rclcpp::Node { public: NodeClass(): Node(\u0026#34;example_node_4\u0026#34;) {} }; int main(int argc, char **argv) { rclcpp::init(argc, argv); auto node = std::make_shared\u0026lt;NodeClass\u0026gt;(); RCLCPP_INFO(node-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 ====\u0026#34;); rclcpp::shutdown(); return 0; } 모든 Node는 rclcpp::Node로부터 상속을 받습니다. 상속 후 생성자에서 Node의 이름을 지정해줘야 하며, topic pub/sub, logger와 같은 기능들은 모두 rclcpp::Node에 구현되어 있습니다.\n더불어, Node 자체는 포인터로 취급된다는 점도 다시 한 번 강조드립니다.\nexample 4 - OOP Timer Node callback 함수를 binding하는 부분에 집중하세요. timer_callback는 클래스 메소드이기 때문에 binding 시 NodeClass::timer_callback와 같이 명시해주어야 합니다. #include \u0026lt;memory\u0026gt; #include \u0026#34;rclcpp/rclcpp.hpp\u0026#34; class NodeClass: public rclcpp::Node { private: size_t count; rclcpp::TimerBase::SharedPtr timer; void timer_callback() { RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 : %d\u0026#34;, count); count++; } public: NodeClass() : Node(\u0026#34;example_node_5\u0026#34;) { timer = this-\u0026gt;create_wall_timer( std::chrono::milliseconds(200), std::bind(\u0026amp;NodeClass::timer_callback, this) ); } }; int main(int argc, char **argv) { rclcpp::init(argc, argv); auto node = std::make_shared\u0026lt;NodeClass\u0026gt;(); rclcpp::spin(node); rclcpp::shutdown(); return 0; } 마지막으로 rclcpp logger level을 간단히 살펴보고 마무리짓겠습니다. void timer_callback() { RCLCPP_DEBUG(this-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 : %d ====\u0026#34;, count); RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 : %d ====\u0026#34;, count); RCLCPP_WARN(this-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 : %d ====\u0026#34;, count); RCLCPP_ERROR(this-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 : %d ====\u0026#34;, count); RCLCPP_FATAL(this-\u0026gt;get_logger(), \u0026#34;==== Hello ROS 2 : %d ====\u0026#34;, count); count++; } 참고자료\nhttps://roboticsbackend.com/ros2-yaml-params/ https://roboticsbackend.com/rclpy-params-tutorial-get-set-ros2-params-with-python/ https://www.jetbrains.com/help/clion/ros2-tutorial.html#change-prj-root "
},
{
	"uri": "/kr/ros2_basic_foxy/lecture5/",
	"title": "Lecture5 - ROS 2 Topic and Examples",
	"tags": [],
	"description": "",
	"content": " Topic에 대해 배워보기 전에, 실습 시스템을 구축해봅시다.\nSRC Gazebo 이번 ROS 2 강의의 실습들은 Road Balance의 차량형 로봇 SRC를 통해 진행하고자 합니다. 실습을 진행하기 전 Gazebo 환경을 함께 세팅해보겠습니다.\nsrc_gazebo 실행 세팅 - 다소 번거로운 작업이므로 gif를 보시면서 차근차근 잘 따라와주세요! cd ~/ros2_ws/src/du2023-ros2 ./setup_scripts.sh # CMakeLists.txt 수정 (주석) colcon build --packages-select src_gazebo source install/local_setup.bash # CMakeLists.txt 수정 (주석 해제) colcon build --packages-select src_gazebo colcon build --packages-select src_odometry colcon build --packages-select src_controller source install/local_setup.bash empty world 실행 ros2 launch src_gazebo empty_world.launch.py 빈 gazebo 환경에 차량형 로봇이 등장할 것입니다. 함께 등장하는 rqt_robot_steering을 통해 로봇을 움직여보세요. 실행 중 발생할 수 있는 오류와 해결방법을 제시드립니다. 아래와 같은 에러 발생 시 sudo apt dist-upgrade를 입력하면 됩니다. 로봇에 부착되어 있는 센서 데이터들과 제어 데이터를 ros2 topic list로 확인해봅시다.\n/cmd_vel : Twist msg를 통해 로봇을 제어하는 topic /imu/data : imu 데이터 /scan : 2D lidar /logi_camera_sensor/image_raw : 전방 카메라 데이터 ROS 2 Topic 강의를 열심히 따라오면서 ROS 개념을 잊어버렸을 수도 있으므로 간단히 개념 복습을 해보겠습니다.\nTopic은 Node들 사이에 데이터(Message)가 오가는 길(Bus)의 이름이며, 적절한 이름으로 데이터를 송수신하지 않으면 원하는 동작을 수행할 수 없습니다. image from : docs.ros.org\nTopic의 중요한 특징으로 Topic은 여러 Node들로부터 데이터를 받을 수 있고, 전송 시에도 여러 Node들에게 전송이 가능한 방식입니다. image from : docs.ros.org topic을 통해 데이터가 전달되는 과정은 다음과 같습니다.\n데이터를 보내는 주체인 publisher는 topic을 통해 원하는 정보를 subscriber에게 전달합니다. 이것을 topic publish라고 부르지요. 반대로, 데이터를 받는 주체인 subscriber 입장에선 topic을 통해 데이터를 받게 되며 이것은 topic subscribe라고 불립니다. ROS 2 Topic msg 로봇 프로그래밍 시 센서, 제어 데이터를 비롯하여 다양한 유형의 데이터들이 Topic을 통해 오고 갑니다. ROS에서는 이러한 데이터 형식을 msg - Message라는 형태로 제공하며, 원하는 데이터에 적합한 topic msg를 사용하면 더욱 효율적인 로봇 프로그래밍이 가능해집니다.\nimage from : ethz.ch geometry_msgs/Twist와 같은 message는 ROS 2에서도 동일하게 사용할 수 있습니다. 다만, ROS 2에서는 msg/srv/action 과 같이 필드의 구분이 하나 더 추가됩니다.\nROS 1 : geometry_msgs/Twist ROS 2 : geometry_msgs/msg/Twist 출처 : http://docs.ros.org/ 특정 message가 어떻게 구성되어 있는지 알고 싶을 때는 다음과 같은 커멘드 라인을 사용합니다.\n$ ros2 interface show geometry_msgs/msg/Twist # This expresses velocity in free space broken into its linear and angular parts. Vector3 linear Vector3 angular 혹은 앞서 제가 살펴본 것 처럼 검색을 해 보아도 됩니다.\nROS 2로 넘어오면서, topic 커멘드들은 다음과 같이 살짝 바뀌었습니다.\nrostopic list ⇒ ros2 topic list rostopic info ⇒ ros2 topic info rostopic echo ⇒ ros2 topic echo ROS 2 Topic Tools ROS 2에서도 GUI툴 RQT를 사용할 수 있습니다. Topic과 관련된 rqt tools들을 사용해봅시다.\nROS 1과 ROS 2의 rqt는 다른 프로그램이며 ROS 1의 plugin과 ROS 2의 plugin이 완전 동일하지는 않습니다.\n실습을 위해 gazebo와 rqt를 실행합니다. # Terminal 1 ros2 launch src_gazebo empty_world.launch.py # Terminal 2 rqt rqt 상단의 메뉴바에서 Plugins ⇒ Topics ⇒ Topic Monitor를 클릭합니다. topic monitor를 통해 현재 오가고 있는 topic들을 한눈에 볼 수 있습니다. 이번에는 rqt 상단의 메뉴바에서 Plugins ⇒ Topics ⇒ Message Publisher를 클릭하고, + 버튼을 눌러 publish를 원하는 topic을 추가합니다.\nTopic Publisher는 별도의 작업 없이 msg에 원하는 값을 채워 topic publish가 가능하게 해주는 툴입니다. 최종 publish를 위해 체크박스를 클릭하고, 원하는 값을 채워넣습니다. ROS Bridge 강의노트를 작성하고 있는 2023년 지금도 ROS 1으로 개발된 시스템에 종속성을 가진 기업들과 프로젝트들이 많습니다. ROS 1과 ROS 2를 같이 사용할 수는 없을까요? ros1 bridge를 실습해봅시다.\n일전, ROS 1에서 사용하던 smb gazebo를 오랜만에 실행시켜봅시다. roslaunch smb_gazebo smb_gazebo.launch ros1 bridge를 통해 ROS 2 시스템에서 로봇을 제어해보겠습니다. 새로운 터미널을 열고, 초기 옵션 선택 시 3번을 선택하면 ros1 bridge가 실행됩니다. (이 동작은 사실 dynamic_bridge를 실행시키는 것입니다.) sudo apt install ros-foxy-ros1-bridge -y # Terminal 1 - ros bridge ros2 run ros1_bridge dynamic_bridge # Terminal 2 - ros2 foxy ros2 run teleop_twist_keyboard teleop_twist_keyboard ROS 2로 설정된 터미널에서 ROS 1으로 구동되고 있는 로봇을 조종할 수 있습니다. ros bridge가 있으니 ROS 2 개발을 굳이 하지 않아도 된다고 생각할 수 있습니다. 하지만 보안, 지연과 같은 ROS 1의 고질적인 문제들은 여전히 남아있게 되므로 프로젝트를 시작하는 단계라면, ROS 2로 모든 개발을 진행하시길 추천드립니다. image from : swri.org 참고로, /opt/ros/\u0026lt;ros-version\u0026gt;/setup.bash는 ROS 시스템을 사용하기 위해서 필요한 설정이 담긴 파일입니다. 혹여나 galactic, humble과 같이 최신 버전을 사용하고 싶을 때 참고하시기 바랍니다.\nROS 1과 ROS 2를 모두 관리하기에는 많은 노력이 필요하고, 원하는 기능이 모두 동작하지 않을 수 있습니다. 이전 버전 legacy가 있는 경우, 잘 판단하여 시스템을 유지/보수합시다.\nMy Gazebo World Topic의 응용으로 Gazebo를 사용하여 나만의 장애물을 만들고, 충돌을 회피하는 코드를 작성해보고자 합니다. 이를 위해 Gazebo의 Building Editor 사용법을 알려드리겠습니다.\ngazebo를 실행시킨 뒤, 상단 Edit 옵션에서 Building Editor를 실행합니다. 상단 모눈종이에 스케치를 통해 건물 벽을 생성할 수 있으며, 하단 view를 통해 실시간으로 업데이트되는 건물을 확인할 수 있습니다. 혹여 실수를 했거나, 보다 정확한 수치를 입력하고 싶은 경우, 모눈종이 위의 검은 선을 더블 클릭하면 사진과 같이 구체적인 설정을 변경할 수 있는 탭이 등장합니다. 수정이 완료되었다면, 왼쪽 탭에서 door, stairs도 사용해보고, Texture도 입혀봅시다. 모든 작업을 마친 뒤, File 탭에서 Save As를 선택하여 완성한 물체를 저장합니다. (저는 wall 이라는 이름으로 저장해보겠습니다.) 저장된 폴더 내부는 다음과 같은 구조를 갖게 됩니다. ├─ wall ├── model.config └── model.sdf model.config : 해당 model의 이름, 작성자 등 기본적인 정보들이 기입됩니다. model.sdf : 실직적인 sdf 형식의 모델이 위치합니다. 작성한 물체를 Gazebo에서 두고두고 사용하는 몇가지 방법들이 있습니다.\nGAZEBO_MODEL_PATH에 추가하기 ⇒ ~/.gazebo/gui.ini 파일 내 model_paths에 building 폴더에 절대 경로를 추가합니다. $ gedit ~/.gazebo/gui.ini [geometry] x=0 y=0 [model_paths] filenames=/home/kimsooyoung/\u0026lt;your-folder-location\u0026gt; launch file에서 GAZEBO_MODEL_PATH 수정하기 ⇒ 대신 이렇게 하면 해당 launch file 사용 시에만 GAZEBO_MODEL_PATH가 반영됩니다. if \u0026#39;GAZEBO_MODEL_PATH\u0026#39; in os.environ: os.environ[\u0026#39;GAZEBO_MODEL_PATH\u0026#39;] += \u0026#34;:\u0026#34; + gazebo_model_path else: os.environ[\u0026#39;GAZEBO_MODEL_PATH\u0026#39;] = gazebo_model_path 이제 Gazebo를 실행시키면, 사진과 같이 Insert 부분에 building이 추가되어있음을 확인 가능합니다. 이를 클릭 후 gazebo 환경으로 커서를 옮기면 원하는 위치에 wall을 위치시킬 수 있습니다. wall이 추가된 world는 별도로 저장해줘야 합니다. File ⇒ Save World As를 클릭하면 완성된 world 파일을 저장합시다. 생성한 world 파일을 launch 파일로 실행해봅시다.\n저장해두었던 Gazebo world 파일을 src_gazebo의 worlds 폴더에 위치시킵니다. launch 파일을 수정하여 새로운 world 파일의 위치를 전달합니다.\ndef generate_launch_description(): ... # gazebo pkg_gazebo_ros = FindPackageShare(package=\u0026#39;gazebo_ros\u0026#39;).find(\u0026#39;gazebo_ros\u0026#39;) pkg_path = os.path.join(get_package_share_directory(\u0026#39;src_gazebo\u0026#39;)) world_path = os.path.join(pkg_path, \u0026#39;worlds\u0026#39;, \u0026#39;여러분의-world-file.world\u0026#39;) ... # Start Gazebo server start_gazebo_server_cmd = IncludeLaunchDescription( PythonLaunchDescriptionSource(os.path.join(pkg_gazebo_ros, \u0026#39;launch\u0026#39;, \u0026#39;gzserver.launch.py\u0026#39;)), launch_arguments={\u0026#39;world\u0026#39;: world_path}.items() ) package를 빌드하고, gazebo를 다시 실행해봅시다. colcon build --packages-select src_gazebo source install/local_setup.bash ros2 launch src_gazebo empty_world.launch.py 제작한 world와 로봇이 함께 등장하는 것을 확인할 수 있습니다. 최대한 여러분들만의 장애물을 만들어보시고, 혹시나 이 과정에서 도저히 모르겠는 오류가 발생했거나, 시간이 없는 경우, 우선 제가 제작한 world와 launch file을 사용하도록 합니다. ⇒ ros2 launch src_gazebo wall_world.launch.py\nROS 2 Topic 프로그래밍 example1 - cmd_vel publish 준비된 예시를 우선 실행해봅시다. # Terminal 1 ros2 launch src_gazebo empty_world.launch.py # Terminal 2 cd ~/ros2_ws colcon build --packages-select py_topic_tutorial source install/local_setup.bash ros2 run py_topic_tutorial topic_pub_node 로봇이 원을 그리며 움직이기 시작합니다. ROS 1 강의를 완료하였다면 어떻게 구현하였을지 아시겠지요? 코드를 살펴보겠습니다 - 시작으로, 필요한 파이썬 패키지들을 import 합니다. ROS 2에서 파이썬 프로그래밍을 하기 위해서는 rclpy를 import 해야 합니다. 더불어, Twist를 import하는 문법도 눈여겨봅시다. import random from geometry_msgs.msg import Twist import rclpy from rclpy.node import Node 핵심이 되는 TwistPubNode 클래스의 생성자부터 살펴보겠습니다. class TwistPubNode(Node): def __init__(self): super().__init__(\u0026#39;twist_pub_node\u0026#39;) self.get_logger().info( f\u0026#39;TwistPubNode Created at {self.get_clock().now().to_msg().sec}\u0026#39; ) # self.twist_publisher = self.create_publisher(Twist, \u0026#34;twist_topic\u0026#34;, 10) self.twist_publisher = self.create_publisher(Twist, \u0026#39;/cmd_vel\u0026#39;, 10) create_publisher는 topic publisher를 생성하는 함수로 3개의 매개변수를 받으며 각각에 대한 설명은 다음과 같습니다.\nmessage type : Topic 통신에 사용될 msg Type 입니다. topic name : 사용할 Topic 이름을 지정합니다. (이 이름을 잘못 설정하면 존재하지 않는 topic에 Publish하는 오류 상황이 발생하니 주의합니다.) queue_size : 대기열의 크기라고 이해하시면 좋습니다. timer callback에서 publish가 이루어집니다. 생성한 publisher에서 publish 함수를 사용하며 매개변수로 message가 전달됩니다. ... self.create_timer(0.2, self.timer_callback) def timer_callback(self): \u0026#34;\u0026#34;\u0026#34;Timer will run this function periodically.\u0026#34;\u0026#34;\u0026#34; msg = Twist() # Fill in msg with compatible values msg.linear.x = 0.5 msg.angular.z = 1.0 self.twist_publisher.publish(msg) example2 - scan subscription 이번 예시는 라이다 데이터를 다뤄보고자 합니다. 명령어를 실행해봅시다. # Terminal 1 $ ros2 launch src_gazebo empty_world.launch.py # Terminal 2 $ ros2 run py_topic_tutorial topic_sub_node [INFO] [1672494602.141200628] [scan_sub_node]: msg.ranges[0] : inf msg.ranges[30] : inf msg.ranges[60] : 0.7975894212722778 msg.ranges[90] : inf msg.ranges[119] : inf ... 예시를 실행시킨 상황에서 Gazebo 상의 로봇 주변으로 물체를 등장시켜봅시다.\nscan data의 ranges는 사진과 같은 거리 데이터를 담고 있답니다.\n코드를 살펴봅시다. 이번에는 sensor_msgs/msg/LaserScan이 사용되었습니다. import rclpy from rclpy.node import Node from sensor_msgs.msg import LaserScan ScanSubNode 클래스의 생성자에서는 scan topic의 subscriber가 생성됩니다. class ScanSubNode(Node): def __init__(self): super().__init__(\u0026#39;scan_sub_node\u0026#39;) queue_size = 10 # Queue Size self.pose_subscriber = self.create_subscription( LaserScan, \u0026#39;scan\u0026#39;, self.sub_callback, queue_size ) create_subscription은 4개의 매개변수를 받으며 각각에 대한 설명은 다음과 같습니다.\nMessage Type : Topic 통신에 사용될 msg Type 입니다. topic name : 데이터를 Subscribe할 Topic의 이름을 지정합니다. (이 이름을 잘못 설정하면 아무것도 publish하고 있지 않는 topic을 마냥 기다리고 있게 되는 상황이 발생할 것입니다.) subscribe callback : 데이터가 전달될 때마다 실행되는 callback 함수로, 전달된 데이터를 통해 실행할 작업이 이 함수 안에 구현됩니다. queue_size : create_publisher때와 마찬가지로, 대기열의 크기라고 이해하시면 좋습니다. sub_callback의 첫번쨰 매개변수는 항상 topic message data가 됩니다. 해당 message에서 원하는 데이터만 추출한 다음, logger를 통해 콘솔 출력을 진행합니다.\ndef sub_callback(self, msg): \u0026#34;\u0026#34;\u0026#34;Timer will run this function periodically.\u0026#34;\u0026#34;\u0026#34; self.get_logger().info(f\u0026#39; \\ \\nmsg.ranges[0] : {msg.ranges[0]} \\ \\nmsg.ranges[30] : {msg.ranges[30]} \\ \\nmsg.ranges[60] : {msg.ranges[60]} \\ \\nmsg.ranges[90] : {msg.ranges[90]} \\ \\nmsg.ranges[119] : {msg.ranges[119]} \\ \u0026#39;) example3 - parking 이번 예시를 실행하기 전에, empty_world.launch.py를 수정해야 합니다. # gazebo pkg_gazebo_ros = FindPackageShare(package=\u0026#39;gazebo_ros\u0026#39;).find(\u0026#39;gazebo_ros\u0026#39;) pkg_path = os.path.join(get_package_share_directory(\u0026#39;src_gazebo\u0026#39;)) # world_path = os.path.join(pkg_path, \u0026#39;worlds\u0026#39;, \u0026#39;empty_world.world\u0026#39;) world_path = os.path.join(pkg_path, \u0026#39;worlds\u0026#39;, \u0026#39;wall_world.world\u0026#39;) 물체와 충돌하기 전까지 로봇을 움직이다가 일정 거리 내 벽이 검출되면 자동으로 멈추는 예시입니다. # Terminal 1 $ ros2 launch src_gazebo empty_world.launch.py # Terminal 2 $ ros2 run py_topic_tutorial parking_node ... [INFO] [1672563255.067421128] [parking_node]: Distance from Front Object : 0.6280616521835327 [INFO] [1672563255.173734128] [parking_node]: Distance from Front Object : 0.5546504259109497 [INFO] [1672563255.281276729] [parking_node]: Distance from Front Object : 0.5124648809432983 [INFO] [1672563255.389067729] [parking_node]: ==== Parking Done!!! ==== ... 이 기능을 구현하기 위해서는 Topic Publish와 Subscribe가 모두 필요합니다.\n/cmd_vel topic publish /scan topic subscribe ⇒ 따라서, Node의 생성자에서도 Publisher와 Subscriber를 모두 생성합니다.\nclass ParkingNode(Node): def __init__(self): super().__init__(\u0026#39;parking_node\u0026#39;) queue_size = 10 # Queue Size self.twist_publisher = self.create_publisher(Twist, \u0026#39;cmd_vel\u0026#39;, queue_size) self.scan_subscriber = self.create_subscription( LaserScan, \u0026#39;scan\u0026#39;, self.sub_callback, queue_size ) sub_callback에서는 전방 (msg.ranges[60]) 물체와의 거리를 탐지하고, 이 거리가 0.5m 이하가 되면 정지 topic을 publish 합니다. def sub_callback(self, msg): twist_msg = Twist() distance_forward = msg.ranges[60] if distance_forward \u0026gt; 0.5: self.get_logger().info(f\u0026#39;Distance from Front Object : {distance_forward}\u0026#39;) twist_msg.linear.x = 0.5 self.twist_publisher.publish(twist_msg) else: self.get_logger().info(\u0026#39;==== Parking Done!!! ====\\n\u0026#39;) twist_msg.linear.x = 0.0 self.twist_publisher.publish(twist_msg) CV 2 and ROS 2 Topic과 ROS 2 Bag을 사용한 예시를 실행해보고자 합니다.\n이번 실습을 위해 제가 미리 준비한 데이터셋을 제공드리니, 기억하기 쉬운 위치에 다운받아 주세요.\n📁 quadrupped_train.zip\nWindows + WSL2 유저의 경우 explorer.exe 명령어를 통해 파일 탐색기를 열 수 있습니다.\n준비된 예시를 실행해봅시다. # 예제 실행 준비 sudo apt install ros-foxy-rosbag2 cd ~/ros2_ws colcon build --packages-select py_cv_tutorial source install/local_setup.bash # 터미널 1 – 데이터 위치로 이동하여 ros2 bag 실행 cd \u0026lt;데이터를 저장한 위치\u0026gt; ros2 bag play quadrupped_train.bag_0.db3 # 터미널 2 – image_view 실행 ros2 run rqt_image_view rqt_image_view 사진과 같이 기차 선로 모습이 보인다면 성공입니다. 해당 데이터셋은 기차 선로에서 주행하는 4족 보행 로봇으로부터 취득한 것입니다. 기차 선로는 주기적으로 관리가 필요하며, 길고 긴 선로를 로봇이 자동으로 검사해준다면 아주 유용할 것입니다. 이러한 상상을 해보면서 실습에 임해봅시다.\nExample1 - CV Bridge 이미지를 다루기 위한 오픈소스 라이브러리인 OpenCV를 사용해보려 합니다. 준비된 예시와, ros2 bag 파일을 실행하면 cv2.imshow를 통해 연속된 이미지를 확인할 수 있습니다.\n# 터미널 1 $ cd \u0026lt;bag 파일 위치\u0026gt; $ ros2 bag play quadruped_train.bag_0.db3 [INFO] [1667077909.362223100] [rosbag2_storage]: Opened database \u0026#39;quadrupped_train/quadrupped_train.bag_0.db3\u0026#39; for READ_ONLY. # 터미널 2 $ ros2 run py_cv_tutorial img_sub [INFO] [1667077909.613586300] [image_subscriber]: Receiving video frame [INFO] [1667077910.934147000] [image_subscriber]: Receiving video frame ... OpenCV에서는 CV::Mat 이라는 특정 타입을 사용합니다. 이를 ROS 2의 Topic Message로 변환하기 위해서 CV Bridge라는 것을 사용합니다. from cv_bridge import CvBridge # Package to convert between ROS and OpenCV Images import cv2 # OpenCV library class ImageSubscriber(Node): def __init__(self): # Used to convert between ROS and OpenCV images self.br = CvBridge() ... def listener_callback(self, data): ... # Convert ROS Image message to OpenCV image current_frame = self.br.imgmsg_to_cv2(data, \u0026#34;bgr8\u0026#34;) edge_frame = self.hough_transform(current_frame) imgmsg_to_cv2를 통해 CV::Mat으로 변환된 이미지 데이터를 OpenCV의 다양한 기능들과 함께 사용할 수 있습니다. 코드의 imshow 부분을 바꿔서 이미지 처리를 적용해 봅시다. 직선을 검출하는 알고리즘이며, 매개변수의 최적화를 통해 선로를 인지할 수 있습니다. 직선 검출을 위해 사용된 OpenCV 기능들은 아래와 같습니다. 로직을 업그레이드하여 여러분만의 선로 검출 알고리즘을 만들어 보세요!\ncv2.GaussianBlur cv2.fillPoly / cv2.bitwise_and ROI 설정 cv2.HoughLinesP rosbag to img 컴퓨터 비전만으로 완벽한 선로 인식을 구현하기는 너무나 힘듭니다. 딥러닝을 사용해서 이를 극복할 수 있을 것이며, 데이터셋의 제작을 위해 rosbag 데이터에서 이미지를 추출하는 예시를 준비하였습니다.\n$ ros2 run py_cv_tutorial rosbag2_to_timedimg /home/kimsooyoung/djhrd_ws/quadrupped_train/quadrupped_train.bag_0.db3 saved: color_1666796292992515592.png saved: color_1666796293035428479.png saved: color_1666796293079139778.png saved: color_1666796293120768031.png 예제 실행 전 main 함수에서 bag 파일의 위치를 여러분의 것으로 수정해야 합니다. def main(args=None): # Change below roots to your ros2 bag locations ROOT_DIR = \u0026#34;/home/kimsooyoung/djhrd_ws/quadrupped_train\u0026#34; FILENAME = \u0026#34;/quadrupped_train.bag_0.db3\u0026#34; DESCRIPTION = \u0026#34;color_\u0026#34; 예제 실행 후 사진과 같이 기차 생성된 이미지들이 보인다면 성공입니다. "
},
{
	"uri": "/kr/ros2_basic_foxy/lecture6/",
	"title": "Lecture6 - ROS 2 Service and Examples",
	"tags": [],
	"description": "",
	"content": "ROS 2 Service ROS Service의 개념을 다시 복습해봅시다.\nimage from : docs.ros.org Service 개념 정리\nService를 요청하는 주체를 Service Client라고 하며, Service 요청 자체를 Request, 혹은 Call이라고 합니다. Service를 요청받는 주체를 Service Server라고 하며, Service Server는 Request에 대한 응답, 즉 Service Response를 다시 Service Client에게 회답합니다. Request와 Response를 위해 사용되는 데이터 타입은 srv라고 하며 Request와 Response로 나뉩니다. Service의 중요한 특징 한 가지 추가하자면, 하나의 Service Server에 여러 Client가 request 할 수 있지만, Server는 동시에 여러 request를 처리하지 못합니다.\nimage from : docs.ros.org ROS Service 커멘드 라인 지난 topic 예시와 같이 ROS 1에서 ROS 2로 넘어오면서 변경된 커멘드 라인들을 살펴보겠습니다.\nrosservice list ⇒ ros2 service list ros2 service info는 없으며, ros2 service type으로 변경되었습니다. srv는 ros2 interface show로 조회 가능합니다. $ ros2 interface show turtlesim/srv/Spawn float32 x float32 y float32 theta string name # Optional. A unique name will be created and returned if this is empty --- string name 서비스 타입 중간에 보이는 - - - 부분은 request와 response의 구분자라고 생각하시면 됩니다.\nService Example - 📸 KimChi Service 이번에 보여드릴 ROS 2 service 예시는 사진을 찍는 service server입니다.\n예시 실행 - rqt를 통해 service call이 성공하면 현재 시간에 해당하는 파일이름으로 로봇이 바라보는 시야의 카메라 이미지가 PNG 형식으로 저장됩니다. # Terminal 1 - 여러분들만의 world를 사용하시면 더욱 좋습니다. $ ros2 launch src_gazebo empty_world.launch.py # Terminal 2 $ colcon build --packages-select py_service_tutorial $ source install/local_setup.bash $ ros2 run py_service_tutorial take_picture_server [INFO] [turtle_circle_server]: Picture Taking Node Started [INFO] [turtle_circle_server]: KimChi~ [INFO] [turtle_circle_server]: Image saved in 1672569224.png # Terminal 3 - rqt 실행 후 service caller 실행 (plugins =\u0026gt; services =\u0026gt; service caller) $ rqt Service Caller의 사용법과 결과는 다음과 같습니다. 코드를 살펴보기 전에, 이를 어떻게 구현할 수 있을지 같이 생각해봅시다.\n사진 촬영을 포함하는 Service Server 필요 로봇 전방 image data의 Subscriber 필요 ROS의 sensor_msgs/msg/Image를 저장 가능한 포멧으로 변경 필요 따라서, Node의 생성자는 다음과 같이 작성합니다.\nclass PictureNode(Node): def __init__(self): super().__init__(\u0026#39;turtle_circle_server\u0026#39;) self.server = self.create_service( SetBool, \u0026#39;take_picture\u0026#39;, self.take_picture_callback ) self.subscriber = self.create_subscription( Image, \u0026#39;logi_camera_sensor/image_raw\u0026#39;, self.sub_callback, 10 ) self.br = CvBridge() self.is_request = False 이번에 사용하는 srv는 example_interfaces/srv/SetBool이며, Bool Type의 request와 String response를 갖고 있습니다. $ ros2 interface show example_interfaces/srv/SetBool # This is an example of a service to set a boolean value. # This can be used for testing but a semantically meaningful # one should be created to be built upon. bool data # e.g. for hardware enabling / disabling --- bool success # indicate successful run of triggered service string message # informational, e.g. for error messages service call에 대한 callback입니다. is_request를 바꿔주기만 하는데, 이것이 하는 역할이 무엇일지 생각해보세요. def take_picture_callback(self, request, response): if request.data is True: self.get_logger().info(\u0026#39;KimChi~\u0026#39;) self.is_request = True response.success = True response.message = \u0026#34;Successfully image written\u0026#34; return response 정답은 subscription callback에서 찾을 수 있습니다. subscribe된 이미지 데이터는 is_request가 True인 순간에만 사용됩니다. CV Bridge를 통해 ROS topic을 OpenCV 포맷으로 바꿀 수 있으며, imwrite를 통해 이미지를 저장할 수 있습니다. def sub_callback(self, data): if self.is_request: current_frame = self.br.imgmsg_to_cv2(data, \u0026#34;bgr8\u0026#34;) file_name = str(self.get_clock().now().to_msg().sec) + \u0026#39;.png\u0026#39; cv2.imwrite(file_name, current_frame) self.get_logger().info(f\u0026#39;Image saved in {file_name}\u0026#39;) self.is_request = False Gazebo에 다양한 물체를 배치시킨 뒤 사진을 찍어보는 것도 좋은 실습이 될 것입니다. 제가 준비한 dataset을 사용하여 여러분들만의 실습도 해보세요.\n📁 3DGEMS.zip\n제공되는 3DGEMS 폴더를 압축해제한 뒤, ~/.gazebo/models 폴더에 위치시킵니다. 해당 모델들의 출처는 다음과 같습니다. (\u0026ldquo;The Effect of Color Space Selection on Detectability and Discriminability of Colored Objects.\u0026rdquo; arXiv preprint arXiv:1702.05421 (2017).)\nWSL2를 사용하시는 분들께서는 터미널에서 explorer.exe . 를 입력하면 윈도우 파일 탐색기를 실행 가능합니다.\n다시 한 번 Gazebo를 실행시킨 뒤 새로 추가된 모델들을 사용해봅시다. Server Client Example - Spawn Model 이번 예시는 ROS 1강의에서도 살펴본 바 있는, urdf를 사용하여 gazebo 상에 물체를 등장시키는 예시입니다.\n예시 실행 ros2 launch src_gazebo wall_world.launch.py ros2 run py_service_tutorial spawn_model Gazebo에서 일정한 간격을 두고, 하얀색 박스가 등장하게 됩니다. 매번 박스가 등장할 때마다 service call이 이루어지는 것이지요.\nROS 1에서의 예시와 기능은 동일하므로 중요한 코드들만 간단히 분석해봅시다. 사용하는 srv는 gazebo_msgs/srv/SpawnEntity 입니다. from gazebo_msgs.srv import SpawnEntity import rclpy from rclpy.node import Node create_client를 통해 Service Client를 생설할 수 있습니다. class SpawnRobot(Node): def __init__(self): super().__init__(\u0026#39;gazebo_model_spawner\u0026#39;) self.client = self.create_client(SpawnEntity, \u0026#39;spawn_entity\u0026#39;) while not self.client.wait_for_service(timeout_sec=1.0): self.get_logger().error(\u0026#39;service not available, waiting again...\u0026#39;) create_client의 매개변수는 각각 다음과 같습니다.\nService srv type - SpawnEntity Service server 이름 - \u0026lsquo;spawn_entity\u0026rsquo; main문은, 일반적인 node 실행과 다소 차이를 보입니다. Future라는 개념을 사용하여 이벤트 기반 spin을 구현하였습니다.\nfuture = robot_spawn_node.send_req() rclpy.spin_until_future_complete(robot_spawn_node, future) if future.done(): try: response = future.result() except Exception: raise RuntimeError( \u0026#39;exception while calling service: %r\u0026#39; % future.exception() ) else: robot_spawn_node.get_logger().info(\u0026#39;==== Service Call Done ====\u0026#39;) robot_spawn_node.get_logger().info(f\u0026#39;Status_message : {response.status_message}\u0026#39;) finally: robot_spawn_node.get_logger().warn(\u0026#39;==== Shutting down node. ====\u0026#39;) 친구와 명확한 약속을 했다면, 그동안 다른 일을 할 수 있는 것처럼 Future는, 효율적인 비동기 프로그래밍을 위해 사용됩니다.\nimage from : brunch.co\nservice call이 이루어지는 send_req에서 이 Future를 반환하고 있습니다. def send_req(self): ... self.future = self.client.call_async(self.req) return self.future launch file을 보면 gazebo의 실행을 비롯하여 spawn_model node도 함께 실행됩니다. 그래서 gazebo가 등장하자마자 하얀 박스들이 생성되었던 것입니다. spawn_parking_lot = Node( package=\u0026#39;py_service_tutorial\u0026#39;, executable=\u0026#39;spawn_model\u0026#39;, name=\u0026#39;spawn_model\u0026#39;, output=\u0026#39;screen\u0026#39; ) 이 예시는 다음 Action에서도 활용되므로 잘 기억해두시기 바랍니다.\nCustom Interface와 코딩 과제 - Turtle Jail ROS 2에서 custom interface를 만들기 위해서는 C++ Package에서 작업이 이루어져야 합니다. C++ package는 build type ament_cmake를 사용하는 package였습니다.\n$ ros2 pkg create --build-type ament_cmake \u0026lt;package-name\u0026gt; $ ros2 pkg create --build-type ament_cmake custom_interfaces 해당 패키지 내 action, msg, srv 라는 폴더를 만들고 해당 폴더 안에 나만의 인터페이스를 작성합니다. 사용할 수 있는 기본 데이터 형식들은 이 링크를 참고합니다.\n이번에 만들어볼 custom interface는 다음 과제와 연결됩니다. 우선 저를 따라와 주세요.\nsrv라는 폴더를 만들고, TurtleJail.srv라는 파일을 생성하여 아래와 같은 내용을 작성합니다. float32 width float32 height --- bool success 해당 interface를 rclpy, rclcpp에서 사용 가능하도록 해봅시다. ROS 2는 DDS의 IDL(Interface Description Language)를 사용하여 다양한 언어에서 사용 가능한 데이터 타입을 만들 수 있습니다.\nCMakeLists.txt 수정 find_package(rosidl_default_generators REQUIRED) rosidl_generate_interfaces(${PROJECT_NAME} \u0026#34;msg/Num.msg\u0026#34; \u0026#34;srv/AddThreeInts.srv\u0026#34; \u0026#34;srv/TurningControl.srv\u0026#34; \u0026#34;srv/TurtleJail.srv\u0026#34; \u0026#34;action/Fibonacci.action\u0026#34; \u0026#34;action/Maze.action\u0026#34; ) package.xml 수정 \u0026lt;build_depend\u0026gt;rosidl_default_generators\u0026lt;/build_depend\u0026gt; \u0026lt;exec_depend\u0026gt;rosidl_default_runtime\u0026lt;/exec_depend\u0026gt; \u0026lt;member_of_group\u0026gt;rosidl_interface_packages\u0026lt;/member_of_group\u0026gt; 패키지 빌드 $ colcon build --packages-select custom_interfaces \u0026amp;\u0026amp; rosfoxy Starting \u0026gt;\u0026gt;\u0026gt; custom_interfaces Finished \u0026lt;\u0026lt;\u0026lt; custom_interfaces [0.62s] Summary: 1 package finished [0.84s] 이제 ROS 2에서 해당 인터페이스를 사용할 수 있습니다 (단, 해당 workspace를 바라보게 해야 합니다.) $ ros2 interface show custom_interfaces/srv/TurtleJail float32 width float32 height --- bool success custom interface의 사용 시 파이썬 패키지에서는 별도 작업 없이 사용 가능하지만 C++ 패키지는 코딩 시 CMakeLists.txt의 수정이 필요합니다. 이는 다소 난이도가 있어 강의에서 살피지는 않고 링크를 남겨두겠습니다.\nhttps://docs.ros.org/en/foxy/Tutorials/Beginner-Client-Libraries/Custom-ROS2-Interfaces.html#id10 Assignment - Turtle Jail topic과 service에 대해서 모두 살펴본 지금 상황에서 여러분들께 코딩 과제를 제시해보고자 합니다. 이번 코딩 과제에서 구현해야 하는 최종 결과는 다음과 같습니다.\nrqt를 통해 turtle_jail_size service call을 하며, 감옥의 사이즈를 설정합니다.\n거북이는 감옥을 벗어날 수 없으며, 감옥을 벗어나는 순간 원점으로 순간이동합니다.\n터미널에서 실행하는 절차는 다음과 같습니다. # Terminal 1 – turtlesim실행 ros2 run turtlesim turtlesim_node # Terminal 2 - turtle_teleop 실행 ros2 run turtlesim turtle_teleop_key # Terminal 3 - 과제 프로그램 실행 ros2 run py_service_tutorial turtle_jail [INFO] [turtle_jail_node]: === [Service Client : Ready to Call Service Request] === [INFO] [turtle_jail_node]: ==== [Service Server : Ready to receive Service Request] ==== # Terminal 4 - rqt의 service caller 실행 후 /turtle_jail_size에게 service call cd ~/ros2_ws source install/local_setup.bash rqt 이번 예시는 custom interface를 사용하므로 local_setup.bash를 꼭 실행해주세요!\n이 예시에서는 topic과 service를 모두 사용해야 합니다. 지금까지 학습한 내용들을 확인해볼 수 있는 좋은 기회가 될 것입니다.\n힌트1 : turtlesim의 좌표계 힌트 2 : 거북이를 순간이동시키기 위해 /turtle1/teleport_absolute service를 사용하세요. "
},
{
	"uri": "/kr/ros2_basic_foxy/lecture7/",
	"title": "Lecture7 - Useful ROS 2 Example, Navigation2",
	"tags": [],
	"description": "",
	"content": " 코딩을 시작하기 전에 구현해야 하는 기능들과 Topic, Service 기준 input, output을 정리해봅시다.\nPart 1 - 감옥 구현 거북이가 일정 범위를 벗어나게 되면 다시 원위치로 돌아오게 한다.\n거북이의 위치는 /turtle1/pose topic subscribe을 통해 얻을 수 있습니다. 거북이가 일정 위치를 벗어나는 순간, 원위치로 돌아오게 하는 /turtle1/teleport_absolute service call을 해야 합니다. 이를 위한 service client가 필요합니다. Part 2 - 감옥 크기 변경 사용자로부터 감옥의 크기를 변경해달라는 service request가 오면 기존 감옥의 크기를 변경하는 작업이 필요하다.\n/turtle_jail_size service server를 구현해야 합니다. 감옥의 크기가 변경되면 topic 로직에도 반영되어야 하므로 OOP의 형태로 구현이 필요할 듯 합니다. 코드를 구현하기 위해 필요한 topic, service interface들을 조회합시다.\n$ ros2 interface show custom_interfaces/srv/TurtleJail float32 width float32 height --- bool success $ ros2 interface show turtlesim/srv/TeleportAbsolute float32 x float32 y float32 theta --- $ ros2 interface show turtlesim/msg/Pose float32 x float32 y float32 theta float32 linear_velocity float32 angular_velocity 모든 필요조건들을 알게 되었습니다. 이제 프로그래밍을 해보겠습니다.\n필요 파이썬 패키지 import import rclpy from rclpy.node import Node from turtlesim.msg import Pose from turtlesim.srv import TeleportAbsolute from custom_interfaces.srv import TurtleJail Service Server, Service Client, Topic Subscriber 생성 # Create Turtle teleport client self.client = self.create_client(TeleportAbsolute, \u0026#39;turtle1/teleport_absolute\u0026#39;) while not self.client.wait_for_service(timeout_sec=1.0): self.get_logger().info(\u0026#39;Service not available, Waiting again...\u0026#39;) self.request_srv = TeleportAbsolute.Request() self.get_logger().info(\u0026#39;=== [Service Client : Ready to Call Service Request] ===\u0026#39;) # Create Subscriber for turtle1/pose queue_size = 10 # Queue Size self.pose_subscriber = self.create_subscription( Pose, \u0026#39;turtle1/pose\u0026#39;, self.sub_callback, queue_size ) # Create Service Server for User Interfaces self.srv = self.create_service( TurtleJail, \u0026#39;turtle_jail_size\u0026#39;, self.turtle_jail_callback ) self.get_logger().info(\u0026#39;==== [Service Server : Ready to receive Service Request] ====\u0026#39;) 클래스 변수 선언 (감옥 사이즈, 벽에 도달하기 전 거북이의 각도) # Preserve its rotation before teleport self.cur_theta = 0.0 # jail size in rectangular form self.jail_width = 6.0 self.jail_height = 6.0 topic subscribe와 service server에 대한 callback이 두 개 필요합니다.\n거북이의 Pose Topic Subscribe Callback def sub_callback(self, msg): \u0026#34;\u0026#34;\u0026#34;Turtle Pose Subscriber Callback\u0026#34;\u0026#34;\u0026#34; if abs(msg.x - 6.0) \u0026gt; self.jail_width or abs(msg.y - 6.0) \u0026gt; self.jail_height: self.cur_theta = msg.theta self.get_logger().warn(\u0026#34;You can\u0026#39;t go out Turtle! :(\u0026#34;) self.send_request() 감옥 사이즈 변경 요청 시 발생하는 Service Server Callback def turtle_jail_callback(self, request, response): \u0026#34;\u0026#34;\u0026#34;Service Server for jail resizing client request\u0026#34;\u0026#34;\u0026#34; self.jail_width = request.width self.jail_height = request.height self.get_logger().info(f\u0026#34;\u0026#34;\u0026#34;Jail Size Update to {self.jail_width}/{self.jail_height}\u0026#34;\u0026#34;\u0026#34;) response.success = True return response 마지막으로, 거북이를 원점으로 이동시켜달라는 service request를 구현합니다. def send_request(self): \u0026#34;\u0026#34;\u0026#34;Service Clinet request fuction\u0026#34;\u0026#34;\u0026#34; self.request_srv.x = 6.0 self.request_srv.y = 6.0 self.request_srv.theta = self.cur_theta self.future = self.client.call_async(self.request_srv) return self.future 바로 코딩을 시작하지 말고, 무엇을 구현해야 하는지 적어보는 것, 조금씩 조금씩 구현한 뒤, 확인하면서 개발하는 것, ROS 뿐만 아니라 앞으로의 프로그래밍에서 반드시 잊지 마시기 바랍니다.\nNavigation 2 이번 시간에는 유용한 ROS 2 프로젝트를 소개하고, 관련된 내용을 함께 살펴보고자 합니다. ROS 2의 자율 주행 메타페키지인 Navigation 2, Nav2 입니다.\nimage from : https://navigation.ros.org\nNav 2는 삼성 리서치 아메리카의 Steven Macenski의 주도 하에 개발되고 있으며, 아래와 같은 자율주행을 위해 필요한 거의 모든 기능들을 집합해둔 프로젝트입니다.\n지도 저장, 전송, 관리 (Map Server) 지도 상에서 로봇의 위치 파악하기 (AMCL) A to B 주행을 위한 경로 생성 (Nav2 Planner) 경로를 따라 로봇을 이동시키기 위한 컨트롤 시스템 (Nav2 Controller) 주행 경로의 최적화 (Nav2 Smoother) Costmap 생성과 센서 데이터 반영 (Nav2 Costmap 2D) Behavior Tree를 통한 복잡한 주행 시나리오 핸들링 (Nav2 Behavior Trees and BT Navigator) 주행 실패를 방지하기 위한 recovery behaviors (Nav2 Recoveries) Waypoints 주행 (Nav2 Waypoint Follower) Nav2 Node들의 모니터링과 관리 (Nav2 Lifecycle Manager) 커스텀 알고리즘 개발을 위한 Plugins (Nav2 Core) 일반 개발자나 기업이 자율주행을 구현하기 위해서는 이렇게 많은 것들이 필요합니다. 하지만, ROS 2를 사용한다면 Nav 2를 통해 많은 시간을 단축할 수 있지요!\n이 강의에서 모든 내용을 다루고 싶지만, 시간적 한계가 있기 때문에 예시를 통해 로봇 자율주행에 대한 개념을 체감해보도록 하겠습니다.\nNav 2 Example 1 - SLAM_ToolBox 처음 가보는 환경을 맞닥뜨리면, 우리는 주변 상황을 탐색하고 내 위치를 파악하려 할 것입니다. 이것을 로보틱스에서는 SLAM - Simultaneous localization and mapping이라고 이야기합니다.\nSLAM Toolbox는 Steven Macenski에 의해 제작된 ROS 2 패키지이며 backend와 frontend SLAM 알고리즘 뿐만 아니라, ROS 2와 호환되는 관리 도구, 최적화까지 담고 있습니다. 예시를 통해 SRC 로봇으로 SLAM을 실습해봅시다. 로봇을 이동시키면서 rviz에 갱신되는 지도를 확인합니다. colcon build --packages-select src_slam colcon build --packages-select src_odometry source install/local_setup.bash # Terminal 1 ros2 launch src_gazebo racecourse.launch.py use_rviz:=false # Terminal 2 ros2 launch src_slam src_slam_gazebo_slam_toolbox.launch.py 지도를 저장하는 두 가지 방법이 있습니다.\nrviz plugin 사용 - RViz상의 공란에 지도를 저장할 위치를 포함한 절대경로를 기입하고 왼쪽 “Save Map” 버튼을 눌러 최종 지도를 추출합니다. 커멘드 라인 사용 - 저장 위치가 존재하는지 확인 후 실행하세요. ros2 run nav2_map_server map_saver_cli -f \u0026lt;map_dir\u0026gt;/\u0026lt;map_name\u0026gt; 저장 결과로 두 가지 파일이 생성되며, 이러한 지도 데이터를 관리해주는 것이 Nav 2의 Map Server 입니다. 지도 이미지 파일 지도 정보를 담은 yaml 파일 Localization 로봇의 현재 위치와 방향을 파악하는 것을 localization이라고 부릅니다.\nNav2의 AMCL 패키지는 주어진 맵을 기반으로 Adaptive Monte Carlo Localization 방식을 사용하여 로봇의 위치를 파악합니다.\nimage from : wikipedia\n이 Adaptive Monte Carlo Localization은 입자(Particle)를 사용하여 로봇의 위치를 파악하는 방식이며, 이 입자들은 실제 로봇처럼 주어진 가중치와 함께 그들만의 좌표와 방향 값을 가지고 있게 됩니다.\n로봇이 주어진 환경에서 이동하여 새 센서 데이터를 제공할 때마다 입자가 다시 샘플링되며, 각 샘플링에서 가중치가 작은 입자는 소멸되고 가중치가 큰 입자는 더 커지면서 생존합니다.\nAMCL 알고리즘을 여러 번 반복하게 되면 입자들의 위치가 수렴하여 로봇 포즈의 근사치를 평가할 수 있고, 결국 이 로봇의 최종 방향과 위치를 추정하게 됩니다.\nNav2 Lifecycle Manager Map Server, AMCL과 같은 Nav2의 stack은 Nav2 Lifecycle Manager에 의해 관리됩니다.\nLifecycle이라는 것은 생성과 실행, 일시정지와 최종 종료와 같이 Node의 상태를 지칭합니다. image from : roscon2019\n기존 ROS 2도 lifecycle을 갖고 있지만, Nav 2는 전용 lifecycle_manager를 사용함으로 다른 node과 별도로 자율주행과 관련된 최적화된 시스템 설계가 가능해졌습니다. image from : navigation2\n하지만, ROS 2의 lifecycle이 아닌 독자적인 방식을 사용하게 됨으로 디버깅 툴 사용이 불가하다는 점이 문제점으로 대두됩니다. 이러한 이유로, nav2 개발 시에는 rqt console의 사용을 권장합니다.\nCostmap 2D 자율주행의 경로를 계산할 시, 일반적으로 구역을 나누고 장애물 여부, 충돌 가능 여부등을 점수화하여 구역별 costmap을 만듭니다.\nNav2에서도 로봇의 크기와 사용자의 정의에 따라 inflation을 적용한 costmap을 생성합니다.\nNav2의 costmap에서 각 셀의 cost는 unknown, free, occupied, inflated로 정의되고, controller, planner, recovery plugin등이 이를 사용하여 안전하고 효율적인 경로를 계산하게 됩니다. 이 costmap에는 두가지 종류가 있는데\nGlobal Costmap은 SLAM을 통해 얻은 정적 지도를 기반으로 생성되며, 벽, 가구와 같이 SLAM 당시 존재했던 장애물들에 대한 costmap입니다. Local Costmap은 로봇 주위 일정 범위에 로봇에 부착된 센서들을 기반으로 생성되며, 동적 장애물을 감지할 수 있습니다. 로봇이 이동함에 따라 매번 갱신되는 데이터입니다. 아래 사진에서 왼쪽은 Global costmap을, 오른쪽은 Local costmap을 보이고 있습니다.\ninflation의 변경에 따른 costmap의 차이는 아래와 같이 rviz 화면에서 확인할 수 있습니다. inflation을 줄이게 되면 경로 상 갈 수 있는 영역이 많아졌지만, 충돌 측면에서는 좀 더 위험해졌다고 말할 수 있습니다. 따라서, 로봇의 크기와 최대 속도, 제동거리를 고려하여 적절한 inflation radius를 설정해야 합니다.\nLocal Path와 Global Path 센서 데이터에서 장애물이 검출되었다면, local planner는 이를 회피하기 위해 기존 global planner와는 다른 별도의 경로를 따르도록 로봇에게 지시할 것입니다.\nNav2에서 물체 회피를 위해 수행되는 동작들은 다음과 같습니다.\nglobal planner가 지도를 기반으로 거시적인 경로를 계산하면 이 경로의 일부가 local planner에게 전달됩니다. local planner는 기본적으로 global Planner의 파편이지만, 현재 주행중인 환경과 센서 데이터를 입력으로 받아, 경로를 최신화합니다. global plan과 local plan은 엄연히 다른 알고리즘이 사용되는 분야입니다.\nimage from : Autonomous Wheeled Mobile Robot Control\nController local Path가 계산되었다면, 이제 로봇이 실제로 해당 경로를 주행할 차례입니다.\n로봇의 최대 선속도, 각속도와 후진 여부 등 매개변수에 따라 경로를 최적화해야 합니다. Nav2에서는 Controller가 이를 담당하고 있습니다.\nController는 그 이름과 같이 주어진 경로를 따르기 위해 로봇에게 실제 제어 신호를 전달하게 되며, 따라서 사용하는 로봇의 모델과 밀접한 관련이 있습니다. (제자리 회전, y축 이동 등)\nimage from : dwa_local_planner\nNav2 Behavior Tree 로봇의 일련의 행동들은 Tree 자료 구조로 표현될 수 있으며, Tree의 Node에 해당하는 작업을 구현해두고 이들을 조합하여 시나리오를 구성할 수 있습니다.\nex) A 위치에 도착한 뒤, 물건을 싣고, 다시 B 위치로 이동하여 새로운 물건을 싣고, 최종적으로 C지점으로 돌아와라. 만약 C 지점에 물건이 가득 차있다면 D 지점으로 이동하여 물건을 최종 이송해라\u0026hellip; image from : wikipedia\nNav2는 **BehaviorTree.CPP**를 사용하여 로봇의 자율주행 시나리오 기능을 제공합니다. Behavior Tree는 Nav2와는 별도의 오픈소스 프로그램인데, 시각화를 포함한 높은 완성도를 갖추고 있어 게임 및 로봇 도메인에서 많이 사용됩니다. https://robohub.org/introduction-to-behavior-trees/\nNav2 Core nav2_core 패키지는 custom 알고리즘을 적용한 플러그인을 구현할 수 있도록 인터페이스를 제공합니다. 연구실이나 기업에서는 자신만의 로직을 Plugin으로 구현해서 Nav2 시스템에 적용할 수 있으며, 이러한 방식으로 구현의 시간을 단축시킬 수 있습니다.\nGlobal Planner – global_planner.hpp Local Planner – local_planner.hpp Recovery behaviors – recovery.hpp Goal checker – goal_checker.hpp Exceptions – exceptions.hpp 여러분만의 plugin을 만들어보고 싶다면, 아래 링크를 참고하세요.\nhttps://navigation.ros.org/plugin_tutorials/index.html Nav2 실행 예시 지루한 이론을 듣느라 고생하셨습니다. 이제 src를 통해 자율 주행 예시를 함께 실행해보겠습니다. colcon build --packages-select src_nav source install/local_setup.bash # Terminal 1 ros2 launch src_gazebo racecourse.launch.py use_rviz:=false # Terminal 2 ros2 launch src_nav bringup_launch.py rqt_graph를 확인해봅시다. 방금 우리가 실행한 launch file을 같이 살펴볼까요?\nLaunchDescription부터 살펴봅시다. 대부분 launch arguement의 선언이고 결국 실행과 관련된 것은 bringup_cmd_group 뿐입니다. # Set environment variables ld.add_action(stdout_linebuf_envvar) # Declare the launch options ld.add_action(declare_namespace_cmd) ld.add_action(declare_use_namespace_cmd) ld.add_action(declare_map_yaml_cmd) ld.add_action(declare_use_sim_time_cmd) ld.add_action(declare_slam_cmd) ld.add_action(declare_params_file_cmd) ld.add_action(declare_autostart_cmd) ld.add_action(declare_bt_xml_cmd) ld.add_action(declare_open_rviz_cmd) # Add the actions to launch all of the navigation nodes ld.add_action(bringup_cmd_group) return ld Launch file의 실행 시 GroupAction을 통해 관련된 실행 프로그램들을 한데 묶을 수 있습니다. 이렇게 하는 이유는, 여러 로봇의 실행을 대비한 것입니다. IncludeLaunchDescription을 통해 4개의 launch file들을 다시 추가하고 있습니다. # Specify the actions bringup_cmd_group = GroupAction([ PushRosNamespace( condition=IfCondition(use_namespace), namespace=namespace), IncludeLaunchDescription( PythonLaunchDescriptionSource(os.path.join(my_launch_dir, \u0026#39;slam_launch.py\u0026#39;)), ... IncludeLaunchDescription( # Run Localization only when we don\u0026#39;t use SLAM PythonLaunchDescriptionSource(os.path.join(my_launch_dir, \u0026#39;localization_launch.py\u0026#39;)), ... IncludeLaunchDescription( PythonLaunchDescriptionSource(os.path.join(my_launch_dir, \u0026#39;navigation_launch.py\u0026#39;)), ... IncludeLaunchDescription( PythonLaunchDescriptionSource(os.path.join(my_launch_dir, \u0026#39;rviz_view_foxy_launch.py\u0026#39;)), ... ]) 각각의 하위 launch file은 개별 실행될 수 있도록 구성되었습니다. nav2_lifecycle_manager가 위치하고 있는 점도 확인 가능하고 node를 전달하는 방법도 알 수 있습니다. Node( package=\u0026#39;nav2_lifecycle_manager\u0026#39;, executable=\u0026#39;lifecycle_manager\u0026#39;, name=\u0026#39;lifecycle_manager_localization\u0026#39;, output=\u0026#39;screen\u0026#39;, parameters=[{\u0026#39;use_sim_time\u0026#39;: use_sim_time}, {\u0026#39;autostart\u0026#39;: autostart}, {\u0026#39;node_names\u0026#39;: lifecycle_nodes}]) ... lifecycle_nodes = [nav2, related, nodes] Nav2의 최적화를 위해서는 수많은 매개변수들과 씨름해야 합니다. yaml 파일을 통해 관리되며 지금까지 살펴본 내용들이 모두 녹아들어 있습니다. amcl: ros__parameters: bt_navigator: ros__parameters: controller_server: ros__parameters: controller_server_rclcpp_node: ros__parameters: use_sim_time: False local_costmap: local_costmap: global_costmap: global_costmap: map_server: ros__parameters: use_sim_time: False yaml_filename: \u0026#34;turtlebot3_world.yaml\u0026#34; map_saver: ros__parameters: planner_server: ros__parameters: planner_server_rclcpp_node: ros__parameters: use_sim_time: False recoveries_server: ros__parameters: robot_state_publisher: ros__parameters: use_sim_time: False 자율 주행 시 발생하는 상황들에 대처하기 위해 기본적으로 Behavior Tree 예시를 제공합니다. 구체적인 내용보다 Node를 작성하고 시나리오를 구성할 수 있다는 점에 집중합시다.\n"
},
{
	"uri": "/kr/ros2_basic_foxy/lecture8/",
	"title": "Lecture8 - ROS 2 Action and Examples",
	"tags": [],
	"description": "",
	"content": " 지금까지 Topic, Service에 대해 모두 배워보았습니다. 마지막 통신 메커니즘인 Action에 대해서 배워봅시다.\nROS2 Action 개념 Action은 Service와 Topic의 특성을 모두 갖고 있으며, 실제로 가장 늦게 탄생한 통신 메커니즘입니다. 일전 Service의 단점을 상기시켜보면서 Action의 필요성에 대해 체감해봅시다.\nService의 중요한 특징 한 가지 추가하자면, 하나의 Service Server에 여러 Client가 request 할 수 있지만, Server는 동시에 여러 request를 처리하지 못합니다.\nimage from : docs.ros.org Action은 바로 이러한 Service의 단점을 극복하기 위해 탄생한 통신 메커니즘입니다.\nAction의 특징 action client는 action server가 Result를 보내기 전까지 마냥 기다리지 않고, 다른 일을 할 수 있습니다. action client는 Result Response를 받기 전에도 지속적으로 Feedback을 받을 수 있습니다. 따라서, Feedback을 받고 있다가, 뭔가 잘못 돌아가고 있다는 것을 감지한 경우 cancel을 할 수도 있습니다. ⇒ 하지만, 여러 request를 동시에 작업하는 것이나, Feedback 중에 topic subscribe와 같은 작업은 본질적으로 불가합니다. 이에 대한 해결 방법도 후에 살펴보겠습니다.\nimage from : https://docs.ros.org/en/foxy/Tutorials/Understanding-ROS2-Actions.html\n사진과 같이 Action Client와 Server가 주고받는 내용은 크게 5가지가 있습니다.\nClient ⇒ Server, Goal Request (service request와 유사합니다.) server ⇒ client, Goal Response client ⇒ server, Result Request server ⇒ client, Feedback (topic과 유사합니다.) server ⇒ client, Result Response 만약 4번 도중 cancel이 발생하면 Action은 종료됩니다.\n이렇게 Action은 Topic, Service의 특징을 모두 갖고 있으며 Cancel이라는 추가 기능까지 갖추고 있는 복잡한 통신 메커니즘입니다.\nAction 커멘드 라인 툴 turtlesim을 실행시킨 뒤, 실습을 진행해봅시다. ros2 run turtlesim turtlesim_node 실행 중인 action은 다음과 같이 조회 가능합니다. $ ros2 action list /turtle1/rotate_absolute 특정 action의 정보를 조회하기 위해 ros2 action info를 사용합니다. $ ros2 action info /turtle1/rotate_absolute Action: /turtle1/rotate_absolute Action clients: 0 Action servers: 1 /turtlesim Action에서 사용되는 데이터 타입은 action이며 ros2 interface show를 통해 조회 가능합니다. $ ros2 interface show turtlesim/action/RotateAbsolute # The desired heading in radians float32 theta --- # The angular displacement in radians to the starting position float32 delta --- # The remaining rotation in radians float32 remaining 커멘드 라인에서 손쉽게 Action Goal을 보낼 수 있습니다. (feedback option을 제공합니다.) $ ros2 action send_goal \u0026lt;action_name\u0026gt; \u0026lt;action_type\u0026gt; \u0026lt;values\u0026gt; $ ros2 action send_goal /turtle1/rotate_absolute turtlesim/action/RotateAbsolute \u0026#34;{theta : 0.0}\u0026#34; --feedback 1657646954.088327 [0] ros2: using network interface enp7s0 (udp/166.104.135.89) selected arbitrarily from: enp7s0, docker0 Waiting for an action server to become available... Sending goal: theta: 0.0 Goal accepted with ID: d3ddca85948d4099a13dbeb8183e5ecc Result: delta: -0.7839995622634888 Goal finished with status: SUCCEEDED Action 프로그래밍 Action Client 작성하기 일전 거북이를 회전시키는 Action Server에 매칭되는 Action Client입니다. 거북이가 움직이기 원하는 각도를 입력하면 해당 각도록 회전하기 시작합니다. $ colcon build --packages-select py_action_tutorial $ source install/local_setup.bash $ ros2 run py_action_tutorial turtle_turning_client [INFO] [1672647544.783857088] [turtle_rotate_client]: === Turtle Rotate Action Client Started ==== Enter Target Angle : 3.14 [INFO] [1672647549.097662572] [turtle_rotate_client]: Goal accepted [INFO] [1672647549.193173672] [turtle_rotate_client]: Received feedback: 0.051996707916259766 [WARN] [1672647549.226111271] [turtle_rotate_client]: Action Done !! Result: -0.12800025939941406 Action Client를 생성하기 위해서는 ActionClient 패키지를 추가해야 합니다. import rclpy from rclpy.action import ActionClient from rclpy.node import Node 우리가 사용할 turtlesim/action/RotateAbsolute라는 action은 다음과 같은 구조를 갖습니다. # The desired heading in radians float32 theta --- # The angular displacement in radians to the starting position float32 delta --- # The remaining rotation in radians float32 remaining Action Client는 ActionClient 인스턴스입니다. Service Client와 매우 비슷하다는 것을 알 수 있습니다. # Create Action Client self.action_client = ActionClient(self, RotateAbsolute, \u0026#39;turtle1/rotate_absolute\u0026#39;) action type : Client가 사용할 action 데이터 타입 action name : Action Server 이름 wait_for_server를 통해 Action Server의 존재 여부를 우선 확인합니다. # Wait for server first if self.action_client.wait_for_server(10) is False: self.get_logger().error(\u0026#39;Server Not exists\u0026#39;) Action Client는 callback이 많아 각 함수에 대한 실행 시점을 잘 알아두셔야 합니다. # Send Goal then receive future self._send_goal_future = self.action_client.send_goal_async( goal_msg, feedback_callback=self.feedback_callback ) # Done callback Add self._send_goal_future.add_done_callback(self.goal_response_callback) send_goal : main 함수에서 호출되며, Goal request를 진행합니다. feedback_callback : Server로부터의 Feedback이 들어올 때마다 실행되는 Callback 입니다. goal_response_callback : Goal Accpet와 Reject 여부를 확인합니다. get_result_callback : 최종 result에 대한 Callback으로, Action의 제일 마지막에 실행됩니다. Action은 메커니즘 자체가 어렵기 때문에 일부러 쉬운 예제를 가져왔습니다. 코드의 로직은 간단하며, Action Client API 자체에 집중하며 따라와주세요.\ngoal_response_callback : goal은 그 자체로 Service라고 말할 수 있습니다. 따라서, goal 완료까지 대기한 뒤 get_result_callback을 연동합니다. def goal_response_callback(self, future): goal_handle = future.result() if not goal_handle.accepted: self.get_logger().info(\u0026#39;Goal rejected\u0026#39;) return self.get_logger().info(\u0026#39;Goal accepted\u0026#39;) # Add Result cb self._get_result_future = goal_handle.get_result_async() self._get_result_future.add_done_callback(self.get_result_callback) feedback_callback은 subscriber의 callback과 유사하게 매개변수로 feedback 데이터를 받습니다. get_result_callback은 goal_response_callback과 유사하게, future를 매개변수로 받습니다. 하지만 더이상 추가할 callback은 없고 result를 받으면서 마무리됩니다. def feedback_callback(self, feedback_msg): feedback = feedback_msg.feedback self.get_logger().info(f\u0026#39;Received feedback: {feedback.partial_sequence}\u0026#39;) def get_result_callback(self, future): result = future.result().result self.get_logger().warn(f\u0026#39;Action Done !! Result: {result.sequence}\u0026#39;) rclpy.shutdown() 이번 예시에 구현되어 있지는 않지만, goal_handle로부터 cancel handler를 생성할 수도 있습니다. 아래 코드를 예시에 적용한 다음, cancel도 실습해보세요. # Cancel the goal future = self.goal_handle.cancel_goal_async() future.add_done_callback(self.cancel_done) # Cancel the timer self.timer.cancel() def cancel_done(self, future): cancel_response = future.result() if len(cancel_response.goals_canceling) \u0026gt; 0: self.get_logger().info(\u0026#39;Goal successfully canceled\u0026#39;) else: self.get_logger().info(\u0026#39;Goal failed to cancel\u0026#39;) rclpy.shutdown() Action Server Example - Parking Master image from : 기호일보\n이번에는 재미있는 예시를 준비해 보았습니다. 아래 명령어을 입력해 주세요 cbp custom_interfaces cbp parking_action_server source install/local_setup.bash # Terminal 1 ros2 launch src_gazebo wall_world.launch.py # Terminal 2 ros2 run py_action_tutorial parking_action_server [INFO] [1672654091.689062703] [parking_action_server]: Action Ready... [INFO] [1672654101.355609636] [parking_action_server]: Executing goal... [INFO] [1672654101.356973636] [parking_action_server]: Distance from forward obstacle : 100.0 ... # Terminal 3 ros2 action send_goal /src_parking custom_interfaces/action/Parking \u0026#34;start_flag: true\u0026#34; --feedback Waiting for an action server to become available... Sending goal: start_flag: true Goal accepted with ID: d7bcfec5a6e94bd4a349f4955cc495c8 Feedback: distance: 100.0 Feedback: distance: 1.7898634672164917 ... 벽에 인접하여 흰색 상자들이 주차 공간을 배정해줄 것입니다. rqt_robot_steering으로 로봇을 잘 제어하여 주어진 주차 공간에 알맞게 주차를 해보세요!\nFeedback을 통해 벽과의 거리를 확인할 수 있으며, 이 거리가 0.5m 이내가 되면 주차가 완료됩니다. 이 시점에서 좌우 공간이 얼마가 균형이 맞는지에 따라 다른 Result를 얻게 됩니다.\n올바른 주차 시 ⇒ Success! 잘못된 주차 시 ⇒ Fail Action Server 프로그래밍 프로그래밍을 시작하기 전, 필요한 통신 메커니즘들을 살펴봅시다.\nAction Server : Goal을 받으면, 정면 벽과의 거리를 feedback으로 전달합니다. 최종 Result는 String으로 성공 여부를 알려줍니다. LaserScan Sub : 주변 물체와의 스캔된 거리를 알 수 있습니다. Feedback Callback과 Subscription Callback 두 함수도 구현해야 할 것입니다.\n이번 예시를 위해 custom interface를 만들어 보았습니다. Action 데이터 타입은 세 종류의 데이터로 이루어져 있습니다. #goal definition bool start_flag --- #result definition string message --- #feedback definition float32 distance 이제 코드를 살펴봅시다. Action Server를 사용하기 위해서는 ActionServer 패키지를 import 해야 합니다. import rclpy from rclpy.node import Node from rclpy.action import ActionServer 코드 분석 전 살펴본 바와 같이 두 종류의 핸들러를 생성합니다. class ParkingActionServer(Node): def __init__(self): super().__init__(\u0026#39;parking_action_server\u0026#39;) self.laser_sub = self.create_subscription( LaserScan, \u0026#39;scan\u0026#39;, self.sub_callback, 10 ) self.action_server = ActionServer( self, Parking, \u0026#39;src_parking\u0026#39;, self.execute_callback ) Action Server의 Callback입니다. 첫 인자는 goal handler로 feedback 전송이 이를 통해 이루어집니다. feedback msg에는 정면 물체와의 거리가 담깁니다. def execute_callback(self, goal_handle): self.is_sub = True self.get_logger().info(\u0026#39;Executing goal...\u0026#39;) feedback_msg = Parking.Feedback() while self.f_obs_distance \u0026gt; 0.5: feedback_msg.distance = self.f_obs_distance goal_handle.publish_feedback(feedback_msg) self.get_logger().info( f\u0026#34;Distance from forward obstacle : {self.f_obs_distance}\u0026#34; ) time.sleep(1) while loop를 벗어나게 되면 goal succed를 수행하고, Result를 리턴합니다. 현재의 로직은 좌우 물체와의 거리가 균일할 때 성공으로 판정짓습니다. goal_handle.succeed() result = Parking.Result() lr_diff = abs(self.r_obs_distance - self.l_obs_distance) print(lr_diff) if lr_diff \u0026lt; 0.15: result.message = \u0026#34;[Success!] Oh... Teach me how you did :0\u0026#34; else: result.message = \u0026#34;[Fail] Be careful, Poor Driver! \u0026#34; return result main문에서 특별한 점을 찾아볼 수 있습니다. MultiThreadedExecutor를 사용하고 있는데요. 이것이 하는 역할이 무엇일지 실습을 통해 살펴봅시다. try: parking_action_server = ParkingActionServer() # MultiThreadedExecutor ref # https://url.kr/x4kf2b executor = MultiThreadedExecutor() executor.add_node(parking_action_server) try: executor.spin() except KeyboardInterrupt: parking_action_server.get_logger().info(\u0026#39;Keyboard Interrupt (SIGINT)\u0026#39;) finally: executor.shutdown() parking_action_server.destroy_node() finally: rclpy.shutdown() main 문의 주석을 토글하고, sub_callback에 디버깅 메세지를 심은 다음, 다시 예제를 실행 시켜봅니다. 어떠한 결과를 얻으셨나요? def sub_callback(self, data): if self.is_sub: self.f_obs_distance = data.ranges[60] self.r_obs_distance = data.ranges[30] self.l_obs_distance = data.ranges[90] self.get_logger().info(\u0026#34;sub success\u0026#34;) ... # parking_action_server = ParkingActionServer() # rclpy.spin(parking_action_server) # parking_action_server.destroy_node() # rclpy.shutdown() 현재의 시스템은 두 종류의 callback을 갖고 있습니다. execute_callback이 실행되면서 while loop로 진입하면, 자원을 점유하여 sub_callback이 동작할 수 없는 구조가 됩니다. 이를 해결하기 위해 ROS 2에서는 rclpy단에서 멀티 스레딩을 구현해 두었습니다.\nimage from : docs.ros.org 이후 여러가지 구현을 하다 보면 지금처럼 다중 Subscribe를 해야하는 경우가 반드시 생깁니다. 혹은 하나의 프로세스에서 여러개의 Node를 실행시켜야 하는 경우가 발생합니다. 이때, Node Composition과 MultiThreadedExecutor를 적극 사용해보세요!\n참고자료\nhttps://docs.ros.org/en/foxy/Concepts/About-Executors.html "
},
{
	"uri": "/kr/ros2_basic_foxy/lecture9/",
	"title": "Lecture9 - C++ Programming Again, Outro",
	"tags": [],
	"description": "",
	"content": "C++ Programming Again 실질적으로 C++을 통해 ROS 2 개발이 많이 이루어진다 이야기하였습니다. Topic Publish와 Subscriber의 C++코드들도 turtlesim 예제와 함꼐 간단하게 정리해보았습니다.\nTopic Publish 예제 - Random Movement Turtle 예제 실행 cbp cpp_topic_tutorial source install/local_setup.bash # Terminal 1 ros2 run turtlesim turtlesim_node # Terminal 2 ros2 run cpp_topic_tutorial topic_pub_node ⇒ 거북이가 마구잡이로 움직이기 시작할 것입니다\n로봇을 움직이기 위해서는 geometry_msgs/msg/Twist 형식의 topic message type을 사용해야 함을 배운 바 있습니다. 이를 위해서 다음과 같이, 헤더를 include 하면 됩니다. #include \u0026#34;geometry_msgs/msg/twist.hpp\u0026#34; #include \u0026#34;rclcpp/rclcpp.hpp\u0026#34; 단, 파이썬과 달리 c++ 헤더는 snake_case를 취하며, 코드 사용 시 CamelCase를 사용합니다.\nrclcpp::Publisher\u0026lt;geometry_msgs::msg::Twist\u0026gt;::SharedPtr twist_publisher; ... twist_publisher = this-\u0026gt;create_publisher\u0026lt;geometry_msgs::msg::Twist\u0026gt;(\u0026#34;turtle1/cmd_vel\u0026#34;, 10); publisher는 create_publisher 함수를 통해 생성할 수 있습니다.\n\u0026lt;\u0026gt; 안에는 message type을 적어주고 첫 번째 매개변수는 생성할 topic의 이름 두 번째 매개변수로 queue size를 전달합니다. geometry_msgs::msg::Twist와 같이 타입이 길기 때문에 using을 사용하여 축약하곤 합니다.\nTopic Subscribe 예제 - Turtle Pose Sub turtlesim 상의 거북이의 위치를 Subscribe 받습니다. # Terminal 1 ros2 run turtlesim turtlesim_node # Terminal 2 ros2 run cpp_topic_tutorial topic_sub_node [INFO] [1666434438.709117200] [turtlepose_sub_node]: x: 5.544/ y: 5.544/ theta: 0.000/ lin_vel: 0.000, ang_vel: 0.000 [INFO] [1666434438.725522800] [turtlepose_sub_node]: x: 5.544/ y: 5.544/ theta: 0.000/ lin_vel: 0.000, ang_vel: 0.000 [INFO] [1666434438.741218300] [turtlepose_sub_node]: x: 5.544/ y: 5.544/ theta: 0.000/ lin_vel: 0.000, ang_vel: 0.000 ... 로직 자체는 어렵지 않기에 API에 집중하여 분석해보겠습니다. TwistPubNode() : Node(\u0026#34;twist_pub_node\u0026#34;) { twist_publisher = this-\u0026gt;create_publisher\u0026lt;geometry_msgs::msg::Twist\u0026gt;(\u0026#34;turtle1/cmd_vel\u0026#34;, 10); timer = this-\u0026gt;create_wall_timer( std::chrono::milliseconds(500), std::bind(\u0026amp;TwistPubNode::timer_callback, this) ); } subscriber는 create_subscription 함수를 통해 생성할 수 있습니다.\n\u0026lt;\u0026gt; 안에는 message type을 적어주고 첫 번째 매개변수는 subscribe topic의 이름 두 번째 매개변수로 queue size 세 번째 매개변수로는 std::bind를 통해 callback 함수를 전달합니다. callback의 매개변수가 1개이기에 이를 알려야 하며, std::placeholders::_1이 사용되었습니다.\nsub_callback의 첫번째 매개변수인 데이터는 SharedPtr 타입이 사용된다는 것에 주의하며, 때문에 레퍼런스를 사용할 수 없습니다.\nService Client와 Server의 C++코드들도 분석해봅시다.\nService Client 예제 - Turtle Spawn Turtle Spawn 예제 - 영상과 같이 우리가 내린 명령대로 거북이가 등장한 모습을 볼 수 있습니다. cbp cpp_service_tutorial source install/local_setup.bash # Terminal 1 ros2 run turtlesim turtlesim_node # Terminal 2 ros2 run cpp_service_tutorial turtle_spawn_client \u0026gt; Turtle X position : 5.0 \u0026gt; Turtle Y position : 5.0 \u0026gt; Turtle Angle : 0.0 \u0026gt; Turtle Name : my_turtle [INFO] [1666434554.012857700] [spawn_turtle_node]: Turtle Named : my_turtle Spawned Successfully. create_client는 다음과 같은 정보를 요합니다.\n사용하는 srv 타입 request할 service 이름 wait_for_service를 통해 Service Server의 존재 여부를 체크할 수 있습니다.\n... public: SpawnTurtle() : Node(\u0026#34;spawn_turtle_node\u0026#34;){ spawn_client = this-\u0026gt;create_client\u0026lt;Spawn\u0026gt;(\u0026#34;spawn\u0026#34;); while (!spawn_client-\u0026gt;wait_for_service(1s)) { if (!rclcpp::ok()) { RCLCPP_ERROR(this-\u0026gt;get_logger(), \u0026#34;Interrupted while waiting for the service. Exiting.\u0026#34;); exit(0); } RCLCPP_INFO(this-\u0026gt;get_logger(), \u0026#34;service not available, waiting again...\u0026#34;); } } send_request를 호출함으로 Service call이 가능합니다. 이때, send_request의 반환값을 살펴보면, 비동기 실행을 하고 있음을 알 수 있습니다. auto send_request(){ get_user_input(\u0026#34;\u0026gt; Turtle X position : \u0026#34;, spawn_request-\u0026gt;x); get_user_input(\u0026#34;\u0026gt; Turtle Y position : \u0026#34;, spawn_request-\u0026gt;y); get_user_input(\u0026#34;\u0026gt; Turtle Angle : \u0026#34;, spawn_request-\u0026gt;theta); get_user_input(\u0026#34;\u0026gt; Turtle Name : \u0026#34;, spawn_request-\u0026gt;name); return spawn_client-\u0026gt;async_send_request(spawn_request); } spin_until_future_complete는 async_send_request의 비동기 promise를 받아 실행 완료까지 대기하게 됩니다. int main(int argc, char **argv) { rclcpp::init(argc, argv); auto node = std::make_shared\u0026lt;SpawnTurtle\u0026gt;(); auto result = node-\u0026gt;send_request(); // Wait for the result. if (rclcpp::spin_until_future_complete(node, result) == rclcpp::FutureReturnCode::SUCCESS) { RCLCPP_INFO(node-\u0026gt;get_logger(), \u0026#34;Turtle Named : %s Spawned Successfully.\u0026#34;, result.get()-\u0026gt;name.c_str()); } else { RCLCPP_ERROR(node-\u0026gt;get_logger(), \u0026#34;Failed to call service add_two_ints\u0026#34;); } rclcpp::shutdown(); return 0; } promise의 반환 완료값은 enumerator type을 갖고 있으며, 공식 문서를 참고하였습니다. image from : docs.ros2.org\nService Server 예제 - Turtle Turn 거북이가 원을 그리며 돌기 시작하다가, 일정 시간이 지나면 움직임을 멈추게 됩니다. rqt의 Service Caller를 사용하며, turtle_turn service를 사용하시면 됩니다. # Terminal 1 ros2 run turtlesim turtlesim_node # Terminal 2 ros2 run cpp_service_tutorial turtle_circle_server # Terminal 3 [INFO] [1666435009.330619900] [turtle_circle_server]: Turtle Turning Server Started, Waiting for Request... [INFO] [1666435026.497839300] [turtle_circle_server]: 0.00 Seconds Passed [INFO] [1666435026.498143700] [turtle_circle_server]: 0.00 Seconds Passed [INFO] [1666435026.498297800] [turtle_circle_server]: 0.00 Seconds Passed [INFO] [1666435026.498427400] [turtle_circle_server]: 0.00 Seconds Passed ... 전체 코드 중 Service Server를 생성하는 핵심을 위주로 살펴봅시다. class TurtleCircleNode : public rclcpp::Node { private: rclcpp::Service\u0026lt;SetBool\u0026gt;::SharedPtr bool_server; void turtle_circle(){ ... } ... } void server_callback(const std::shared_ptr\u0026lt;SetBool::Request\u0026gt; request, const std::shared_ptr\u0026lt;SetBool::Response\u0026gt; response){ if (request-\u0026gt;data) { turtle_circle(); } response-\u0026gt;success = true; response-\u0026gt;message = \u0026#34;Turtle successfully drawed Circle\u0026#34;; } public: TurtleCircleNode() : Node(\u0026#34;turtle_circle_server\u0026#34;){ bool_server = this-\u0026gt;create_service\u0026lt;SetBool\u0026gt;( \u0026#34;turtle_circle\u0026#34;, std::bind(\u0026amp;TurtleCircleNode::server_callback, this, std::placeholders::_1, std::placeholders::_2) create_service는 다음과 같은 정보를 필요로 합니다.\n사용하는 srv 타입 - SetBool 생성할 service 이름 - turtle_circle request 시 실행될 callback - server_callback service callback은 request와 response 두 데이터를 매개변수로 받습니다. 때문에, std::placeholders::_1, _2가 명시된 것이 보입니다. 더불어, 거북이를 움직이기 위해 Publisher도 하나 생성하였습니다.\n이렇게 C++ 코드까지 살펴보았는데요, Action의 C++ 코드는 이번 강의에서는 넘어가도록 하겠으며, 링크를 남겨두겠습니다.\nhttps://docs.ros.org/en/foxy/Tutorials/Intermediate/Writing-an-Action-Server-Client/Cpp.html\nAbout Real Robot 지금까지 우리의 실습을 책임졌던 src 로봇이 어떻게 만들어졌는지 살펴보면서, 실제 로봇 제품의 개발 과정을 살펴봅시다.\n항상 로봇 시스템을 제작하기 전, 저는 부품의 수급부터 계획합니다.\n메인 PC - 라즈베리파이, 젯슨 나노, 라떼판다, 오드로이드, Mini PC, etc… MCU 보드 - 아두이노, ESP 시리즈, Teensy, Node MCU etc… Actuator - 서보/스텝 모터, BLDC 모터, (엔코더 장착 여부, 전압 고려) … Sensor - Lidar, Camera (Monocular, Stereo, RGB-D, 360도 카메라…), Lidar, Range Sensor, etc… 외관 - 알루미늄, 3D 프린팅, 절곡, 카본 플레이트, CNC 가공… 이러한 이유로 로봇 제작에는 일정 비용과 경험이 요구됩니다. 하지만 모두 피와 살이 되니 아낌없이 투자하시기 바랍니다.\nimage from : 로봇 신문 로봇 개발의 초기부터 너무 모든 것을 고려할 필요는 없습니다. 작은 사이즈의 테스트 베드를 구축하여 기능과 경험을 충분히 쌓은 뒤, 점차 하드웨어를 개선해 나가면서 업그레이드를 진행합니다.\n함께하는 개발은 언제나 즐겁습니다.\n개발을 진행하고 하드웨어를 업그레이드해가면서, CAD 파일도 함께 관리합니다. 비록 SRC는 금속 가공이 들어간 것은 아니라 비교적 간단하지만, 규모 있는 로봇 프로젝트에서는 반드시 거쳐야 하는 과정입니다. CAD 파일로부터 urdf를 추출하고, 움직이는 joint들에는 gazebo controller plugin을, 센서 joint에는 gazebo sensor plugin을 적용하여 시뮬레이션을 제작합니다. 시뮬레이션을 통해 제어기와 Odometry Driver, 자율 주행 로직의 검증이 완료되면, 실제 로봇에 이를 적용합니다. 적용과 검증을 반복하면서 로봇을 계속해서 개선해나갑니다.\n작은 팁을 이야기하자면, 발생하는 모든 기록들을 문서화하는 것을 추천드립니다. 하드웨어를 다루다보면, 방금까지 되던 기능이 갑자기 말썽을 일으켜서 하루를 날리는 날도 있습니다. 항상 모든 것을 기록합시다.\nimage from : 에누리닷컷 강의의 마지막으로, ROS / ROS 2에 대한 프로젝트들, 센서들, 도전해볼 수 있는 것들을 제시해보고자 합니다.\nTutorial \u0026amp; Courses\nawesome-ros2 : https://github.com/fkromer/awesome-ros2 ROS2 Packages on NVIDIA Jetson : https://nvidia-ai-iot.github.io/ros2_jetson/ros2-packages/ Stereo labs : Getting Started with ROS2 and ZED Micro ROS Tutorial : https://micro.ros.org/docs/tutorials/core/overview/ Self-Driving Cars with ROS 2 \u0026amp; Autoware : https://www.youtube.com/playlist?list=PLL57Sz4fhxLpCXgN0lvCF7aHAlRA5FoFr Certification\nGoogle Source of Code : https://summerofcode.withgoogle.com/ Jetson AI Ambassador : Jetson AI Courses and Certification - NVIDIA Developer Open Source Contribution\nNav2 : https://navigation.ros.org/contribute/index.html ROS 2 Control : https://control.ros.org/master/doc/project_ideas.html MoveIt : https://moveit.ros.org/documentation/contributing/ Gazebo : https://gazebosim.org/docs/all/contributing 지금까지 부족한 강의를 함께해주셔서 감사드리며, 재미있는 로봇 개발을 프로젝트를 시작하시거나, 기획하고 계신 분, 커피 한잔 하며 로봇 이야기를 나누고 싶으신 분, 언제나 환영합니다. 김수영 / Kim Soo Young\nTel : 010-8689-0259 Email : tge1375@hanyang.ac.kr / mr.swimmingkim@gmail.com "
},
{
	"uri": "/kr/advanced_contents_ros2/lecture1/",
	"title": "Lecture1 - About DDS",
	"tags": [],
	"description": "",
	"content": "About DDS ROS 1과 대두되는 가장 큰 차이점으로, ROS 2는 DDS를 미들웨어로 기반하여 개편되었습니다. 따라서 DDS에 대한 개요와 기능을 이해하는 것은 ROS 2의 성질을 파악하는 데 많은 도움이 됩니다.\nWhat is DDS? DDS - Data Distribution Service는 OMG에서 정의한 Publish-Subscribe 방식의 실시간 데이터 분배 서비스 표준입니다.\nPub-Sub이라는 용어는 ROS 개발자에게 무척 익숙한 단어이지요? DDS의 기본 통신 개념은 ROS의 Topic과 매우 유사합니다. 이러한 결론을 머리속에 잘 담아두고 계속해서 진행해 보겠습니다.\nOMG(Object Management Group)는 분산 객체 컴퓨팅(Distributed Object Computing) 영역의 표준을 제정하는 국제 비영리 컨소시엄으로 영향력 있는 각종 세계 표준을 정의하고 있습니다.\nimage from : 분산이동컴퓨팅 연구실 OMG DDS는 통신 프로토콜이 아닌 기능적 표준으로, 위 그림과 같이 TCP/UDP 같은 통신 프로토콜 위에서 정의되는 객체입니다.\n그림의 아래에서부터 OMG DDS의 구조를 간단히 살펴보겠습니다.\nRTPS(Real-Time Publish-Subscribe Wire Protocol) Layer RTPS Layer는 네트워크 내, 참여자 정보를 유지하고, 네트워크 참여자에 대한 정보를 기반으로 자동 검색을 해주며, (같은 네트워크를 사용하는 ROS 2 시스템은 서로 통신이 가능합니다.) 더불어, 참여자의 동적 추가와 이탈에 대응하는 기능을 합니다.\nRTPS는 OMG에 의해 표준화된, 데이터 분산 시스템을 위한 프로토콜로써 Pub-Sub 구조의 통신 모델을 지원합니다. UDP와 같이 신뢰성 없는 계층 위에서도 동작 가능하도록 설계되었으며, 4가지 모듈로 구성되어 있습니다.\nStructure Module : 데이터 교환 시, 통신에 참여하게 되는 개체들에 대해 정의합니다. Message Module : Writer와 Reader간 정보 교환을 위해 사용되는 메시지에 대해 정의합니다. Behavior Module : Writer와 Reader간 상태, 시간 조건에 따라 수행되어야 할 메시지 전송 절차에 대해 정의합니다. Discovery Module : 같은 도메인 상에 존재하는 개체에 대한 정보를 탐색하는 기능을 수행합니다. Discovery Module은 다음과 같이 두 가지의 RTPS 프로토콜을 사용합니다. PDP(Participant Discovery Protocol) : 서로 다른 네트워크 상에서의 Participant탐색을 위한 프로토콜 EDP(Endpoint Discovery Protocol) : Writer, Reader와 같이 서로 다른 종단점 간의 탐색 정보 교환에 사용되는 프로토콜 image from : OMG DDS(Data Distrubution Service) 기술 개요 DDS Discovery ROS 2를 사용하는 두 디바이스는 같은 네트워크를 사용하고 있다면 자동으로 서로를 인식할 수 있습니다. 어떻게 이러한 동작이 가능하며, 이를 위한 필요조건은 무엇인지 살펴보겠습니다.\nDiscovery를 위해 필요한 정보들 - DDS 미들웨어 통신을 위해 아래 4가지 정보를 사전에 교환해야 합니다.\nWho : Topic Publish 혹은 Subscribe 대상 Where : DDS 표준에서 생성한 Locator 정보 What : Publish하거나 Subscribe하려는 Topic How : Topic Publisher인지 Subscriber인지에 대한 정보 DDS RTPS도 결국 UDP나 TCP 네트워크 레이어를 사용하며, 이를 위해서 실질적으로 IP와 PORT등의 정보가 필요합니다. 하지만, DDS는 사용자가 주소를 지정하지 않아도 “Topic”만으로 통신이 가능합니다. 이를 가능하게 해주는 것이 Locator이며, 이는 Middle Ware단에서 능동적으로 통신에 필요한 정보를 포함하는 새로운 개념을 별도로 생성하는 것입니다.\nDDS 표준에서는 Discovery를 수행하는 절차를 PDP 와 EDP로 구분하고 있습니다.\nPDP(Participant Discovery Protocol) : 같은 도메인에 존재하는 서로 다른 Participant를 검색하는 절차로, Participant에 포함되어 있는 endpoint 의 정보를 검색합니다. EDP(Endpoint Discovery Protocol) : PDP를 통해 Participant가 서로를 탐지하고 나면, EDP가 수행됩니다. 표준에서는 각 프로토콜이 지원해야할 최소한의 기능을 만족하는 SPDP와 SEDP에 대해 설명하고 있습니다. vendor에 따라 다양한 PDP와 EDP를 지원할 수 있지만, 호환성을 위해 모든 RTPS는 SPDP(Simple Participant Discovery Protocol)와 SEDP(Simple Endpoint Discovery Protocol)를 필수로 지원해야합니다. 서로 다른 vendor를 가진 머신 사이에 통신이 가능한 이유이기도 합니다.\n그림을 통해 SPDP와 SEDP를 활용한 Discovery 절차에 대해 알아봅시다.\n같은 Domain을 사용하는 Participant는 생성 시, Discovery를 수행하는 3쌍의 builtin Writer와 builtin Reader, 그리고 pre-defined topic를 포함하게 됩니다. DDS가 구동되면, Participant는 Multicast로 PDP(Participant Discovery Protocol) 메시지를 주기적으로 전송하기 시작합니다. 각 Participant의 builtinParticipantWriter와 builtinPariticpantReader 사이 SPDP 교환이 이루어집니다. 전달되는 정보에는 Participant에 포함된 builtinPublicationWriter와 builtinPublicationReader의 Locator 정보가 담겨 있습니다. SPDP 교환 이후, 상대방 Participant의 정보를 통해 양측 Participant들은 서로 연결됩니다. 이후, Topic 수행을 위해 각 Participant에 Endpoint에 해당하는 Publisher와 Datawriter가 하나씩 생성됩니다. SPDP에서 교환했던 Locator정보를 바탕으로 builtinPublicationWriter는 builtiinPublicationReader에게, builtinSubscriptionWriter는 SubscriptionReader에게 Unicast를 통해 정보를 전달합니다.(SEDP를 교환하는 것입니다.) 전달되는 정보에는 topic, data type, Qos등의 정보가 포함되어 있습니다. SEDP의 결과로 Participant에 포함된 Endpoint들이 연결되고, 연결된 두 Endpoint는 동일 Topic으로 통신을 시작합니다. Discovery 과정을 한번에 정리한 그림입니다. 다시 한 번 의미를 이해하면서 과정을 복기해봅시다.\nDCPS(Data-Centric Publish-Subscribe) Layer DCPS Layer는 RTPS Layer와 Application 사이의 인터페이스 역할을 합니다. 이후 다뤄지는 Participant, Domain, Topic 등을 정의하고, Publish-Subscribe를 수행합니다. 더불어, DDS의 중요한 기능 중 하나인 QoS(Quality of Service)도 담당하고 있습니다.\n구현 측면에서, DCPS는 Data read/write API를 제공함으로 응용 프로그램들 사이 데이터를 교환할 상대에 대한 인지 없이 원하는 데이터의 송수신이 가능하게 합니다.\nimage from : OMG DDS(Data Distrubution Service) 기술 개요 DataWriter / DataReader DataWriter는 송신자, DataReader는 수신자의 역할을 합니다. DataWriter는 Sample(실제 데이터)을 생성하고 전송하는 역할을 하며, DataReader는 Sample을 수신하는 기능을 합니다. 단일 DataWriter와 DataReader는 단일 Topic만을 보유할 수 있습니다.\nPublisher 데이터 Publish를 담당하는 객체로, 하나의 Publisher는 다수의 DataWriter를 가질 수 있습니다. 때문에, 각 Publisher들은 여러 Topic 데이터를 Publish 할 수 있습니다. Publish하고자 하는 데이터 객체의 값이 Publisher에게 전해지면 Publisher는 자신에게 설정된 QoS값에 따라 연관된 Subscriber에게 전달합니다.\nSubscriber 데이터 Subscribe를 담당하는 객체로, Publisher와 유사하게 다수의 DataReader를 가질 수 있으며 여러 Topic 데이터를 수신할 수 있습니다. Subscriber가 데이터를 수신한 이후, 응용 프로그램은 DataReader를 통해 실제 데이터로 접근하는 방식입니다.\nDDS Pub-Sub의 기본 구성 요소 image from : MDS 테크 Topic\nTopic은 Publish-Subscribe의 관계를 정의하는 Key입니다. topic은 데이터 타입과 해당 데이터의 QoS에 대한 정보를 담고 있습니다. QoS를 Topic 데이터에 추가하고, Topic과 연관된 DataWriter, Datawriter에 연관된 QoS를 설정하는 식으로 제어됩니다. (Subscriber 측도 동일합니다.)\nTopic의 이름은 Domain 내에서 유일해야 합니다.\nParticipant\nParticipant는 DDS Publisher와 Subscriber를 담게 되는 객체입니다. ROS 2의 Node안에 다수의 Publisher와 Subscriber와 공존할 수 있는 것처럼, Participant도 다수의 DataWriter와 DataReader를 가질 수 있습니다.\nDomain\nDomain은 Participant들이 활동하는 영역으로, 같은 Domain을 갖는 Participant내에서만 정보전달을 할 수 있습니다. ROS 2 터미널의 실행 시 ROS_DOMAIN_ID라는 콘솔 출력이 나왔던 것을 기억하시나요?\n*************** Startup Menu for ROS *************** * Usage: To set ROS env to be auto-loaded, please * * assign ros_option in ros_menu/config.yaml * ****************************************************** 0) Do nothing 1) ROS 1 noetic 2) ROS 2 foxy 3) ROS2/ROS1_bridge Please choose an option: 2 ------------------------------------------------------ * ROS_DOMAIN_ID = 30 ------------------------------------------------------ 이렇게 DDS의 통신 구조에 대해서 알아보았습니다. 위 구조에서 실제 사용자는 Topic, Publisher, Subscriber만 구현하면 되며, DataWriter, DataReader와 RTPS, DCPS는 DDS가 알아서 처리하게 됩니다. 이러한 DDS의 장점에 기반하여 ROS 2 시스템이 올라가게 되는 것이지요.\nDDS QoS TCPROS/UDPROS라는 자체 프로토콜을 사용했던 기존 ROS 1과는 달리, ROS 2에서는 QoS 옵션을 통해 원하는 기능을 선택적으로 사용할 수 있습니다. 이는 DDS의 QoS를 도입하였기 때문으로, Publisher, Subscriber를 선언할 때, QoS를 매개변수형태로 지정하는 방식이 사용됩니다.\n상황에 따라 데이터의 신뢰성이 중요할 수도 있고, 버퍼의 크기를 크게 하여 Topic의 안정성을 높여야 할 수도 있습니다. 이러한 통신의 품질을 옵션화하기 위해서, DDS에서는 아래와 같은 22가지의 QoS를 정의하고 있습니다.\n각각의 QoS 옵션은 연관된 조합으로 Topic, DataWriter, DataReader, Publisher, Subscriber, Domain, Participant에 적용되며, 본 세션에서는 주로 사용되는 QoS를 위주로 살펴보고자 합니다.\nRELIABILITY: 데이터 통신의 신뢰성 레벨(재전송 여부)을 결정하며 두 가지 속성을 설정 할 수 있습니다. RELIABLE : DataWriter History에 있는 모든 샘플들이 DataReader에 전달되는 것을 보장합니다. BEST_EFFORT : 통신 시 손실된 데이터 샘플을 재전송 하지 않고, 전달된 데이터의 순서는 유지 합니다. 알파벳은 다음과 같은 의미를 갖습니다. T : TOPIC, DR : DataReader, DW : DataWriter, P : Publisher, S : Subscriber\nRxO는 Requested/Offered의 약자로 QoS가 적용되는 대상을 Publisher(발간/송신) 측과 Subscriber(구독/수신) 측으로 구분해서 서로의 상관관계를 표현하는 방법입니다.\n‘YES’ : Publisher 측과 Subscriber 측 모두 QoS가 적용되어야 하고, 설정된 QoS 값이 호환되어야 한다. ‘NO’ : Publisher 측과 Subscriber 측 모두 QoS 가 적용되어야 하지만, 설정된 QoS 값은 서로 독립적이다. ‘N/A’ : Publisher 측과 Subscriber 측 중 한 측에만 적용되어야 한다. Changeable이 ‘YES’ 일 경우에는, 동작하면서도 QoS 의 값이 변경될 수 있지만, ‘NO’일 경우에는 처음 생성된 이후에는 변경할 수 없습니다.\nHISTORY : 데이터의 재전송을 위해 HistoryCache내 데이터 보관 방법을 결정하며 두 가지 속성을 설정 할 수 있습니다. KEEP_LAST : Depth(History Cache안에 유지하고 있을 데이터 개수) 크기 만큼 최신 데이터를 유지 합니다. KEEP_ALL : DataReader에게 인스턴스의 모든 값들을 유지하고 전송 합니다. DURABILITY : 나중에 참여한 DataReader에게 이전 데이터를 전송할지 여부를 결정 하며 네 가지 속성을 설정 할 수 있습니다. VOLATILE : 연결이 설정 된 이후의 데이터만 제공 합니다. TRANSIENT LOCAL : DataWriter 생명주기와 일치 일치합니다. TRANSIENT : DataReader에 과거 데이터를 제공 합니다. PERSISTENT : Permanent-Storage에 과거 데이터를 저장하며, 데이터의 유효성은 System 보다 오래 지속 됩니다. OWNERSHIP : 다수의 DataWriter가 동일한 인스턴스를 갱신하게 허용할지를 결정합니다. SHARED : 다수의 DataWriter들이 동일한 데이터 인스턴스 업데이트가 가능합니다. EXCLUSIVE : 데이터 객체의 각 인스턴스는 하나의 DataWriter에 의해서만 수정 가능합니다. PARTITION : Domain 내부에서 Node들을 분리하는 방법을 결정 합니다. (Domain 내에서 별도의 논리적인 통신 채널 형성) - Partition Name이 같은 DataWriter/DataReader간 데이터 배포 가 가능합니다. Partition과 Domain의 차이 - 다른 Domain들에 속하는 개체들은 완전히 서로 독립 된 상태입니다. Entity는 다수의 Partition에 있을 수 있지만 하나의 Domain에만 속할 수 있습니다.\nDEADLINE : 데이터 샘플 사이의 최대 도착 시간을 정의할 수 있습니다. DataWriter는 DEADLINE(period:Duration_t)이 설정된 시간 안에 적어도 한번 이상의 데이터를 전송합니다. DataReader는 DEADLINE(period:Duration_t) 시간 안에 DataWriter로부터 데이터를 받지 못하면 DDS로부터 위반 통보를 받습니다. TIME_BASED_FILTER : DataReader 가 데이터를 필터링 하는 시간을 결정 합니다. Minimum_separation: Duation_t 값을 설정하여 DataReader는 이 값 이내에 수신한 데이터는 삭제 합니다. ROS 2에서는 자주 사용되는 QoS 조합을 묶어 RMW QoS Profile이라는 이름으로 제공하고 있습니다. 지금까지 우리가 queue_size만을 전달하고 있었지만, 사실은 아래 사진의 Default에서 Depth만 바꿔주고 있었던 것입니다.\nimage from : 오로카 ros2에서 QoS 설정하는 방법은 매우 간단합니다. Publisher, Subscriber 클래스를 생성하면서 QoS 옵션을 매개변수로 전달하면 됩니다.\npython example - RMW QoS Profile 사용 시 from rclpy.qos import qos_profile_sensor_data self.string_publisher = self.create_publisher(String, \u0026#39;qos_test_topic\u0026#39;, qos_profile_sensor_data) python example - 직접 Profile 설정 시 from rclpy.qos import QoSDurabilityPolicy from rclpy.qos import QoSHistoryPolicy from rclpy.qos import QoSProfile from rclpy.qos import QoSReliabilityPolicy my_profile = QoSProfile( reliability=QoSReliabilityPolicy.BEST_EFFORT, history=QoSHistoryPolicy.KEEP_LAST, depth=10, durability=QoSDurabilityPolicy.VOLATILE ) self.string_publisher = self.create_publisher(String, \u0026#39;qos_test_topic\u0026#39;, my_profile) =\u0026gt; 참고 링크 : rclpy/qos.py\ntopic 통신이 이루어지고 있는 상황에서, QoS 옵션을 보고 싶다면 Topic 커멘드에 verbose 옵션을 추가하면 됩니다. # Terminal 1 - publisher $ ros2 run py_topic_tutorial qos_example_publisher # Terminal 2 - subscriber $ ros2 run py_topic_tutorial qos_example_subscriber # Terminal 3 - topic info $ ros2 topic info /qos_test_topic --verbose Type: std_msgs/msg/String Publisher count: 1 Node name: twist_pub_node Node namespace: / Topic type: std_msgs/msg/String Endpoint type: PUBLISHER GID: 60.77.10.01.f3.67.78.3d.6b.0c.cc.7b.00.00.14.03.00.00.00.00.00.00.00.00 QoS profile: Reliability: RMW_QOS_POLICY_RELIABILITY_BEST_EFFORT Durability: RMW_QOS_POLICY_DURABILITY_VOLATILE Lifespan: 9223372036854775807 nanoseconds Deadline: 9223372036854775807 nanoseconds Liveliness: RMW_QOS_POLICY_LIVELINESS_AUTOMATIC Liveliness lease duration: 9223372036854775807 nanoseconds Subscription count: 1 Node name: string_sub_node Node namespace: / Topic type: std_msgs/msg/String Endpoint type: SUBSCRIPTION GID: d2.03.10.01.d5.6b.69.e0.be.3f.b5.a2.00.00.14.04.00.00.00.00.00.00.00.00 QoS profile: Reliability: RMW_QOS_POLICY_RELIABILITY_BEST_EFFORT Durability: RMW_QOS_POLICY_DURABILITY_VOLATILE Lifespan: 9223372036854775807 nanoseconds Deadline: 9223372036854775807 nanoseconds Liveliness: RMW_QOS_POLICY_LIVELINESS_AUTOMATIC Liveliness lease duration: 9223372036854775807 nanoseconds DDS QoS는 RxO - requested by offered 특성을 갖고 있어 서로 양립할 수 없는 조합이 존재합니다. 예를 들어, Publish의 Reliability가 BEST_EFFORT일때, Subscriber의 Reliability가 RELIABLE라면, Topic 통신이 발생할 수 없습니다.\n코드를 수정하여 직접 실습해봅시다. qos_example_publisher.py qos_example_subscriber.py my_profile = QoSProfile( reliability=QoSReliabilityPolicy.BEST_EFFORT, history=QoSHistoryPolicy.KEEP_LAST, depth=10, durability=QoSDurabilityPolicy.VOLATILE ) ... self.string_publisher = self.create_publisher(String, \u0026#39;qos_test_topic\u0026#39;, qos_profile_sensor_data) my_profile = QoSProfile( reliability=QoSReliabilityPolicy.RELIABLE, history=QoSHistoryPolicy.KEEP_LAST, depth=10, durability=QoSDurabilityPolicy.VOLATILE ) ... self.pose_subscriber = self.create_subscription( String, \u0026#39;qos_test_topic\u0026#39;, self.sub_callback, my_profile ) 코드 변경 후 실행 - Warning과 함께 Subscriber가 동작하지 않음을 알 수 있습니다. $ ros2 run py_topic_tutorial qos_example_publisher [WARN] [1673945160.449603592] [twist_pub_node]: New subscription discovered on this topic, requesting incompatible QoS. No messages will be sent to it. Last incompatible policy: RELIABILITY_QOS_POLICY $ ros2 run py_topic_tutorial qos_example_subscriber [WARN] [1673945160.455319911] [string_sub_node]: New publisher discovered on this topic, offering incompatible QoS. No messages will be received from it. Last incompatible policy: RELIABILITY_QOS_POLICY QoS를 통해 원하는 도메인에서의 성능을 끌어올리고 안정성을 갖춘 시스템을 구축합시다.\n⇒ 다음 페이지에서 계속됩니다.\n"
},
{
	"uri": "/kr/advanced_contents_ros2/lecture2/",
	"title": "Lecture11 - About DDS (2)",
	"tags": [],
	"description": "",
	"content": "DDS의 IDL DDS에서는 특정 언어에 의존적이지 않는 데이터 통신을 위해 IDL을 사용합니다.\nIDL - Interface Description Language 또는 Interface Definition Language는 어느 한 언어에 국한되지 않는 언어중립적인 방법으로 인터페이스를 표현함으로써, 같은 언어를 사용하지 않는 컴포넌트 사이의 통신을 가능하게 합니다.\nOMG의 Interface Definition Language Version 3.5에 따른 사용 가능한 키워드들은 아래와 같습니다. image from : MDS 테크 ROS 2에서는 interface라는 이름으로 topic message, service srv, action action이 사용되었지요. 이들이 모두 IDL 타입을 갖기 때문에 rclpy, rclcpp, rcljava 모두에서 사용할 수 있는 것입니다.\ncustom interface를 빌드하게 되면, 해당 패키지 내부에 생성된 IDL들을 확인할 수 있습니다. build 폴더 내부 패키지 폴더에 진입하면 사진과 같이 다양한 언어를 지원하기 위한 설정 파일들이 위치하는 것을 확인 가능합니다.\nrosidl_generator_py__arguments.json { \u0026#34;package_name\u0026#34;: \u0026#34;custom_interfaces\u0026#34;, \u0026#34;output_dir\u0026#34;: \u0026#34;/home/kimsooyoung/ros2_ws/build/custom_interfaces/rosidl_generator_py/custom_interfaces\u0026#34;, \u0026#34;template_dir\u0026#34;: \u0026#34;/opt/ros/foxy/share/rosidl_generator_py/cmake/../resource\u0026#34;, \u0026#34;idl_tuples\u0026#34;: [ \u0026#34;/home/kimsooyoung/ros2_ws/build/custom_interfaces/rosidl_adapter/custom_interfaces:action/Parking.idl\u0026#34;, \u0026#34;/home/kimsooyoung/ros2_ws/build/custom_interfaces/rosidl_adapter/custom_interfaces:srv/CircleTurtle.idl\u0026#34;, \u0026#34;/home/kimsooyoung/ros2_ws/build/custom_interfaces/rosidl_adapter/custom_interfaces:srv/TurtleJail.idl\u0026#34; ], \u0026#34;ros_interface_dependencies\u0026#34;: [ \u0026#34;action_msgs:/opt/ros/foxy/share/action_msgs/msg/GoalInfo.idl\u0026#34;, \u0026#34;action_msgs:/opt/ros/foxy/share/action_msgs/msg/GoalStatus.idl\u0026#34;, \u0026#34;action_msgs:/opt/ros/foxy/share/action_msgs/msg/GoalStatusArray.idl\u0026#34;, \u0026#34;action_msgs:/opt/ros/foxy/share/action_msgs/srv/CancelGoal.idl\u0026#34;, \u0026#34;builtin_interfaces:/opt/ros/foxy/share/builtin_interfaces/msg/Duration.idl\u0026#34;, \u0026#34;builtin_interfaces:/opt/ros/foxy/share/builtin_interfaces/msg/Time.idl\u0026#34;, \u0026#34;unique_identifier_msgs:/opt/ros/foxy/share/unique_identifier_msgs/msg/UUID.idl\u0026#34; ], ... 생성된 IDL 파일 내부를 함께 살펴봅시다. custom_interfaces ⇒ rosidl_adapter ⇒ custom_interfaces ⇒ action 폴더 내부에 위치한 Parking.idl은 아래와 같은 IDL 형태를 띄고 있습니다.\nParking.idl // generated from rosidl_adapter/resource/action.idl.em // with input from custom_interfaces/action/Parking.action // generated code does not contain a copyright notice module custom_interfaces { module action { @verbatim (language=\u0026#34;comment\u0026#34;, text= \u0026#34;goal definition\u0026#34;) struct Parking_Goal { boolean start_flag; }; struct Parking_Result { @verbatim (language=\u0026#34;comment\u0026#34;, text= \u0026#34;result definition\u0026#34;) string message; }; struct Parking_Feedback { @verbatim (language=\u0026#34;comment\u0026#34;, text= \u0026#34;feedback definition\u0026#34;) float distance; }; }; }; DDS RTPS 패킷 확인해보기 (wireshark) DDS RTPS의 well-know UDP/IP\ndiscovery과정에서 participant는 미리 정의된 rule에 따라 address와 port를 사용합니다. SPDP에서는 multicast의 address로 239.255.0.1 을 사용하고 아래와 같은 port 설정 rule을 따릅니다.\n=\u0026gt; 따라서, wireshark 실행 시 destination option을 239.255.0.1로 설정합니다.\nip.dst == 239.255.0.1 Publisher와 Subscriber는 서로의 Participant와 Endpoint를 찾고, 주기적으로 HEARBEAT와 ACKNACK를 주고받습니다. 이번에는 ROS 2 Publisher와 Subscriber를 실행시켜 보고 이들 사이 데이터를 주고받는 과정에서 RTPS 프로토콜이 어떻게 동작하는지, 패킷의 분석을 진행해보겠습니다.\n터미널을 실행하여 topic publisher를 실행합니다. $ ros2 run examples_rclcpp_minimal_publisher publisher_member_function [INFO] [1673789194.561595897] [minimal_publisher]: Publishing: \u0026#39;Hello, world! 0\u0026#39; [INFO] [1673789195.061600207] [minimal_publisher]: Publishing: \u0026#39;Hello, world! 1\u0026#39; [INFO] [1673789195.561601140] [minimal_publisher]: Publishing: \u0026#39;Hello, world! 2\u0026#39; [INFO] [1673789196.061605037] [minimal_publisher]: Publishing: \u0026#39;Hello, world! 3\u0026#39; [INFO] [1673789196.561602313] [minimal_publisher]: Publishing: \u0026#39;Hello, world! 4\u0026#39; ... publisher node가 일정 시간마다 multicast로 RTPS DATA(p)를 송신하는 모습을 확인할 수 있습니다. Publish하는 DATA(p)에는 DEFAULT_UNITCAST_LOCATOR, DEFAULT_MULTICAST_LOCATOR, METATRAFFIC_UNICAST_LOCATER, METATRAFFIC_MUTICAST_LOCATOR정보 등 particiapnt에 대한 정보가 담겨 있습니다.\n더불어 현재 사용하고 있는 Domain ID는 30번이기 때문에, 14900포트를 Discovery Multicast Port로 사용하게 됩니다.\ntopic sublisher를 실행하고 다시 패킷을 수집합니다. $ ros2 run examples_rclcpp_minimal_subscriber subscriber_member_function [INFO] [1673790688.700183037] [minimal_subscriber]: I heard: \u0026#39;Hello, world! 1199\u0026#39; [INFO] [1673790689.200236939] [minimal_subscriber]: I heard: \u0026#39;Hello, world! 1200\u0026#39; [INFO] [1673790689.700209001] [minimal_subscriber]: I heard: \u0026#39;Hello, world! 1201\u0026#39; [INFO] [1673790690.200257339] [minimal_subscriber]: I heard: \u0026#39;Hello, world! 1202\u0026#39; [INFO] [1673790690.700230772] [minimal_subscriber]: I heard: \u0026#39;Hello, world! 1203\u0026#39; ... 패킷 초반부 publisher node와 subscriber node는 사이의 정보 교환(PDP)을 확인할 수 있습니다. subscribe node의 등록과, reader/writer Entity 사이 PDP가 교환되며, Data(w)는 publisher의 정보, Data(r)은 subscriber의 정보를 담고 있습니다. PDP 이후 EDP는 데이터 타입 등 Topic에 대한 정보, QoS Profile등 많은 정보를 담고 있기 때문에 수차례 패킷 전송이 오고갑니다. topic info verbose option을 사용하여 topic에 대한 정보와 패킷 정보를 비교해봅시다.\n$ ros2 topic info /topic --verbose Type: std_msgs/msg/String Publisher count: 1 Node name: minimal_publisher Node namespace: / Topic type: std_msgs/msg/String Endpoint type: PUBLISHER GID: f9.f7.10.01.2b.c5.e1.c7.cd.59.7c.2a.00.00.15.03.00.00.00.00.00.00.00.00 QoS profile: Reliability: RMW_QOS_POLICY_RELIABILITY_RELIABLE Durability: RMW_QOS_POLICY_DURABILITY_VOLATILE Lifespan: 9223372036854775807 nanoseconds Deadline: 9223372036854775807 nanoseconds Liveliness: RMW_QOS_POLICY_LIVELINESS_AUTOMATIC Liveliness lease duration: 9223372036854775807 nanoseconds ... PDP와 EDP가 모두 끝나면, Publisher는 자신과 매칭 된 Subscriber에게 Topic을 Publish를 진행합니다. 주기적으로 아래 두 종류의 패킷이 반복되는 것을 확인 가능합니다. publisher의 DATA와 HEARTBEAT 패킷 subscriber의 HEARTBEAT 수신 및 ACKNACK 송신 패킷 ROS 2 Domain ID DDS 시간 살펴본 바와 같이 각 DDS Participant들은 특정 Domain에 속하게 됩니다. 기본적으로 ROS 2에서는 Domain ID 0을 사용하고 있으며, 같은 Domain ID를 사용하는 Participant들 사이에서만 Discovery와 통신이 가능합니다.\n이번 시간에는 ROS 2의 Domain ID를 수정해보고, Domain ID를 설정할 시 주의해야 할 점들에 대해서도 알아보겠습니다.\n우선, 예시를 통해 서로 다른 Domain ID를 갖는 Participant들을 실행해봅시다. # Ternimal 1 ros2 topic pub -r 1 /string_topic std_msgs/String \u0026#34;{data: \\\u0026#34;Hello from my 2ND domain\\\u0026#34;}\u0026#34; # Terminal 2 ROS_DOMAIN_ID=1 ros2 topic list # Terminal 3 ros2 topic list 예시 결과에서 알 수 있듯이 통신을 위해서는 같은 Domain ID를 갖는 조건이 필수적입니다. $ ros2 topic list /parameter_events /rosout /string_topic Domain ID는 환경변수를 통해 변경할 수 있습니다. 터미널의 실행 시 Domain ID를 자동 적용하기 위해 ~/.bashrc를 수정하거나 config.yaml을 수정하시면 됩니다. export ROS_DOMAIN_ID=\u0026lt;your_domain_id\u0026gt; or # edit ~/ros_menu/config.yaml Config: menu_enable: true ros_option: menu default_ros_domain_id: 30 Menu: ... ROS 2 foxy: option_num: 2 ROS_version: 2 distro_name: foxy ros2_path: /opt/ros/foxy domain_id: # set if you don\u0026#39;t want to use default domain id cmds: DDS는 Domain ID를 사용하여 Participant들이 사용할 UDP Port를 지정합니다. Port가 계산되는 방법은 아래와 같으며, 링크를 참고합니다. - 추가 링크 ROS 2 공식 문서에서는 Domain ID와 Participant 순서에 따라 사용되는 포트 번호를 계산해주는 계산기를 제공하고 있습니다. 이를 통해 최대 가질 수 있는 Domain ID와 Participant 수를 확인해 보겠습니다. - 공식 문서 링크 Domain ID 설정 시 고려해야 할 요소들은 다음과 같습니다.\n각 OS 별로 침범하면 안되는 포트 영역이 있습니다. (Linux - 32768-60999 / Windows \u0026amp; macOS - 49152-65535) 각 Participant당 2개의 Unicast Port를 사용합니다. 따라서, 하나의 Domain ID에서 사용할 수 있는 최대 Participant의 수는 120개 입니다. (ROS 2는 하나의 프로세스에서 여러 Node를 실행할 수 있기 때문에 Node를 120개까지 사용할 수 있는 것은 아닙니다.) 이러한 이유로 ROS 2 공식 문서에서는 0-101 사이의 Domain ID를 사용하기를 권장하고 있습니다.\nROS RMW와 다양한 DDS 벤더들 DDS 자체는 산업 표준이다보니 다양한 벤더들에서 제공되고 있습니다. ROS 2 설치 시 자동으로 Fast DDS가 사용되지만, 아래 표와 같이 다양한 DDS 벤더들이 존재하고 있습니다.\n이렇게 다양한 DDS 벤더들에 맞추기 위해 ROS 2는 RMW(“ROS MiddleWare interface”)라는 패키지들을 제공합니다. 다른 벤더의 DDS를 사용하게 되면, 이 RMW를 바꿔줘야 하는 것입니다.\nProduct name License RMW implementation Status eProsima Fast DDS Apache 2 rmw_fastrtps_cpp Full support. Default RMW. Packaged with binary releases. Eclipse Cyclone DDS Eclipse Public License v2.0 rmw_cyclonedds_cpp Full support. Packaged with binary releases. RTI Connext commercial, research rmw_connext_cpp Full support. Support included in binaries, but Connext installed separately. GurumNetworks GurumDDS commercial rmw_gurumdds_cpp Community support. Support included in binaries, but GurumDDS installed separately. 오픈소스인 Fast DDS, Cyclone DDS는 무료이지만, 더 좋은 성능을 위해서는 rti와 같은 유료 서비스를 사용하시기 바랍니다.\napt를 통해 손쉽게 rmw를 설치할 수 있습니다. $ sudo apt install ros-foxy-rmw ros-foxy-rmw ros-foxy-rmw-fastrtps-dynamic-cpp ros-foxy-rmw-connext-cpp ros-foxy-rmw-fastrtps-dynamic-cpp-dbgsym ros-foxy-rmw-connext-cpp-dbgsym ros-foxy-rmw-fastrtps-shared-cpp ros-foxy-rmw-connext-shared-cpp ros-foxy-rmw-fastrtps-shared-cpp-dbgsym ros-foxy-rmw-connext-shared-cpp-dbgsym ros-foxy-rmw-gurumdds-cpp ros-foxy-rmw-cyclonedds-cpp ros-foxy-rmw-gurumdds-cpp-dbgsym ros-foxy-rmw-cyclonedds-cpp-dbgsym ros-foxy-rmw-gurumdds-shared-cpp ros-foxy-rmw-dbgsym ros-foxy-rmw-gurumdds-shared-cpp-dbgsym ros-foxy-rmw-dds-common ros-foxy-rmw-implementation ros-foxy-rmw-dds-common-dbgsym ros-foxy-rmw-implementation-cmake ros-foxy-rmw-fastrtps-cpp ros-foxy-rmw-implementation-dbgsym ros-foxy-rmw-fastrtps-cpp-dbgsym ROS 2 시스템 상에서 사용하는 DDS 벤더를 바꾸는 것은 환경변수를 설정하는 것으로 손쉽게 진행할 수 있습니다. (해당 DDS와 RMW가 설치되어 있다는 가정 하에) 더불어, 서로 다른 벤더의 DDS를 사용하고 있더라도 DDS 표준(SPDP와 SEDP)을 따르고 있다면 상호 통신이 가능합니다.\nExample - Fast DDS \u0026lt;\u0026gt; Cyclone DDS 상호간 Topic 통신 $ export RMW_IMPLEMENTATION=rmw_cyclonedds_cpp $ ros2 run demo_nodes_cpp listener [INFO]: I heard: [Hello World: 1] [INFO]: I heard: [Hello World: 2] [INFO]: I heard: [Hello World: 3] $ export RMW_IMPLEMENTATION=rmw_fastrtps_cpp $ ros2 run demo_nodes_cpp talker [INFO]: Publishing: \u0026#39;Hello World: 1\u0026#39; [INFO]: Publishing: \u0026#39;Hello World: 2\u0026#39; [INFO]: Publishing: \u0026#39;Hello World: 3\u0026#39; 예시의 실행에서 지연이 발생함으로 알 수 있듯이, 실제 제품을 제작할 때는 사용하는 RMW를 통일시켜주는 것을 추천합니다.\n강의 개발환경에서 제공하는 설치 튜토리얼을 따라오셨다면 config.yaml 파일을 수정함으로 손쉽게 DDS Vendor를 변경하실 수 있습니다. $ gedit ~/ros_menu/config.yaml ROS 2 foxy: option_num: 2 ROS_version: 2 distro_name: foxy ros2_path: /opt/ros/foxy domain_id: # set if you don\u0026#39;t want to use default domain id cmds: # - source ${HOME}/ros2_ws/install/local_setup.${shell} - source_plugin dds_bashrc 1 # - source_plugin openvino_bashrc 제공되는 기본 DDS Vendor들은 아래와 같습니다.\nNumber DDS Vendor 0 Show Menu 1 Eclipse Cyclone DDS 2 OpenSplice 3 FastRTPS dds_bashrc를 0으로 수정한 다음 새로운 터미널을 실행시키면, 아래와 같이 DDS를 선택하는 옵션이 등장합니다. 0) Do nothing 1) ROS 1 noetic 2) ROS 2 foxy 3) ROS2/ROS1_bridge Please choose an option: 2 ------------------------------------------------------ * ROS_DOMAIN_ID = 0 ------------------------------------------------------ source /home/kimsooyoung/.ros_menu/plugins_bashrc/dds_bashrc 0 **** Choose DDS you want to use **** 1) Eclipse Cyclone DDS 2) OpenSplice CE 3) FastRTPS Please choose an option 1-3: 참고자료\nMDS테크 로봇 운영체제 강좌 community.rti.com docs.ros.org https://github.com/ADLINK-IST/opensplice "
},
{
	"uri": "/kr/ros_basic_noetic/lecture1/",
	"title": "Lecture1 - Introduction to ROS",
	"tags": [],
	"description": "",
	"content": "What is ROS? ROS란, 로봇 소프트웨어 개발에 사용되는 일종의 프레임워크입니다.\n프레임워크라는 말은, ROS 나름대로의 실행 시나리오를 갖고 있다는 뜻입니다.\n사용자인 우리들은, 이 시나리오를 사용하여 로봇을 다루는 우리만의 Application을 만들게 됩니다.\nimage from : wikimedia 그런데 왜 OS라는 이름이 붙게 되었을까요?\n로봇을 실행하기 위해서, 수많은 프로그램들이 실행되며, ROS는 이들 사이의 우선순위와, 프로그램 사이의 데이터 흐름을 책임집니다. 이 작업은 스케쥴링이라고 불리며, 이러한 동작을 수행하는 시스템을 Operating System이라고 부르기 때문에 ROS라는 이름을 갖게 되었습니다.\nimage from : tutorialspoint 로봇을 개발하기 위해서 어떠한 프로그램들이 필요할까요?\n로봇이 수행하는 임무들을 크게 3가지로 분류하면 인지, 판단, 제어의 3가지로 나뉩니다.\n인지란, 센서들을 통한 물체 인지, 자기 자신의 위치와 방향 인지, 상황 인지 등 로봇에게 있어 환경과 상호작용하는 과정에 해당합니다. 판단이란, 앞/뒤로 움직일지, 로봇 팔을 뻗을지와 같이 인지를 기반으로 얻은 데이터를 통해 결정을 내리는 작업들이 해당할 것입니다. 제어는 로봇에서 빼놓을 수 없는 영역으로, 로봇은 실제 세상에서 움직이기 때문에, 얼마나 움직일지, 어느정도의 속도로 힘은 얼마나 강하게 줄지 등 물리적인 임무를 포함합니다. 이렇게 로봇 시스템은 무척 복잡하며, 이뿐만 아니라 회로, 설계, 재료, 에너지 등을 고려해야 하는 완성품 로봇은 현대 공학의 집합 그 자체라고 말할 수 있습니다.\nAbout this lecture 이 강의에서 다루고자 하는 부분을 정확히하자면, 인지도 판단도 제어도 아닌, 시스템입니다.\n로봇의 센서, 구동부, 알고리즘이 모두 준비되어 있는 상황에서, 이들을 하나의 시스템으로 엮어주는 역할을 하는 것이 바로 ROS입니다.\nimage from : ROS Industrial ROS라는 시스템의 특성상 정해진 코드와 방법으로 소프트웨어를 개발해야 하며, 대부분 ROS를 다루는 강의라고 하면 이를 지칭합니다. 우리가 배우고자 하는 주된 내용도 바로 이 부분이라고 말할 수 있습니다.\nROS 개념 ROS 커멘드 다루기 ROS 프로그래밍 - Topic, Service, Action etc… 하지만, 여기서 그치지 않고, 저는 좀 더 실질적인 로봇 개발을 이야기하고자 합니다.\n리눅스 시스템 Docker 사용하기 로봇 시뮬레이션 라이브 코딩과 에러 디버깅 학교를 다니다 보면 아무리 많은 이론을 공부하고 머릿속에 집어넣어도, 시험을 치고 나면 모두 사라지곤 합니다. 머리 속에 남는 공부를 위해서는 직접 코딩을 해보고, 프로젝트를 진행해봐야 합니다.\n강의를 수강하기 위해 필요한 선수지식 본 강의는 최대한 많은 분들이 끝까지 이해할 수 있도록 설계되었습니다. 따라서, 최대한 쉽고, 프로그래밍 실력이 출중하지 않아도 모두 완강할 수 있게 진행합니다. 하지만 그럼에도, 아래 코드를 이해할 수 있을 정도의 배경지식은 필요합니다. class OOPNode: def __init__(self): self.counter_ = 0 def hello_du(self, event=None): hello_du = f\u0026#34;hello du {rospy.get_time()}, counter: {self.counter_}\u0026#34; print(hello_du) self.counter_ += 1 def my_first_oop_node(): oop_node = OOPNode() if __name__ == \u0026#39;__main__\u0026#39;: try: my_first_oop_node() except Exception as e: print(e) 파이썬 클래스, 메소드와 인스턴스 for, while, if/else 등 기본 문법 강의 코드와 강의 노트 사용법 강의 도중 사용되는 코드들은 Github Repository를 통해 배포되어 있습니다. 코드 강의 중 지속해서 링크를 해드리며, 강의 시작 전 미리 살펴보시면 더욱 좋습니다.\nhttps://github.com/RB2023ROS/du2023-ros1 강의 노트의 주소는 https://rb2023ros.github.io/kr/ 입니다. 코드와 명령어 등 필요한 리소스를 모두 담고 있으므로 복사/붙여넣기를 활용하여 강의 청취 시간을 절약하시기 바랍니다.\n참고로 해당 노트는 hugo를 사용하여 제작된 웹 페이지임을 밝힙니다.\n"
},
{
	"uri": "/kr/ros_basic_noetic/lecture2/",
	"title": "Lecture2 - Dev Env Setup",
	"tags": [],
	"description": "",
	"content": "Develpoment Environment Setup 프로젝트 기반의 강의인 만큼, 개발 환경이 구축되지 않으면 앞으로의 실습을 진행할 수 없습니다. 따라서 이번 파트에 많은 시간을 배정하였고, 힘들 수 있지만 끝까지 따라와주시면 감사합니다.\n준비한 환경은 다음과 같습니다.\nUbuntu Linux 설치와 ROS 설정 wsl2를 기반으로 한 Windows 내 ROS 설정 Docker 기반의 ROS 설정 1,2,3 순서로 추천하는 설정입니다. 1번을 진행하시다가 도저히 못하겠으면 2번으로, 그래도 안되면 3번으로 진행해 주시면 됩니다.\nUbuntu Linux 설치와 ROS 설정 Linux라고 함은 사실 OS 자체라기보다 OS의 기초가 되는 코어 소프트웨어에 가깝습니다. 이 코어를 사용하여 여러 버전의 OS가 개발되었으며 이를 Liunx 배포판 이라고 지칭합니다.\nUbuntu Linux는 리눅스 배포판 중 가장 널리 알려진 배포판으로, 영국의 Software회사인 Canonical과 우분투 재단에서 개발, 유지보수 및 배포를 하고 있습니다.\nimage from : omdriod.com 기존의 Windows 노트북을 사용하고 있었다면 듀얼 부팅이라는 것을 통해 Ubuntu + Windows를 모두 사용 가능합니다. 듀얼 부팅에 방법에 대해선 잘 설명한 영상들이 많으므로 링크로 대체하겠습니다.\nHow to Dual Boot Ubuntu 20.04 LTS and Windows 10 How to Dual Boot Ubuntu and Windows 11 Ubuntu 20.04 설치를 확인 하셨다면 터미널을 실행한 뒤 아래의 명령어들을 실행합니다.\nterminator 설치 sudo apt update sudo apt install terminator -y terminator 화면 분할 예시\nctrl + alt + t : 터미널 실행 ctrl + shift + e : 세로 분할 ctrl + shift + o : 가로 분할 ctrl + shift + w : 창 닫기 alt + 화살표 : 창 간 이동 ROS / ROS 2 한줄 설치 cd ~/ sh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/kimsooyoung/ros_menu/main/scripts/setup.sh)\u0026#34; … Do you want to install ROS automatically? (y/N): y 다음으로, 시뮬레이션 프로그램인 Gazebo를 설치합니다. Gazebo는 ROS를 관리하는 조직인 OSRF에서 공식 지원하는 로봇 시뮬레이터입니다.\nsudo sh -c \u0026#39;echo \u0026#34;deb http://packages.osrfoundation.org/gazebo/ubuntu-stable `lsb_release -cs` main\u0026#34; /etc/apt/sources.list.d/gazebo-stable.list\u0026#39; wget https://packages.osrfoundation.org/gazebo.key -O - | sudo apt-key add - sudo apt update sudo apt install gazebo11 libgazebo11-dev -y sudo apt install ros-foxy-gazebo-ros-pkgs -y 그림와 같이 Gazebo의 화면이 어둡고, 그림자가 보이지 않는다면 호환되는 그래픽 드라이버를 설치해야 합니다.\nsudo ubuntu-drivers autoinstall sudo reboot # 장착된 장치 확인 ubuntu-drivers devices 마지막으로, catkin build system을 사용하기 위해 아래 커멘드 명령어를 실행합니다.\nsudo apt update sudo apt install python3-catkin-tools Windows + WSL2 설정 WSL(Windows Subsystem for Linux) 이란, 리눅스용 윈도우 하위 시스템의 약자로, 윈도우 10에서 네이티브로 리눅스 실행 파일(ELF)을 실행하기 위한 호환성 계층입니다.\nWindows10부터 WSL을 지원하며, Windows 2004(20H1) version부터 WLS2를 지원하고 있습니다.\n최신 Windows 업데이트 적용 (\u0026ldquo;Windows Key ⇒ 업데이트\u0026quot;로 이동하여 최신 업데이트를 적용합니다.) powershell을 관리자 권한으로 실행한 뒤, 설치 되어있는 WSL 2를 활성화시킵니다. \u0026gt; dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart 배포 이미지 서비스 및 관리 도구 버전: 10.0.19041.844 이미지 버전: 10.0.19043.1348 기능을 사용하도록 설정하는 중 [==========================100.0%==========================] 작업을 완료했습니다. \u0026gt; dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 배포 이미지 서비스 및 관리 도구 버전: 10.0.19041.844 이미지 버전: 10.0.19043.1348 기능을 사용하도록 설정하는 중 [==========================100.0%==========================] 작업을 완료했습니다. MS Store로 이동하여 windows terminal을 설치합니다. windows terminal 화면 분할 예시 alt + shift + - : 가로 분할 alt + shift + + : 세로 분할 ctrl + shift + w : 창 닫기 alt + 화살표 : 창 간 이동 다음 링크를 통해 프로그램을 다운받고 WSL 2 Linux 커널 업데이트를 설치/진행 후 재부팅합니다.\n커널 업데이트를 마친 다음, powershell에 아래 커맨드 라인을 입력하여 WSL 2를 기본 사용하도록 설정합니다.\n\u0026gt; wsl --set-default-version 2 WSL 2와의 주요 차이점에 대한 자세한 내용은 https://aka.ms/wsl2를 참조하세요 작업을 완료했습니다. 이 시점에서 발생할 수 있는 문제들을 한차례 살펴보고 가겠습니다.\nwsl --set-default-version 2 에서 작업 완료 메세지가 등장하지 않는 경우 ⇒ 제일 처음 명령어부터 제가 보여드린 예시와 동일한 결과를 얻었는지 확인해보세요\nLinux용 Windows 하위 시스템 설정 여부도 확인합니다.\n지금까지 진행한 작업들이 제대로 설정 되어있는지 확인해봅시다. \u0026gt; wsl -l -v NAME STATE VERSION * Ubuntu-20.04 Running 2 문제가 없다면 MS Store 진입 후, Ubuntu 20.04 버전을 설치합니다. 설치 이후, 열기 버튼을 눌러 초기 실행을 하고 username, password를 설정합니다.\n이 시점에서 발생할 수 있는 문제들도 다시 한차례 살펴보고 가겠습니다.\n‘The WSL Optional Component is not Enabled. Please Enable it and Try again’ 오류가 발생하는 경우 \u0026gt; Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux 0x80370102 에러가 발생한 경우 ⇒ 부팅 BIOS에서 가상화 기능을 활성화해줍니다.\n0xc03a001a 에러가 발생한 경우 ⇒ 다음 블로그 포스팅을 참고합니다.\n설치 이후에는 windows terminal에서 Ubuntu Terminal을 선택하여 실행 및 진입이 가능합니다. 설정 탭을 통해 Ubuntu 20.04를 기본 터미널로 설정 후 저장합시다.\nROS / ROS 2를 한줄 설치합니다. $ cd ~/ $ sh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/kimsooyoung/ros_menu/main/scripts/setup.sh)\u0026#34; Installing Neuron Startup Menu... Cloning into \u0026#39;/home/kimsooyoung/ros_menu\u0026#39;... remote: Enumerating objects: 583, done. remote: Counting objects: 100% (290/290), done. remote: Compressing objects: 100% (193/193), done. remote: Total 583 (delta 179), reused 173 (delta 93), pack-reused 293 Receiving objects: 100% (583/583), 154.50 KiB | 3.22 MiB/s, done. Resolving deltas: 100% (340/340), done. Do you want to install ROS automatically? (y/N): y 설치가 완료되었다면, 앞으로 터미널을 새로 등장시킬 때마다 다음과 같이 사용할 ROS 버전을 묻게 됩니다. GUI 인터페이스 설정 링크를 통해 VcXsrv를 설치합니다. ⇒ https://sourceforge.net/projects/vcxsrv/ 설치 이후, XLaunch를 실행하고, 사진과 같은 설정을 진행합니다. 앞으로 재부팅 시마다 이 설정을 반복해줘야 하며, 종종 Gazebo의 Memory Leak로 인해 화면이 종료되지 않는 경우가 있는데, 이런 경우 XLaunch를 강제 종료해주면 됩니다.\n설정이 잘 되었는지 Gazebo를 실행해봅시다. export GAZEBO_IP=127.0.0.1 export DISPLAY=$(cat /etc/resolv.conf | grep nameserver | awk \u0026#39;{print $2}\u0026#39;):0 export LIBGL_ALWAYS_INDIRECT=0 gazebo Gazebo의 실행 시 그래픽 카드 인식 문제가 발생하면 아래와 같이 어두운 화면이 등장합니다.\n이러한 경우, World 탭 ⇒ Scene ⇒ Shadows 옵션을 토글해주시면 됩니다. 마지막입니다! ~/.bashrc를 수정합니다. echo \u0026#39;export GAZEBO_IP=127.0.0.1\u0026#39; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#34;export DISPLAY=$(cat /etc/resolv.conf | grep nameserver | awk \u0026#39;{print $2}\u0026#39;):0 \u0026#34; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#39;export LIBGL_ALWAYS_INDIRECT=0\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 발생할 수 있는 오류 상황들을 살펴보고 가겠습니다.\ngazebo 실행 시 symbol error $ gazebo gazebo: symbol lookup error: /usr/lib/x86_64-linux-gnu/libgazebo_common.so.9: undefined symbol: _ZN8ignition10fuel_tools12ClientConfig12SetUserAgentERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE 해결 방법 ⇒ sudo apt upgrade -y libignition-math2\nGazebo 자체가 실행되지 않는 경우\nPC 재시작 후 백신 프로그램을 종료시킵니다. 제어판 ⇒ 시스템 및 보안 ⇒ Windows 방화벽 ⇒ 고급 설정 ⇒ 인바운드 규칙 ⇒ VcXsrv 사용 허용\nGazebo는 실행되지만, Grid (실선)이 등장하지 않는 경우\n안타깝지만 그래픽 드라이버 문제일 가능성이 큽니다. (Window ⇒ 업데이트 확인 진입 후 가장 최신 버전으로 모두 업그레이드를 실행해줍니다.)\nDocker 기반의 ROS 설정 이전 설치 모두 실패하신 경우 사용할 수 있는 최후의 방법이자. MacOS 사용자들을 위한 설정입니다.\ndocker desktop for windows를 설치합니다. ⇒ https://docs.docker.com/desktop/windows/install/ # 설치 확인 \u0026gt; docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 설치 확인 이후 동일한 명령 프롬프트에서 다음 커멘드 라인을 입력하여 도커 이미지를 다운받습니다. (해당 docker image는 강의에 필요한 작업을 제가 미리 준비해둔 것입니다.) docker pull tge1375/du_ros_noetic:0.0.0 docker 이미지를 최초 실행 시, 방금의 명령 프롬프트에서 아래와 같은 커멘드 라인을 입력해 주세요. docker run -it -p 6080:80 --name ros_noetic tge1375/du_ros_noetic:0.0.0 입력 후 링크를 통해 로컬 VNC 서버로 접속이 가능합니다. 첫 실행 시 방화벽 보안 경고가 등장하며, 이때 반드시 엑세스를 허용해줍니다. ⇒ (http://127.0.0.1:6080/) 위와 같은 화면이 등장했다면 noVNC에 접속이 성공한 것입니다.\n최초 명령 프롬프트에서 실행한 이후 다시 실행시키고 싶은 경우, 혹은 중지시키고 싶은 경우 docker desktop을 사용하면 매우 편리하게 작업이 가능합니다. VScode 셋업 VNC내에서의 개발은 매우 불편하기 때문에, VScode를 통해 코드 개발을 하고자 합니다. 다음과 같은 extension들을 설치합시다.\nDocker Docker Explorer Remote Development 설치 이후, cmd + p를 통해 Remote-Containers를 입력하면, 현재 실행 중인 컨테이너의 목록을 조회할 수 있습니다.\n이들 중 원하는 컨테이터를 선택하면, 새로운 vscode가 새로이 실행되며 작업 폴더를 설정하게 됩니다.\nLinux Commands 셋팅한 환경은 모두 리눅스를 기반으로 합니다.\n때문에 최소한의 리눅스 커멘드 지식이 필요하며, 짚고 넘어가겠습니다.\n리눅스 필수 명령어\ncd \u0026lt;디렉토리\u0026gt; : 해당 디렉토리로 이동하기 (절대 경로와 상대 경로, ../ 와 ~/) pwd : 현재 위치한 절대 경로 ls : 현재 디렉토리에 위치하는 모든 파일들 (ls -al 옵션) touch \u0026lt;파일 이름\u0026gt; : 해당 이름을 가진 파일 생성 source : 쉘 스크립트 실행하기 (source ~/.bashrc) 강의를 위해 알아야 할 추가 명령어들\nsudo : root 권한으로 실행하기 apt install / remove / purge : 리눅스 배포 패키지 설치 apt update : apt의 상태를 최신화, 설치된 패키지들을 최신화하는 과정을 포함함 그 외 알아두면 좋은 것들\ntop / htop : 리눅스의 작업 관리자 ps aux : 실행 중인 프로세스 출력 (ps aux | grep ros) tee \u0026lt;파일 이름\u0026gt; : 터미널 로그를 기록하기 xdg-open . : 현재 위치에서 파일 탐색기 열기 강의 중 설정된 Alias 설명\neb : edit bashrc의 약자로 ~/.bashrc 파일을 gedit을 통해 수정할 수 있습니다. sb : source bashrc의 약자로 수정된 ~/.bashrc 파일을 반영시킵니다. killg : 실행중인 Gazebo관련 모든 프로그램을 종료시킵니다. 유용한 프로그램들 설치하기\nsudo apt install gedit sudo apt install terminator -y 코드 에디터와 IDE 추천\nVSCode - https://code.visualstudio.com/ PyCharm - https://www.jetbrains.com/ko-kr/pycharm/download CLion - https://www.jetbrains.com/ko-kr/clion/ 참고자료\nhttps://www.youtube.com/watch?v=DW7l9LHdK5c https://www.lainyzine.com/ko/article/how-to-install-wsl2-and-use-linux-on-windows-10/ https://github.com/Tiryoh/docker-ros2-desktop-vnc https://89douner.tistory.com/123 "
},
{
	"uri": "/kr/ros_basic_noetic/lecture3/",
	"title": "Lecture3 - Core of ROS",
	"tags": [],
	"description": "",
	"content": " 지난 시간 개발환경 세팅을 잘 진행하였는지 확인을 해보면서 강의를 시작해보겠습니다.\n터미널 프로그램을 실행한 뒤, gazebo를 실행해 봅시다.\ngazebo 위 사진과 같은 화면이 나오지 않았다면 설치가 제대로 되지 않은 것입니다. (sudo apt install libgazebo11 을 통해 다시 설치해봅시다.)\nAbout Gazebo Gazebo의 특징과 기본적인 UI, 그리고 사용법을 짚고 넘어가고자 합니다.\nimage from : Open Robotics Gazebo는 로봇공학을 위해 제작된 전용 물리 엔진 기반의 높은 3D 시뮬레이터입니다.\nROS를 관리하는 Open Robotics에서 비롯된 시뮬레이터인만큼 ROS와 높은 호환성을 자랑합니다.\nGazebo는 실제 로봇을 위한 설계 검증 테스트와 시뮬레이션을 용이하게 하며, 윈도우, 맥, 리눅스에서 모두 실행되지만 대부분 리눅스 시스템에서 ROS와 함께 사용됩니다.\n⇒ 이후 Gazebo 사용 및 오류 발생 시 디버깅을 위해, Gazebo를 구성하는 요소들을 간단하게 짚고 넘어가겠습니다.\ngzserver \u0026amp; gzclient Gazebo는 Socket-Based Communication을 갖습니다. 따라서 서버와 Client를 분리하여 실행 가능하며 다른 기기에서의 실행 후 연동도 가능합니다.\nGazebo Server gzserver는 Gazebo 동작의 대부분을 수행합니다. 시뮬레이션하려는 장면과 그 안에 있는 개체 파일을 분석하고, 그런 다음 물리 엔진과 센서 엔진을 사용하여 전체 장면을 시뮬레이션합니다.\n터미널에서 다음 명령을 사용하여 서버를 독립적으로 시작할 수 있습니다.\n$ gzserver Gazebo Client gzclient는 gzserver에 연결하여 대화형 도구와 함께 시뮬레이션을 렌더링하는 Graphic Client를 제공합니다.\n다음 명령을 사용하여 gzclient를 단독으로 실행할 수 있습니다.\n$ gzclient client만 실행하면, 연결되고 명령을 수신할 서버가 없기 때문에 (컴퓨팅 리소스를 소비하는 것을 제외하고) 아무 것도 하지 않습니다.\nCombining Gazebo Server and Gazebo Client gzserver를 먼저 실행한 다음 gzclient를 실행하는 것이 일반적이며, 렌더링하기 전에 시뮬레이션 장면, 객체 관련 파라미터를 초기화할 수 있습니다.\ngazebo 명령어를 입력하면 내부적으로 server와 client가 순차적으로 실행됩니다.\n$ gazebo 이러한 이유로 Gazebo를 종료했다고 생각하지만 gzserver가 깔끔하게 종료되지 않는 상황이 발생합니다. ⇒ killg를 사용합시다!\nWorld File과 Model File image from : dronecode World Files Gazebo world file에는 로봇 모델, 환경, 조명, 센서, 다른 기타 물체들까지 시뮬레이션 환경의 모든 요소가 포함되어 있습니다. 일반적으로 확장자명 .world를 사용합니다.\n아래 예시와 같이 Gazebo 실행 시 world 파일을 옵션으로 하여 실행이 가능합니다.\n$ gazebo \u0026lt;yourworld\u0026gt;.world Model Files Gazebo의 World는 다양한 Model들로 구성됩니다. 하지만 Model만을 가지고 gazebo를 실행시킬 수는 없습니다. (gazebo 이렇게는 불가합니다.)\n모델을 별도의 파일로 보관하는 이유는 다른 프로젝트에 재사용하기 위해서이며, 로봇의 모델 파일 또는 다른 모델을 월드 파일 내에 포함하려면 다음과 같이 태그를 통해 import 할 수 있습니다.\n\u0026lt;include\u0026gt; \u0026lt;uri\u0026gt;model://model_file_name\u0026lt;/uri\u0026gt; \u0026lt;/include\u0026gt; Environment Variables Gazebo에 World, Model을 연동하고, gzserver와 gzclient 간 통신을 설정하기 사용하는 많은 환경 변수가 있습니다.\n예를 들어, GAZEBO_MODEL_PATH는 Gazebo가 모델 파일을 검색할 시 참조하는 경로입니다.\nPlugins Gazebo의 World, Model에 장착되는 각종 센서와 제어를 위한 다양한 플러그인이 준비되어 있으며, 이러한 플러그인은 커멘드 라인에서 로드하거나 SDF 파일 내부에 추가할 수 있습니다. (자체 Plugin을 개발할 수도 있습니다.)\nUnderstanding Gazebo GUI 이번에는 Gazebo의 기본 조작 방법과 내장 Tool들을 살펴보겠습니다.\n우선 Gazebo를 실행시킵니다. $ gazebo Gazebo의 시점 변환은 마우스를 사용하여 손쉽게 조작 가능합니다. 마우스 왼쪽 버튼을 누르고 드래그하면 시점을 이동할 수 있습니다. 마우스 휠을 누른 상태로 이동시키면 회전 시점을 조작할 수 있습니다. 최상단에 위치한 Top Toolbar를 살펴보겠습니다. 왼쪽부터 오른쪽 순서대로 각 아이콘 별 기능을 설명해보겠습니다.\nSelect mode Select mode는 가장 일반적으로 사용되는 커서 모드입니다. 장면을 탐색할 수 있습니다.\nTranslate mode 커서 모드를 선택한 다음 이동시키길 원하는 객체를 클릭합니다. 이후 등장하는 3축 중 적절한 축을 사용하여 개체를 원하는 위치로 끌기만 하면 됩니다.\nRotate mode translate mode와 마찬가지로 이 커서 모드를 사용하면 주어진 모델의 방향을 변경할 수 있습니다.\nScale mode Scale mode를 사용하면 객체의 전체 크기를 변경할 수 있습니다.\nUndo/Redo 앞,뒤로 되돌리는 기능입니다.\nSimple shapes 큐브, 구체 또는 실린더와 같은 기본 3D 모델을 환경에 삽입할 수 있습니다.\nLights 스포트라이트, 포인트 라이트 또는 방향이 정해진 조명과 같은 다양한 광원을 환경에 추가합니다.\nCopy/Paste 모델을 복사/붙여넣을 수 있습니다. (Ctrl+C/V를 통해서도 가능합니다.)\nAlign 이 도구를 사용하면 x y z 축 중 하나를 따라 한 모형을 다른 모델과 정렬할 수 있습니다.\n또는 두 모델을 특정한 면 기반으로 서로 붙이는 것도 가능합니다.\nChange view 상단 뷰, 측면 뷰, 전면 뷰, 하단 뷰와 같은 다양한 관점에서 장면을 볼 수 있습니다.\n다음으로 Side Panel을 살펴보겠습니다.\nWorld 현재 사용중인 조명 및 모델들이 표시됩니다. 개별 모델을 클릭하여 위치 및 방향과 같은 모델의 기본 파라미터를 보거나 편집할 수 있습니다. 또한 물리 옵션을 통해 중력 및 자기장과 같은 물성치도 변경할 수 있습니다. GUI 옵션을 사용하면 기본 카메라 뷰 각도 및 포즈에 액세스할 수 있습니다.\nInsert 추가할 모델을 찾을 수 있습니다. 환경 변수에 지정된 폴더에서 모델들을 검색한 뒤 배치하는 것이 가능하며, 환경 변수 설정 없이도 Add Path 옵션을 통해 정해진 포멧을 갖는 모델을 가져올 수 있습니다.\n다시 본론으로 돌아와서, ROS 설치는 잘 되었는지도 확인해봅시다.\n# Terminal 1 roscore # Terminal 2 rosrun rospy_tutorials talker 모든 확인이 끝났다면, 예제 프로그램을 실행시켜보겠습니다.\nHusky Gazebo 예제 패키지 설치 sudo apt-get update sudo apt-get install ros-noetic-husky-desktop sudo apt-get install ros-noetic-husky-simulator 예제 프로그램 실행 # Terminal 1 roslaunch husky_gazebo husky_empty_world.launch # Terminal 2 roslaunch husky_viz view_robot.launch # Terminal 3 rosrun teleop_twist_keyboard teleop_twist_keyboard.py cmd_vel:=/husky_velocity_controller/cmd_vel Terminal 1에서 발생하는 아래 오류는 무시해도 좋습니다.\n모든 실행이 정상 동작하였다면, Terminal 3에서 키보드를 통해 Husky를 제어할 수 있습니다. 로봇이 움직임에 따라 두번째 터미널 결과였던 Rviz에 아래와 같은 변화가 생깁니다. 다음으로, 새로운 터미널에서 아래 커멘드 라인을 실행시켜 봅시다. rosrun rqt_graph rqt_graph 위 그림은 방금 전 실행한 예제 내부적으로 어떠한 동작들이 이루어지고 있었는지를 보여주는 것으로, 강의를 마칠 때면 여러분들은 위 그림이 어떠한 의미를 갖는지 모두 이해하실 수 있을 것입니다.\n다음으로, 터미널을 새로 실행시켜 rosnode list와 rostopic list를 실행시켜 봅시다.\nrosnode list $ rosnode list /base_controller_spawner /ekf_localization /gazebo /gazebo_gui /joy_teleop/joy_node /joy_teleop/teleop_twist_joy /robot_state_publisher /rosout /teleop_twist_keyboard /twist_marker_server /twist_mux rostopic list $ rostopic list /clock /cmd_vel /diagnostics /e_stop /gazebo/link_states /gazebo/model_states /gazebo/parameter_descriptions /gazebo/parameter_updates /gazebo/performance_metrics /gazebo/set_link_state /gazebo/set_model_state ... 앞으로의 강의들에서, 위 명령어들이 어떠한 의미를 갖는지 하나하나씩 함께 살펴보겠습니다.\nROS Node ROS는 각 프로세스들을 Node라는 단위로 관리합니다.\n로봇을 움직이는 Node, 센서와 통신하는 Node, 시각화 Node 등 다양한 Node들이 얽혀 로봇 시스템을 구성하게 됩니다. Node들 사이에는 데이터의 송수신이 필요합니다. 이를 담당하는 ROS의 통신 메커니즘들이 있으며 각기 다른 특성을 갖고 있습니다. Node들끼리 데이터를 주고받기 위해서는 어떤 노드가 존재하는지, id는 몇번인지 등의 정보가 공유되어야 할 것입니다. 아래 그림의 ROS Master가 이를 관리해주는 것이라고 이해하시면 됩니다. image from : clearpathrobotics 그렇다면, 방금 우리가 실행한 예시에서도 ROS Master와 Node들이 실행되었겠군요!\n실행되는 Node를 확인하는 방법은 크게 두 가지가 있습니다.\nrosnode command $ rosnode list /base_controller_spawner /ekf_localization /gazebo /gazebo_gui /joy_teleop/joy_node /joy_teleop/teleop_twist_joy /robot_state_publisher /rosout /teleop_twist_keyboard /twist_marker_server /twist_mux rqt_graph rosrun rqt_graph rqt_graph rqt graph를 살펴보면, 동그란 Node와 Node들 사이의 데이터 송수신이 화살표로 표현된 것을 알 수 있습니다. 키보드를 통해 제어 데이터를 송신하는 teleop_twist_keyboard는 gazebo node로 데이터를 보내고 있으며, 따라서 gazebo는 이 데이터를 통해 실제 로봇을 움직이게 되는 것입니다.\n특정 Node에 대해서 더 자세한 정보를 얻고 싶다면, rosnode info 커맨드를 사용합니다. $ rosnode info /base_controller_spawner -------------------------------------------------------------------------------- Node [/base_controller_spawner] Publications: * /rosout [rosgraph_msgs/Log] Subscriptions: * /clock [rosgraph_msgs/Clock] Services: * /base_controller_spawner/get_loggers * /base_controller_spawner/set_logger_level contacting node http://192.168.55.236:33811/ ... Pid: 63764 Connections: * topic: /rosout * to: /rosout * direction: outbound (43329 - 192.168.55.236:34456) [10] * transport: TCPROS * topic: /clock * to: /gazebo (http://192.168.55.236:33853/) * direction: inbound * transport: TCPROS 이전 예제들은 일단 종료시킨 뒤, 간단한 새로운 예시를 실행해봅시다.\n# Terminal 1 roscore # Terminal 2 rosrun roscpp_tutorials talker # Terminal 3 rosrun roscpp_tutorials listener # Terminal 4 rqt_graph rqt_graph를 보면 talker ⇒ listener로 데이터가 전송되는 것을 알 수 있습니다.\n이제, rqt_graph를 보는 것은 익숙해졌지요?\n첫번째 Gazebo 예시와 다른 점으로 roscore라는 것을 실행해주었습니다.\nroscore는 ROS Master를 실행시키는 명령어로 모든 ROS Node들은 Master에 의해 관리되기 때문에 roscore를 통해 실행시키거나, roslaunch를 사용해야 합니다. ROS Master가 실행되고 있지 않다면, 아래와 같이 오류가 발생합니다. ETH Super Mega Bot \u0026amp; ROS Workspace ROS는 catkin이라는 빌드 시스템을 사용합니다. 기존 c/c++ cross-platform 개발을 경험하셨다면 cmake에 익숙하실텐데, 이와 매우 비슷합니다. catkin을 통해 실행 가능한 프로그램 (C/C++의 빌드), 라이브러리, 인터페이스들을 만들 수 있으며, catkin 시스템을 사용하기 위해서는 workspace라는 특별한 폴더가 필요합니다. ROS 개발을 하다 보면 여러 프로젝트를 동시에 진행하는 경우가 생깁니다. 새로운 작업은 새로운 폴더를 만들어 작업하듯이 ROS 에서도 새로운 프로젝트는 새로운 WorkSpace에서 작업을 수행하는 것이 일반적입니다. 새로운 WS로 이동하게 되면 ROS에게 이러한 변화를 알려줘야 하며 이 명령어가 source devel/setup.bash 입니다. 이번 강의용 WS를 만들어보고, 이후 여러분들만의 WS도 만들어 작업해보세요! 일반적으로 ROS의 workspace는 name_ws라는 이름을 갖는 것이 일반적이며, 우리는 catkin_ws라는 workspace를 만들어보고자 합니다.\n아래 커멘드 라인들을 따라해주세요 cd ~/ mkdir -p catkin_ws/src cd catkin_ws catkin config --init catkin build 다음과 같이 build, devel, src, log 폴더가 만들어집니다. ROS 코드들은 모두 src 폴더 안에 위치하게 됩니다. src 폴더 내부에서 코드 개발 ⇒ catkin을 사용한 빌드 ⇒ build 폴더 내부에 실행 가능한 프로그램 생성의 순서로 개발이 이루어집니다. 실습을 통해 개발 프로세스에 익숙해져봅시다.\n아래 폴더를 catkin_ws/src 안에 압축 해제합니다. Example Packages smb_common.zip (2 ) 터미널 프로그램을 실행시키고 아래 커멘드 라인을 따라합니다. catkin build smb_description catkin build smb_gazebo catkin build smb_control source devel/setup.bash source로 시작하는 마지막 라인은 새로운 빌드 후에 항상 실행해줘야 합니다. 1강을 잘 따라했다면 sds라는 단축어로 사용이 가능합니다.\n예제 프로그램을 실행시킵니다. roslaunch smb_gazebo smb_gazebo.launch 실행 시 붉은 에러 메세지가 나오지만 동작만 된다면 문제 없습니다.\n이 로봇을 한번 움직여 볼까요? - teleop 실행 rosrun teleop_twist_keyboard teleop_twist_keyboard.py 파일 구조 관점에서, ROS Application은 여러 Package들로 이루어집니다. 이들 Package가 소스 파일을 담고 있고, catkin이 이들을 빌드하여 실행 프로그램들을 만들었습니다. 제가 공유한 압축 파일 안에도 3개의 Package가 포함되어있던 것이며, ROS 개발자들은 자신들의 로봇 Package를 개발하고 공유합니다. Package 생성 실습 Package를 생성하는 방법은 다음과 같습니다.\ncd \u0026lt;your-ws\u0026gt;/src catkin_create_pkg \u0026lt;package_name\u0026gt; [depend1] [depend2] [depend3] my_first_package라는 package를 시험삼아 생성해봅시다.\n# exameple $ catkin_create_pkg my_first_package rospy std_msgs Created file my_first_package/package.xml Created file my_first_package/CMakeLists.txt Created folder my_first_package/src Successfully created files in /home/kimsooyoung/catkin_ws/src/my_first_package. Please adjust the values in package.xml. depend에는 해당 패키지의 의존성 패키지들이 나열되며, rospy는 파이썬을 통해 ROS를 사용하기 위한 의존성입니다.\n미리 제공되었던 Package, smb_gazebo를 살펴봅시다.\nGazebo 실행에 필요한 모델 파일과 환경 파일 등 기능별 정리된 모습을 볼 수 있습니다.\n이렇게 Package를 잘 구성해두면 이후 코드의 관리에도 편리하다는 장점이 있습니다.\n참고자료\nhttp://wiki.ros.org/ko/ROS/Tutorials/CreatingPackage https://rsl.ethz.ch/education-students/lectures/ros.html https://www.clearpathrobotics.com/assets/guides/noetic/ros/Drive a Husky.html "
},
{
	"uri": "/kr/ros_basic_noetic/lecture4/",
	"title": "Lecture4 - ROS Launch, RViz",
	"tags": [],
	"description": "",
	"content": "ROS Launch 일전 예시 실행에서 다음과 같은 커멘드 라인을 사용했었습니다.\nroslaunch smb_gazebo smb_gazebo.launch roslaunch란, 다수의 ROS Node들을 한번에 실행할 수 있도록 해주는 툴 입니다.\nroslaunch를 사용하기 위해서는 xml이라는 포멧을 사용하는 launch file이 있어야 하며, 이는 보통 패키지의 launch 폴더에 위치하고 있습니다.\nlaunch file의 구조를 파악해봅시다.\nlaunch파일은 xml이라는 문법을 사용합니다. html을 사용해보셨다면 아시겠지만, \u0026lt;\u0026gt;를 이용하여 라인을 구분하는 포멧입니다. 한 라인에서 끝나는 경우 /\u0026gt;로 맺을 수 있지만, 여러 라인이 필요한 경우에는 여는 태그와 닫는 태그를 사용하여 구분합니다. \u0026lt;tag /\u0026gt; or \u0026lt;tag (value)\u0026gt; ... \u0026lt;/tag\u0026gt; launch file은 시작과 끝, 태그로 감싸집니다.\nnode 태그는 실행되는 ROS Node를 지칭합니다. name 태그는 node를 실행할 때의 이름을 설정하는 부분으로 자유롭게 지정 가능합니다. pkg 태그에는 해당 node가 속해있는 package를 적습니다. type 태그에는 실행가능한 파일, 혹은 프로그램을 적게 되며, c++의 경우 빌드된 프로그램, 파이썬의 경우 파이썬 파일이 됩니다. output 태그는 로그가 출력되는 위치를 지정하며 screen일 시 터미널에 출력됩니다. \u0026lt;launch\u0026gt; \u0026lt;node name=\u0026#34;listener\u0026#34; pkg=\u0026#34;rospy_tutorials\u0026#34; type=\u0026#34;listener.py\u0026#34; output=\u0026#34;screen\u0026#34;/\u0026gt; \u0026lt;node name=\u0026#34;talker\u0026#34; pkg=\u0026#34;rospy_tutorials\u0026#34; type=\u0026#34;talker.py\u0026#34; output=\u0026#34;screen\u0026#34;/\u0026gt; \u0026lt;/launch\u0026gt; 이번에는 smb_gazebo.launch를 살펴봅시다.\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;launch\u0026gt; \u0026lt;!-- GAZEBO ARGUMENTS --\u0026gt; \u0026lt;!-- Run Gazebo headless --\u0026gt; \u0026lt;arg name=\u0026#34;headless\u0026#34; default=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;model_path\u0026#34; default=\u0026#34;$(find smb_gazebo)/\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;robot_namespace\u0026#34; default=\u0026#34;\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;robot_model_name\u0026#34; default=\u0026#34;smb\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;enable_ekf\u0026#34; default=\u0026#34;true\u0026#34;/\u0026gt; ... \u0026lt;!-- Load Gazebo world --\u0026gt; \u0026lt;include file=\u0026#34;$(find gazebo_ros)/launch/empty_world.launch\u0026#34;\u0026gt; \u0026lt;env name=\u0026#34;GAZEBO_MODEL_PATH\u0026#34; value=\u0026#34;$(arg model_path)\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;world_name\u0026#34; value=\u0026#34;$(arg world_file)\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;paused\u0026#34; value=\u0026#34;$(arg paused)\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;use_sim_time\u0026#34; value=\u0026#34;$(arg use_sim_time)\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;gui\u0026#34; value=\u0026#34;$(arg run_gui)\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;headless\u0026#34; value=\u0026#34;$(arg headless)\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;debug\u0026#34; value=\u0026#34;$(arg debug)\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;verbose\u0026#34; value=\u0026#34;$(arg verbose)\u0026#34;/\u0026gt; \u0026lt;/include\u0026gt; arg란, argument의 약자이며 launch 파일에서 인자로 작용하는 일종의 변수입니다.\narg 태그를 통해 argument를 선언하고 default를 통해 초기값을 정할 수 있습니다. argument의 선언 후 사용은 $(arg \u0026ldquo;argument name\u0026rdquo;) 입니다. roslaunch 시 argument를 바꿔 실행이 가능합니다. 예를 들어, smb_gazebo.launch 실행 시. world를 바꾸어 아래와 같이 사용이 가능합니다.\nroslaunch smb_gazebo smb_gazebo.launch world:=big_map_summer_school 초기 실행 시 시간이 다소 걸릴 수 있습니다.\n현재 예시에서 제공되는 world는 다음 3가지 입니다.\nroslaunch smb_gazebo smb_gazebo.launch 제작한 launch file을 다시 다른 launch file에서 불러오는 경우가 더러 있습니다.\n이때, include 태그를 사용하며, 패키지 단위를 기반으로 파일의 경로를 가져오게 됩니다.\ninclude하는 launch file의 내부에도 여러 argument들이 있을 것입니다. 이들은 arg 태그를 통해 접근할 수 있습니다.\n\u0026lt;include file=\u0026#34;$(find gazebo_ros)/launch/empty_world.launch\u0026#34;\u0026gt; \u0026lt;env name=\u0026#34;GAZEBO_MODEL_PATH\u0026#34; value=\u0026#34;$(arg model_path)\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;world_name\u0026#34; value=\u0026#34;$(arg world_file)\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;paused\u0026#34; value=\u0026#34;$(arg paused)\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;use_sim_time\u0026#34; value=\u0026#34;$(arg use_sim_time)\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;gui\u0026#34; value=\u0026#34;$(arg run_gui)\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;headless\u0026#34; value=\u0026#34;$(arg headless)\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;debug\u0026#34; value=\u0026#34;$(arg debug)\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;verbose\u0026#34; value=\u0026#34;$(arg verbose)\u0026#34;/\u0026gt; \u0026lt;/include\u0026gt; html과 마찬가지로 \u0026lt;!-- --\u0026gt; 사이에 오는 코드는 주석으로 무시됩니다.\n단, 주의사항 하나 있습니다. launch 파일을 사용하다보면 --가 종종 쓰이곤 하는데요. 이 경우 주석에 오류가 나니 주의하시기 바랍니다.\nLaunch File을 다루는 연습을 해봅시다.\nsmb_gazebo.launch를 다음과 같이 수정합니다.\nworld를 big_map_summer_school로 수정합니다. 로봇이 등장하는 위치를 다음과 같이 수정합니다. xyz : (-0.5, -1.0, 0.4) yaw angle : 90도 (3.1415를 1 radian으로 잡습니다.) launch file에 rospy_tutorials Package에 있는 talker Node를 추가합니다. Rqt와 RViz ROS에는 로봇의 다양한 센서 데이터들을 시각화해주는 3D 툴이 있으며, 이는 RViz라고 불립니다.\nRviz의 사용법을 알아봅시다.\n예제 실행 # Terminal 1 roslaunch smb_gazebo smb_gazebo.launch world:=big_map_summer_school # Terminal 2 rviz 사진과 같이 Gazebo와 RViz가 잘 실행된 상황에서 강의를 따라합니다.\nrviz에서 센서 데이터를 시각화하기 전, 우선 어떤 좌표계를 기준으로 시각화할지 설정해주어야 합니다.\n같은 센서라도 원점 좌표계에서 본 모습과, 센서 좌표계에서 본 모습이 다르기 때문입니다.\nimg from : mathworks 이는 RViz의 Fixed Frame에서 설정 가능합니다. (odom으로 설정해보겠습니다.)\n이제 다양한 시각화 기능들을 사용해보려 합니다.\n기본적으로 데이터의 추가는 왼쪽 하단 Add 버튼으로 실행합니다. tf 시각화 odometry 시각화 point cloud 시각화 이렇게 잘 설정해둔 RViz는 config 포멧으로 추출하여 이후에 다시 사용할 수 있습니다.\nFile ⇒ Save Config를 통해 config를 저장하고, Open Config를 통해 저장한 config를 불러올 수 있습니다.\n아래와 같이 다양한 Plugin을 통해 여러 센서, 로봇 데이터를 시각화할 수 있으며, 자신만의 Plugin을 제작할 수도 있습니다.\n지금까지 여러분들이 만든 RViz 설정을 저장해보고, launch file에 통합해봅시다.\nRViz의 좌측 상단 File 옵션을 사용하여 config file을 저장합니다. 저장 위치는 smb_gazebo/rviz로 지정하겠습니다. (새롭게 폴더를 만들어주었습니다.) 이제, launch file을 수정합시다. 파일 하단 launch 태그가 닫히기 전 부분에 아래와 같은 라인을 추가합니다. \u0026lt;node name=\u0026#34;rviz\u0026#34; pkg=\u0026#34;rviz\u0026#34; type=\u0026#34;rviz\u0026#34; args=\u0026#34;-d $(find smb_gazebo)/rviz/my_config.rviz\u0026#34; /\u0026gt; \u0026lt;/launch\u0026gt; 이제, 다시 Gazebo launch를 해봅시다.\nroslaunch smb_gazebo smb_gazebo.launch world:=big_map_summer_school Rqt Tools 지금까지 사용한 ROS 툴은 rqt_graph와 RViz가 있었습니다.\n사실 ROS에는 수많은 추가 툴들이 존재하며 이들을 묶어 rqt tools라고 부릅니다.\nrqt image view image from : wiki.ros.org\nrqt multiplot image from : project march\nrqt console image from : wiki.ros.org\nrqt robot steering rqt tf tree image from : rqt tf tree\n이러한 수많은 툴들이 있어 ROS 개발을 편리하게 해주고 있으며, 함께 ROS를 공부하면서 하나씩 같이 살펴보고 사용해보려 합니다.\n참고자료\nhttp://wiki.ros.org/roslaunch https://www.clearpathrobotics.com/assets/guides/noetic/ros/Drive a Husky.html https://rsl.ethz.ch/education-students/lectures/ros.html "
},
{
	"uri": "/kr/ros_basic_noetic/lecture5/",
	"title": "Lecture5 - First Programming, ROS Topic",
	"tags": [],
	"description": "",
	"content": "이번 강의부터, 본격적인 프로그래밍이 시작됩니다. 첫번째로 Node의 프로그래밍을 살펴보고자 하며, 시작 전 간단한 복습을 진행하고 시작하겠습니다.\nimage from : clearpathrobotics\nWorkspace와 패키지 # WS 생성 mkdir -p catkin_ws/src cd catkin_ws catkin config --init # Package 생성 catkin_create_pkg \u0026lt;pkg-name\u0026gt; \u0026lt;depend1\u0026gt; \u0026lt;depend2\u0026gt; ... ROS Node Programming C++ 코드는 src 폴더 안에, 파이썬 코드는 scripts라는 폴더 안에 위치시키는 것이 일반적입니다. cd \u0026lt;pkg-name\u0026gt; mkdir scripts 지금부터, 직접 명령어를 한줄씩 따라치면서 실습하셔도 좋고, 제가 미리 준비해둔 Package를 사용하셔도 좋습니다.\n다음으로, 파이썬 코드를 작성하고 패키지를 빌드해봅시다.\ncd scripts # my_first_node.py 생성 첫번째 프로그래밍 코드는 Node의 기본입니다.\n모든 소스코드는 github repo에서 확인 가능합니다.\nmy_first_node.py #!/usr/bin/env python3 import rospy from std_msgs.msg import String def my_first_node(): # ROS nodes require initialization # It contains master registration, uploading parameters rospy.init_node(\u0026#39;my_first_node\u0026#39;, anonymous=True) # ROS safe timer rate = rospy.Rate(10) # 10hz # Loop control Example while not rospy.is_shutdown(): hello_du = \u0026#34;hello du %s\u0026#34; % rospy.get_time() rospy.loginfo(hello_du) # Below line calls sleep method in Python internally. rate.sleep() if __name__ == \u0026#39;__main__\u0026#39;: try: my_first_node() except rospy.ROSInterruptException: pass 코드를 새로 작성한 다음에는 습관적으로 패키지를 빌드하고 실행합니다. 파이썬 코드의 경우 파일의 실행 권한이 주어져 있어야 합니다. cd scripts chmod +x * cd ~/catkin_ws catkin build my_first_pkg 작성한 node를 실행해봅시다. 반복해서 터미널 로그가 남을 것입니다. # Terminal 1 roscore # Terminal 2 rosrun my_first_package my_first_node.py 코드 분석 첫 코드인 만큼 자세하게 분석하고 넘어가보려 합니다.\nROS Noetic은 Python 3를 사용합니다. 가상환경의 파이썬, 직접 설치한 파이썬 등 여러 버전이 설치되어 있을 것입니다. 공식 문서에서는 이러한 혼란을 방지하기 위해 코드의 제일 처음 아래 라인을 추가하는 것을 추천하고 있습니다. #!/usr/bin/env python3 Python을 사용하여 ROS를 다루기 위해 사용되는 패키지는 rospy입니다. import를 사용해도 좋고 from / import를 통해 특정 클래스만 가져올 수도 있습니다. import rospy from std_msgs.msg import String 당장 사용하지는 않지만 Test Code를 작성해야 하는 경우가 있습니다. 이러한 상황에 대비하기 위해 main 함수를 따로 두고 아래와 같이 프로그램을 시작하기를 권장합니다. if __name__ == \u0026#39;__main__\u0026#39;: try: my_first_node() except rospy.ROSInterruptException: pass 이제, my_first_node를 분석해 보겠습니다. Node의 실행을 위해 Master에 등록하고, 초기화하는 작업이 필요하며, 이를 위해 별도로 init_node라는 메소드를 실행해주어야 합니다. def my_first_node(): # ROS nodes require initialization # It contains master registration, uploading parameters rospy.init_node(\u0026#39;my_first_node\u0026#39;, anonymous=True) ROS 시스템은 기본적으로 무한 Loop입니다. 이 Loop가 한차례 반복되는 주기를 설정하는 부분입니다. ROS의 시간 체계에 대해서는 이후 한번 더 다루겠습니다. # ROS safe timer rate = rospy.Rate(10) # 10hz rospy를 통해 실행 중인 Node의 상태를 확인할 수 있으며, is_shutdown()은 예기치 못한 에러가 발생하거나 사용자의 종료를 인지할 수 있습니다. 10Hz를 맞추기 위해 Loop마다 sleep을 걸어주고 있습니다. # Loop control Example while not rospy.is_shutdown(): ... rate.sleep() ROS에서 콘솔 로그를 얻는 방법으로 print 보다 rospy.log를 사용하기를 추천합니다. hello_du = \u0026#34;hello du %s\u0026#34; % rospy.get_time() rospy.loginfo(hello_du) # Below line calls sleep method in Python internally. ROS Timer ROS는 기본적으로 무한 Loop를 하나의 프로세스 안에서 동작시키는 프로그램입니다. Timer를 통해 일정 시간마다 동작하는 코드를 구현할 수 있습니다.\ncd my_first_pkg/scripts # spin_node.py 생성 spin_node.py #!/usr/bin/env python3 import rospy # callback method requires event, which is TimerEvent def hello_du(event=None): hello_du = \u0026#34;hello du %s\u0026#34; % rospy.get_time() rospy.loginfo(hello_du) def my_first_node(): rospy.init_node(\u0026#39;my_first_node\u0026#39;, anonymous=True) # Timer Class is kind of Thread. # It\u0026#39;s rule is execute sleep in certain period with given event. rospy.Timer(rospy.Duration(1.0/100.0), hello_du) rospy.spin() if __name__ == \u0026#39;__main__\u0026#39;: try: my_first_node() except rospy.ROSInterruptException: pass 코드의 실행 결과는 이전과 같기 때문에 Timer와 spin에 대해서만 짚고 넘어가겠습니다.\nTimer는 크게 두가지 매개변수를 받습니다. 실행 주기와 Callback 함수입니다. 해당 주기마다 Callback 함수를 실행시킵니다. rospy.Timer(rospy.Duration(1.0/100.0), hello_du) 앞으로 여러분들은 직접 while loop를 구현하기보다 rospy.spin()을 더 많이 사용하시게 될 겁니다. Timer를 선언한 이후, 하나의 Thread에서 막혀버리는 것을 방지하는 역할을 수행합니다. rospy.Timer(rospy.Duration(1.0/100.0), hello_du) rospy.spin() image from : python tutorial\nOOP Node Programming my_first_oop_node.py #!/usr/bin/env python3 import rospy class OOPNode: def __init__(self): self.counter_ = 0 self.timer_ = rospy.Timer(rospy.Duration(1.0/100.0), self.hello_du) def hello_du(self, event=None): hello_du = f\u0026#34;hello du {rospy.get_time()}, counter: {self.counter_}\u0026#34; rospy.loginfo(hello_du) self.counter_ += 1 def my_first_oop_node(): rospy.init_node(\u0026#39;my_first_oop_node\u0026#39;, anonymous=True) oop_node = OOPNode() rospy.spin() if __name__ == \u0026#39;__main__\u0026#39;: try: my_first_oop_node() except rospy.ROSInterruptException: pass 이후의 실습들을 위해 한가지 예시만 더 살펴보고자 합니다. 객체 지향을 사용한 ROS Node 작성방법입니다. 파이썬에서 OOP를 사용하기 위해 Class 키워드를 사용하며, self등 OOP와 관련된 내용은 모두 알고 있다는 상태에서 진행하겠습니다.\nOOP를 사용하면 main 메소드가 매우 간편해진다는 장점이 있습니다. 클래스를 생성하고, spin을 하기만 하면 됩니다. def my_first_oop_node(): rospy.init_node(\u0026#39;my_first_oop_node\u0026#39;, anonymous=True) oop_node = OOPNode() rospy.spin() OOP로 전환되면서 변경된 구현에 주목합시다. Timer의 Callback 함수로 클래스 메소드가 사용되었으며, 클래스 변수인 counter를 사용하여 구현한 점에 주목합니다. class OOPNode: def __init__(self): self.counter_ = 0 self.timer_ = rospy.Timer(rospy.Duration(1.0/100.0), self.hello_du) def hello_du(self, event=None): hello_du = f\u0026#34;hello du {rospy.get_time()}, counter: {self.counter_}\u0026#34; rospy.loginfo(hello_du) self.counter_ += 1 앞으로, 대부분의 코드는 OOP 기반으로 작성됩니다. 파이썬의 클래스에 대해 숙지가 되어있지 않다면 꼭 복습하고 다음 강의를 청취하세요!\nROS Topic 다시 개념 학습으로 돌아와보았습니다. 아래 그림은 지난 강의의 rqt_graph입니다.\n위 그림에서 동그라미는 Node를 뜻하고, 화살표는 topic을 뜻합니다.\n이번 시간에는 이 Topic이 무엇인지 배워보고자 합니다.\nTopic은 Node들 사이에 데이터(Message)가 오가는 길(Bus)의 이름입니다. image from : docs.ros.org 그림에서와 같이 ROS Topic은\nPublisher(발행자) Subscriber(구독자)로 나누어 Topic의 송신, 수신자를 구분합니다. Publisher, Subscriber는 Node안에서 생성되며 별도로 사용할 수는 없습니다. Pub/Sub 사이에 Message가 전달되며, 이 길의 이름이 Topic인 것입니다. 주의할 점은, Publisher, Subscriber는 오로지 Topic의 이름으로 소통한다는 것입니다. 어떤 Node에 publish 할지 Publisher는 전혀 모르며 오로지 Topic이 같은 Subscriber가 데이터를 받게 됩니다. 더불어, Topic은 여러 Node들로 부터 데이터를 받을 수 있고, 전송 시에도 여러 Node들에게 전송이 가능한 방식입니다. ⇒ Topic의 중요한 속성이니 꼭 알아두셨으면 좋겠습니다.\nimage from : docs.ros.org Node와 Topic의 개념을 다시 한 번 다잡고 갑시다.\nNode는 실행되는 프로그램이며, ROS Master에 등록하고 관리됩니다. Node들 사이의 통신 메커니즘 중 Topic이라는 것이 있으며, 이는 Publisher와 Subscriber라는 개념을 갖고 있습니다. Publisher와 Subscriber 사이의 오가는 데이터는 특정한 타입을 갖습니다. 이를 Message라고 부릅니다. Topic Message 로봇 프로그래밍 시에는 다양한 센서 데이터들이 다뤄집니다. 센서 뿐만 아니라, 제어 데이터도 주고 받아야 합니다. ROS에서는 주로 사용되는 이러한 데이터 형식을 Message라는 이름으로 지칭하며, 여러 기본 형태를 제공합니다. 더불어 사용자가 직접 Message를 커스터마이징할 수도 있습니다.\n일전 예시의 분석을 통해 Topic과 Message에 대해 다시 한 번 살펴봅시다. # Terminal 1 roscore # Terminal 2 rosrun roscpp_tutorials talker # Terminal 3 rosrun roscpp_tutorials listener 두 프로그램이 실행되고 있는 상태를 유지하면서, 아래 내용을 따라와주세요\nrostopic list를 통해 사용중인 topic들을 모두 조회 가능합니다. $ rostopic list /chatter /rosout /rosout_agg 특정 topic에 대한 자세한 정보를 알고 싶다면 rostopic info를 사용합니다. talker와 listener가 조회된 모습도 보입니다. $ rostopic info /chatter Type: std_msgs/String Publishers: * /talker_215337_1671763968667 (http://192.168.55.236:37863/) Subscribers: * /listener_215355_1671763970127 (http://192.168.55.236:44969/) 해당 topic이 사용중인 Message를 조회하기 위해 rostopic type을 사용합니다. $ rostopic type /chatter std_msgs/String rosmsg show를 통해 Message의 원형을 확인할 수 있습니다. $ rosmsg show std_msgs/String string data topic 데이터를 엿볼 수 있는 rostopic echo입니다. $ rostopic echo /chatter data: \u0026#34;hello world 1671764088.1913402\u0026#34; --- data: \u0026#34;hello world 1671764088.2913551\u0026#34; --- ... rostopic hz로 topic의 pub/sub 주기를 분석할 수 있습니다. $ rostopic hz /chatter subscribed to [/chatter] average rate: 10.000 min: 0.100s max: 0.100s std dev: 0.00014s window: 10 average rate: 9.999 min: 0.099s max: 0.100s std dev: 0.00023s window: 20 마지막으로 rqt_graph를 다시 한 번 살펴봅시다.\nrqt_graph 방금 살펴본 커멘드 라인들을 충분히 숙지하시기 바랍니다. 그러한 의미에서, 이번에는 Gazebo 예시를 분석해볼까 합니다.\n# Terminal 1 roslaunch smb_gazebo smb_gazebo.launch # Terminal 2 rosrun teleop_twist_keyboard teleop_twist_keyboard.py rostopic list 결과 $ rostopic list /clicked_point /clock /cmd_vel /diagnostics /e_stop /gazebo/link_states /gazebo/model_states /gazebo/parameter_descriptions /gazebo/parameter_updates /gazebo/performance_metrics /gazebo/set_link_state ... 우리가 집중하고자 하는 topic은 로봇을 제어하는 /cmd_vel입니다.\nrostopic info 결과 $ rostopic info /cmd_vel Type: geometry_msgs/Twist Publishers: * /teleop_twist_keyboard (http://192.168.55.236:33903/) Subscribers: * /twist_mux (http://192.168.55.236:38201/) * /gazebo (http://192.168.55.236:33033/) rostopic type 결과 $ rostopic type /cmd_vel geometry_msgs/Twist geometry_msgs/Twist의 rosmsg show 결과 $ rosmsg show geometry_msgs/Twist geometry_msgs/Vector3 linear float64 x float64 y float64 z geometry_msgs/Vector3 angular float64 x float64 y float64 z /scan의 rostopic echo 결과 $ rostopic echo /scan header: seq: 0 stamp: secs: 204 nsecs: 678000000 frame_id: \u0026#34;rslidar\u0026#34; angle_min: -1.5707999467849731 angle_max: 1.5707999467849731 angle_increment: 0.008700000122189522 time_increment: 0.0 scan_time: 0.033330000936985016 range_min: 0.44999998807907104 range_max: 50.0 ranges: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, ... /scan의 rostopic hz결과 $ rostopic hz /scan subscribed to [/scan] WARNING: may be using simulated time average rate: 10.000 min: 0.100s max: 0.100s std dev: 0.00000s window: 8 average rate: 10.000 min: 0.100s max: 0.100s std dev: 0.00000s window: 17 rqt_graph에서 /cmd_vel을 찾아볼까요?\nrqt_graph Publisher 프로그래밍 이번 시간 사용할 Package는 py_topic_pkg 입니다. 실습 전 실행부터 해보겠습니다.\nPackage Build cd ~/catkin_ws catkin build py_topic_pkg source devel/setup.bash 예제 실행 # Terminal 1 roslaunch smb_gazebo smb_gazebo.launch # Terminal 2 rosrun py_topic_pkg cmd_vel_pub.py 로봇이 아래와 같이 원을 그리며 움직일 것입니다.\ncmd_vel_pub.py #!/usr/bin/env python3 import rospy from geometry_msgs.msg import Twist class CmdVelPubNode: def __init__(self): # Publisher requires 3 paramters # 1. topic name # 2. topic msg type # 3. topic queue size self.cmd_vel_pub_ = rospy.Publisher(\u0026#34;cmd_vel\u0026#34;, Twist, queue_size=10) self.timer_ = rospy.Timer(rospy.Duration(1.0/10.0), self.pub_msg) self.twist_ = Twist() def pub_msg(self, event=None): # geometry_msgs.Twist # ref: http://docs.ros.org/en/melodic/api/geometry_msgs/html/msg/Twist.html self.twist_.linear.x = 0.5 self.twist_.angular.z = 1.0 self.cmd_vel_pub_.publish(self.twist_) def cmd_vel_node(): rospy.init_node(\u0026#39;cmd_vel_node\u0026#39;, anonymous=True) cmd_vel_pub_node = CmdVelPubNode() rospy.spin() if __name__ == \u0026#39;__main__\u0026#39;: try: cmd_vel_node() except rospy.ROSInterruptException: pass 파이썬 ros 프로그래밍을 위한 rospy, 로봇의 속도 제어에 필요한 Message type인 Twist를 import 하고 있습니다. import rospy from geometry_msgs.msg import Twist rospy.Publisher를 통해 publisher를 생성할 수 있습니다. 이는 최소 3개의 매개변수를 필요로 합니다. topic 이름 topic type queue size self.cmd_vel_pub_ = rospy.Publisher(\u0026#34;cmd_vel\u0026#34;, Twist, queue_size=10)= 우리는 로봇의 제어 신호를 주기적으로 전송하고자 합니다. 따라서 Timer도 선언하였습니다. self.timer_ = rospy.Timer(rospy.Duration(1.0/10.0), self.pub_msg) 다음으로, Message Type인 geometry_msgs/Twist 값을 채웁니다. 현재 우리 로봇은 2차원 평면에서 움직이며, 로봇 형태 때문에 앞뒤 선속도와 각속도를 갖게 됩니다. ... self.twist_ = Twist() def pub_msg(self, event=None): self.twist_.linear.x = 0.5 self.twist_.angular.z = 1.0 Message의 종류는 매우 많습니다. 구글을 통해 검색하면서 코딩하는 습관을 들여봅시다.\nfrom : http://docs.ros.org/ linear의 단위는 m/s 이며, angular의 단위는 rad/s 입니다. pi = 3.14\n마지막, 가장 중요한 topic publish는 생성한 Publisher의 publish() 메소드를 사용합니다. 미리 준비해둔 topic message를 사용합시다. def pub_msg(self, event=None): # geometry_msgs.Twist # ref: http://docs.ros.org/en/melodic/api/geometry_msgs/html/msg/Twist.html self.twist_.linear.x = 0.5 self.twist_.angular.z = 1.0 self.cmd_vel_pub_.publish(self.twist_) 이 Node를 실행하면, 우리의 ROS가 일정 주기에 맞추어 알맞게 topic publish를 실행시켜줄 것입니다. 우리는 정해진 구현에 맞추어 코드만 작성하면 되는 것이지요 😊\ndef cmd_vel_node(): rospy.init_node(\u0026#39;cmd_vel_node\u0026#39;, anonymous=True) cmd_vel_pub_node = CmdVelPubNode() rospy.spin() Subscriber 프로그래밍 이번 예시에는 로봇에 장착된 라이다 센서를 사용해보려 합니다. 예시를 실행해보겠습니다. # Terminal 1 roslaunch smb_gazebo smb_gazebo.launch # Terminal 2 rosrun py_topic_pkg laser_scan_sub.py 실행 이후, 영상과 같이 박스를 로봇의 전방에 배치해봅시다. 터미널에 등장하는 문구에 집중해보세요. 박스가 추가되면서 출력창에 어떠한 변화가 생기나요?\n로봇에 부착된 라이다 센서는 전방 180도 사방으로 360개의 레이저를 흩뿌립니다.\n레이저의 특성상 물체를 맞고 되돌아오게 되며, 이 시간을 통해 물체와의 거리를 알 수 있습니다.\n예시의 프로그램은 로봇에 부착된 레이저에서 publish되는 데이터를 subscribe한 것입니다. 이를 프로그래밍하면서 python으로 subscriber를 다루는 방법에 대해 배워봅시다.\nlaser_scan_sub.py #!/usr/bin/env python3 import rospy from sensor_msgs.msg import LaserScan class LaserSubNode: def __init__(self): # Publisher requires 3 paramters # 1. topic name # 2. topic msg type # 3. sub callback method self.laser_sub_ = rospy.Subscriber(\u0026#34;scan\u0026#34;, LaserScan, self.laser_cb) # first param of callback method is always topic msg def laser_cb(self, data): rospy.loginfo( len(data.ranges)) print(f\u0026#34;\u0026#34;\u0026#34; data.ranges[0]: {data.ranges[0]} data.ranges[90]: {data.ranges[90]} data.ranges[179]: {data.ranges[179]} data.ranges[270]: {data.ranges[270]} data.ranges[360]: {data.ranges[360]} \u0026#34;\u0026#34;\u0026#34;) def laser_sub_node(): rospy.init_node(\u0026#39;laser_sub_node\u0026#39;, anonymous=True) laser_sub_node = LaserSubNode() rospy.spin() if __name__ == \u0026#39;__main__\u0026#39;: try: laser_sub_node() except rospy.ROSInterruptException: pass 이번에 사용하는 topic message는 sensor_msgs/LaserScan입니다. import rospy from sensor_msgs.msg import LaserScan subscriber는 publisher와 달리 Timer가 필요하지 않습니다. publish되는 데이터가 없으면 아무 동작을 할 수 없으며, publish 주기에 맞추어 subscribe할 수밖에 없는 것이지요.\nsubscriber는 rospy.Subscriber로 생성하며 최소 3개의 매개변수를 요구합니다. topic 이름 topic message 이름 subscribe 마다 실행되는 callback 메소드 class LaserSubNode: def __init__(self): # Publisher requires 3 paramters # 1. topic name # 2. topic msg type # 3. sub callback method self.laser_sub_ = rospy.Subscriber(\u0026#34;scan\u0026#34;, LaserScan, self.laser_cb) 이 callback 메소드에서 주의해야 할 점은, 항상 callback method의 매개변수가 subscribe된 데이터라는 점입니다. 지금의 경우 LaserScan 타입의 데이터일 것입니다. # first param of callback method is always topic msg def laser_cb(self, data): rospy.loginfo( len(data.ranges)) ... 마지막으로, 깔끔한 터미널 출력을 위해 print 함수를 사용하였습니다. print(f\u0026#34;\u0026#34;\u0026#34; data.ranges[0]: {data.ranges[0]} data.ranges[90]: {data.ranges[90]} data.ranges[179]: {data.ranges[179]} data.ranges[270]: {data.ranges[270]} data.ranges[360]: {data.ranges[360]} \u0026#34;\u0026#34;\u0026#34;) Subscriber 실행 시에는 항상 rospy.spin()을 잊지 말도록 합니다. spin 되지 않는다면 특정 쓰레드가 자원을 점유하기 때문에 subscriber의 상태를 갱신할 수 없습니다.\ndef laser_sub_node(): rospy.init_node(\u0026#39;laser_sub_node\u0026#39;, anonymous=True) laser_sub_node = LaserSubNode() rospy.spin() 과제 - 물체 회피하기 pub/sub의 개념을 잘 이해하였는지 알아볼 수 있는 과제를 준비해보았습니다. 정답이 따로 있는 것은 아니기에 부담 없이 해보시고, 저의 답안도 한번 살펴보세요.\n예제 실행 # Terminal 1 roslaunch smb_gazebo smb_gazebo.launch # Ternimal 2 rosrun py_topic_pkg collision_aviod.py Gazebo 예제를 실행하였다면, 로봇의 전방에 장애물을 놓아 진로를 막아봅니다. 여러분께서 구현해야 하는 것은, 라이다 센서를 사용하여 로봇이 회피 주행을 하도록 만드는 것입니다. 일종의 템플렛 코드를 첨부하였으며, my_collision_aviod.py라는 이름의 코드입니다.\n해당 코드의 TODO 부분을 작성하여 여러분만의 회피 알고리즘을 만들어 보세요!\n로봇의 라이다 데이터인 LaserScan을 Subscribe하여 Twist Type을 사용하는 scan topic으로 publish를 하게 됩니다. class CollisionAvoidNode: def __init__(self): self.laser_sub_ = rospy.Subscriber(\u0026#34;scan\u0026#34;, LaserScan, self.laser_cb) self.cmd_vel_pub_ = rospy.Publisher(\u0026#34;cmd_vel\u0026#34;, Twist, queue_size=10) self.twist_ = Twist() def laser_cb(self, data): # TODO: Prevent robot from collision # make your own logic to do that return None 제가 작성한 예시를 수정하여 더욱 똑똑한 로봇을 구현하셔도 좋고, 자유롭게 실습해보시기 바랍니다.\n참고자료\nhttps://rsl.ethz.ch/education-students/lectures/ros.html https://docs.ros.org/en/foxy/index.html http://wiki.ros.org/msg "
},
{
	"uri": "/kr/ros_basic_noetic/lecture6/",
	"title": "Lecture6 - ROS Service, Parameter",
	"tags": [],
	"description": "",
	"content": " 지난 시간 마지막 예시였던 장애물 회피 코드부터 간단하게 리뷰해보고자 합니다.\n제가 작성한 로직은 다음과 같습니다.\n과제를 해보셨다면 아시겠지만, 측정 범위를 벗어나게 되면 data.ranges는 inf 값을 갖게 됩니다. 이를 걸러내는 코드가 아래 부분입니다. for i, point in enumerate(data.ranges): if not math.isinf(point) and point \u0026lt; 1.0: 저의 로직은, 정면을 기점으로 왼쪽과 오른쪽 각각 inf가 아닌 데이터의 개수를 카운팅합니다. 전체 데이터가 362개이고 마지막 데이터는 사용하기 않는 값이기 때문에, 180을 기점으로 잡았습니다. left_side_count = 0 right_side_count = 0 for i, point in enumerate(data.ranges): if not math.isinf(point) and point \u0026lt; 1.0: if i \u0026gt; 180: left_side_count += 1 else: right_side_count += 1 이제, 제어 데이터를 만들어줍니다. ROS를 비롯하여 로봇 시스템에서는 대부분 오른손 좌표계를 사용합니다. 따라서 위에서 보았을 rospy.loginfo(hello_du)때 오른손이 감기는 반시계 방향이 + 부호를 갖게 됩니다. 이를 고려하여 각속도를 정했습니다. 180은 magic number, 일종의 변환 상수입니다. image from : 오로카\ndef laser_cb(self, data): left_side_count = 0 right_side_count = 0 for i, point in enumerate(data.ranges): if not math.isinf(point) and point \u0026lt; 1.0: if i \u0026gt; 180: left_side_count += 1 else: right_side_count += 1 self.twist_.linear.x = 0.3 self.twist_.angular.z = (right_side_count - left_side_count) / 100 self.cmd_vel_pub_.publish(self.twist_) 지난 강의에서 이야기한 것과 같이 이 문제의 정답은 없습니다.\n다만, Topic의 Pub / Sub을 모두 사용할 수 있는지 스스로 점검해볼 수 있을 것입니다.\nROS Parameter 앞선 저의 예시에서 마지막 속도로 변환하는 부분 수식에 나누기 100이 있었던 것을 기억하시나요? 이런 상수를 직접 코드에 적는 것은 사실 추천되지 않습니다. 개발 이후 해당 상수를 변경하고자 하였을 시, 직접 코드를 수정하고 다시 실행해야 하기 때문에 불편을 야기합니다.\n이러한 문제의 해결 방법으로 ROS의 매개변수, parameter를 다루는 방법을 알아보겠습니다.\npy_param_pkg/scripts/various_params.py #!/usr/bin/env python3 import rospy class ParamNode: def __init__(self): self.str_param_ = rospy.get_param(\u0026#39;~str_param\u0026#39;, \u0026#39;hello_world\u0026#39;) self.int_param_ = rospy.get_param(\u0026#39;~int_param\u0026#39;, 2023) self.double_param_ = rospy.get_param(\u0026#39;~double_param\u0026#39;, 3.14) self.bool_param_ = rospy.get_param(\u0026#39;~bool_param\u0026#39;, True) self.list_of_float_param_ = rospy.get_param(\u0026#39;~list_of_float_param\u0026#39;, [1., 2., 3., 4.]) rospy.loginfo(f\u0026#34;\u0026#34;\u0026#34; self.str_param_ = {self.str_param_} self.int_param_ = {self.int_param_} self.double_param_ = {self.double_param_} self.bool_param_ = {self.bool_param_} self.list_of_float_param_ = {self.list_of_float_param_} \u0026#34;\u0026#34;\u0026#34;) def param_node(): rospy.init_node(\u0026#39;param_node\u0026#39;, anonymous=True) param_node = ParamNode() rospy.spin() if __name__ == \u0026#39;__main__\u0026#39;: try: param_node() except rospy.ROSInterruptException: pass 실행 결과는 다음과 같습니다. $ rosrun py_param_pkg various_params.py [INFO] [1672014267.630578]: self.str_param_ = hello_world self.int_param_ = 2023 self.double_param_ = 3.14 self.bool_param_ = True self.list_of_float_param_ = [1.0, 2.0, 3.0, 4.0] 매개변수를 선언하고 기본값을 지정하는 방법은 rospy.get_param을 사용하는 것입니다. 두번째 기본값을 잘 보면 어떤 타입을 사용하는지 알 수 있습니다. def __init__(self): self.str_param_ = rospy.get_param(\u0026#39;~str_param\u0026#39;, \u0026#39;hello_world\u0026#39;) self.int_param_ = rospy.get_param(\u0026#39;~int_param\u0026#39;, 2023) self.double_param_ = rospy.get_param(\u0026#39;~double_param\u0026#39;, 3.14) self.bool_param_ = rospy.get_param(\u0026#39;~bool_param\u0026#39;, True) self.list_of_float_param_ = rospy.get_param(\u0026#39;~list_of_float_param\u0026#39;, [1., 2., 3., 4.]) parameter 앞에 붙는 물결 표시 (~)는 private parameter를 의미합니다. 이에 대해 궁금하다면 아래의 추가 자료를 학습해보세요. global_name = rospy.get_param(\u0026#34;/global_name\u0026#34;) relative_name = rospy.get_param(\u0026#34;relative_name\u0026#34;) private_param = rospy.get_param(\u0026#39;~private_name\u0026#39;) default_param = rospy.get_param(\u0026#39;default_param\u0026#39;, \u0026#39;default_value\u0026#39;) 추가 자료 : wiki.ros\n매개변수를 변경하는 가장 보변적인 방법은 launch file을 사용하는 것입니다. launch file의 param 태그를 사용하여 Node에 원하는 parameter를 전달할 수 있습니다. \u0026lt;launch\u0026gt; \u0026lt;node name=\u0026#34;various_param_node\u0026#34; pkg=\u0026#34;py_param_pkg\u0026#34; type=\u0026#34;various_params.py\u0026#34; respawn=\u0026#34;false\u0026#34; output=\u0026#34;screen\u0026#34; \u0026gt; \u0026lt;param name=\u0026#34;str_param\u0026#34; type=\u0026#34;string\u0026#34; value=\u0026#34;roslaunch changed me\u0026#34; /\u0026gt; \u0026lt;/node\u0026gt; \u0026lt;/launch\u0026gt; ROS 프로그래밍을 하다 보면 매개변수가 아주 많이 필요한 경우가 있습니다. 이럴 때마다 launch file에 param 태그 라인을 추가하는 것은 매우 귀찮은 일입니다.\nyaml이라는 형식의 파일로 매개변수를 한번에 관리할 수 있습니다.\npy_param_pkg/param/config.yaml str_param: \u0026#34;yaml string\u0026#34; int_param: 9 double_param: 2.71828 bool_param: \u0026#34;false\u0026#34; list_of_float_param: [3., 2., 1.] py_param_pkg/launch/param_with_yaml.launch \u0026lt;launch\u0026gt; \u0026lt;node name=\u0026#34;various_param_node\u0026#34; pkg=\u0026#34;py_param_pkg\u0026#34; type=\u0026#34;various_params.py\u0026#34; respawn=\u0026#34;false\u0026#34; output=\u0026#34;screen\u0026#34; \u0026gt; \u0026lt;rosparam command=\u0026#34;load\u0026#34; file=\u0026#34;$(find py_param_pkg)/param/config.yaml\u0026#34; /\u0026gt; \u0026lt;param name=\u0026#34;str_param\u0026#34; type=\u0026#34;string\u0026#34; value=\u0026#34;roslaunch changed me\u0026#34; /\u0026gt; \u0026lt;/node\u0026gt; \u0026lt;/launch\u0026gt; launch file에 rosparam 태그를 추가하고, load command를 사용하며 사용하는 yaml 파일의 위치를 file 옵션을 통해 전달합니다.\nROS parameter Commands rostopic, rosnode와 같이 parameter 또한 터미널 명령어를 갖고 있습니다.\n접근 가능한 모든 parameter들을 나열합니다. rosparam list 특정 paramter의 값을 얻고자하면 아래 키워드를 사용합니다. rosparam get \u0026lt;parameter_name\u0026gt; 선언되어 있는 parameter의 값을 변경하고 싶은 경우 아래 키워드를 사용합니다. rosparam set \u0026lt;parameter_name\u0026gt; \u0026lt;value\u0026gt; 여러분들이 작성한 회피 프로그램에도 매개변수로 작용하는 상수들이 있을 것입니다. 이를 parameter로 변경하여 launch file과 yaml file로 업데이트하는 작업을 해보세요\nROS Service Topic에 이어 ROS의 통신 메커니즘 두번째로 Service를 배워보겠습니다.\nService가 동작하는 방식은 아래와 같습니다.\n그림과 같이 Client Node가 Server Node로 request를 주면, 해당 request에 대응하는 적절한 response가 다시 Client에게로 전달됩니다. 이 과정을 Service Call이라고 부릅니다.\nimage from : docs.ros.org\n하나의 Service Server에는 여러 Client Node가 request 할 수 있지만, Server는 동시에 여러 request를 처리하지는 못합니다. 두 Node에서 동시에 request가 왔다면, 조금이라도 먼저 통신한 Node의 작업을 우선 진행하고, 그동안 다른 Node는 기다리고 있어야 합니다. image from : https://docs.ros.org/en/foxy/Tutorials/Services/Understanding-ROS2-Services.html\nTopic과 비교하여 Service의 특징을 알아봅시다.\n1:1 통신 : Topic publish를 하면 여러 Node가 Subscribe 가능합니다. 반면, Service는 request가 온 대상에게만 response를 줍니다. 순차적 통신 : Service Server는 동시에 여러 request를 처리할 수 없습니다. 현재 작업중인 request가 처리될 때 까지 다른 request는 기다리고 있어야 합니다. 단발성 : Topic은 대부분 지속적으로 publish를 진행하는 반면, Service는 1회성 통신입니다. 실제 로봇 프로그램에서 Service는 어떻게 사용될 수 있을지, 예시를 통해 살펴봅시다.\n예제 패키지 빌드 cd ~/catkin_ws catkin build py_service_pkg source devel/setup.bash Service Client 예제 실행 - 아르키메데스 나선 # Terminal 1 roslaunch py_service_pkg empty_gazebo.launch # Terminal 2 rosrun py_service_pkg spawn_model_client.py 방금 실행한 예시는 Gazebo에게 box를 등장시켜달라고 하는 Service Client를 포함하고 있습니다.\nBox가 등장하는 위치를 아래 사진과 같은 수식에 맞추어 설정한 것 뿐입니다.\n그럼, 코드를 분석해 볼까요?\n필요한 파이썬 패키지들을 import 합니다. import math import rospy import rospkg from geometry_msgs.msg import Pose from gazebo_msgs.srv import SpawnModel 여기서 중요한 점은 msg와 srv 부분입니다. topic에서 사용되는 데이터 타입이 Message였고, 프로그래밍 시에는 msg로 사용하였습니다.\nService에서는 msg가 아니라 srv라는 데이터 타입을 사용합니다. image from : rsl.eth\n이 srv는 msg와 다른 점이 있는데, request와 response로 나뉘어 있다는 점입니다. \u0026mdash; 표시를 기점으로 위쪽은 Server에게 전달하는 request, 아래쪽은 Server가 다시 회답하는 response 부분입니다. 이번 예시에서 사용한 gazebo_msgs/SpawnModel도 아래와 같은 구조를 갖습니다. image from : docs.ros.org\ngazebo_msgs/SpawnModel를 살펴보면 파란 글자로 geometry_msgs/Pose라는 부분이 있습니다. 이와 같이 srv는 다른 msg를 품을 수도 있고, 이렇게 만든 srv를 또다시 다른 srv에 포함시킬 수도 있습니다.\n코드 구현 관점에서, geometry_msgs/Pose는 Model을 등장시킬 초기 위치를 지정하는데 사용됩니다.\n# initial_pose initial_pose = Pose() initial_pose.position.x = 0.0 initial_pose.position.y = -1 initial_pose.position.z = 0.2 # z rotation -pi/2 to Quaternion initial_pose.orientation.z = -0.707 initial_pose.orientation.w = 0.707 Service Client의 생성과 사용은 아래와 같습니다. spawn_model_prox = rospy.ServiceProxy(\u0026#34;gazebo/spawn_urdf_model\u0026#34;, SpawnModel) ... result = spawn_model_prox( entity_name, model_xml, robot_namespace, initial_pose, reference_frame ) rospy.ServiceProxy()는 2개의 매개변수를 필요로 합니다.\nservice 이름 service 데이터 타입 (srv) 생성한 client로 request를 하기 위해서는 생성한 인스턴스에 매개변수를 전달하기만 하면 됩니다. 마치 함수 호출처럼 말이지요. 이는 ServiceProxy 내부적으로 call 메소드가 구현되어있기 때문입니다.\nservice call의 결과로 result가 반환되며, 예시에서는 성공 여부를 반환하도록 되어 있습니다.\n추가적으로, model을 불러오는 부분을 간단하게 설명하고자 합니다. # model_xml rospack = rospkg.RosPack() model_path = rospack.get_path(\u0026#34;py_service_pkg\u0026#34;) + \u0026#34;/urdf/\u0026#34; with open(model_path + model_name + \u0026#34;.urdf\u0026#34;, \u0026#34;r\u0026#34;) as xml_file: model_xml = xml_file.read().replace(\u0026#34;\\n\u0026#34;, \u0026#34;\u0026#34;) Gazebo는 urdf라는 파일을 전달하면 해당 파일을 기반으로 시뮬레이션에 물체를 등장시켜줍니다. 이 urdf라는 것은 로봇을 표현하기 위한 일종의 약속된 파일 확장명입니다.\nimage from : spart\n세상 모든 로봇들은 joint와 link로 표현 가능합니다. 이러한 개념을 바탕으로 로봇의 특성을 텍스트 파일로 표현하는 형식이 바로 urdf이며, 아래와 같이 여러 태그와 속성을 사용하여 작성 가능합니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;robot name=\u0026#34;box\u0026#34;\u0026gt; \u0026lt;link name=\u0026#34;box\u0026#34;\u0026gt; \u0026lt;inertial\u0026gt; \u0026lt;mass value=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;!-- Inertia values were calculated to be consistent with the mass and geometry size, assuming a uniform density. --\u0026gt; \u0026lt;inertia ixx=\u0026#34;0.0108\u0026#34; ixy=\u0026#34;0\u0026#34; ixz=\u0026#34;0\u0026#34; iyy=\u0026#34;0.0083\u0026#34; iyz=\u0026#34;0\u0026#34; izz=\u0026#34;0.0042\u0026#34;/\u0026gt; \u0026lt;/inertial\u0026gt; \u0026lt;visual\u0026gt; \u0026lt;geometry\u0026gt; \u0026lt;box size=\u0026#34;.1 .2 .3\u0026#34;/\u0026gt; \u0026lt;/geometry\u0026gt; \u0026lt;/visual\u0026gt; \u0026lt;collision name=\u0026#34;box\u0026#34;\u0026gt; \u0026lt;geometry\u0026gt; \u0026lt;box size=\u0026#34;.1 .2 .3\u0026#34;/\u0026gt; \u0026lt;/geometry\u0026gt; \u0026lt;/collision\u0026gt; \u0026lt;/link\u0026gt; \u0026lt;/robot\u0026gt; ROS Service Commands gazebo/spawn_urdf_model과 같은 service는 gazebo_ros를 사용할 때 자동으로 함께 실행됩니다. 이렇게 현재 어떠한 service가 존재하며, 또 구체적인 정보는 어떻게 조회하는지 알아봅시다.\n현재 사용 가능한 모든 service를 조회해봅시다. $ rosservice list /delete_entity /gazebo/describe_parameters /gazebo/get_parameter_types /gazebo/get_parameters /gazebo/list_parameters /gazebo/set_parameters ... 리눅스의 grep 명령어를 함께 사용해 보세요.\n특정 service가 어떤 srv 타입을 사용하는지 검색하고 싶다면 다음 커멘드 라인을 사용합니다. $ rosservice type /gazebo/spawn_urdf_model gazebo_msgs/SpawnModel 이렇게 검색된 srv는 rossrv show와 결합할 때 더욱 진가를 발휘합니다. $ rossrv show `rosservice type /gazebo/spawn_urdf_model` string model_name string model_xml string robot_namespace geometry_msgs/Pose initial_pose geometry_msgs/Point position float64 x float64 y float64 z geometry_msgs/Quaternion orientation float64 x float64 y float64 z float64 w string reference_frame --- bool success string status_message 특정 srv 타입에 대한 자세한 정보는 다음과 같이 조회할 수 있습니다. $ rosservice info /gazebo/spawn_urdf_model Node: /gazebo URI: rosrpc://192.168.55.236:55405 Type: gazebo_msgs/SpawnModel Args: model_name model_xml robot_namespace initial_pose reference_frame gazebo_ros에서 제공하는 다양한 service들이 있습니다. rosservice 커멘드를 사용하여 조회해보고 여러분들만의 Application을 생각해 보세요.\nService Server 예제 실행 - 긴급 정지 # Terminal 1 roslaunch smb_gazebo smb_gazebo.launch # Terminal 2 rosrun py_service_pkg emergency_stop.py # Terminal 3 rqt 두번째 Node 실행 시, 로봇이 원을 그리며 움직이기 시작합니다. 세번째 명령어를 통해 등장하는 rqt는 아래와 같이 사용 가능합니다. 로봇에게 긴급 정지 명령을 내려보겠습니다. 실제 로봇 개발시에도 Service는 이렇게 단발성이고, 빠르게 실행되어야 하는 동작에 주로 사용됩니다. 더불어, 지금 실행한 예시가 Service Server임을 다시 한 번 상기시켜드립니다.\nimage from : rsl.eth\n코드를 분석해 봅시다.\npy_service_pkg/scripts/emergency_stop.py from geometry_msgs.msg import Twist from std_srvs.srv import SetBool, SetBoolResponse 이번에 사용하는 데이터 타입은 크게 2 종류입니다.\n로봇 제어 topic에 사용되는 Twist 긴급 정지 service에 사용될 SetBool image from : docs.ros.org\nSetBoolResponse이라는 것은 SetBool srv 중 response 부분에 해당합니다. 기본 데이터 타입 이름 + Response를 붙여주기만 하면 사용 가능합니다.\nROS의 msg, srv는 다양한 언어와 상황을 고려하도록 만들어져 있으며, ROS 2에서는 IDL이라는 이름으로 더욱 발전하였습니다. 이후의 커스텀 데이터 타입 제작을 통해 이 과정을 다시 살펴봅시다.\n다음으로 통신 메커니즘을 생성합니다. class EmergencyStopNode(object): def __init__(self): self.cmd_vel_pub_ = rospy.Publisher(\u0026#34;cmd_vel\u0026#34;, Twist, queue_size=10) self.stop_server_ = rospy.Service(\u0026#34;emergency_stop\u0026#34;, SetBool, self.stop_cb) 로봇 제어를 위한 topic publisher와 service server를 생성합니다.\nrospy.Service()를 통해 Service Server를 생성할 수 있으며 다음과 같은 매개변수를 필요로합니다.\nService 이름 srv 타입 Client로부터 request가 올 시 실행되는 callback 함수 callback 함수는 일전 subscriber에서 살펴본 바 있습니다. service server의 callback 함수는 항상 매개변수로 request srv를 받습니다. 그리고 return 값은 항상 response가 됩니다.\ndef stop_cb(self, request): ... return self.response_ request 데이터 중 boolean 값을 갖는 data의 true / false 여부에 따라 로봇의 정지 여부가 결정됩니다. if request.data is True: self.twist_msg_.linear.x = 0.0 self.twist_msg_.angular.z = 0.0 self.cmd_vel_pub_.publish(self.twist_msg_) self.response_.success = True self.response_.message = \u0026#34;Successfully Stopped\u0026#34; else: self.response_.success = False self.response_.message = \u0026#34;Stop Failed\u0026#34; 마지막에 사용한 rqt의 service caller는 별도의 프로그래밍이나 복잡한 터미널 명령어 없이도 손쉽게 service를 다룰 수 있게 해주는 ROS의 툴입니다.\n지금까지 ROS Service에 대해 배워보았습니다. Topic과 더불어 많이 사용되는 통신 메커니즘이므로 잘 숙지하고 복습하시기 바랍니다.\n참고자료\nhttps://rsl.ethz.ch/education-students/lectures/ros.html https://ko.wikipedia.org/wiki/아르키메데스_와선 https://docs.ros.org/en/foxy/index.html http://wiki.ros.org/Services "
},
{
	"uri": "/kr/ros_basic_noetic/lecture7/",
	"title": "Lecture7 - Rqt Tools and rosbag, ROS Time",
	"tags": [],
	"description": "",
	"content": " 강의 초반, 다양한 rqt tool들을 살펴본 바 있습니다. 이제는 Topic과 Service에 모두 익숙해졌기 때문에, rqt의 많은 기능들을 사용할 수 있습니다. 다시 한 번 rqt를 살펴보면서 편리한 툴들의 사용법을 익혀봅시다.\nMessage Publisher \u0026amp; Topic Monitor 강의자를 따라 다음과 같이 화면을 구성합니다.\nplugins ⇒ topics ⇒ Message Publisher pulgins ⇒ topics ⇒ Topic Monitor message publisher를 사용하면 코딩 없이 cmd_vel을 publish가 가능합니다. Topic Msg에 원하는 데이터를 채워넣은 뒤, 주기를 선택한 후 체크박스를 클릭하면 로봇이 움직이기 시작합니다. Topic Monitor를 사용하면, 여러 데이터들을 효과적으로 모니터링 가능합니다. Topic Publisher와 동일하게 체크박스를 눌러 topic을 선택한 뒤, 변하는 데이터를 확인해봅시다. 코딩 없이 간단히 값의 확인과 동작 여부를 확인할 수 있는 툴들이었습니다.\nRQT Multiplot 수치 데이터를 그래프로 보고싶은 경우 rqt의 multiplot이 유용하게 사용됩니다.\nsudo apt install ros-noetic-rqt-multiplot rosrun rqt_multiplot rqt_multiplot /odom topic의 X,Y position을 기준으로 그래프를 그려보도록 하겠습니다. 아래의 gif를 통해 모든 과정을 기록하였으니 차근차근 따라와주세요.\nRQT Console 지금까지 ROS의 콘솔 로그를 위해 rospy.loginfo()를 사용하였습니다. 사실 ROS에는 loginfo말고도 다양한 level의 logger level이 존재합니다. 실습을 통해 살펴봅시다.\nrospy logger level # Terminal 1 roscore # Terminal 2 rosrun my_first_package logger_level.py 코드의 내용과 함께 예시를 살펴봅시다. def hello_du(self, event=None): hello_du = f\u0026#34;hello du {rospy.get_time()}, counter: {self.counter_}\u0026#34; rospy.logdebug(hello_du) rospy.loginfo(hello_du) rospy.logwarn(hello_du) rospy.logerr(hello_du) rospy.logfatal(hello_du) self.counter_ += 1 ROS는 총 5가지의 logger level을 갖추고 있으며, Debug 부터 Fatal로 갈수록 더 높은 level을 갖는다고 보시면 됩니다. Info level 부터 콘솔 출력이 이루어지며, Python의 stdout를 사용합니다.\nimage from : 51CTO 상황에 따라 각기 다른 level의 log를 사용하도록 하면, 실제 로봇 개발시에도 큰 도움이 됩니다.\nrqt에는 이러한 다양한 level을 갖는 ros의 log를 필터링하는 rqt console이라는 툴이 있습니다. 사용 방법을 함께 알아봅시다.\n그 밖에도 수많은 rqt 도구들이 있지만, 모두 살펴보는 대신 링크로 대체하겠습니다. \u0026gt; ROS Wiki\nROS Bags rqt 툴에 속하지는 않지만, 개발 시 매우 유용한 ROS의 기능을 하나 더 소개시켜드리고자 합니다.\nrosbag은 프로그램 동작 중 발생하는 message 데이터를 기록하고 복기할 수 있게 해주는 툴입니다. 로봇 알고리즘을 개발할 때, 같은 상황에 대해 성능을 비교하는 경우, 혹은 교육 목적으로 데이터셋을 제공하는 경우 등에 매우 유용하게 사용할 수 있습니다.\nrosbag 사용법을 함께 실습해보겠습니다.\nsmb gazebo를 실행합니다. roslaunch smb_gazebo smb_gazebo.launch world:=big_map_summer_school rosbag의 사용 시 여러 옵션들이 있습니다. -o 옵션으로 rosbag의 이름을 지정합니다. -a 옵션 사용 시 모든 topic을 저장합니다. rosbag의 종료는 ctrl + c를 사용합니다. rosbag record -o first_rosbag /scan /tf /tf_static /tf와 /tf_static은 왜 저장하는 것일까요? 생각해봅시다.\nrosbag info를 통해 저장을 마친 rosbag의 정보를 조회할 수 있습니다. $ rosbag info first_rosbag_\u0026lt;time-format-sth\u0026gt;.bag path: first_rosbag_2022-12-27-15-51-55.bag version: 2.0 duration: 4.8s start: Jan 01 1970 09:07:35.31 (455.31) end: Jan 01 1970 09:07:40.12 (460.12) size: 83.8 KB messages: 49 compression: none [1/1 chunks] types: sensor_msgs/LaserScan [90c7ef2dc6895d81024acba2ac42f369] topics: /scan 49 msgs : sensor_msgs/LaserScan 저장 완료된 rosbag을 다시 복기해봅시다. $ rosbag play first_rosbag_2022-12-27-15-56-23.bag [ INFO] [1672124296.822088842]: Opening first_rosbag_2022-12-27-15-56-23.bag Waiting 0.2 seconds after advertising topics... done. ... rviz를 통해 시각화까지 해봅시다. rosbag은 기본적으로 topic을 저장합니다.\nrviz 화면을 살펴보면 아래와 같은 Warning이 발생할 것입니다. 그런데 이 문구, 익숙하지 않나요?\n[ WARN] [1672124550.336965013]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame LF_WHEEL at time 472.056000 according to authority unknown_publisher [ WARN] [1672124550.336981403]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame LH_WHEEL at time 472.056000 according to authority unknown_publisher [ WARN] [1672124550.336991753]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame RF_WHEEL at time 472.056000 according to authority unknown_publisher [ WARN] [1672124550.337003964]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame RH_WHEEL at time 472.056000 according to authority unknown_publisher [ WARN] [1672124550.356035553]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame base_link at time 472.076000 according to authority unknown_publisher [ WARN] [1672124550.356945321]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame LF_WHEEL at time 472.076000 according to authority unknown_publisher [ WARN] [1672124550.356960231]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame LH_WHEEL at time 472.076000 according to authority unknown_publisher [ WARN] [1672124550.356970561]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame RF_WHEEL at time 472.076000 according to authority unknown_publisher ROS Time 일전 강의에서 언급한 바와 같이, 이번 강의에 ROS의 시간 체계에 대해서 다잡고 가고자 합니다.\nrospy.loginfo를 통해 콘솔에 출력되는 시간과 같이 ROS에서 기본적으로 사용되는 시간의 기준은 PC의 Clock입니다. (이를 wall timer라고 부릅니다.) ROS 프로그램은 일정 주기를 갖고 무한히 반복되는 상황이 잦습니다. 이때 사용하는 주기가 정확해야 할 것입니다. 우리는 2023년 00월 00일이라는 시간체계를 사용하지만, Gazebo와 같은 시뮬레이션 툴은 시작되는 시점이 곧 0분 0초가 됩니다. 이러한 시간의 차이로 인해 warning과 error가 빈번하게 발생합니다. 그럼, 실질적으로 ROS에서 시각과 주기, 시간은 어떻게 다루는지 예시와 함께 python 코드를 살펴봅시다.\nros_time.py $ rosrun my_first_package ros_time.py [INFO] [1672127477.793024]: Current time 1672127477 792964935 [INFO] [1672127477.793593]: Current time to_sec 1672127477 [INFO] [1672127477.794082]: Past time 1672127477 292964935 [INFO] [1672127477.893132]: Current time 1672127477 893082141 [INFO] [1672127477.893684]: Current time to_sec 1672127477 [INFO] [1672127477.894148]: Past time 1672127477 393082141 ... 코드는 다음 위치에서 확인이 가능합니다. \u0026gt; https://github.com/RB2023ROS/du2023-ros1/blob/main/my_first_package/scripts/ros_time.py\nrospy Time instance rospy에서는 Time이라는 클래스로 시간을 표현합니다. 가장 많이 사용되는 현재 시간은 rospy.Time.now() 로 파악할 수 있으며, 이는 sec와 nsec등의 클래스 변수를 갖고 있습니다.\ndef hello_du(self, event=None): now = rospy.Time.now() seconds = now.to_sec() rospy.loginfo(\u0026#34;Current time %i %i\u0026#34;, now.secs, now.nsecs) rospy.loginfo(\u0026#34;Current time to_sec %i\u0026#34;, seconds) rospy Time Duration 시간 간격을 나타내는 클래스로 Duration이 사용되며, Time 인스턴스와 +,- 연산이 가능합니다.\ndelta = rospy.Duration(0.5) past = now - delta rospy.loginfo(\u0026#34;Past time %i %i\u0026#34;, past.secs, past.nsecs) rospy Rate while loop와 Rate를 사용하여 일정 주기다마 반복되는 구현이 가능합니다. 이때 사용되는 시간 기준은 PC의 Clock입니다.\nr = rospy.Rate(10) # 10hz while not rospy.is_shutdown(): time_ex.hello_du() r.sleep() Topic vs Service and Action 지금까지 ROS의 통신 메커니즘으로 Topic과 Service에 대해 배워보았습니다. 그런데, 사실 ROS의 통신 메커니즘에는 Action이라는 한가지가 더 있습니다.\nAction은 Topic과 Service 모두의 특징을 갖고 있는 진보된 통신 메커니즘입니다. Action은 Feedback이라는 것으로 Goal Request 이후 계속적인 데이터 송수신이 가능합니다. Action은 ROS 2 강의에서 살펴볼 예정으로 어떻게 사용될 수 있을지 한번 고민해보세요.\nimage from : docs.rog.org 참고자료\nhttp://wiki.ros.org/rospy/Overview/Time https://docs.ros.org/en/foxy/index.html "
},
{
	"uri": "/kr/ros_basic_noetic/lecture8/",
	"title": "Lecture8 - Deal with Open Source Projects, Custom Interfaces",
	"tags": [],
	"description": "",
	"content": "Deal with Open Source Projects 이번 시간에는 오픈 소스 프로젝트를 사용하는 방법에 대해 배워보겠습니다. 보다 실질적인 사용 방법을 보여드리기 위해 저 또한 여러분들과 같은 상황에서 처음부터 하나씩 같이 해보겠습니다.\n오늘 데모하고자 하는 로봇 소프트웨어는 드론 시뮬레이션입니다. 지금까지 지상을 움직이는 바퀴 로봇만을 다루었기 때문에 새로운 플렛폼을 동작시켜보고자 합니다.\n항상 시작은 구글링부터!! 검색 결과 원하는 패키지를 찾은 것 같습니다. \u0026gt; https://github.com/RAFALAMAO/hector-quadrotor-noetic 목적에 부합하는 오픈소스를 찾기 위해서 아래와 같은 기본적인 내용을 고려해야 합니다.\n버전 호환성 구체적인 목표에 부합하는지 Star, Fork를 통해 검증된 소스코드임을 확인 Issue를 통해 사용 중 문제가 있지는 않은지 Readme를 따라 package build를 진행하고 최초 실행을 해보겠습니다.\n# Terminal 1 roslaunch hector_quadrotor_gazebo quadrotor_empty_world.launch # Terminal 2 rosrun hector_ui ui_hector_quad.py 동작에는 문제가 없어보입니다. 그럼 이 프로젝트가 내부적으로 어떻게 구현되어있는지 분석해봅시다.\nrqt_graph 로봇의 위치를 알려주는 topic인 /ground_truth/state와 /ground_truth_to_tf/pose를 파악할 수 있습니다. gazebo에서 물체의 절대적인 위치를 알려주기 때문에 이를 ground truth라고 부르고 있습니다.\n이번에는 조종 프로그램의 소스코드를 확인해봅시다. (hector_quadrotor_noetic/hector_ui/src에 위치하고 있습니다.) #Callback de pose y orientacion simulador def pose_callback(data): x_p.set(\u0026#34;{0:.2f}\u0026#34;.format(data.pose.pose.position.x)) y_p.set(\u0026#34;{0:.2f}\u0026#34;.format(data.pose.pose.position.y)) z_p.set(\u0026#34;{0:.2f}\u0026#34;.format(data.pose.pose.position.z)) def rot_callback(data): z_o.set(\u0026#34;{0:.2f}\u0026#34;.format( math.degrees(quaterionToRads(data)) )) rospy.init_node(\u0026#39;HectorQ_GUI\u0026#39;, anonymous=False) #Subscribers posicionLider_sub = rospy.Subscriber(\u0026#34;/ground_truth/state\u0026#34;, Odometry , pose_callback) orientaLider_sub = rospy.Subscriber(\u0026#34;/ground_truth_to_tf/pose\u0026#34;, PoseStamped , rot_callback) 두 종류의 subscriber가 존재하며 각각 UI의 상태를 업데이트하는 것 같이 보입니다.\n이번에는 launch file을 분석해봅시다 - hector_quadrotor/hector_quadrotor_gazebo/launch/quadrotor_empty_world.launch \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;launch\u0026gt; \u0026lt;arg name=\u0026#34;paused\u0026#34; default=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;use_sim_time\u0026#34; default=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;gui\u0026#34; default=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;headless\u0026#34; default=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;debug\u0026#34; default=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;include file=\u0026#34;$(find gazebo_ros)/launch/empty_world.launch\u0026#34;\u0026gt; \u0026lt;arg name=\u0026#34;paused\u0026#34; value=\u0026#34;$(arg paused)\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;use_sim_time\u0026#34; value=\u0026#34;$(arg use_sim_time)\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;gui\u0026#34; value=\u0026#34;$(arg gui)\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;headless\u0026#34; value=\u0026#34;$(arg headless)\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;debug\u0026#34; value=\u0026#34;$(arg debug)\u0026#34;/\u0026gt; \u0026lt;/include\u0026gt; \u0026lt;include file=\u0026#34;$(find hector_quadrotor_gazebo)/launch/spawn_quadrotor.launch\u0026#34; /\u0026gt; \u0026lt;arg name=\u0026#34;model\u0026#34; value=\u0026#34;$(find hector_quadrotor_description)/urdf/quadrotor_hokuyo_utm30lx.gazebo.xacro\u0026#34;/\u0026gt; \u0026lt;/launch\u0026gt; gazebo_ros의 empty_world.launch, hector_quadrotor_gazebo의 spawn_quadrotor.launch가 실행되며, model이라는 argument를 갖습니다.\nspawn_quadrotor.launch에는 다음과 같은 node들이 실행됩니다.\nspawn_model robot_state_publisher ground_truth_to_tf controller.launch ⇒ controller_spawner 이렇게 rqt 툴들과 코드의 구조를 파헤치면서 전체 구조를 파악할 수 있으며 원하는 부분만을 고치면서 Package를 발전시켜나가는 것입니다.\nlaunch file의 응용을 실습해봅시다. 일전 배워본 husky gazebo와 hector gazebo를 함께 사용해보는 것입니다.\nhusky gazebo 는 다음과 같은 내용을 담고 있었습니다. gazebo_ros를 실행시키고 husky model을 spawn하는 또다른 launch file을 include 하였습니다. \u0026lt;launch\u0026gt; \u0026lt;arg name=\u0026#34;world_name\u0026#34; default=\u0026#34;worlds/empty.world\u0026#34;/\u0026gt; \u0026lt;include file=\u0026#34;$(find gazebo_ros)/launch/empty_world.launch\u0026#34;\u0026gt; \u0026lt;arg name=\u0026#34;world_name\u0026#34; value=\u0026#34;$(arg world_name)\u0026#34;/\u0026gt; \u0026lt;!-- world_name is wrt GAZEBO_RESOURCE_PATH environment variable --\u0026gt; \u0026lt;arg name=\u0026#34;paused\u0026#34; value=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;use_sim_time\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;gui\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;headless\u0026#34; value=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;debug\u0026#34; value=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;/include\u0026gt; \u0026lt;include file=\u0026#34;$(find husky_gazebo)/launch/spawn_husky.launch\u0026#34;\u0026gt; \u0026lt;/include\u0026gt; \u0026lt;/launch\u0026gt; 그럼, 겹치는 부분을 제외하고 quadrotor_empty_world.launch의 내용을 추가하여 새로운 launch file을 만들어 봅시다. (hetero_spawn.launch 생성) \u0026lt;launch\u0026gt; \u0026lt;include file=\u0026#34;$(find husky_gazebo)/launch/husky_empty_world.launch\u0026#34; /\u0026gt; \u0026lt;include file=\u0026#34;$(find hector_quadrotor_gazebo)/launch/spawn_quadrotor.launch\u0026#34; /\u0026gt; \u0026lt;arg name=\u0026#34;model\u0026#34; value=\u0026#34;$(find hector_quadrotor_description)/urdf/quadrotor_hokuyo_utm30lx.gazebo.xacro\u0026#34;/\u0026gt; \u0026lt;/launch\u0026gt; 아래와 같은 오류가 발생하네요, 이는 robot_state_publisher node가 중복되기 때문에 발생하는 문제입니다. RLException: roslaunch file contains multiple nodes named [/robot_state_publisher]. Please check all \u0026lt;node\u0026gt; \u0026#39;name\u0026#39; attributes to make sure they are unique. Also check that $(anon id) use different ids. The traceback for the exception was written to the log file 이를 해결하기 위해서, 저는 다른 launch file(spawn_two_quadrotors.launch)을 참고해보았습니다. group 태그를 사용하면 같은 로봇의 중복 선언을 namespace를 통해 구분할 수 있게됩니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;launch\u0026gt; \u0026lt;arg name=\u0026#34;model\u0026#34; default=\u0026#34;$(find hector_quadrotor_description)/urdf/quadrotor.gazebo.xacro\u0026#34; /\u0026gt; \u0026lt;group ns=\u0026#34;uav1\u0026#34;\u0026gt; \u0026lt;include file=\u0026#34;$(find hector_quadrotor_gazebo)/launch/spawn_quadrotor.launch\u0026#34;\u0026gt; ... \u0026lt;/group\u0026gt; \u0026lt;group ns=\u0026#34;uav2\u0026#34;\u0026gt; \u0026lt;include file=\u0026#34;$(find hector_quadrotor_gazebo)/launch/spawn_quadrotor.launch\u0026#34;\u0026gt; ... \u0026lt;/group\u0026gt; \u0026lt;/launch\u0026gt; 이제, hetero_spawn.launch를 최종 수정해봅시다. \u0026lt;launch\u0026gt; \u0026lt;include file=\u0026#34;$(find husky_gazebo)/launch/husky_empty_world.launch\u0026#34; /\u0026gt; \u0026lt;arg name=\u0026#34;model\u0026#34; default=\u0026#34;$(find hector_quadrotor_description)/urdf/quadrotor.gazebo.xacro\u0026#34; /\u0026gt; \u0026lt;group ns=\u0026#34;uav1\u0026#34;\u0026gt; \u0026lt;include file=\u0026#34;$(find hector_quadrotor_gazebo)/launch/spawn_quadrotor.launch\u0026#34;\u0026gt; \u0026lt;arg name=\u0026#34;name\u0026#34; value=\u0026#34;uav1\u0026#34; /\u0026gt; \u0026lt;arg name=\u0026#34;tf_prefix\u0026#34; value=\u0026#34;uav1\u0026#34; /\u0026gt; \u0026lt;arg name=\u0026#34;model\u0026#34; value=\u0026#34;$(arg model)\u0026#34; /\u0026gt; \u0026lt;arg name=\u0026#34;z\u0026#34; value=\u0026#34;1.0\u0026#34; /\u0026gt; \u0026lt;/include\u0026gt; \u0026lt;/group\u0026gt; \u0026lt;/launch\u0026gt; 실행 후 topic을 조회해보면, 아래와 같이 quadrotor의 topic 앞에 namespace가 추가되어 있는 모습이 확인 가능합니다. 여러 로봇을 사용하게 되면 /cmd_vel, /scan등 사용하는 topic의 이름이 중복될 수 있어 namespace를 추가 설정하는 것이 일반적입니다.\n$ rostopic list /clock /cmd_vel /husky_velocity_controller/cmd_vel /husky_velocity_controller/odom /husky_velocity_controller/parameter_descriptions /husky_velocity_controller/parameter_updates /imu/data /odometry/filtered ... /uav1/aerodynamics/wrench /uav1/cmd_vel /uav1/command/motor /uav1/command/twist /uav1/command/wrench /uav1/fix_velocity ... 마지막으로, 로봇을 제어해보면서 이번 세션을 마무리해보겠습니다. gazebo의 world를 바꾸거나, husky가 아닌 smb로 모델을 바꾸는 등 응용 예시들을 직접 해보면서 launch file의 사용에 익숙해지시기 바랍니다.\n# husky 제어 rosrun teleop_twist_keyboard teleop_twist_keyboard.py # quadrotor 제어 rosrun hector_ui ui_hector_quad_leader.py ROS Custom Interfaces ROS에서 기본 제공되는 msg와 srv도 훌륭하지만, 상황에 따라 나만의 custom msg/srv를 사용해야 하는 경우가 있습니다. 이번 시간에는 custom interface를 만들어보고, 사용해보겠습니다.\n드론의 이착륙을 제어하는 srv를 만들어보고자 합니다.\n이륙/착륙을 구분하는 string이 필요할 것이며, 기준은 시간을 사용하고자 합니다. ( ex - 2초간 이륙 ) service request는 성공 여부인 bool type으로 해보겠습니다. custom interface를 만들기 위해 저는 별도의 package를 생성하였습니다. cd ~/catkin_ws/src/du2023-ros1 catkin_create_pkg custom_interfaces package 내부에 msg 혹은 srv라는 폴더를 만들고, custom interface를 정의하는것이 추천됩니다. cd custom_interfaces mkdir srv # QuadrotorControl.srv 생성 string command uint8 seconds --- bool success custom_interfaces package의 package.xml을 수정합니다. \u0026lt;build_depend\u0026gt;message_generation\u0026lt;/build_depend\u0026gt; \u0026lt;exec_depend\u0026gt;message_runtime\u0026lt;/exec_depend\u0026gt; custom_interfaces package의 CMakeLists.txt를 수정합니다. # 1. find_package 수정 find_package(catkin REQUIRED COMPONENTS roscpp rospy std_msgs message_generation ) # 2. catkin_package 주석 해제 후 수정 catkin_package( ... CATKIN_DEPENDS message_runtime ... ...) # 3. add_service_files에 파일 반영 add_service_files( FILES QuadrotorControl.srv ) # 4. generate_messages 주석 해제 후 수정 generate_messages( DEPENDENCIES std_msgs # Or other packages containing msgs ) custom interface를 빌드하고 생성을 확인해봅시다. $ catkin build custom_interfaces $ rossrv show custom_interfaces/QuadrotorControl string command uint8 seconds --- bool success 지금 생성한 QuadrotorControl은 catkin_ws에서만 사용 가능한 srv라는 점에 유의합니다. 다른 workspace에서는 QuadrotorControl에 대해 알 길이 없습니다.\nCustom Interfaces 사용해보기 작성한 QuadrotorControl를 사용하여 Service Server를 만들어봅시다! 정해진 시간동안 takeoff와 land 움직임을 수행하는 Service입니다. # Terminal 1 roslaunch hector_quadrotor_gazebo quadrotor_empty_world.launch # Terminal 2 rosrun py_service_pkg quadrotor_custom_srv.py # Terminal 3 rqt 소스 코드는 이 링크에서 확인이 가능합니다.\ncustom_interfaces package에서 QuadrotorControl srv를 import 하며, 로봇의 제어를 위해 Twist msg도 import 하였습니다. import rospy from geometry_msgs.msg import Twist from custom_interfaces.srv import QuadrotorControl, QuadrotorControlResponse Service Server와 Topic Publisher를 생성합시다. class QuadRotorUpDown(object): def __init__(self): self.cmd_vel_pub_ = rospy.Publisher(\u0026#34;cmd_vel\u0026#34;, Twist, queue_size=10) self.stop_server_ = rospy.Service(\u0026#34;up_down\u0026#34;, QuadrotorControl, self.up_down_cb) self.twist_msg_ = Twist() self.response_ = QuadrotorControlResponse() rospy.loginfo(\u0026#34;Quadrotor Up-Down Server Started\u0026#34;) callback 함수인 up_down_cb입니다. command가 land/takeoff일 때의 경우를 나누고, 그 이외의 입력은 오류로 판명합니다. def up_down_cb(self, request): if request.command == \u0026#34;land\u0026#34;: self.twist_msg_.linear.z = -0.5 self.response_.success = True elif request.command == \u0026#34;takeoff\u0026#34;: self.twist_msg_.linear.z = 0.5 self.response_.success = True else: rospy.logwarn(\u0026#34;Unknown Command\u0026#34;) self.response_.success = False return self.response_ request의 seconds 시간동안 로봇이 움직여야 할 것이며, 이를 위해 now를 갱신하며 지나간 시간을 계속해서 tracking 합니다. start = rospy.Time.now() now = rospy.Time.now() while (now - start).secs \u0026lt; request.seconds: now = rospy.Time.now() self.cmd_vel_pub_.publish(self.twist_msg_) 모든 동작이 완료된 이후에는 로봇을 다시 정지시킵니다. rospy.loginfo(f\u0026#34;{request.command} done, quadrotor stop\u0026#34;) self.twist_msg_.linear.z = 0.0 self.cmd_vel_pub_.publish(self.twist_msg_) return self.response_ Husky Move Base ROS 1에서 로봇 자율주행을 위해 사용하는 스택을 Move Base라고 지칭합니다. ROS 1 noetic에서 husky 로봇을 통해 Move Base를 실습해보겠습니다.\n예시를 위해 필요한 패키지를 다운받습니다. sudo apt-get install ros-noetic-husky-navigation slam 예시를 실행합니다. # Terminal 1 export HUSKY_LMS1XX_ENABLED=1; roslaunch husky_gazebo husky_playpen.launch # Terminal 2 roslaunch husky_viz view_robot.launch # Terminal 3 roslaunch husky_navigation gmapping_demo.launch 사진과 같은 world와 함께 husky가 등장할 것입니다.\nrviz에서 map topic을 추가합니다. rviz의 2D Nav Goal을 사용하면 로봇을 특정 위치로 이동시킬 수 있습니다. 해당 예시는 slam과 navigation을 동시에 실행하는 예시입니다. rqt_graph를 통해 살펴본 현 상황의 node들과 topic입니다. 참고자료\nhttp://wiki.ros.org/rospy/Overview/Time https://github.com/RAFALAMAO/hector-quadrotor-noetic https://docs.ros.org/en/foxy/index.html http://wiki.ros.org/ROS/Tutorials/CreatingMsgAndSrv https://www.clearpathrobotics.com/assets/guides/noetic/husky/HuskyMove.html "
},
{
	"uri": "/kr/ros_basic_noetic/lecture9/",
	"title": "Lecture9 - ROS TF and Examples",
	"tags": [],
	"description": "",
	"content": " 대부분의 로보틱스 과정들에서 가장 먼저 다루는 것이 바로 좌표계 변환(Transformation) 입니다. 로봇은 수많은 joint와 link로 이루어져 있기 때문에 좌표계를 다루는 일이 매우 빈번합니다.\nROS에서는 TF라는 특수한 형태로 이 좌표계와 시간을 함께 다루고 있습니다. 예시와 설명을 통해 ROS의 TF에 대해 배워봅시다 😊\nimage from : eth robot dynamics lecture notes ROS는 오픈소스이니만큼 사용자들이 원하는 기능들에 맞추어 변화가 빠릅니다. 하지만 이것이 단점이 되는 경우도 있는데, 이전 버전과 최신 버전의 호환성 문제가 종종 발생합니다.\ntf 또한 tf2로 개편되면서 코드의 수정이 있었으며, 이번 강의에서는 tf2를 중심으로 살펴보겠습니다.\nimage from : wiki.ros 예시를 먼저 살펴봅시다.\ntf broadcaster # setup example catkin build py_tf2_tutorial source devel/setup.bash roscore # Terminal 1 rosrun turtlesim turtlesim_node # Terminal 2 rosrun py_tf2_tutorial turtle_tf2_broadcaster.py # Terminal 3 rosrun turtlesim turtle_teleop_key # Terminal 4 rviz rviz를 실행한 뒤 아래와 같이 설정합니다. rviz에서 보이는 세가지 색상의 막대가 바로 tf 입니다.\nx,y,z의 각 축을 각기 다른 색으로 표현하였으며, 연관된 좌표계끼리는 노란 선을 통해 연결한 모습이 보입니다.\nTerminal 1에서 실행시킨 프로그램은 turtlesim이라는 것으로, 2차원 평면에서 거북이 형태의 로봇을 시뮬레이션한 프로그램입니다. 이제, Terminal 3에 커서를 두고 거북이를 움직이면서, rviz와 turtlesim의 변화를 살펴보세요. 거북이를 조종함에 따라 변화하는 rviz 화면을 확인할 수 있습니다.\n전체 코드는 아래 링크에서 확인할 수 있으며, 지금은 필요한 부분만 집중적으로 분석해보겠습니다.\nhttps://github.com/RB2023ROS/du2023-ros1/blob/main/py_tf2_tutorial/scripts/turtle_tf2_broadcaster.py\ntf 또한 하나의 Package입니다. 이에 따라 관련된 python import가 필요합니다. import rospy # Because of transformations import tf_conversions import tf2_ros import geometry_msgs.msg import turtlesim.msg tf의 데이터 송출은 broadcast라고 부릅니다. topic의 publisher와 같이 tf에서는 TransformBroadcaster를 사용하며 sendTransform이라는 메소드를 사용합니다. def handle_turtle_pose(msg, turtlename): # tf requires broadbaster # Be Careful, !!TF IS NOT A TOPIC!! br = tf2_ros.TransformBroadcaster() ... br.sendTransform(t) TransformBroadcaster가 사용하는 데이터 타입은 geometry_msgs.msg.TransformStamped입니다. 해당 데이터 타입에는 3차원 좌표계에서의 위치, 방향, 그리고 시간이 포함되어 있습니다. image from : docs.ros.org\n해당 데이터 타입에 적절한 값을 채워넣어준 다음, 최종 broadcast가 진행됩니다. 주의할 점으로 쿼터니언 각도 체계를 사용했다는 점입니다. # prepare tf msg t = geometry_msgs.msg.TransformStamped() t.header.stamp = rospy.Time.now() t.header.frame_id = \u0026#34;world\u0026#34; t.child_frame_id = turtlename t.transform.translation.x = msg.x t.transform.translation.y = msg.y t.transform.translation.z = 0.0 q = tf_conversions.transformations.quaternion_from_euler(0, 0, msg.theta) t.transform.rotation.x = q[0] t.transform.rotation.y = q[1] t.transform.rotation.z = q[2] t.transform.rotation.w = q[3] 쿼터니언은 직관적으로 이해하기는 힘든 각도 체계입니다. 계산의 편의를 위해 다음과 같은 사이트를 사용할 수 있습니다. \u0026gt; 3D Rotation Converter\ntf의 사용 시 주의해야 할 점을 언급하고자 합니다.\nturtle_tf2_broadcaster.py 수정 - Experiment라고 되어 있는 부분을 주석 해제한 다음 다시 실행해봅시다. def handle_turtle_pose(msg, turtlename): # tf requires broadbaster # Be Careful, !!TF IS NOT A TOPIC!! br = tf2_ros.TransformBroadcaster() # prepare tf msg t = geometry_msgs.msg.TransformStamped() # t.header.stamp = rospy.Time.now() # Experiment, Late tf2 t.header.stamp = rospy.Time.now() - rospy.Duration(60) t.header.frame_id = \u0026#34;world\u0026#34; rviz를 실행시킨 터미널에서 아래와 같은 에러가 발생합니다. [ WARN] [1671940248.738235698]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame turtle1 at time 1671940148.738096 according to authority unknown_publisher tf에는 시간 데이터가 포함되어 있습니다. 따라서 현재 시간과 tf에 담기 시간의 차이가 크다면 ROS는 이를 안정적이지 못한 것으로 판단해 무시합니다. (위 에러는 아마 로봇 개발을 하면서 마주치게 되는 Warning Top3안에 들지 않을까 싶습니다.)\n이번 예시에는 터미널이 4개나 필요하였습니다. 예시의 빠른 실행을 위해 launch file을 만들 수 있습니다. \u0026lt;launch\u0026gt; \u0026lt;node pkg=\u0026#34;turtlesim\u0026#34; type=\u0026#34;turtlesim_node\u0026#34; name=\u0026#34;sim\u0026#34;/\u0026gt; \u0026lt;node pkg=\u0026#34;turtlesim\u0026#34; type=\u0026#34;turtle_teleop_key\u0026#34; name=\u0026#34;teleop\u0026#34; output=\u0026#34;screen\u0026#34;/\u0026gt; \u0026lt;node name=\u0026#34;turtle1_tf2_broadcaster\u0026#34; pkg=\u0026#34;py_tf2_tutorial\u0026#34; type=\u0026#34;turtle_tf2_broadcaster.py\u0026#34; respawn=\u0026#34;false\u0026#34; output=\u0026#34;screen\u0026#34; \u0026gt; \u0026lt;param name=\u0026#34;turtle\u0026#34; type=\u0026#34;string\u0026#34; value=\u0026#34;turtle1\u0026#34; /\u0026gt; \u0026lt;/node\u0026gt; \u0026lt;node name=\u0026#34;rviz\u0026#34; pkg=\u0026#34;rviz\u0026#34; type=\u0026#34;rviz\u0026#34; args=\u0026#34;-d $(find py_tf2_tutorial)/rviz/turtlesim_tf.rviz\u0026#34; /\u0026gt; \u0026lt;/launch\u0026gt; tf listener tf broadcaster의 다음으로 tf listener에 대해 배워봅시다.\nturtlesim follow demo roslaunch py_tf2_tutorial follow_demo.launch 사진과 같이 우리가 조종하는 첫번째 거북이를 두번째 거북이가 따라오게 됩니다. rviz를 통해 tf들 사이에 어떠한 변화가 있는지도 직접 확인해보세요 launch 파일은 다음과 같은 내용을 포함하고 있습니다.\n\u0026lt;launch\u0026gt; \u0026lt;node pkg=\u0026#34;turtlesim\u0026#34; type=\u0026#34;turtlesim_node\u0026#34; name=\u0026#34;sim\u0026#34;/\u0026gt; \u0026lt;node pkg=\u0026#34;turtlesim\u0026#34; type=\u0026#34;turtle_teleop_key\u0026#34; name=\u0026#34;teleop\u0026#34; output=\u0026#34;screen\u0026#34;/\u0026gt; \u0026lt;node name=\u0026#34;turtle1_tf2_broadcaster\u0026#34; pkg=\u0026#34;py_tf2_tutorial\u0026#34; type=\u0026#34;turtle_tf2_broadcaster.py\u0026#34; respawn=\u0026#34;false\u0026#34; output=\u0026#34;screen\u0026#34; \u0026gt; \u0026lt;param name=\u0026#34;turtle\u0026#34; type=\u0026#34;string\u0026#34; value=\u0026#34;turtle1\u0026#34; /\u0026gt; \u0026lt;/node\u0026gt; \u0026lt;node name=\u0026#34;turtle2_tf2_broadcaster\u0026#34; pkg=\u0026#34;py_tf2_tutorial\u0026#34; type=\u0026#34;turtle_tf2_broadcaster.py\u0026#34; respawn=\u0026#34;false\u0026#34; output=\u0026#34;screen\u0026#34; \u0026gt; \u0026lt;param name=\u0026#34;turtle\u0026#34; type=\u0026#34;string\u0026#34; value=\u0026#34;turtle2\u0026#34; /\u0026gt; \u0026lt;/node\u0026gt; \u0026lt;node pkg=\u0026#34;py_tf2_tutorial\u0026#34; type=\u0026#34;turtle_tf2_listener.py\u0026#34; name=\u0026#34;listener\u0026#34; output=\u0026#34;screen\u0026#34;/\u0026gt; \u0026lt;/launch\u0026gt; turtlesim 실행 teleop key 실행 turtle1의 tf broadcaster turtle2의 tf broadcaster tf listener 이번 예제에서 살펴보고자 하는 것은 tf listener입니다.\nTransformListener 클래스는 생성되는 순간부터 /tf topic에 귀기울이기 시작합니다. Buffer는 정해진 사이즈만큼 tf 데이터를 품게 되며, TransformListener에 전달하게 되면, tf topic data를 받아 Buffer에 쌓아두는 것입니다. if __name__ == \u0026#39;__main__\u0026#39;: rospy.init_node(\u0026#39;tf2_turtle_listener\u0026#39;) tfBuffer = tf2_ros.Buffer() listener = tf2_ros.TransformListener(tfBuffer) Buffer의 lookup_transform 메소드는 두 frame 사이의 translation, rotation 변환을 계산해줍니다. while not rospy.is_shutdown(): try: # calculate transformation btw two dynamic tfs # those tfs were broadcasted from TransformBroadcaster trans = tfBuffer.lookup_transform(turtle_name, \u0026#39;turtle1\u0026#39;, rospy.Time(), rospy.Duration(1.0)) except (tf2_ros.LookupException, tf2_ros.ConnectivityException, tf2_ros.ExtrapolationException): rate.sleep() continue lookup_transform 메소드의 원형은 다음과 같습니다. image from : docs.ros2.org lookup_transform의 계산 결과를 직접 살펴보고자 print 문을 추가하였으며, 캡쳐 사진을 통해 간단히 함께 살펴봅시다.\ntranslation은 두 거북이의 frame사이 수평 거리를 보여주며 rotation은 두 frame사이 회전을 쿼터니언으로 보여줍니다. 기준이 되는 frame과 목표 frame은 id로 구분하며, 현재 turtle1, turtle2로 구분하고 있습니다. 현 상황을 그림으로 간단히 정리하자면 다음과 같습니다.\nlookup_transform의 계산 결과는 target frame인 turtle2의 위치가 source frame인 turtle1 기준에서는 어떠한 좌표를 갖는지를 포함합니다.\nimage from : CMU Qatar 로보틱스에서 이러한 좌표 변환은 매우 자주 사용되며, 일반적으로 Homogeneous Matrix의 형태로 표현합니다.\nfrom : eth robotics lecture notes 그 밖에, 코드에서 구현된 기능을 간단히 살펴보며 마무리하겠습니다.\n두번째 거북이를 등장시키는 service client # Spawn second turtle rospy.wait_for_service(\u0026#39;spawn\u0026#39;) spawner = rospy.ServiceProxy(\u0026#39;spawn\u0026#39;, turtlesim.srv.Spawn) turtle_name = rospy.get_param(\u0026#39;turtle\u0026#39;, \u0026#39;turtle2\u0026#39;) spawner(4, 2, 0, turtle_name) 거북이를 제어하기 위한 Twist msg topic publisher # turtle2 controller turtle_vel = rospy.Publisher(\u0026#39;%s/cmd_vel\u0026#39; % turtle_name, geometry_msgs.msg.Twist, queue_size=1) rate = rospy.Rate(50.0) while not rospy.is_shutdown(): ... turtle_vel.publish(msg) rate.sleep() 이렇게 tf에 대해서 turtlesim 예시와 함께 살펴보았습니다. 로보틱스에서 자주 사용되는 좌표계와 그들 사이의 변환을 시간 데이터와 함께 표현하는 것이 ROS의 tf2입니다.\n다음 강의에 계속 이어집니다.\n"
},
{
	"uri": "/kr/ros_basic_noetic/lecture10/",
	"title": "Lecture10 - TF2 Examples, Outro",
	"tags": [],
	"description": "",
	"content": "tf2 사례 제가 강조해서 자꾸 좌표계가 tf가 중요하다고 말하고 있는데, 그 이유를 예시와 함께 좀 더 자세히 살펴보고자 합니다.\nhusky slam # 예시 종속성 설치 sudo apt install ros-noetic-slam-gmapping # Terminal 1 roslaunch smb_gazebo smb_gazebo.launch world:=big_map_summer_school # Terminal 2 roslaunch py_tf2_tutorial slam_gmapping.launch # Terminal 3 rosrun teleop_twist_keyboard teleop_twist_keyboard.py # [option] rviz (이전 예시에서 rviz를 추가하였다면 넘어가셔도 좋습니다.) rviz rviz를 다음과 같이 세팅합니다. 이제 teleop을 통해 로봇을 이동시키면서, rviz 화면의 변화를 확인해봅시다. 로봇이 움직이면서 자신의 위치를 파악함과 동시에 지도를 생성하는 예시입니다.\n마지막으로, rqt를 실행하여 tf tree를 실행시킵니다. tf tree는 tf 관련 상태를 시각화하여 한번에 볼 수 있게 해주는 고마운 툴입니다. tree를 확대해서 살펴보자면, slam_gmapping은 map → odom으로의 tf broadcast를 담당하고 있습니다. 더불어 map은 모든 tf의 최상단에 존재하고 있습니다. 이러한 이유로 rviz에서 fixed frame을 map으로 설정한 것입니다. 퀴즈: 만약 tf tree가 온전히 연결되어 있지 않다면 어떤 일이 발생할까요?\nimage from : answers.ros.org 센서 입장에서도 tf는 매우 중요합니다.\n같은 데이터라도 그 기준이 어딘지에 따라서 전혀 다른 의미를 가질 수 있기 때문입니다.\n예를 들어, 라이다의 tf를 180도 반대로 설정해버리면 후방에 있는 장애물을 전방 장애물로 잘못 인식할 수 있습니다.\nimage from : answers.ros.org 더불어, 로봇 팔과 같은 관절로봇에게도 tf는 무척 중요한 의미를 갖습니다. 각 joint의 상태를 통해 tf를 계산하고 이를 통해 최종적으로 로봇 팔의 끝점이 어디에 위치하는지 계산할 수 있습니다.\nMoveIt! 실습해보기 이번 시간에는 조금 쉬어가는 느낌으로 유용한 ROS Package를 소개해드리고자 합니다.\nimage from : moveit github MoveIt은 다관절 로봇의 모션 제어를 위한 프레임워크입니다. 이름만 들어서는 감이 잘 오지 않지요? 간단한 예시를 통해 살펴봅시다.\n우리 인간은 팔을 이용하여 물건을 잡는 것이 매우 쉽고 간단하지만, 사실 이는 기구학적으로, 동역학적으로, 에너지 차원에서 매우 최적화된 움직임입니다. 로봇 팔의 경우 장착된 모터의 방향각이 제한된 경우도 있고, 자기 자신과 얽혀버리는 문제도 발생할 수 있으며, 같은 목표를 갖더라고 다양한 경로로 움직일 수 있기 때문에 최적의 경로에 대한 기준도 고려해야 합니다. image from : mecademic 로봇 팔의 주요 구성 Base : 고정된 지지부 Arm : 실질적인 로봇 팔 End Effector : Arm 끝에 부착되는 기구의 통칭, 일반적으로 물체를 잡고 놓는 동작을 수행 MoveIt은 관절 로봇의 기본 구성과 Mass Matrix, 각 모터의 제한과 원하는 움직임을 지정해주면 이에 따라 각 관절의 위치, 속도, 가속도 경로를 최적화(Planning) 해주는 프레임워크이며, 그 밖에도, 물체 인지, 장애물 회피, End Effector에 가해지는 힘까지 고려 가능한 거대한 오픈소스 프로젝트입니다.\nMoveIt Motion Planning Framework\n이번 예제로 저와 함께 MoveIt의 가장 기본적인 데모를 함께 실행해보겠습니다. 예시에 사용되는 로봇은 FRANKA EMIKA의 PANDA라는 로봇입니다. FRANKA EMIKA - PANDA\n아래 커멘드 라인을 함께 따라와주세요.\napt 패키지 설치 sudo apt install ros-noetic-moveit-setup-assistant sudo apt install ros-noetic-moveit sudo apt install ros-noetic-gazebo-ros-control joint-state-publisher sudo apt install ros-noetic-controller-manager sudo apt install ros-noetic-ros-controllers sudo apt install ros-noetic-ros-control sudo apt install ros-noetic-robot-state-publisher 예제 패키지 Clone cd ~/catkin_ws git clone https://github.com/ros-planning/moveit_tutorials.git -b master git clone https://github.com/ros-planning/panda_moveit_config.git -b noetic-devel 관련 종속성 설치 - rosdep 추가 설명 cd ~/catkin_ws/src rosdep install -y --from-paths . --ignore-src --rosdistro noetic 패키지 빌드 cd ~/catkin_ws catkin build source devel/setup.bash 데모 실행 roslaunch panda_moveit_config demo_gazebo.launch 여기까지 잘 따라오셨나요? 그렇다면 강의자의 설명에 따라 RViz Motion Planning Plugin을 사용해봅니다.\n참고자료\nhttps://rsl.ethz.ch/education-students/lectures/ros.html https://ros-planning.github.io/moveit_tutorials/ http://wiki.ros.org/tf/Tutorials "
},
{
	"uri": "/kr/advanced_contents_ros1/lecture1/",
	"title": "Lecture1 - ROSCPP",
	"tags": [],
	"description": "",
	"content": "roscpp Programming ros는 다양한 언어를 지원하고 있습니다. 지금까지 살펴보았던 rospy는 가장 쉽고 빠르게 배울 수 있어서 사용하였지만, UDPROS, Nodelet, Plugin과 같은 Advanced ROS 개발을 위해서는 C++ 프로그래밍을 통한 Node 개발이 필요합니다.\nimage from : wikipedia rospy를 통해 개념을 모두 익혔기 때문에 이번 강의에서는 개발 API를 위주로 roscpp을 배워보겠습니다.\n가장 기초가 되는 Node 프로그래밍부터 차이점을 살펴봅시다. rospy roscpp #!/usr/bin/env python3 import rospy from std_msgs.msg import String def my_first_node(): # ROS nodes require initialization # It contains master registration, uploading parameters rospy.init_node(\u0026#39;my_first_node\u0026#39;, anonymous=True) # ROS safe timer rate = rospy.Rate(10) # 10hz # Loop control Example while not rospy.is_shutdown(): hello_du = \u0026#34;hello du %s\u0026#34; % rospy.get_time() rospy.loginfo(hello_du) # Below line calls sleep method in Python internally. rate.sleep() if __name__ == \u0026#39;__main__\u0026#39;: try: my_first_node() except rospy.ROSInterruptException: pass #include \u0026lt;ros/ros.h\u0026gt; #include \u0026lt;std_msgs/String.h\u0026gt; int main(int argc, char** argv){ ros::init(argc, argv, \u0026#34;basic_node\u0026#34;); ros::NodeHandle nh; ros::Rate r(5); while ( ros::ok() ) { ROS_INFO(\u0026#34;This is Basic Node\u0026#34;); // ros::spinOnce(); r.sleep(); } return 0; } 간단히 표를 통해 비교해보면 아래와 같이 상당 부분 반복되는 점들을 확인할 수 있습니다.\nrospy roscpp Client Library import rospy #include \u0026lt;ros/ros.h\u0026gt; initialization rospy.init_node ros::init interface import from std_msgs.msg import String #include \u0026lt;std_msgs/String.h\u0026gt; logging rospy.loginfo() ROS_INFO() spin rospy.spin() ros::spin() rate rospy.Rate() ros::Rate() rospy와의 차이점으로, roscpp은 NodeHandle이라는 클래스를 사용합니다. roscpp은 NodeHandle을 통해 parameter, publisher, subscriber, serviceServer들을 생성하며, 매개변수로 namespace를 받습니다.\ncmd_vel_pub 예시코드에 namespace를 설정한 뒤 topic값의 변화를 살펴봅시다.\nros::NodeHandle nh(\u0026#34;my_namespace\u0026#34;); 더불어, NodeHandle은 ROS Node lifecycle 중 “start”의 트리거가 됩니다. Node의 Lifecycle에 대한 자세한 설명은 링크로 대체하겠습니다.\nimage from : Initialization and Shutdown NodeHandle은 반드시 ros::init 보다 뒤에 생성되어야 합니다\nROS C++ Package Build C++로 작성된 코드는 빌드가 필요하며 caktin 시스템에서는 CMake가 빌드를 도와줍니다.\n빌드 시에 필요한 공유 라이브러리, 외부 라이브러리들, 빌드 속성과 같은 상세 내용들이 CMakeLists.txt에 위치합니다.\n본 강의에서는 CMake에 대해서는 자세히 다루지 않고, 프로그래밍 시 알아야 하는 부분만 살펴보겠습니다.\nfind_package - ROS에서 기본 제공하는 패키지들을 손쉽게 추가할 수 있습니다. ## Find catkin macros and libraries ## if COMPONENTS list like find_package(catkin REQUIRED COMPONENTS xyz) ## is used, also find other catkin packages find_package(catkin REQUIRED COMPONENTS roscpp geometry_msgs sensor_msgs ) 컴파일 옵션 - add_executable과 add_dependencies를 적용하고, 빌드 결과가 위치하는 지점을 catkin workspace의 build 폴더로 지정해야 합니다. ## Declare a C++ executable ## With catkin_make all packages are built within a single CMake context ## The recommended prefix ensures that target names across packages don\u0026#39;t collide add_executable(cmd_vel_pub_node src/cmdvel_pub.cpp) add_executable(laser_sub_node src/laser_sub.cpp) ... add_dependencies(cmd_vel_pub_node ${cmd_vel_pub_node_EXPORTED_TARGETS} ${catkin_EXPORTED_TARGETS}) add_dependencies(laser_sub_node ${laser_sub_node_EXPORTED_TARGETS} ${catkin_EXPORTED_TARGETS}) ... target_link_libraries(cmd_vel_pub_node ${catkin_LIBRARIES} ) target_link_libraries(laser_sub_node ${catkin_LIBRARIES} ) 이후 catkin build와 실행은 rospy와 동일합니다. (executable name에 주의합니다.) catkin build \u0026lt;pkg-name\u0026gt; source devel/setup.bash rosrun \u0026lt;pkg-name\u0026gt; \u0026lt;executable-name\u0026gt; roscpp Topic roscpp의 예시들은 rospy와 동일한 기능을 하도록 작성하였습니다. 코드의 API에 집중하여 비교, 분석해보겠습니다. # Terminal 1 roslaunch smb_gazebo smb_gazebo.launch # Example 1 rosrun cpp_topic_pkg cmd_vel_pub # Example 2 rosrun cpp_topic_pkg laser_scan_sub cmd_vel_pub code python c\u0026#43;\u0026#43; #!/usr/bin/env python3 import rospy from geometry_msgs.msg import Twist class CmdVelPubNode: def __init__(self): # Publisher requires 3 paramters # 1. topic name # 2. topic msg type # 3. topic queue size self.cmd_vel_pub_ = rospy.Publisher(\u0026#34;cmd_vel\u0026#34;, Twist, queue_size=10) self.timer_ = rospy.Timer(rospy.Duration(1.0/10.0), self.pub_msg) self.twist_ = Twist() def pub_msg(self, event=None): # geometry_msgs.Twist # ref: http://docs.ros.org/en/melodic/api/geometry_msgs/html/msg/Twist.html self.twist_.linear.x = 0.5 self.twist_.angular.z = 1.0 self.cmd_vel_pub_.publish(self.twist_) def cmd_vel_node(): rospy.init_node(\u0026#39;cmd_vel_node\u0026#39;, anonymous=True) cmd_vel_pub_node = CmdVelPubNode() rospy.spin() if __name__ == \u0026#39;__main__\u0026#39;: try: cmd_vel_node() except rospy.ROSInterruptException: pass #include \u0026lt;ros/ros.h\u0026gt; #include \u0026lt;geometry_msgs/Twist.h\u0026gt; class CmdVelPubNode { private: ros::Publisher cmd_vel_pub_; ros::Timer timer_; geometry_msgs::Twist twist_msg_; public: CmdVelPubNode(ros::NodeHandle *nh) { ROS_INFO(\u0026#34;Publisher and Subscriber initialized\u0026#34;); timer_ = nh-\u0026gt;createTimer(ros::Duration(0.1), \u0026amp;CmdVelPubNode::timerCallback, this); cmd_vel_pub_ = nh-\u0026gt;advertise\u0026lt;geometry_msgs::Twist\u0026gt;(\u0026#34;cmd_vel\u0026#34;, 10); } void timerCallback(const ros::TimerEvent\u0026amp; event){ twist_msg_.linear.x = 0.5; twist_msg_.angular.z = 0.5; cmd_vel_pub_.publish(twist_msg_); } }; int main(int argv, char** argc) { ros::init(argv, argc, \u0026#34;cmd_vel_node\u0026#34;); // ros::NodeHandle nh(\u0026#34;my_namespace\u0026#34;); ros::NodeHandle nh; CmdVelPubNode cmd_pub_node(\u0026amp;nh); ros::spin(); return 0; } laser_scan_sub code python c\u0026#43;\u0026#43; #!/usr/bin/env python3 import rospy from sensor_msgs.msg import LaserScan class LaserSubNode: def __init__(self): # Publisher requires 3 paramters # 1. topic name # 2. topic msg type # 3. sub callback method self.laser_sub_ = rospy.Subscriber(\u0026#34;scan\u0026#34;, LaserScan, self.laser_cb) # first param of callback method is always topic msg def laser_cb(self, data): rospy.loginfo( len(data.ranges)) print(f\u0026#34;\u0026#34;\u0026#34; data.ranges[0]: {data.ranges[0]} data.ranges[90]: {data.ranges[90]} data.ranges[179]: {data.ranges[179]} data.ranges[270]: {data.ranges[270]} data.ranges[360]: {data.ranges[360]} \u0026#34;\u0026#34;\u0026#34;) def laser_sub_node(): rospy.init_node(\u0026#39;laser_sub_node\u0026#39;, anonymous=True) laser_sub_node = LaserSubNode() rospy.spin() if __name__ == \u0026#39;__main__\u0026#39;: try: laser_sub_node() except rospy.ROSInterruptException: pass #include \u0026lt;ros/ros.h\u0026gt; #include \u0026lt;geometry_msgs/Twist.h\u0026gt; #include \u0026lt;sensor_msgs/LaserScan.h\u0026gt; class LaserSubNode { private: ros::Subscriber laser_sub_; ros::Timer timer_; public: LaserSubNode(ros::NodeHandle *nh) { ROS_INFO(\u0026#34;Publisher and Subscriber initialized\u0026#34;); // TCPROS // laser_sub_ = nh-\u0026gt;subscribe(\u0026#34;scan\u0026#34;, 10, \u0026amp;LaserSubNode::laserSubCallback, this); // UDPROS laser_sub_ = nh-\u0026gt;subscribe(\u0026#34;scan\u0026#34;, 10, \u0026amp;LaserSubNode::laserSubCallback, this, ros::TransportHints() .unreliable() .reliable() .maxDatagramSize(1000) .tcpNoDelay() ); } void laserSubCallback(const sensor_msgs::LaserScanConstPtr data){ ROS_INFO_STREAM(\u0026#34;data.ranges[0]: \u0026#34; \u0026lt;\u0026lt; data-\u0026gt;ranges[0]); ROS_INFO_STREAM(\u0026#34;data.ranges[90]: \u0026#34; \u0026lt;\u0026lt; data-\u0026gt;ranges[90]); ROS_INFO_STREAM(\u0026#34;data.ranges[179]: \u0026#34; \u0026lt;\u0026lt; data-\u0026gt;ranges[179]); ROS_INFO_STREAM(\u0026#34;data.ranges[270]: \u0026#34; \u0026lt;\u0026lt; data-\u0026gt;ranges[270]); ROS_INFO_STREAM(\u0026#34;data.ranges[360]: \u0026#34; \u0026lt;\u0026lt; data-\u0026gt;ranges[360]); // std::cout \u0026lt;\u0026lt; std::to_string(data.ranges[0]) \u0026lt;\u0026lt; std::endl; ROS_INFO(\u0026#34;Publisher and Subscriber initialized\u0026#34;); } }; int main(int argv, char** argc) { ros::init(argv, argc, \u0026#34;laser_sub_node\u0026#34;); // ros::NodeHandle nh(\u0026#34;my_namespace\u0026#34;); ros::NodeHandle nh; LaserSubNode laser_sub_node(\u0026amp;nh); ros::spin(); return 0; } rospy roscpp Publisher rospy.Publisher(topic_name, Message-Type, queue_size) advertise(topic_name, queue_size) Subscriber rospy.Subscriber(topic_name, Message-Type, callback) subscribe(topic_name, queue_size, callback) C++로 OOP 코드 작성 시, boost를 통한 binding이 필요함에 유의합니다. CmdVelPubNode(ros::NodeHandle *nh) { ROS_INFO(\u0026#34;Publisher and Subscriber initialized\u0026#34;); timer_ = nh-\u0026gt;createTimer(ros::Duration(0.1), \u0026amp;CmdVelPubNode::timerCallback, this); cmd_vel_pub_ = nh-\u0026gt;advertise\u0026lt;geometry_msgs::Twist\u0026gt;(\u0026#34;cmd_vel\u0026#34;, 10); } 파이썬과 마찬가지로 sub callback의 첫번째 매개변수는 topic msg data이며, std::shared_ptr가 사용됩니다. void sub_callback(const sensor_msgs::LaserScanConstPtr \u0026amp;data ){ ROS_INFO_STREAM(\u0026#34;data.ranges[0]: \u0026#34; \u0026lt;\u0026lt; data-\u0026gt;ranges[0]); } roscpp에서는 Logger 사용 시 c_str 포멧으로 변환해줘야 한다는 단점이 있습니다. 이를 간편하게 하기 위해 저는 ROS_INFO_STREAM를 애용합니다. ROS_INFO_STREAM(\u0026#34;data.ranges[0]: \u0026#34; \u0026lt;\u0026lt; data-\u0026gt;ranges[0]); ROSUDP ROS Topic 통신을 위해 Publisher와 Subscriber간의 negotiation이 이루어지며, 이 시점에서 Subscriber에 의해 TCP/UDPROS 중 어떠한 통신이 사용될 지 결정됩니다. Subscriber 코드를 수정하여 UDPROS를 사용해봅시다.\nsubscribe 예시를 다음과 같이 수정하고 빌드 후 다시 실행시켜봅시다. laser_sub_ = nh-\u0026gt;subscribe(\u0026#34;scan\u0026#34;, 10, \u0026amp;LaserSubNode::laserSubCallback, this, ros::TransportHints() .unreliable() .reliable() .maxDatagramSize(1000) .tcpNoDelay() ); 위 코드에서, unreliable은 UDPROS를, reliable은 TCPROS를 뜻합니다. UDPROS를 사용하는 경우, maxDatagramSize를 지정할 수 있으며, TCPROS를 사용하는 경우 tcpNoDelay를 사용 가능합니다. 위 코드는 UDPROS 통신을 먼저 시도한 뒤, 응답이 없다면 TCPROS를 사용하게 됩니다.\n이 같은 설정에 대한 상세 내용은 링크를 확인합시다. ⇒ 참고링크 : ros::TransportHints Class Reference\n소스코드 빌드 후 다시 실행 catkin build cpp_topic_pkg source devel/setup.bash rosrun cpp_topic_pkg laser_scan_sub rosnode info를 통해 transport 상태를 확인합니다. ⇒ UDPROS를 사용하고 있음을 알 수 있습니다. $ rosnode info /laser_sub_node -------------------------------------------------------------------------------- ... * topic: /scan * to: /pointcloud_to_laserscan (http://192.168.55.236:39875/) * direction: inbound * transport: UDPROS roscpp Service service 예시들도 rospy와 동일한 기능을 갖습니다. # Terminal 1 roslaunch smb_gazebo smb_gazebo.launch # Example 1 rosrun cpp_service_pkg emergency_stop # Example 2 rosrun cpp_service_pkg spawn_model_client emergency_stop code python c\u0026#43;\u0026#43; #! /usr/bin/env python3 import rospy from roslaunch.pmon import start_process_monitor from geometry_msgs.msg import Twist from std_srvs.srv import SetBool, SetBoolResponse class EmergencyStopNode(object): def __init__(self): self.cmd_vel_pub_ = rospy.Publisher(\u0026#34;cmd_vel\u0026#34;, Twist, queue_size=10) self.stop_server_ = rospy.Service(\u0026#34;emergency_stop\u0026#34;, SetBool, self.stop_cb) self.pm_ = start_process_monitor() self.twist_msg_ = Twist() self.response_ = SetBoolResponse() rospy.loginfo(\u0026#34;E Stop Server Started\u0026#34;) self.twist_pub() rospy.sleep(0.1) def twist_pub(self): self.twist_msg_.linear.x = 0.5 self.twist_msg_.angular.z = 1.0 self.cmd_vel_pub_.publish(self.twist_msg_) def stop_cb(self, request): if request.data is True: self.twist_msg_.linear.x = 0.0 self.twist_msg_.angular.z = 0.0 self.cmd_vel_pub_.publish(self.twist_msg_) self.response_.success = True self.response_.message = \u0026#34;Successfully Stopped\u0026#34; else: self.response_.success = False self.response_.message = \u0026#34;Stop Failed\u0026#34; return self.response_ def main(): rospy.init_node(\u0026#34;emergency_stop_node\u0026#34;) e_stop_node = EmergencyStopNode() rospy.sleep(1.0) e_stop_node.twist_pub() rospy.spin() if __name__ == \u0026#39;__main__\u0026#39;: try: main() except rospy.ROSInterruptException: pass #include \u0026lt;ros/ros.h\u0026gt; #include \u0026lt;std_srvs/SetBool.h\u0026gt; #include \u0026lt;geometry_msgs/Twist.h\u0026gt; using SetBool = std_srvs::SetBool; class EmergencyStopNode { private: ros::ServiceServer service_; ros::Publisher cmd_vel_pub_; geometry_msgs::Twist twist_msg_; public: EmergencyStopNode(ros::NodeHandle *nh){ service_ = nh-\u0026gt;advertiseService(\u0026#34;emergency_stop\u0026#34;, \u0026amp;EmergencyStopNode::eStopCallback, this); cmd_vel_pub_ = nh-\u0026gt;advertise\u0026lt;geometry_msgs::Twist\u0026gt;(\u0026#34;cmd_vel\u0026#34;, 10); ROS_INFO_STREAM(\u0026#34;EmergencyStopNode Started\u0026#34;); } void moveRobot(){ twist_msg_.linear.x = 0.5; twist_msg_.angular.z = 1.0; cmd_vel_pub_.publish(twist_msg_); } bool eStopCallback(SetBool::Request \u0026amp;req, SetBool::Response \u0026amp;res){ if(req.data == true){ twist_msg_.linear.x = 0.0; twist_msg_.angular.z = 0.0; cmd_vel_pub_.publish(twist_msg_); res.success = true; res.message = \u0026#34;Successfully Stopped\u0026#34;; return true; } else { res.success = false; res.message = \u0026#34;Stop Failed\u0026#34;; return false; } } }; int main(int argc, char **argv) { ros::init(argc, argv, \u0026#34;emergency_stop_node\u0026#34;); ros::NodeHandle nh; EmergencyStopNode e_stop_service(\u0026amp;nh); auto start_time = ros::Time::now(); auto cur_time = ros::Time::now(); while( (cur_time - start_time) \u0026lt; ros::Duration(3.0)){ e_stop_service.moveRobot(); cur_time = ros::Time::now(); } ros::spin(); ros::shutdown(); return 0; } spawn_model_client code python c\u0026#43;\u0026#43; #! /usr/bin/env python3 \u0026#34;\u0026#34;\u0026#34; referenced from programcreek url : https://www.programcreek.com/python/example/93572/rospkg.RosPack \u0026#34;\u0026#34;\u0026#34; import math import rospy import rospkg from geometry_msgs.msg import Pose from gazebo_msgs.srv import SpawnModel def spawn_helix(): rospy.init_node(\u0026#34;gazebo_spawn_model\u0026#34;) # model_name model_name = \u0026#34;box\u0026#34; # model_xml rospack = rospkg.RosPack() model_path = rospack.get_path(\u0026#34;py_service_pkg\u0026#34;) + \u0026#34;/urdf/\u0026#34; with open(model_path + model_name + \u0026#34;.urdf\u0026#34;, \u0026#34;r\u0026#34;) as xml_file: model_xml = xml_file.read().replace(\u0026#34;\\n\u0026#34;, \u0026#34;\u0026#34;) # robot_namespace robot_namespace = \u0026#34;\u0026#34; # initial_pose initial_pose = Pose() initial_pose.position.x = 0.0 initial_pose.position.y = -1 initial_pose.position.z = 0.2 # z rotation -pi/2 to Quaternion initial_pose.orientation.z = -0.707 initial_pose.orientation.w = 0.707 # reference_frame reference_frame = \u0026#34;world\u0026#34; theta = 0.0 spawn_model_prox = rospy.ServiceProxy(\u0026#34;gazebo/spawn_urdf_model\u0026#34;, SpawnModel) for i in range(100): # service call initial_pose.position.x = theta * math.cos(theta) initial_pose.position.y = theta * math.sin(theta) theta += 0.2 entity_name = model_name + str(i) result = spawn_model_prox( entity_name, model_xml, robot_namespace, initial_pose, reference_frame ) \u0026#34;\u0026#34;\u0026#34; result fromat bool success string status_message \u0026#34;\u0026#34;\u0026#34; rospy.loginfo(result) if __name__ == \u0026#39;__main__\u0026#39;: try: spawn_helix() except rospy.ROSInterruptException: pass #include \u0026lt;fstream\u0026gt; // ros.h doesn\u0026#39;t contain this lib #include \u0026lt;ros/ros.h\u0026gt; #include \u0026lt;ros/package.h\u0026gt; #include \u0026lt;geometry_msgs/Pose.h\u0026gt; #include \u0026lt;gazebo_msgs/SpawnModel.h\u0026gt; void addXml(gazebo_msgs::SpawnModel\u0026amp; model_in, const std::string\u0026amp; file_path ){ std::ifstream file(file_path); std::string line; while (!file.eof()){ std::getline(file, line); model_in.request.model_xml += line; } file.close(); } class SpawnModelClient { private: ros::ServiceClient spawn_model_prox; int model_num_ = 0; double theta_ = 0.0; public: SpawnModelClient(ros::NodeHandle *nh){ spawn_model_prox = nh-\u0026gt;serviceClient\u0026lt;gazebo_msgs::SpawnModel\u0026gt;(\u0026#34;gazebo/spawn_urdf_model\u0026#34;); for(auto i = 0; i \u0026lt; 100; i++){ this-\u0026gt;serviceCall(); } } void serviceCall(){ gazebo_msgs::SpawnModel model; // add roslib in find_package() auto file_path = ros::package::getPath(\u0026#34;cpp_service_pkg\u0026#34;) + \u0026#34;/urdf/box.urdf\u0026#34;; addXml(model, file_path); model.request.model_name = \u0026#34;box\u0026#34; + std::to_string(model_num_++); model.request.reference_frame = \u0026#34;world\u0026#34;; model.request.initial_pose = getPose(); // ServiceClient.call() =\u0026gt; return bool type if (spawn_model_prox.call(model)){ auto response = model.response; ROS_INFO(\u0026#34;%s\u0026#34;, response.status_message.c_str()); // Print the result given by the service called } else { ROS_ERROR(\u0026#34;Failed to call service /trajectory_by_name\u0026#34;); ros::shutdown(); } model_num_++; } geometry_msgs::Pose getPose(){ geometry_msgs::Pose initial_pose; initial_pose.position.x = theta_ * cos(theta_); initial_pose.position.y = theta_ * sin(theta_); theta_ += 0.2; initial_pose.position.z = 0.2; initial_pose.orientation.z = -0.707; initial_pose.orientation.w = 0.707; return initial_pose; } }; int main(int argc, char** argv){ ros::init(argc, argv, \u0026#34;gazebo_spawn_model\u0026#34;); ros::NodeHandle nh; SpawnModelClient spawn_model_client(\u0026amp;nh); ros::shutdown(); return 0; } Service Server와 Client를 생성하는 코드 API 차이를 비교해봅시다. rospy roscpp Server rospy.Service(service_name, srv_type, callback) advertiseService(service_name, srv_type, callback) Client rospy.ServiceProxy(server_name, srv_type) serviceClient\u0026lt;srv_type\u0026gt;(service_name) Time rospy.Time.now() ros::Time::now() rospack rospkg.RosPack().get_path() ros::package::getPath() 실제 로봇 프로그래밍시에는 python보다 c++가 우세하게 사용됩니다. 하지만 우리는 이미 rospy를 통해 통신 메커니즘에 대해 이해하였기 때문에 간단히 짚고 넘어갔으며, 관련된 추가 개발은 강의 노트를 통해 지속 업데이트할 예정입니다.\n참고자료\nhttp://wiki.ros.org/roscpp/Overview/Publishers and Subscribers http://docs.ros.org/ "
},
{
	"uri": "/kr/advanced_contents_ros1/lecture2/",
	"title": "Lecture2 - More About ROS System",
	"tags": [],
	"description": "",
	"content": " ROS Node가 실행되고 Topic 통신이 이루어지기 위해서 Master에게 자신을 등록하고 Master에 의한 Node간 TCPROS / UDPROS 연결이 이루어져야 합니다.\n개념 정리와 예시, 그리고 데모를 통해 ROS의 통신 시스템에 대해 배워봅시다.\nXMLRPC Extensible Markup Language - XML이란, 웹 서비스에서 데이터를 표현하기 위해 사용하는 마크업 언어입니다. (such as HTML), 모든 데이터를 구조화해서 transport하기 때문에 검색과 재사용에 유리합니다. ROS에서 사용하는 launch file도 xml을 사용하고 있으므로 ROS 개발자들에게는 익숙한 문법일 것입니다. image from : xml 파일의 비밀 RPC - remote procedure call 란, 분산 네트워크 환경에서의 프로그래밍을 용이하게 하기 위해 등장한 기술로, 원격에 정의된 함수를 로컬에서 호출하는 식으로 사용이 가능합니다.\nimage from : RPC란? 이 둘을 결합한 XML-RPC는 RPC 기술 과정에서 XML을 사용하는 것입니다. 서버-클라이언트 정보가 XML 문서로 만들어져 응답하게 됩니다.\nXML-RPC Request Format Example - HTTP Header를 포함한 예시이며, /xmlrpc라는 서버에 circleArea라는 method를 request 하는 경우입니다. POST /xmlrpc HTTP 1.0 User-Agent: myXMLRPCClient/1.0 Host: 192.168.124.2 Content-Type: text/xml Content-Length: 169 \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;methodCall\u0026gt; \u0026lt;methodName\u0026gt;circleArea\u0026lt;/methodName\u0026gt; \u0026lt;params\u0026gt; \u0026lt;param\u0026gt; \u0026lt;value\u0026gt;\u0026lt;double\u0026gt;2.41\u0026lt;/double\u0026gt;\u0026lt;/value\u0026gt; \u0026lt;/param\u0026gt; \u0026lt;/params\u0026gt; \u0026lt;/methodCall\u0026gt; XML-RPC Response Format Example - Request와 유사한 구조를 갖지만 methodCall 대신 methodResponse가 사용되며, methodName가 없다는 차이를 갖습니다. Header는 성공, 실패 유무와 상관 없이 200 OK를 반환한다는 점에 유의합니다. HTTP/1.1 200 OK Date: Sat, 06 Oct 2001 23:20:04 GMT Server: Apache.1.3.12 (Unix) Connection: close Content-Type: text/xml Content-Length: 124 \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;methodResponse\u0026gt; \u0026lt;params\u0026gt; \u0026lt;param\u0026gt; \u0026lt;value\u0026gt;\u0026lt;double\u0026gt;18.24668429131\u0026lt;/double\u0026gt;\u0026lt;/value\u0026gt; \u0026lt;/param\u0026gt; \u0026lt;/params\u0026gt; \u0026lt;/methodResponse\u0026gt; ROS는 Topic, Service 통신을 위해 standard TCP/UDP socket에 기반하여 독자적인 Header와 프로토콜을 가진 TCPROS/UDPROS를 만들었습니다. 이들에 대해 하나씩 살펴보겠습니다.\nConnection Header Connection Header는 Node간 통신이 이루어지기 위한 typing, routing 데이터를 포함하고 있으며 TCPROS와 UDPROS 별도 다른 형태를 갖고 있습니다. 공식 문서에서 명확히 밝히고 있는 TCPROS의 Connection Header를 분석해봅시다.\nEncoding Format은 다음과 같습니다. 4-byte length + [4-byte field length + field=value ]* * All length fields are little-endian integers * Field names and values are strings. rostopic pub /chatter std_msgs/String \u0026quot;hello” 에 대한 hex output은 아래와 같습니다. 전체 header 길이 176 바이트 ⇒ (b0 00 00 00, little-endian 사용)\nb0 00 00 00 20 00 00 00 6d 65 73 73 61 67 65 5f 64 65 66 69 6e 69 74 69 6f 6e 3d 73 74 72 69 6e 67 20 64 61 74 61 0a 0a 25 00 00 00 63 61 6c 6c 65 72 69 64 3d 2f 72 6f 73 74 6f 70 69 63 5f 34 37 36 37 5f 31 33 31 36 39 31 32 37 34 31 35 35 37 0a 00 00 00 6c 61 74 63 68 69 6e 67 3d 31 27 00 00 00 6d 64 35 73 75 6d 3d 39 39 32 63 65 38 61 31 36 38 37 63 65 63 38 63 38 62 64 38 38 33 65 63 37 33 63 61 34 31 64 31 0e 00 00 00 74 6f 70 69 63 3d 2f 63 68 61 74 74 65 72 14 00 00 00 74 79 70 65 3d 73 74 64 5f 6d 73 67 73 2f 53 74 72 69 6e 67 09 00 00 00 05 00 00 00 68 65 6c 6c 6f message_definition 필드는 아래와 같이 해석됩니다. - 길이 32 bytes (20 00 00 00) 6d 65 73 73 61 67 65 5f 64 65 66 69 6e 69 74 69 6f 6e 3d 73 74 72 69 6e 67- m e s s a g e _ d e f i n i t i o n = s t r i n g- 20 64 61 74 61 0a 0a d a t a \\n \\n callerid 필드는 아래와 같이 해석됩니다. - 길이 37 bytes (25 00 00 00) 63 61 6c 6c 65 72 69 64 3d 2f 72 6f 73 74 6f 70 69 63 5f 34 37 36 37 5f 31 33- c a l l e r i d = / r o s t o p i c _ 4 7 6 7 _ 1 3- 31 36 39 31 32 37 34 31 35 35 37 1 6 9 1 2 7 4 1 5 5 7 latching 필드는 아래와 같이 해석됩니다. - 길이 10 bytes (0a 00 00 00) 6c 61 74 63 68 69 6e 67 3d 31 l a t c h i n g = 1 md5sum 필드는 아래와 같이 해석됩니다. - 길이 39 bytes (27 00 00 00) 6d 64 35 73 75 6d 3d 39 39 32 63 65 38 61 31 36 38 37 63 65 63 38 63 38 62 64- m d 5 s u m = 9 9 2 c e 8 a 1 6 8 7 c e c 8 c 8 b d- 38 38 33 65 63 37 33 63 61 34 31 64 31 8 8 3 e c 7 3 c a 4 1 d 1 topic 필드는 아래와 같이 해석됩니다. - 길이 14 bytes (0e 00 00 00) 74 6f 70 69 63 3d 2f 63 68 61 74 74 65 72 t o p i c = / c h a t t e r message type 필드는 아래와 같이 해석됩니다. - 길이 20 bytes (14 00 00 00) 74 79 70 65 3d 73 74 64 5f 6d 73 67 73 2f 53 74 72 69 6e 67 t y p e = s t d _ m s g s / S t r i n g hello라는 데이터 response는 5 bytes를 갖고, message body 필드 길이는 9 bytes이며, std_msgs/String 타입을 갖습니다. 09 00 00 00 05 00 00 00 68 65 6c 6c 6f h e l l o 이렇게 Topic response는 특정 필드와 데이터로 구성되어 있습니다.\n사용되는 모든 필드에 대한 데이터는 링크로 대체하겠습니다.\n참고링크 : http://wiki.ros.org/ROS/Connection Header TCPROS TCPROS는 ROS의 Topic, Service 통신 시 Inbound connection으로 TCP 소켓을 사용하는 방식입니다. 일전 살펴본 Connection Header에서와 같이 특정 필드들을 결합하여 Header와 Data를 송수신합니다.\n만약 header가 \u0026rsquo;topic\u0026rsquo; 필드를 포함하고 있다면 ROS Topic 연결로 이루어지고 \u0026lsquo;service\u0026rsquo; 필드를 포함하고 있다면 ROS Service 연결로 이루어지는 방식입니다.\n각각의 필드들에 대한 간략한 나열은 아래와 같습니다. TCPROS subscriber의 Request\nmessage_definition: full text of message definition callerid: subscriber node name topic: name of the topic the subscriber is connecting to md5sum: md5sum of the message type type: message type md5sum 이란? 파일을 다운받거나, 이동하거나, 복사한 후에 원본파일과 동일한 파일인지 확인하는 목적으로 쓰이는 해시 알고리즘입니다. (ex - git의 SHA-1)\nTCPROS publisher의 Response\nmd5sum: md5sum of the message type type: message type TCPROS service client의 Request\ncallerid: node name of service client service: name of the topic the subscriber is connecting to md5sum: md5sum of the message type type: service type optional 필드들\ntcp_nodelay: 이 값이 \u0026lsquo;1\u0026rsquo; 일 시 topic 통신에 TCP_NODELAY 옵션을 적용합니다. latching: latch를 사용하면 마지막으로 메시지가 저장되고 이후 연결 시 이 데이터를 전송합니다. 지도와 같이 정적이고 느린 데이터를 다룰 때 유용합니다. 이 값이 \u0026lsquo;1\u0026rsquo; 이면 publish하는 데이터가 latch라는 것을 의미합니다. persistent: 이 값이 \u0026lsquo;1\u0026rsquo; 일 시, Service Server는 여러 Request에 대응하여 계속 통신을 열어둬야 한다는 것을 의미합니다. error: 통신 실패 시 등장하는 human-readable error message입니다. ok: Service Response에서 사용되는 값으로 이 값이 \u0026lsquo;1\u0026rsquo; 일 시, response가 성공적으로 통신되지만, 이 값이 \u0026lsquo;0\u0026rsquo; 일 시, serialized string 타입의 에러 메세지가 이어집니다. 경우에 따라 return false로 인해 비어있을 수 있습니다. UDPROS UDPROS는 ROS의 Topic, Service 통신 시 Inbound connection으로 UDP 소켓을 사용하는 방식입니다. UDPROS는 standard UDP datagram과 serialized된 message data를 사용하며, 로봇의 제어와 센서 데이터를 다루는 것과 같이 빠른 통신에 사용됩니다.\nUDPROS header format은 아래와 같으며 TCPROS에 비해 훨씬 간단합니다.\n+---------------------------------+ | Connection ID | +---------------------------------+ |Opcode | Msg ID | Block # | +---------------------------------+ Connection ID - 32-bit value로 connection negotiation 중 결정됩니다. Opcode - UDPROS는 여러 datagram type을 지원하는데, 이들을 명시하는 코드입니다. DATA0 (0) - ROS message의 가장 처음에 전송됩니다. DATAN (1) - 첫 전송 이후 계속해서 이 타입이 사용됩니다. PING (2) - heartbeat packet입니다. ERR (3) - 갑작스런 connection 단절 시 사용됩니다. Message ID - 새 메시지가 전송될 때마다 증가되며 데이터가 삭제되었는지 여부를 확인하는 데 사용되는 8비트 값입니다. Block # - opcode가 DATAN인 경우, 현재 datagram 번호가 되며, opcode가 DATA0이 아닌 이상 0을 갖고, 전체 ROS message의 개수를 나타냅니다. 추가 특징\nROS messages는 다수의 Subscriber를 가질 수 있습니다. 첫 datagram은 전체 datagrams의 수를 담게 됩니다. connection negotiation 중 사용할 최대 message per datagram이 결정됩니다. ROS의 통신 시스템 총정리 ROS Master와 Node에 의해 Topic과 Service가 이루어지는 과정을 총정리해봅시다.\nroscore 명령어를 통해 Node간 접속을 주관하고 URI 주소/포트를 등록받는 ROS Master를 구동시킵니다. rosrun 혹은 roslaunch에 의해 Node가 실행됩니다. Subscriber Node가 구동되는 과정에서, Node 자신의 이름, Topic 이름, Message Type, URI 주소와 포트가 주고 받아집니다. 다음으로, Publisher Node가 구동되며 Subscriber와 마찬가지로 Topic 등록을 위해 Master와 각종 데이터를 주고 받습니다. ROS Master가 Subscriber Node에게 Publisher의 정보를 전달하고, 이때, XML-RPC를 이용하여 통신합니다. Subscriber Node는 ROS Master로부터 Publisher의 정보를 받아 해당 Node에게 직접 접속 요청을 합니다. Node 이름, Topic 이름, 방식(TCPROS 또는 UDPROS)과 같은 정보를 XMLRPC 를 이용하여 통신하게 됩니다. Publisher Node는 Subscriber Node에게 접속 응답을 하게 되고, 자신의 TCP 서버의 정보인 URI주소와 포트를 XMLRPC 를 이용하여 전달하게 됩니다. Subscriber Node는 TCPROS를 통해 클라이언트를 만들고, Publisher Node와 직접 연결합니다. 이제부터, Publisher Node는 Subscriber Node에게 정해진 메시지를 전송하게 됩니다. Service의 경우 Topic과 달리 1회성 연결이기 때문에, 접속, 서비스 요청, 서비스 응답이 수행되고 서로간의 접속을 끊게 됩니다. 이후 Service 통신을 다시 진행해야 하는 경우 처음부터 다시 진행해야 합니다. Topic 접속의 종료 시, Node의 종료 시에도 각 Node들은 ROS Master에게 XML-RPC를 통해 종료 Message를 주고받습니다. ROS Packet Analysis Demo ROS 내부의 통신이 이루어지는 과정을 배운 만큼 WireShark를 통해 실제 오가는 패킷을 분석해 봅시다.\nWireshark 설치 sudo apt update sudo apt install wireshark sudo wireshark ROS Master는 기본적으로 11311 포트를 사용하도록 설정되어있습니다. 현재 IP의 11311 포트 패킷을 분석하여 roscore 실행 시 오가는 패킷들을 살펴보겠습니다. ip.addr == \u0026lt;my-ip-addr\u0026gt; || tcp.port == 11311 # Terminal roscore TCP handshake가 이루어진 뒤 parameter server, logger, roslaunch, rosgraph, statistics_window_max_size를 비롯하여 다양한 서비스가 Request, Response를 통해 초기화됩니다. ROS Master를 종료할 시에도 실행되고 있는 모든 서비스들은 11311포트를 통해 종료 신호를 Request-Response 합니다.\n이번에는 Publisher를 실행한 뒤, ROS Master와 오가는 패킷을 살펴봅시다. rostopic pub /chatter std_msgs/String \u0026#34;hello\u0026#34; 패킷을 살펴보면, XMLRPC를 통해 Topic Publisher의 포트와 이름, Topic 이름과 Message type 정보를 확인할 수 있습니다. Packet - 1 Packet - 2 \u0026lt;methodCall\u0026gt; \u0026lt;methodName\u0026gt; registerService \u0026lt;/methodName\u0026gt; \u0026lt;params\u0026gt; \u0026lt;param\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; /rostopic_18957_1673097448137 \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;/param\u0026gt; \u0026lt;param\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; /rostopic_18957_1673097448137/get_loggers \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;/param\u0026gt; \u0026lt;param\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; rosrpc://166.104.135.89:44311 \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;/param\u0026gt; \u0026lt;param\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; http://166.104.135.89:33575/ \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;/param\u0026gt; \u0026lt;/params\u0026gt; \u0026lt;/methodCall\u0026gt; \u0026lt;?xml version=\u0026#39;1.0\u0026#39; ?\u0026gt; \u0026lt;methodCall\u0026gt; \u0026lt;methodName\u0026gt; registerPublisher \u0026lt;/methodName\u0026gt; \u0026lt;params\u0026gt; \u0026lt;param\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; /rostopic_18957_1673097448137 \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;/param\u0026gt; \u0026lt;param\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; /chatter \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;/param\u0026gt; \u0026lt;param\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; std_msgs/String \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;/param\u0026gt; \u0026lt;param\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; http://166.104.135.89:33575/ \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;/param\u0026gt; \u0026lt;/params\u0026gt; \u0026lt;/methodCall\u0026gt; Connection Header를 실제로 확인해보겠습니다. rostopic echo를 실행한 뒤 패킷의 data field를 살펴봅니다. $ rostopic echo /chatter data: \u0026#34;hello\u0026#34; --- 실제 /chatter topic의 정보를 조회해보면 data 필드의 결과와 일치하는 것을 확인 가능합니다. $ rostopic info /chatter Type: std_msgs/String Publishers: * /rostopic_18957_1673097448137 (http://166.104.135.89:33575/) Subscribers: None /chatter Topic Subscriber를 실행하고, topic publisher의 포트(현재는 33575)로 오가는 패킷을 분석해보겠습니다. ip.addr == \u0026lt;my-ip-addr\u0026gt; || tcp.port == 33575 (/chatter publisher의 포트가 33575였음) Topic echo를 통해 Subscriber를 실행합니다. $ rostopic echo /chatter data: \u0026#34;hello\u0026#34; --- 우선, 생성된 Subscriber 정보는 아래와 같습니다. $ rostopic info /chatter Type: std_msgs/String Publishers: * /rostopic_18957_1673097448137 (http://166.104.135.89:33575/) Subscribers: * /rostopic_21890_1673098174449 (http://166.104.135.89:36479/) 패킷을 살펴보면, Subscriber에 대한 정보와 데이터 타입에 대한 정보가 XML-RPC를 통해 오고 간 것을 확인할 수 있습니다. Packet - 1 Packet - 2 \u0026lt;methodCall\u0026gt; \u0026lt;methodName\u0026gt; registerPublisher \u0026lt;/methodName\u0026gt; \u0026lt;params\u0026gt; \u0026lt;param\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; /rostopic_21890_1673098174449 \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;/param\u0026gt; \u0026lt;param\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; /rosout \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;/param\u0026gt; \u0026lt;param\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; rosgraph_msgs/Log \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;/param\u0026gt; \u0026lt;param\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; http://166.104.135.89:36479/ \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;/param\u0026gt; \u0026lt;/params\u0026gt; \u0026lt;/methodCall\u0026gt; \u0026lt;methodResponse\u0026gt; \u0026lt;params\u0026gt; \u0026lt;param\u0026gt; \u0026lt;value\u0026gt; \u0026lt;array\u0026gt; \u0026lt;data\u0026gt; \u0026lt;value\u0026gt; \u0026lt;int\u0026gt; 1 \u0026lt;/int\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; current system state \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;value\u0026gt; \u0026lt;array\u0026gt; \u0026lt;data\u0026gt; \u0026lt;value\u0026gt; \u0026lt;array\u0026gt; \u0026lt;data\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; /rosout_agg \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; rosgraph_msgs/Log \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;/data\u0026gt; \u0026lt;/array\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;value\u0026gt; \u0026lt;array\u0026gt; \u0026lt;data\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; /rosout \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; rosgraph_msgs/Log \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;/data\u0026gt; \u0026lt;/array\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;value\u0026gt; \u0026lt;array\u0026gt; \u0026lt;data\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; /chatter \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;value\u0026gt; \u0026lt;string\u0026gt; std_msgs/String \u0026lt;/string\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;/data\u0026gt; \u0026lt;/array\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;/data\u0026gt; \u0026lt;/array\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;/data\u0026gt; \u0026lt;/array\u0026gt; \u0026lt;/value\u0026gt; \u0026lt;/param\u0026gt; \u0026lt;/params\u0026gt; \u0026lt;/methodResponse\u0026gt; 다음으로, turtlesim을 통해 topic message data의 변화를 살펴보고자 합니다.\nturtlesim을 실행시킨 뒤 rosnode info를 통해 각종 정보들을 조회합니다. 사용중인 통신 방법 (TCPROS), Node의 포트 번호 등 다양한 정보들이 조회됩니다. $ rosrun turtlesim turtlesim_node $ rosnode info /turtlesim -------------------------------------------------------------------------------- Node [/turtlesim] Publications: * /rosout [rosgraph_msgs/Log] * /turtle1/color_sensor [turtlesim/Color] * /turtle1/pose [turtlesim/Pose] Subscriptions: * /turtle1/cmd_vel [unknown type] Services: * /clear * /kill * /reset * /spawn * /turtle1/set_pen * /turtle1/teleport_absolute * /turtle1/teleport_relative * /turtlesim/get_loggers * /turtlesim/set_logger_level contacting node http://166.104.135.89:39875/ ... Pid: 29120 Connections: * topic: /rosout * to: /rosout * direction: outbound (33435 - 166.104.135.89:60856) [26] * transport: TCPROS rostopic info를 통해 cmd_vel topic에 대한 정보를 조회하였습니다. 사용중인 포트 번호를 확인한 뒤 wireshark를 통해 해당 포트로 오가는 패킷을 분석합니다. $ rostopic info /turtle1/cmd_vel Type: geometry_msgs/Twist Publishers: None Subscribers: * /turtlesim (http://166.104.135.89:39875/) wireshark 필터 조건문 ip.addr == \u0026lt;my-ip\u0026gt; || tcp.port == 39875 teleop key를 통해 거북이의 조종을 준비하고, 해당 작업 중 발생한 패킷을 분석합니다. rosrun turtlesim turtle_teleop_key XML-RPC 통신들이 이루어진 뒤로, TCP 통신이 이어지는 모습을 확인할 수 있습니다.\nTCP Data 필드의 내용에는 아래와 같은 데이터가 포함되어 있습니다.\ncallerid=/teleop_turtle latching=0\u0026#39;md5sum=acffd30cd6b6de30f120938c17c593fbjmessage_definition=## ## Severity level constants ## byte DEBUG=1 #debug level byte INFO=2 #general level byte WARN=4 #warning level byte ERROR=8 #error level byte FATAL=16 #fatal/critical level ## ## Fields ## Header header byte level string name # name of the node string msg # message string file # file the message came from string function # function the message came from uint32 line # line the message came from string[] topics # topic names that the node publishes ================================================================================ MSG: std_msgs/Header # Standard metadata for higher-level stamped data types. # This is generally used to communicate timestamped data # in a particular coordinate frame. # # sequence ID: consecutively increasing ID uint32 seq #Two-integer timestamp that is expressed as: # * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called \u0026#39;secs\u0026#39;) # * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called \u0026#39;nsecs\u0026#39;) # time-handling sugar is provided by the client library time stamp #Frame this data is associated with string frame_id topic=/rosouttype=rosgraph_msgs/Log callerid=/teleop_turtle latching=0\u0026#39;md5sum=9f195f881246fdfa2798d1d3eebca84armessage_definition=# This expresses velocity in free space broken into its linear and angular parts. Vector3 linear Vector3 angular ================================================================================ MSG: geometry_msgs/Vector3 # This represents a vector in free space. # It is only meant to represent a direction. Therefore, it does not # make sense to apply a translation to it (e.g., when applying a # generic rigid transformation to a Vector3, tf2 will only apply the # rotation). If you want your data to be translatable too, use the # geometry_msgs/Point message instead. float64 x float64 y float64 z topic=/turtle1/cmd_veltype=geometry_msgs/Twist teleop key에서 앞/뒤/CW/CCW와 같이 다양한 조종 신호를 publish해보고 이때의 TCP Data가 어떻게 변화하는지 확인해봅시다. ⇒ 기본적으로 sequence / timestamp가 변화하며, 미묘하게 data가 다른 것을 알 수 있습니다.\n이렇게 topic message는 serialization이 되어 있으며, 공식 문서화 같이 MD5 sum을 사용합니다. image from : roswiki ROS URI 설정 ROS에는 다양한 환경 변수들이 존재합니다. 이들 중 Master가 사용할 IP와 Port를 설정하는 환경 변수가 있으며, 이는 아래와 같이 조회 가능합니다. $ echo $ROS_MASTER_URI http://192.168.0.1:11311 서로 다른 디바이스에서 동작하는 ROS 시스템일지라도 같은 MASTER URI를 갖도록 하면 원격 통신이 가능합니다. 이를 통해 원격 시각화와 원격 제어를 주로 실행합니다.\nimage from : turtlebot3 git ROS_MASTER_URI를 사용하는 방법은 다음과 같습니다.\nROS_MASTER_URI=http://master-ip-addr:master-ip-port ROS_IP=\u0026lt;현재 디바이스의 ip-addr\u0026gt; ROS_HOSTNAME=\u0026lt;현재 디바이스의 hostname\u0026gt; ROS_IP와 ROS_HOSTNAME는 서로 양립할 수 없고, 둘 중 하나를 사용할 수 있습니다.\nbashrc의 수정을 해두면, 새로운 터미널을 실행할 때마다 변경된 내용이 반영될 수 있어 편리합니다. 강의 초반, 저의 셋업을 따라오셨다면, ~/ros_menu/config.yaml을 수정하여 손쉽게 변경하실 수 있습니다. Config: menu_enable: true ros_option: menu default_ros_domain_id: 30 Menu: ROS 1 noetic: option_num: 1 ROS_version: 1 distro_name: noetic ros1_path: /opt/ros/noetic master_ip: # set if roscore isn\u0026#39;t on this computer cmds: # - source ${HOME}/catkin_ws/devel/setup.${shell} # - source_plugin openvino_bashrc 같은 네트워크를 사용하는 두 PC를 사용해서 원격으로 로봇을 조종해보는 실습을 진행해봅시다. # PC 1 - ROS Master를 실행시키고 로봇 등장시키기 roslaunch smb_gazebo smb_gazebo.launch # PC 2 - Master URI 변경 후 로봇 조종 rosrun teleop_twist_keyboard teleop_twist_keyboard.py image from : robots.nootrix 자료출처\nhttps://www.tutorialspoint.com/xml-rpc/xml_rpc_fault.htm http://wiki.ros.org/ROS/Connection Header http://wiki.ros.org/ROS/TCPROS 로봇 운영체제 강좌 : ROS 개념 정리 (오픈소스 소프트웨어 \u0026amp; 하드웨어: 로봇 기술 공유 카페 (오로카)) http://wiki.ros.org/ROS/EnvironmentVariables#ROS_IP.2FROS_HOSTNAME "
},
{
	"uri": "/kr/advanced_contents_ros2/lecture3/",
	"title": "Lecture12 - SROS2",
	"tags": [],
	"description": "",
	"content": "sros2 DDS는 기본적으로 보안이 적용되어 있지는 않습니다. 대신, 아래와 같이 5가지의 보안 기능이 표준 정의에 포함되어 있습니다. 사용자는 이들을 Plugin 형태로 추가하여 사용하게 되며, 주로 Vendor단에서 패치 형태로 제공합니다.\nAuthentication: 같은 네트워크를 사용하고, 특정 domain내에 존재하는 participant 사이의 신원을 검사합니다. (x.509 인증서와 특정 Public Key Infrastructure - PKI를 사용합니다. ) Access control: participant의 동작, 혹은 리소스를 제한합니다. (apparmor나 cgroup이 아니라 특정 participant를 특정 DDS 도메인으로 제한하거나, participant가 특정 DDS 항목을 읽거나 쓸 수 있도록 하는 형태입니다.) Cryptography: encryption/decryption/signing/hashing/digital signatures와 같은 암호화 관련 작업을 담당합니다. (Authentication과 Access control plugin에서 모두 이 기능을 사용하게 되고, DDS의 Topic Message를 암호화합니다.) Logging: DDS의 보안 관련 이벤트를 로깅합니다. Data tagging: data에 추가 label을 달수 있습니다. 이를 통해 데이터의 보안 측면 분류를 할 수 있으며, 더욱 개선된 access control이 가능합니다. 아래 2종류는 필수 표준이 아니기 때문에 대부분의 Vendor들은 제공하고 있지 않습니다.\nROS 2 Security Working Group (SWG)은 DDS와 ROS 2의 보안과 관련된 오픈 그룹입니다. 해당 그룹에서는 DDS의 보안 취약점을 분석하였는데요, 그 결과 총 13종류의 보안 취약점을 발견하였습니다.\n이러한 13가지 취약성은 CVE(Common Vulnerabilities and Exposure)로 등록되었고, 이 중 7개는 CVSS(Common Vulnerability Scoring System) v3를 기준으로 \u0026lsquo;High\u0026rsquo; 등급을 판정받았으며, 나머지 5개 또한 \u0026lsquo;Medium\u0026rsquo; 등급을 판정받았습니다.\n이러한 분석 결과로 US Cybersecurity and Infrastructure Security Agency (CISA)는 DDS 시스템에 보안 권고 경고 ICS Advisory (ICSA-21-315-02)를 내렸고, 그 결과 각 DDS 벤더들은 현재 보안에 계속해서 신경쓰고 있는 상황입니다.\n=\u0026gt; 해당 13종의 보안 취약점에 대해서 간단히 리뷰를 해보겠습니다.\nNetwork-based vulnerabilities Network Layer에서 고의적인 RTPS packet 전송을 통해 DoS 공격이 가능한 점 불충분한 IP Check (기본 Domain Multicast IP 등) 관련 DDS 표준 - CVE-2021-38425, CVE-2021-38429, CVE-2021-38487, CVE-2021-43547 관련 위험 코드 - Common Weakness CWE-406 Configuration-based vulnerabilities DDS의 셋업 파일은 XML, JSON, YAML과 같은 보편적인 형태를 사용하므로 위험하다고 판단 ex1) DDS 시스템 중 보안이 취약한 XML 라이브러리를 파고들어 액세스 권한을 탈취할 수 있음 ex2) 특정 XML Pasrse 내 부적절한 값을 전달하여 buffer overflow를 발생시킬 수 있음 ⇒ 이러한 이유로 현재 대부분의 DDS Vendor들은 보안 Patch를 배포한 상황입니다.\nFast DDS https://github.com/eProsima/Fast-DDS Open DDS https://opendds.org/ rti DDS https://www.rti.com/products/dds-standard 아래 첨부 파일에는 Ubuntu를 관리하는 Canonical 재단에서 배포한 ROS 사용자를 위한 보안 강화 전략들이 담겨 있습니다. 라즈베리파이와 TurtleBot 로봇을 통해 각종 보안 테스트를 한 결과로 얻게 된 인사이트가 담겨 있습니다.\nDisabling USB Remove default users such as “ubuntu” SSH hardening Disabling Internet Protocol v6 Unattended upgrades Example Packages Securing ROS_WhitePapaer_10.03.20.pdf (325 ) SROS2 ROS 1의 sros와 마찬가지로 sros2는 ROS 2의 보안을 위한 도구들의 집합입니다.\nCA 인증서 자동 생성, x.509에 기반한 keypair 생성 keypairs, governance and permissions files등이 담기는 keystore 생성 DDS traffic을 암호화하는 governance file 제공 SROS2 공식 레퍼런스에서 제공하는 기본 예시들을 함께 실행해보고, 패킷 분석도 진행해보겠습니다.\nsros2 setup sudo apt update \u0026amp;\u0026amp; sudo apt install libssl-dev sudo apt install ros-foxy-demo-nodes-cpp -y sudo apt install ros-foxy-demo-nodes-py -y mkdir ~/sros2_demo cd ~/sros2_demo 각종 인증 관련 파일들이 위치하게 될 keystore를 생성합니다. $ ros2 security create_keystore demo_keystore creating keystore: demo_keystore creating new CA key/cert pair creating governance file: demo_keystore/enclaves/governance.xml creating signed governance file: demo_keystore/enclaves/governance.p7s all done! enjoy your keystore in demo_keystore cheers! 생성된 keystore 폴더는 다음과 같은 폴더 형태를 취하고 있습니다. ├── enclaves │ ├── governance.p7s │ └── governance.xml ├── private │ ├── ca.key.pem │ ├── identity_ca.key.pem -\u0026gt; ca.key.pem │ └── permissions_ca.key.pem -\u0026gt; ca.key.pem └── public ├── ca.cert.pem ├── identity_ca.cert.pem -\u0026gt; ca.cert.pem └── permissions_ca.cert.pem -\u0026gt; ca.cert.pem 아래 예시와 같이 각종 인증키가 생성되는 것을 확인 가능합니다.\nca.key.pem -----BEGIN PRIVATE KEY----- MIGHAgEAMBMGByqGSM49AgEGCCqGSM49AwEHBG0wawIBAQQgiXuds0wpQA1F7Cnv +533UuaPWKnZBYscqvHoyo00XOqhRANCAATI2CRyvxYccuxaWGTKDDe5b2dmdqH5 pBBbeHXXD1QRt7khzpX11InLr9jjpmaotgNIl6oap5d5IF1cIQUXuF1Y -----END PRIVATE KEY----- Authentication Example 첫번째 예시에서는 인증 keypair를 가진 topic publisher와 subscriber를 생성해보려 합니다. 더불어 wireshark를 통해 암호화된 topic message도 확인해보겠습니다.\nsros2 키워드를 사용하여 두 세트의 인증서를 생성합니다. ros2 security create_key demo_keystore /talker_listener/talker ros2 security create_key demo_keystore /talker_listener/listener keystore 폴더 내부에 인증서와 permission이라는 config 파일이 추가되었습니다. ├── enclaves │ ├── governance.p7s │ ├── governance.xml │ └── talker_listener │ ├── listener │ │ ├── cert.pem │ │ ├── governance.p7s -\u0026gt; ../../governance.p7s │ │ ├── identity_ca.cert.pem -\u0026gt; ../../../public/identity_ca.cert.pem │ │ ├── key.pem │ │ ├── permissions_ca.cert.pem -\u0026gt; ../../../public/permissions_ca.cert.pem │ │ ├── permissions.p7s │ │ └── permissions.xml │ └── talker │ ├── cert.pem │ ├── governance.p7s -\u0026gt; ../../governance.p7s │ ├── identity_ca.cert.pem -\u0026gt; ../../../public/identity_ca.cert.pem │ ├── key.pem │ ├── permissions_ca.cert.pem -\u0026gt; ../../../public/permissions_ca.cert.pem │ ├── permissions.p7s │ └── permissions.xml ├── private │ ├── ca.key.pem │ ├── identity_ca.key.pem -\u0026gt; ca.key.pem │ └── permissions_ca.key.pem -\u0026gt; ca.key.pem └── public ├── ca.cert.pem ├── identity_ca.cert.pem -\u0026gt; ca.cert.pem └── permissions_ca.cert.pem -\u0026gt; ca.cert.pem 예제를 실행하기 전, 일반적인 Topic 통신 시 String data가 패킷에 노출되는 모습을 살펴보겠습니다. wireshark를 실행시킨 뒤, 커멘드 라인을 실행시키고 패킷을 수집합니다.\n# Terminal 1 ros2 run demo_nodes_cpp talker # Terminal 2 ros2 run demo_nodes_cpp listener ⇒ RTPS Heartbeat 패킷을 살펴보면, Hello World 라는 데이터가 고스란히 노출되어 있는 모습을 확인 가능합니다.\n이제 보안 옵션을 적용해보겠으며, sros2에서는 다양한 환경 변수를 통해 보완 관련 옵션을 변경할 수 있도록 하고 있습니다. security를 enable 시켜보겠습니다. export ROS_SECURITY_KEYSTORE=~/sros2_demo/demo_keystore export ROS_SECURITY_ENABLE=true export ROS_SECURITY_STRATEGY=Enforce 다음으로, 사용한 RMW DDS를 변경해줍니다. 안타깝게도 CycloneDDS의 Debian Package는 보안 plugin을 제공하지 않기 때문에 보안 옵션 적용 시 아래와 같은 에러가 발생합니다. (소스 코드 빌드를 하면 해결됩니다.) $ ros2 run demo_nodes_cpp talker --ros-args --enclave /talker_listener/talker [INFO] [1674150011.742615669] [rcl]: Found security directory: /home/kimsooyoung/sros2_demo/demo_keystore/enclaves/talker_listener/talker 1674150011.756184 [19] talker: Could not load Authentication library: dds_security_auth: cannot open shared object file: No such file or directory 1674150011.756216 [19] talker: Could not load Authentication plugin. 1674150011.756221 [19] talker: Could not load security [ERROR] [1674150011.757250268] [rmw_cyclonedds_cpp]: rmw_create_node: failed to create DDS participant \u0026gt;\u0026gt;\u0026gt; [rcutils|error_handling.c:108] rcutils_set_error_state() This error state is being overwritten: ... 따라서, 이번 예시를 위해 Fast DDS로 RMW를 변경하겠습니다. export RMW_IMPLEMENTATION=rmw_fastrtps_cpp 서로 다른 Vendor 끼리는 보안 plugin이 호환되지 않습니다. (보안은 표준이 아닙니다.)\nrmw_connextdds ( rit DDS )는 유료 사용 시 보안 옵션을 사용 가능하며 30일 무료판을 사용하셔도 됩니다. ⇒ https://www.rti.com/free-trial\n이제 pub-sub 예시를 실행해보겠습니다. # Terminal 1 $ cd ~/sros2_demo/ $ export RMW_IMPLEMENTATION=rmw_fastrtps_cpp $ ros2 run demo_nodes_cpp talker --ros-args --enclave /talker_listener/talker [INFO] [1674150302.868609218] [rcl]: Found security directory: /home/kimsooyoung/sros2_demo/demo_keystore/enclaves/talker_listener/talker [INFO] [1674150303.901477001] [talker]: Publishing: \u0026#39;Hello World: 1\u0026#39; [INFO] [1674150304.901496377] [talker]: Publishing: \u0026#39;Hello World: 2\u0026#39; # Terminal 2 $ cd ~/sros2_demo/ $ export RMW_IMPLEMENTATION=rmw_fastrtps_cpp $ ros2 run demo_nodes_cpp listener ??? $ ros2 run demo_nodes_cpp listener --ros-args --enclave /talker_listener/listener 보안 옵션을 적용하지 않았기 때문에 Publisher가 동작하지 않습니다.\n현 상황에서 다시금 wireshark를 실행하여 패킷을 수집해보겠습니다. 사진과 같이 이제는 RTPS가 아닌, TLSv1.2 프로토콜을 사용하여 데이터가 오가게 됩니다. 해당 패킷을 열어보면 아래와 같이 암호화가 되어있습니다. 더불어, RTPS 프로토콜 패킷을 살펴보면, enclave 옵션이 적용된 것도 확인 가능합니다. 만약, 서로 다른 머신끼리 통신을 하고 싶다면, demo_keystore를 두 머신 모두 동일하게 소유하고 있어야 합니다. 옆자리에 다른 PC가 있다면 직접 실습해보세요\nmkdir -p ~/sros2_demo/demo_keystore scp -r talker USERNAME@oldschool.local:~/sros2_demo/demo_keystore Access Control 시스템의 보안 수준을 높이기 위해 각 노드가 수행할 수 있는 작업을 제한하는 Access Control을 정의할 수 있습니다. 이번 예시에서는 특정 topic만 사용 가능하도록 profile을 지정해보겠습니다.\nROS 2에서 기본 제공하는 policy 예시를 복사합니다. sudo apt update \u0026amp;\u0026amp; sudo apt install subversion cd ~/sros2_demo svn checkout https://github.com/ros2/sros2/trunk/sros2/test/policies clone한 policy를 바탕으로 node의 action을 제한하는 description을 생성합니다. cd ~/sros2_demo ros2 security create_permission demo_keystore /talker_listener/talker policies/sample.policy.xml ros2 security create_permission demo_keystore /talker_listener/listener policies/sample.policy.xml 위 작업은 talker / listener의 cert.pem이 있어야 실행 가능합니다.\n일전 예시를 다시 실행시켜보겠습니다. 얼핏 보기에는 달라진 점이 전혀 없어 보입니다. # Terminal 1 ros2 run demo_nodes_cpp talker --ros-args -e /talker_listener/talker # Terminal 2 ros2 run demo_nodes_py listener --ros-args -e /talker_listener/listener 하지만, argument를 통해 사용하는 topic을 다른 것으로 바꾸는 순간, not found in allow rule라는 명령어와 함께 Node가 생성되지 않습니다. # Terminal 1 ros2 run demo_nodes_cpp talker --ros-args -e /talker_listener/talker # Terminal 2 ros2 run demo_nodes_py listener --ros-args -r chatter:=not_chatter -e /talker_listener/listener [INFO] [1674152415.259964110] [rcl]: Found security directory: /home/kimsooyoung/sros2_demo/demo_keystore/enclaves/talker_listener/listener 2023-01-20 03:20:15.303 [SECURITY Error] rt/not_chatter topic not found in allow rule. (/tmp/binarydeb/ros-foxy-fastrtps-2.1.2/src/cpp/security/accesscontrol/Permissions.cpp:1271) -\u0026gt; Function check_create_datareader 2023-01-20 03:20:15.303 [SECURITY Error] Error checking creation of local reader bb.dd.19.9c.75.22.60.e0.55.c1.c0.3a|0.0.11.4 (rt/not_chatter topic not found in allow rule. (/tmp/binarydeb/ros-foxy-fastrtps-2.1.2/src/cpp/security/accesscontrol/Permissions.cpp:1271)) -\u0026gt; Function register_local_reader 2023-01-20 03:20:15.303 [PARTICIPANT Error] Problem creating associated Reader -\u0026gt; Function createSubscriber 이번 예시에서 사용한 policy file입니다. - policies/sample.policy.xml topic publisher와 subscriber는 오직 /chatter topic만을 사용할 수 있게 access limit 걸리게 됩니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;policy version=\u0026#34;0.2.0\u0026#34; xmlns:xi=\u0026#34;http://www.w3.org/2001/XInclude\u0026#34;\u0026gt; \u0026lt;enclaves\u0026gt; \u0026lt;xi:include href=\u0026#34;talker_listener.policy.xml\u0026#34; xpointer=\u0026#34;xpointer(/policy/enclaves/*)\u0026#34;/\u0026gt; \u0026lt;xi:include href=\u0026#34;add_two_ints.policy.xml\u0026#34; xpointer=\u0026#34;xpointer(/policy/enclaves/*)\u0026#34;/\u0026gt; \u0026lt;xi:include href=\u0026#34;minimal_action.policy.xml\u0026#34; xpointer=\u0026#34;xpointer(/policy/enclaves/*)\u0026#34;/\u0026gt; \u0026lt;enclave path=\u0026#34;/sample_policy/admin\u0026#34;\u0026gt; \u0026lt;profiles\u0026gt; \u0026lt;profile ns=\u0026#34;/\u0026#34; node=\u0026#34;admin\u0026#34;\u0026gt; \u0026lt;xi:include href=\u0026#34;common/node.xml\u0026#34; xpointer=\u0026#34;xpointer(/profile/*)\u0026#34;/\u0026gt; \u0026lt;actions call=\u0026#34;ALLOW\u0026#34; execute=\u0026#34;ALLOW\u0026#34;\u0026gt; \u0026lt;action\u0026gt;fibonacci\u0026lt;/action\u0026gt; \u0026lt;/actions\u0026gt; \u0026lt;services reply=\u0026#34;ALLOW\u0026#34; request=\u0026#34;ALLOW\u0026#34;\u0026gt; \u0026lt;service\u0026gt;add_two_ints\u0026lt;/service\u0026gt; \u0026lt;/services\u0026gt; \u0026lt;topics publish=\u0026#34;ALLOW\u0026#34; subscribe=\u0026#34;ALLOW\u0026#34;\u0026gt; \u0026lt;topic\u0026gt;chatter\u0026lt;/topic\u0026gt; \u0026lt;/topics\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; \u0026lt;/enclave\u0026gt; \u0026lt;/enclaves\u0026gt; \u0026lt;/policy\u0026gt; 참고자료\nhttps://canonical.com/blog/security-vulnerabilities-on-the-data-distribution-service-dds https://github.com/ros2/sros2 https://canonical.com/blog/what-is-sros-2 "
},
{
	"uri": "/kr/advanced_contents_ros1/lecture3/",
	"title": "Lecture3 - SROS",
	"tags": [],
	"description": "",
	"content": " 이전 데모를 통해 ROS의 보안 취약성에 대해 살펴보았습니다. 이러한 취약점들을 개선하기 위한 방법으로 SROS에 대해 배워보겠습니다.\nsros는 마지막 commit 2018년 이후 개발이 사실상 멈춘 프로젝트입니다. ROS 개발자들이 보안을 위해 어떠한 노력을 들였는지 정도만 살펴보고, 데모와 자세한 내용은 ROS 2 강의에서 이어나가도록 하겠습니다.\nUDPROS가 roscpp만 지원했던 것처럼, sros도 rospy와 사용할 시 제한이 있습니다. TCPROS UDPROS rospy X O roscpp O O rosjava O O sros는 ROS의 client 라이브러리 소스 코드에 보안을 적용하여 새롭게 개발한 ROS Client Library입니다. sros가 사용되는 절차는 다음과 같습니다. sros 빌드 (기존 ROS 코드가 아닌) sroskeyserver 실행 sroscore 실행 sroslaunch를 통해 응용 프로그램 실행 sros에서 제공되는 기능들은 다음과 같습니다.\n소켓 전송에 대한 Native TLS 지원 ROS 노드단에서 자동 생성된 node key pairs 관리 리눅스 커널 단에서의 보안 강화 (AppArmor profile library) x.509 인증서 사용 지원 etc… SROS는 ROS 내의 보안 강화를 위한 방법들의 집합을 지칭하며, 크게 3 계층의 보안을 제공합니다. 각 계층들에 대한 간단한 설명을 해보겠습니다.\nTransport Security Access Control Process Profile Transport Security and ROS SROS는 TLS를 활용하여 ROS 관련 트래픽을 보호합니다. 이를 통해 악의적인 행위자의 redirection, 메시지를 탈취하여 중간에 수정한다거나 Spoofing을 막을 수 있습니다. 또한 시스템/물리적 수준 액세스를 통해 로봇이 손상되더라도 TLS에서 제공하는 Forward Secrecy 덕분에 이전에 기록된 트래픽도 보호할 수 있습니다.\nSROS가 TLS를 적용한 방법은, 네트워크 스택과 ROS 클라이언트 라이브러리 사이에 TLS를 끼워 넣는 것입니다. 이를 통해 SROS는 모든 Socket 수준의 ROS 통신을 Wrapping할 수 있으며, 사용자는 기존 ROS 프로그램 코드를 수정하지 않고도 SROS의 모든 이점을 적용할 수 있습니다.\nimage from : hpbn.co SROS Keyserver Keyserver는 ROS node에게 인증된 key를 분배하고 관리하는 역할을 합니다. Keyserver는 ROS와 독립적으로 실행되며, 다른 기기에서 실행되어도 무관합니다. 만약 자신만의 PKI 방식을 갖고 있다면 기본 제공되는 keyserver를 대체할 수 있습니다.\nSROS는 기본적으로 보안에 익숙치 않고, TLS 시스템을 구축하는 개념에 서투른 사용자를 대상으로 만들어졌습니다.\nKeyserver를 통한 Node configuration과 실행은 아래 링크를 참고합니다. How is a Keyserver used in SROS\nRunning Keyserver SROS의 Node들은 실행 전 Keyserver를 통한 key 생성과 CA를 통한 인증이 필요합니다. 이 과정 없이 생성된 node들은 rosmaster와의 연결이 거부됩니다.\nkeyserver 실행 $ sroskeyserver Starting an XML-RPC server to bootstrap SSL key distribution... Certificate generated: root Certificate generated: master sleeping until keyserver has generated the initial keyring... Horray, the keyserver is now open for business. SROS는 ~/.ros 폴더 내 자신만의 configuration을 구축합니다. 이 내부에는 인증에 필요한 각종 파일들이 위치하게 됩니다. $ tree ~/.ros/sros /root/.ros/sros ├── config │ ├── keyserver_config.yaml │ └── policy_config.yaml └── keystore ├── ca │ ├── master │ │ ├── master.cert │ │ └── master.pem │ └── root │ ├── root.cert │ └── root.pem ├── capath │ ├── d11d170d.0 -\u0026gt; /root/.ros/sros/keystore/ca/root/root.cert │ └── f4ad5f10.0 -\u0026gt; /root/.ros/sros/keystore/ca/master/master.cert └── utils └── keyserver ├── keyserver.cert └── keyserver.pem 8 directories, 10 files 초기 실행 시 로딩된 configuration 파일은 keyserver에 CA를 로드하도록 지시하고, keystore에 존재하지 않는 경우 방법을 지시합니다. root와 중간 Master CA가 초기화되면 keyserver는 자체 transport 인증서와 keypair 로딩을 요청받습니다. keyserver는 자체 key를 사용하여 자신에게 연결을 시도하고, keyserver의 API 끝이 온라인 상태이며 작동 중인지 확인합니다. 이 작업이 모두 완료되면 keyserver가 연결 Node의 요청을 받을 준비가 됩니다. Access Control Access Control을 통해 ROS에서 사용하는 리소스와 Action을 제어할 수 있습니다. SROS 튜토리얼에서는 아래와 같은 ROS API들에 대하여 Access Control 설정이 가능하다고 이야기하고 있습니다.\ntopics publish subscribe parameters read write services advertise call ROS API master calls slave calls Access Control의 실제 구현 방식에 있어 SROS에서 제안하는 두가지 방법을 간략히 정리해보았습니다.\nCertificate Embedding SROS는 Node간 보안 네트워크 소켓 연결(TLS 핸드셰이크) 시 X.509 인증서를 사용합니다. 검증된 방식을 사용하고 계산 효율이 좋다는 장점이 있지만, 이러한 방식은 Policy data가 public 이기 때문에 node, topic 이름이 노출될 염려가 있습니다. Online Arbiter 중앙 집중식으로 데이터 통신을 중재할 수 있습니다. global policy에 대한 정보를 알고 있는 중앙 통제 프로세스가 요청된 Node와 접촉하고 허용여부를 판단합니다. 이는 ROS Master Node가 사용하는 기존 DNS 방식과 유사하지만 네임스페이스 대신 access control restriction을 사용한다는 차이점이 있습니다. Linux Security Modules AppArmor(애플리케이션 Armor)는 프로그램 프로파일로 프로그램의 기능을 제한할 수 있도록 하는 리눅스 커널 보안 모듈입니다. SROS 튜토리얼에서는 AppArmor의 ROS 호환 프로파일 예시를 제공하고 있습니다.\nimage from : https://wiki.apparmor.net/ AppArmor를 활용하여 ROS 프로세스를 격리하고 보호할 수 있으며, 이를 통해 악의적이거나 오작동하는 Node가 Host 시스템과 다른 Node에 미칠 수 있는 영향을 제한할 수 있습니다.\n예를 들면, 특정 IMU Node에 대해 전용 Bus를 예약하고 노드가 해당 Serial Port를 사용하지 못하도록 할 수 있습니다. 이와 같이 특정 노드에 대한 프로파일을 지정하고 예약된 장치에만 읽고 쓸 수 있는 권한을 지정할 수 있습니다.\nAppArmor 설치 sudo apt-get install apparmor apparmor-utils AppArmor를 사용하기 위해 프로파일 configuration file을 작성해야 합니다. github를 통해 ROS를 위한 프로파일 예시를 제공하고 있으며, 이를 AppArmor의 설정 폴더로 복사합니다. git clone https://github.com/ros-infrastructure/apparmor_profiles sudo cp --recursive apparmor_profiles/profiles /etc/apparmor.d 각 프로파일들에 대한 설명은 아래와 같습니다. $ tree apparmor_profiles/profiles/ apparmor_profiles/profiles/ ├── ros # root profile library folder │ ├── base # base networking and signal abstractions for ROS │ ├── node # node abstractions executables needed for ros nodes │ ├── nodes # additional node specific abstractions │ │ └── roslaunch # additional file and signal abstractions for roslaunch │ └── python # node abstractions needed for python nodes └── tunables # root tunables folder for AppArmor profile variables ├── ros # path abstractions executables needed for ros nodes └── ros.d # additional distro specific abstractions └── kinetic # path definition for default kinetic install 프로파일을 변경하게 되면, AppArmor를 새롭게 재시작해야 합니다. 이는 아래 키워드를 사용합니다. sudo service apparmor restart SROS Tutorial에서는 Topic을 사용하는 talker - listener에 대한 프로파일과 실행 예시를 제공하고 있습니다. Custom 프로파일의 작성법과 실행 방법은 링크로 대체합니다.\nCustomizing AppArmor Profiles for ROS 참고자료\nhttp://wiki.ros.org/SROS/CommandLineTools http://wiki.ros.org/SROS/Concepts/PolicyDissemination http://wiki.ros.org/SROS/Tutorials/TrasportSecurityAndROS "
},
{
	"uri": "/kr/ros_and_gazebo/lecture1/",
	"title": "Lecture1 - Gazebo and Robot",
	"tags": [],
	"description": "",
	"content": "FusionBot 소개 이번 실습을 위해 모바일 로봇에서 가장 많이 사용되는 타입의 로봇, FusionBot을 준비하였습니다. FusionBot을 통해 ROS에서의 로봇 표현 방법을 익힌 뒤, 실제 CAD 파일에서 Gazebo 상의 로봇을 구현하는 실습을 진행해봅시다.\n실습을 위한 git repo를 clone한 뒤 종속성들을 설치합시다. cd ~/ros2_ws/src git clone https://github.com/RB2023ROS/du2023-gz.git cd du2023-gz ./setup_scripts.sh URDF와 Robot Description 일반적으로, 로봇은 Links와 Joints 두가지 요소로 이루어집니다.\nLink : 단단하게 고정된 강체(rigid-body)이며, 사람의 골격에 해당합니다. Joint : link 사이를 결합해주고 이들 사이 운동을 결정짓습니다. 사람의 관절에 해당합니다. 다양한 종류의 joint들이 존재하지만, 이론적으로 이들은 결국 prismatic + revolute joint의 결합으로 설명될 수 있습니다.\nrevolute joint : 회전 운동을 갖는 joint prismatic joint : 수평 병진 운동을 갖는 joint 그리고 ROS에서는 개발 상 편의를 위해 크게 6가지의 joint를 사용하고 있지요.\nrevolute - 각도 제한을 가진 회전 continuous - 각도 제한이 없는 회전 prismatic - 수평 운동 fixed - 고정 강체 floating - 6 DOF joint로 gazebo에선 사용 불가 Planar – 평면을 미끄러지는 운동 (물리적 구성이 쉽지 않아 거의 사용되지 않음) Link와 Joint로 결합된 로봇을 결국 텍스트로 표현할 수 있지 않겠냐는 기본 전제 하에, 로봇 공학자들은 URDF - Unified Robot Description Format라는 표준을 만들게 됩니다. 실제로 urdf만 있다면 시뮬레이터 종류에 상관 없이 동일한 로봇 외형을 등장시킬 수 있게 됩니다.\nimage from : Martin Androvich URDF는 XML 문법을 사용하고 있으며 ROS 1의 launch file과 같이 다양한 tag를 통해 로봇을 표현하게 됩니다. 예시를 통해 URDF에 대한 이해도를 가져봅시다.\nURDF의 link가 가질 수 있는 속성들은 다음과 같습니다.\ninertial : 해당 link의 질량, 관성 모멘트와 같은 물성치를 포함합니다. visual : 로봇이 겉으로 보여지는 시각적인 요소를 설정합니다. STL과 같은 3D 모델링 파일을 사용할 수 있습니다. collision : visual은 겉으로 보여지는 모습일 뿐, 실제 해당 link가 자치하는 부피는 collision에서 지정됩니다. Visual과 collision을 일치시킬수록 좋기 때문에 3D 모델링 파일을 사용하기도 합니다. 종종 계산 단순화를 위해 간소화된 모델을 사용하기도 합니다. \u0026lt;link name=\u0026#34;base_link\u0026#34;\u0026gt; \u0026lt;inertial\u0026gt; \u0026lt;origin xyz=\u0026#34;0 0 0\u0026#34; rpy=\u0026#34;0 0 0\u0026#34; /\u0026gt; \u0026lt;mass value=\u0026#34;8.3\u0026#34; /\u0026gt; \u0026lt;inertia ixx=\u0026#34;5.249466E+13\u0026#34; ixy=\u0026#34;-1.398065E+12\u0026#34; ixz=\u0026#34;-3.158592E+12\u0026#34; iyy=\u0026#34;5.786727E+13\u0026#34; iyz=\u0026#34;-5.159120E+11\u0026#34; izz=\u0026#34;3.114993E+13\u0026#34; /\u0026gt; \u0026lt;/inertial\u0026gt; \u0026lt;visual\u0026gt; \u0026lt;origin xyz=\u0026#34;0 0 0\u0026#34; rpy=\u0026#34;0 3.1415 3.1415\u0026#34; /\u0026gt; \u0026lt;geometry\u0026gt; \u0026lt;mesh filename=\u0026#34;package://neuronbot2_description/meshes/neuronbot2/base_link.stl\u0026#34; scale=\u0026#34;0.001 0.001 0.001\u0026#34; /\u0026gt; \u0026lt;/geometry\u0026gt; \u0026lt;material name=\u0026#34;black\u0026#34; /\u0026gt; \u0026lt;/visual\u0026gt; \u0026lt;collision\u0026gt; \u0026lt;origin xyz=\u0026#34;0 0 0.125\u0026#34; rpy=\u0026#34;0 0 0\u0026#34; /\u0026gt; \u0026lt;geometry\u0026gt; \u0026lt;box size=\u0026#34;0.25 0.25 0.25\u0026#34; /\u0026gt; \u0026lt;/geometry\u0026gt; \u0026lt;material name=\u0026#34;black\u0026#34; /\u0026gt; \u0026lt;/collision\u0026gt; \u0026lt;/link\u0026gt; URDF의 Joint가 가질 수 있는 속성들은 다음과 같습니다.\nname : joint의 이름은 후에 tf publish 시 그대로 사용되기 때문에 혼란을 야기하지 않도록 설정해야 합니다. type : 예시에서 사용중인 joint type은 fixed와 continuous로. fixed는 단단히 결합된 joint를, continuous는 무한히 돌아갈 수 있는 joint를 뜻합니다. origin : parent link의 원점을 기준으로 한 joint의 위치를 지정하게 되며, 이러한 수치는 모델링 파일을 통해 미리 조사된 이후 URDF로 변환됩니다. axis : 회전하는 joint의 경우 어떠한 축을 기준으로 회전되는지 설정이 필요합니다. parent, child : 해당 joint의 전, 후 link를 설정합니다. 기타 속성들 (limit, dynamics, calibration, mimic, safety_controller …) : 각종 역학적인 속성을 표현합니다. \u0026lt;joint name=\u0026#34;r_wheel_joint\u0026#34; type=\u0026#34;continuous\u0026#34;\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34;/\u0026gt; \u0026lt;child link=\u0026#34;wheel_right_link\u0026#34;/\u0026gt; \u0026lt;origin xyz=\u0026#34;0.0 -0.09 0.0415\u0026#34; rpy=\u0026#34;0 0 0\u0026#34;/\u0026gt; \u0026lt;axis xyz=\u0026#34;0 1 0\u0026#34;/\u0026gt; \u0026lt;/joint\u0026gt; \u0026lt;joint name=\u0026#34;l_wheel_joint\u0026#34; type=\u0026#34;continuous\u0026#34;\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34;/\u0026gt; \u0026lt;child link=\u0026#34;wheel_left_link\u0026#34;/\u0026gt; \u0026lt;origin xyz=\u0026#34;0.0 0.109 0.0415\u0026#34; rpy=\u0026#34;0 0 0\u0026#34;/\u0026gt; \u0026lt;axis xyz=\u0026#34;0 1 0\u0026#34;/\u0026gt; \u0026lt;/joint\u0026gt; urdf의 joint는 절대 좌표를 기준으로 하는 extrinsic 체계를 갖습니다.\n기타 속성들\norigin : 해당 요소의 원점을 기준으로, 위치와 방향을 결정합니다. 3축 직교 좌표계를 기준으로 x,y,z 축과 roll pitch yaw 회전각을 사용하고 있습니다. geometry : visual과 collision의 기하학적 요소를 결정하는 태그입니다. urdf에서는 box, cylinder, sphere와 같이 단순한 도형을 제공하고 있습니다. 별도 stl 파일을 사용해도 되지만 로봇을 단순화하고 싶은 경우 이를 통해 간소화가 가능합니다. material : color, texture등을 지정할 수 있으며, 외향적인 디자인을 위한 요소입니다. Xacro URDF 스크립트를 사람이 모두 작성하기는 매우 비효율적입니다. 더불어, Gazebo에서만 사용하는 속성을 따로 분리하고 싶은 경우, 파일을 나누어 관리하고 싶을 것입니다. 이러한 욕구를 충족시키기 위해서 ROS는 URDF의 작성을 보다 편하게 해주는 XML Macro, Xacro를 지원하고 있습니다.\n특히 xacro는 수식, 조건을 사용 가능하기 때문에 로봇 파일을 다루기 매우 용이하며, 특정 요소를 모듈화 후 재사용하는 등 효율적인 URDF 작성이 가능하도록 도와줍니다.\n\u0026lt;xacro:macro name=\u0026#34;pr2_arm\u0026#34; params=\u0026#34;suffix parent reflect\u0026#34;\u0026gt; \u0026lt;pr2_upperarm suffix=\u0026#34;${suffix}\u0026#34; reflect=\u0026#34;${reflect}\u0026#34; parent=\u0026#34;${parent}\u0026#34; /\u0026gt; \u0026lt;pr2_forearm suffix=\u0026#34;${suffix}\u0026#34; reflect=\u0026#34;${reflect}\u0026#34; parent=\u0026#34;elbow_flex_${suffix}\u0026#34; /\u0026gt; \u0026lt;/xacro:macro\u0026gt; \u0026lt;xacro:pr2_arm suffix=\u0026#34;left\u0026#34; reflect=\u0026#34;1\u0026#34; parent=\u0026#34;torso\u0026#34; /\u0026gt; \u0026lt;xacro:pr2_arm suffix=\u0026#34;right\u0026#34; reflect=\u0026#34;-1\u0026#34; parent=\u0026#34;torso\u0026#34; /\u0026gt; ... \u0026lt;pr2_upperarm suffix=\u0026#34;left\u0026#34; reflect=\u0026#34;1\u0026#34; parent=\u0026#34;torso\u0026#34; /\u0026gt; \u0026lt;pr2_forearm suffix=\u0026#34;left\u0026#34; reflect=\u0026#34;1\u0026#34; parent=\u0026#34;elbow_flex_left\u0026#34; /\u0026gt; \u0026lt;pr2_upperarm suffix=\u0026#34;right\u0026#34; reflect=\u0026#34;-1\u0026#34; parent=\u0026#34;torso\u0026#34; /\u0026gt; \u0026lt;pr2_forearm suffix=\u0026#34;right\u0026#34; reflect=\u0026#34;-1\u0026#34; parent=\u0026#34;elbow_flex_right\u0026#34; /\u0026gt; CMake를 통해 손쉽게 Xacro 파일들을 URDF로 자동 변환하는 작업을 실습해봅시다.\n해당 패키지 빌드 colcon build --packages-select fusionbot_description source install/setup.bash 패키지 빌드가 발생하면 모든 관련 파일들의 symbolic link가 workspace의 install//share 폴더에 생성됩니다. CMake는 이 share 폴더 내에 있는 symbolic link를 위주로 작업하므로 새로운 파일이 생겼다면 주기적으로 colcon build를 실행하는 것을 추천합니다.\nCMakelists.txt 수정 - 주석되어 있는 라인을 주석 해제합니다. find_package(xacro REQUIRED) # Xacro files file(GLOB xacro_files urdf/*.urdf.xacro) foreach(it ${xacro_files}) # remove .xacro extension string(REGEX MATCH \u0026#34;(.*)[.]xacro$\u0026#34; unused ${it}) set(output_filename ${CMAKE_MATCH_1}) # create a rule to generate ${output_filename} from {it} xacro_add_xacro_file(${it} ${output_filename}) list(APPEND urdf_files ${output_filename}) endforeach(it) add_custom_target(media_files ALL DEPENDS ${urdf_files}) 패키지를 다시 빌드하면, 자동으로 생성된 urdf 파일을 확인할 수 있습니다. sudo apt install ros-foxy-xacro -y colcon build --packages-select fusionbot_description \u0026lt;?xml version=\u0026#34;1.0\u0026#34; ?\u0026gt; \u0026lt;!-- =================================================================================== --\u0026gt; \u0026lt;!-- | This document was autogenerated by xacro from /home/swimming/nav2_ws/src/nav2_rosdevday_2021/djhrd_ros2/fusionbot_description/urdf/fusionbot.urdf.xacro | --\u0026gt; \u0026lt;!-- | EDITING THIS FILE BY HAND IS NOT RECOMMENDED | --\u0026gt; \u0026lt;!-- =================================================================================== --\u0026gt; \u0026lt;robot name=\u0026#34;fusionbot\u0026#34;\u0026gt; \u0026lt;material name=\u0026#34;silver\u0026#34;\u0026gt; \u0026lt;color rgba=\u0026#34;0.700 0.700 0.700 1.000\u0026#34;/\u0026gt; \u0026lt;/material\u0026gt; ... 기존 fusionbot.urdf를 제거한 뒤 자동 생성되는 모습을 확인해보세요.\nCMake는 사용자의 편의를 위해 추가해둔 것일 뿐 키워드를 통해 Xacro ⇒ URDF로의 변환도 가능합니다. 편한 방법을 사용하시기 바랍니다. (workspace를 sourcing 하셔야 실행 가능합니다.)\nxacro fusionbot.urdf.xacro \u0026gt; fusionbot.urdf joint state publisher와 robot state publisher urdf를 모두 작성했다면, 이제 ROS에게 이 정보를 전달해야 합니다. 이를 담당하는 패키지인 joint state publisher와 robot state publisher에 대해 학습해 봅시다.\n개념 학습 이전, 예시를 먼저 실행해보겠습니다. ros2 launch fusionbot_description description.launch.py WSL2 + Windows 시스템에서는 로봇 외관이 보이지 않을 수 있습니다.\nrviz 상에 로봇이 등장했으며, 로봇과 tf를 확인할 수 있습니다. joint state publisher gui라는 작은 창이 등장하며, 이 안에 위치한 작은 슬라이드바를 움직이면 로봇의 바퀴에 박힌 tf도 회전합니다. ROS에서는 이렇게 tf와 description의 형태로 로봇을 인지합니다. joint state publisher joint state publisher는 로봇 내 존재하는 다양한 joint 값들을 실시간으로 갱신하여 /joint_states라는 topic으로 publish 합니다. 해당 topic은 sensor_msgs/msg/JointState msg를 사용하며, 각 joint들의 이름, 현재 위치, 속도와 힘을 배열 형태로 담게 됩니다.\n$ ros2 interface show sensor_msgs/msg/JointState # This is a message that holds data to describe the state of a set of torque controlled joints. # # # The state of each joint (revolute or prismatic) is defined by: # * the position of the joint (rad or m), # * the velocity of the joint (rad/s or m/s) and # * the effort that is applied in the joint (Nm or N). # ... std_msgs/Header header string[] name float64[] position float64[] velocity float64[] effort joint state publisher gui 예제 실행 시 등장했던 조그만 창은 joint_state_publisher_gui라고 불리며, 로봇 내 조작이 가능한 joint들을 간단하게 제어할 수 있도록 해주는 작은 프로그램입니다. 이를 통해 구성한 URDF의 방향은 알맞게 설정되었는지, 원점은 잘 맞는지 등을 확인 가능합니다.\ntopic echo를 실행시킨 뒤, joint_state_publisher_gui를 조작해보면서 변화를 살펴봅시다. $ ros2 topic echo /joint_states header: stamp: frame_id: \u0026#39;\u0026#39; name: - right_wheel_joint - left_wheel_joint position: - 1.918884792812646 - -1.409318464400381 velocity: [] effort: [] --- ⇒ right_wheel_joint는 위치 1.9188를 갖고 있으며, 속도와 힘은 제어되고 있지 않고 있습니다.\n⇒ left_wheel_joint는 위치 -1.4093를 갖고 있으며, 속도와 힘은 제어되고 있지 않고 있습니다.\n이렇게 joint state publisher는 현재 로봇이 가진 움직일 수 있는 모든 joint들을 예의주시하고 topic으로 publish하는 node입니다.\nrobot state publisher URDF의 joint는 joint state publisher가 담당했다면, robot state publisher는 모든 link와 joint 값을 지속적으로 Subscribe하여 전체 로봇의 구조를 tf 형식으로 publish합니다. 더불어, robot state publisher가 publish하는 /robot_description topic은 rviz에서 로봇의 시각화를 위해 사용되고, gazebo에서 로봇을 등장시키기 위해 사용됩니다.\n참고로, ROS 2에서 tf tree를 얻기 위해서는 아래와 같은 커멘드 라인을 사용합니다. (몇 초간 tf listen을 거친 뒤 pdf 형태로 tf tree를 도출해줍니다.)\n$ ros2 run tf2_tools view_frames.py 지금까지 배운 내용들을 복습해봅시다.\n로봇 모델이 ROS에게 전달되기 위해 urdf를 사용했고, 이는 link와 joint로 이루어졌습니다. 로봇 내 joint는 joint state publisher가 담당하며, robot state publisher는 joint state와 함께 link를 결합하여 최종 tf를 broadcast했습니다. 각 Node간 연결을 rqt_graph를 통해 살펴보면 아래와 같습니다.\nLaunch file 분석 description.launch.py를 분석해봅시다.\nrviz description을 위해 필요한 Node는 총 3가지입니다. (현재는 joint_state_publish_gui가 사용되고 있지만 이후에는 일반 joint_state_publisher가 사용됩니다.) return LaunchDescription([ joint_state_publisher_gui, robot_state_publisher, TimerAction( period=5.0, actions=[rviz] ), ]) joint_state_publisher_gui는 일반적인 Node 실행 옵션과 동일합니다. # Joint State Publisher joint_state_publisher_gui = Node( package=\u0026#39;joint_state_publisher_gui\u0026#39;, executable=\u0026#39;joint_state_publisher_gui\u0026#39;, name=\u0026#39;joint_state_publisher_gui\u0026#39; ) robot_state_publisher는 urdf를 argument로 요구합니다. urdf 파일의 위치는 os.path.join를 통해 전달하고 있으며, 여기서의 path는 src 폴더가 아닌 install 폴더의 symbolic link를 참조한다는 것에 주의합니다. # Prepare Robot State Publisher Params urdf_file = os.path.join(description_pkg_path, \u0026#39;urdf\u0026#39;, \u0026#39;fusionbot_description.urdf\u0026#39;) # Robot State Publisher robot_state_publisher = Node( package=\u0026#39;robot_state_publisher\u0026#39;, executable=\u0026#39;robot_state_publisher\u0026#39;, name=\u0026#39;robot_state_publisher\u0026#39;, output=\u0026#39;screen\u0026#39;, parameters=[{\u0026#39;use_sim_time\u0026#39;: True}], arguments=[urdf_file], ) 마지막으로 rviz를 3초 후 실행되도록 합니다. 이는 launch.actions에서 제공하는 TimerAction 기능을 사용한 것으로, urdf의 내용이 너무 많으면 joint state와 robot state를 로드하는데 시간이 소요되기 때문에 적당한 Delay를 갖도록 한 것입니다. # Launch RViz rviz_config_file = os.path.join(description_pkg_path, \u0026#39;rviz\u0026#39;, \u0026#39;description.rviz’) rviz = Node( package=\u0026#39;rviz2\u0026#39;, executable=\u0026#39;rviz2\u0026#39;, name=\u0026#39;rviz2\u0026#39;, output=\u0026#39;screen\u0026#39;, arguments=[\u0026#39;-d\u0026#39;, rviz_config_file] ) ... TimerAction( period=3.0, actions=[rviz] ), Make a Mobile Robot 지금까지의 예시들은 모두 제가 미리 작성해둔 xacro를 사용하였는데요, 그럼 이런 xacro와 urdf는 어떻게 만들 수 있는지, 설계된 모바일 로봇을 바탕으로 Gazebo, ROS와 연동하는 방법에 대해 알아보겠습니다.\n로봇을 설계하기 위한 수많은 설계 프로그램들이 존재합니다. 이번 예시는 무료 사용이 가능한 Autodesk의 Fusion 360을 사용하였으며, Fusion 360에 Third Party ADD_IN을 추가하여 URDF를 생성하고, 생성된 URDF파일을 사용하여 Rviz 및 Gazebo와 연동하고자 합니다.\n사용한 Add In 링크는 다음과 같습니다. ⇒ https://github.com/syuntoku14/fusion2urdf\n링크를 통해 FusionBot의 외형을 확인할 수 있습니다. ⇒ https://a360.co/3gdOajr\n완성된 로봇으로부터 URDF를 추출하면 첨부파일과 같은 패키지를 얻을 수 있습니다.\n📂 fusionbot_description.zip\nROS 1의 경우 바로 사용이 가능하지만, ROS 2는 몇가지 추가 설정들이 필요합니다. 따라서, 이번 예시에서는 ROS 2 환경을 기준으로 설정을 변경해보면서 URDF와 ROS 연동에 대해 학습해보겠습니다.\n실습을 위해 새로운 ROS 2 패키지를 생성합니다. (ament_cmake 이용) $ ros2 pkg create --build-type ament_cmake \u0026lt;package_name\u0026gt; ros2 pkg create --build-type ament_cmake temp_description 결국 우리가 만들고자 하는 패키지는 제가 배포한 fusionbot_description과 동일합니다. 예제를 따라오시면서 발생하는 문제는 fusionbot_description을 참고하여 해결하시면 됩니다.\n새롭게 생성한 ROS 2 패키지에 fusionbot_description의 meshes와 urdf 폴더를 이동시킵니다. (meshes에는 표면 질감 등 시각화 관련 파일들이 담겨 있습니다.) urdf 폴더 내부의 파일들을 수정해봅시다.\nfusionbot.gazebo을 아래와 같이 수정합니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34; ?\u0026gt; \u0026lt;robot name=\u0026#34;fusionbot\u0026#34; xmlns:xacro=\u0026#34;http://www.ros.org/wiki/xacro\u0026#34; \u0026gt; \u0026lt;xacro:property name=\u0026#34;body_color\u0026#34; value=\u0026#34;Gazebo/Silver\u0026#34; /\u0026gt; \u0026lt;gazebo\u0026gt; \u0026lt;plugin filename=\u0026#34;libgazebo_ros_control.so\u0026#34; name=\u0026#34;control\u0026#34;/\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;gazebo reference=\u0026#34;base_link\u0026#34;\u0026gt; \u0026lt;material\u0026gt;${body_color}\u0026lt;/material\u0026gt; \u0026lt;mu1\u0026gt;0.1\u0026lt;/mu1\u0026gt; \u0026lt;mu2\u0026gt;0.1\u0026lt;/mu2\u0026gt; \u0026lt;selfCollide\u0026gt;true\u0026lt;/selfCollide\u0026gt; \u0026lt;gravity\u0026gt;true\u0026lt;/gravity\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;gazebo reference=\u0026#34;lidar_1\u0026#34;\u0026gt; \u0026lt;material\u0026gt;${body_color}\u0026lt;/material\u0026gt; \u0026lt;mu1\u0026gt;0.2\u0026lt;/mu1\u0026gt; \u0026lt;mu2\u0026gt;0.2\u0026lt;/mu2\u0026gt; \u0026lt;selfCollide\u0026gt;true\u0026lt;/selfCollide\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;gazebo reference=\u0026#34;right_wheel_1\u0026#34;\u0026gt; \u0026lt;material\u0026gt;${body_color}\u0026lt;/material\u0026gt; \u0026lt;mu1\u0026gt;100000.0\u0026lt;/mu1\u0026gt; \u0026lt;mu2\u0026gt;100000.0\u0026lt;/mu2\u0026gt; \u0026lt;selfCollide\u0026gt;true\u0026lt;/selfCollide\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;gazebo reference=\u0026#34;left_wheel_1\u0026#34;\u0026gt; \u0026lt;material\u0026gt;${body_color}\u0026lt;/material\u0026gt; \u0026lt;mu1\u0026gt;1500\u0026lt;/mu1\u0026gt; \u0026lt;mu2\u0026gt;1500\u0026lt;/mu2\u0026gt; \u0026lt;selfCollide\u0026gt;true\u0026lt;/selfCollide\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;/robot\u0026gt; libgazebo_ros_control는 ros control의 gazebo 버전입니다. ros control interface를 통해 gazebo 상의 로봇과 실제 로봇의 움직임을 별도의 추가 개발 없이 편리하게 Swap 가능합니다.\nmu1, mu2는 마찰력과 관련된 변수로 자세한 설명은 아래 링크를 참고하세요.\n=\u0026gt; https://answers.gazebosim.org//question/13083/explain-gazebo-friction-coefficients-mu-and-mu2/\n다음으로, 아래 작업들을 수행합니다.\n=\u0026gt; fusionbot.trans를 삭제합니다. 해당 파일은 ROS 1에서만 필요한 파일입니다. 이는 ros_control을 gazebo에서 실행할 때 필요한 파일로 ROS 1 시간에 함께 살펴보겠습니다.\n=\u0026gt; fusionbot.xacro를 fusionbot.urdf.xacro으로 이름을 변경합니다. (이후 자동 URDF 생성을 위함입니다.)\n=\u0026gt; 변경한 fusionbot.urdf.xacro를 수정합니다.\n이제, fusionbot.urdf.xacro에서 fusionbot.trans 부분을 삭제합니다. \u0026lt;xacro:include filename=\u0026#34;$(find fusionbot_description)/urdf/materials.xacro\u0026#34; /\u0026gt; \u0026lt;!-- \u0026lt;xacro:include filename=\u0026#34;$(find fusionbot_description)/urdf/fusionbot.trans\u0026#34; /\u0026gt; --\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find fusionbot_description)/urdf/fusionbot.gazebo\u0026#34; /\u0026gt; ȸ��7 과 같이 잘못 인코딩된 joint 이름을 적절히 수정합니다. # From \u0026lt;joint name=\u0026#34;��ü3\u0026#34; type=\u0026#34;fixed\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.05 0.0 0.11\u0026#34;/\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34;/\u0026gt; \u0026lt;child link=\u0026#34;lidar_1\u0026#34;/\u0026gt; \u0026lt;/joint\u0026gt; \u0026lt;joint name=\u0026#34;ȸ��7\u0026#34; type=\u0026#34;continuous\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.0 -0.1 0.05\u0026#34;/\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34;/\u0026gt; \u0026lt;child link=\u0026#34;right_wheel_1\u0026#34;/\u0026gt; \u0026lt;axis xyz=\u0026#34;-0.0 -1.0 0.0\u0026#34;/\u0026gt; \u0026lt;/joint\u0026gt; \u0026lt;joint name=\u0026#34;ȸ��8\u0026#34; type=\u0026#34;continuous\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.0 0.1 0.05\u0026#34;/\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34;/\u0026gt; \u0026lt;child link=\u0026#34;left_wheel_1\u0026#34;/\u0026gt; \u0026lt;axis xyz=\u0026#34;-0.0 1.0 0.0\u0026#34;/\u0026gt; \u0026lt;/joint\u0026gt; # To \u0026lt;joint name=\u0026#34;lidar_joint\u0026#34; type=\u0026#34;fixed\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.05 0.0 0.11\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;lidar_1\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; \u0026lt;joint name=\u0026#34;right_wheel_joint\u0026#34; type=\u0026#34;continuous\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.0 -0.1 0.05\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;right_wheel_1\u0026#34; /\u0026gt; \u0026lt;axis xyz=\u0026#34;-0.0 -1.0 0.0\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; \u0026lt;joint name=\u0026#34;left_wheel_joint\u0026#34; type=\u0026#34;continuous\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.0 0.1 0.05\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;left_wheel_1\u0026#34; /\u0026gt; \u0026lt;axis xyz=\u0026#34;-0.0 1.0 0.0\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; joint 축 방향을 수정합니다. \u0026lt;joint name=\u0026#34;right_wheel_joint\u0026#34; type=\u0026#34;continuous\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.0 -0.1 0.05\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;right_wheel_1\u0026#34; /\u0026gt; \u0026lt;axis xyz=\u0026#34;0.0 1.0 0.0\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; \u0026lt;joint name=\u0026#34;left_wheel_joint\u0026#34; type=\u0026#34;continuous\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.0 0.1 0.05\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;left_wheel_1\u0026#34; /\u0026gt; \u0026lt;axis xyz=\u0026#34;0.0 1.0 0.0\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; 파일 상단 base_footprint link를 추가하고 base_footprint와 base_link를 연결하는 joint를 추가합니다. base_footprint는 추후 자율주행 시 필요한 tf ID로 로봇 중심에서 바닥면에 projection한 위치를 뜻합니다. \u0026lt;link name=\u0026#39;base_footprint\u0026#39; /\u0026gt; ... \u0026lt;joint name=\u0026#39;base_link_joint\u0026#39; type=\u0026#39;fixed\u0026#39;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0 0 0\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;base_footprint\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;base_link\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; mesh 파일의 uri와 xacro 라인의 package명을 여러분의 패키지로 수정합니다. # From \u0026lt;xacro:include filename=\u0026#34;$(find fusionbot_description)/urdf/materials.xacro\u0026#34; /\u0026gt; ... \u0026lt;mesh filename=\u0026#34;package://fusionbot_description...\u0026#34; /\u0026gt; # To \u0026lt;xacro:include filename=\u0026#34;$(find temp_description)/urdf/materials.xacro\u0026#34; /\u0026gt; ... \u0026lt;mesh filename=\u0026#34;package://temp_description...\u0026#34; /\u0026gt; 색상을 입히고 싶다면 materials.xacro를 수정합니다. (Gazebo는 고유한 색상 체계를 갖고 있습니다. 이는 링크를 참고합니다.) \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;robot name=\u0026#34;fusionbot\u0026#34; xmlns:xacro=\u0026#34;http://www.ros.org/wiki/xacro\u0026#34;\u0026gt; \u0026lt;material name=\u0026#34;silver\u0026#34;\u0026gt; \u0026lt;color rgba=\u0026#34;0.700 0.700 0.700 1.000\u0026#34; /\u0026gt; \u0026lt;/material\u0026gt; \u0026lt;material name=\u0026#34;white\u0026#34;\u0026gt; \u0026lt;color rgba=\u0026#34;1 1 1 0.6\u0026#34; /\u0026gt; \u0026lt;/material\u0026gt; \u0026lt;material name=\u0026#34;black\u0026#34;\u0026gt; \u0026lt;color rgba=\u0026#34;0 0 0 0.7\u0026#34; /\u0026gt; \u0026lt;/material\u0026gt; \u0026lt;material name=\u0026#34;red\u0026#34;\u0026gt; \u0026lt;color rgba=\u0026#34;1 0 0 1\u0026#34; /\u0026gt; \u0026lt;/material\u0026gt; \u0026lt;material name=\u0026#34;blue\u0026#34;\u0026gt; \u0026lt;color rgba=\u0026#34;0 0 0.8 1\u0026#34;/\u0026gt; \u0026lt;/material\u0026gt; \u0026lt;/robot\u0026gt; CMakeLists.txt를 수정합니다. ament_package() 이전 아래 코드를 추가하시면 됩니다. ## Install install(DIRECTORY meshes urdf DESTINATION share/${PROJECT_NAME} ) ** ament_package() 작업을 마친 뒤, colcon build를 한차례 실시합니다. cd ~/ros2_ws colcon build --packages-select temp_description source install/local_setup.bash CMakeLists.txt에 다음 라인을 추가한 뒤 다시 한 번 colcon build를 실시합니다. find_package(xacro REQUIRED) # Xacro files file(GLOB xacro_files urdf/*.urdf.xacro) foreach(it ${xacro_files}) # remove .xacro extension string(REGEX MATCH \u0026#34;(.*)[.]xacro$\u0026#34; unused ${it}) set(output_filename ${CMAKE_MATCH_1}) # create a rule to generate ${output_filename} from {it} xacro_add_xacro_file(${it} ${output_filename}) list(APPEND urdf_files ${output_filename}) endforeach(it) add_custom_target(media_files ALL DEPENDS ${urdf_files}) ⇒ 이 과정이 필요한 이유는 다음과 같습니다.\n첫번째 colcon build로 필요 파일들의 symbolic link가 install 폴더 내 생성됩니다. 두번째 colcon build 시 CMakeLists.txt에 작성한 xacro 빌드 스크립트를 통해 xacro ⇒ urdf로 변환되며, 이 과정에서 CMake는 install 폴더 내 symbolic link들을 필요로 합니다. 만약 첫번째 작업이 없다면, mesh, urdf 관련 파일이 없다는 에러가 발생합니다. 위 과정을 마치면 자동으로 fusionbot.urdf가 생성되며, 이후 해당 urdf는 description과 gazebo 등 다양한 목적으로 사용할 수 있습니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34; ?\u0026gt; \u0026lt;!-- =================================================================================== --\u0026gt; \u0026lt;!-- | This document was autogenerated by xacro from /home/kimsooyoung/ros2_ws/src/du2023-gz/test_description/urdf/fusionbot.urdf.xacro | --\u0026gt; \u0026lt;!-- | EDITING THIS FILE BY HAND IS NOT RECOMMENDED | --\u0026gt; \u0026lt;!-- =================================================================================== --\u0026gt; \u0026lt;robot name=\u0026#34;fusionbot\u0026#34;\u0026gt; \u0026lt;material name=\u0026#34;silver\u0026#34;\u0026gt; \u0026lt;color rgba=\u0026#34;0.700 0.700 0.700 1.000\u0026#34;/\u0026gt; \u0026lt;/material\u0026gt; ... Description launch 실행해보기 robot state publisher와 joint_state_publisher_gui를 통해 robot_description topic을 생성하고 rviz를 통해 이를 시각화해봅시다.\n예시를 위해 아래와 같은 폴더 구조가 필요합니다. (launch 폴더와 rviz 폴더를 추가하였습니다.) launch 폴더를 생성하고, 해당 폴더 내부에 launch 파일을 작성해볼 것입니다. 필요한 Node는 아래와 같은 3개 이며, fusionbot_description.launch.py를 참고하여 직접 launch file을 작성해보세요! return LaunchDescription([ joint_state_publisher_gui, robot_state_publisher, rviz, ]) rviz 폴더도 생성하고 기존 fusionbot_description에서 config 파일을 가져옵니다. 새로운 폴더가 추가되면 항상 CMakeLists.txt를 수정해야 합니다. ## Install install(DIRECTORY meshes urdf launch rviz DESTINATION share/${PROJECT_NAME} ) 패키지를 빌드한 뒤, 여러분이 작성한 launch file을 실행해보세요! colcon build --symlink-install --packages-select temp_description source install/local_setup.bash ros2 launch temp_description description.launch.py "
},
{
	"uri": "/kr/ros_and_gazebo/lecture2/",
	"title": "Lecture2 - Gazebo and Robot(2)",
	"tags": [],
	"description": "",
	"content": "FusionBot과 Gazebo Description 예시를 통해 URDF에 대해 습득하였다면, 이제 Gazebo에 로봇을 등장시키고, 이동, 센싱을 구현할 차례입니다. FusionBot을 통해 실습을 진행해보고, 이전 예시에서의 로봇들도 함께 분석해 보겠습니다.\n강의에서는, Gazebo에서 로봇을 등장시키는 2가지 방법을 제시하고자 합니다.\nXacro 파일을 통한 로봇 Spawn URDF 파일을 통한 로봇 Spawn 두 방식 모두 launch file에서 실행되는 Node들은 동일합니다.\ngazebo_ros를 통해 gazebo server와 client를 실행하고 robot_state_publisher와 joint_state_publisher를 통해 robot_description topic을 준비합니다. 마지막으로, gazebo_ros에서 제공하는 spawn_entity라는 Node를 통해 로봇을 Gazebo 상에 등장시킵니다. 저는 새로운 예시를 위해 패키지를 분리하고, launch file의 이름을 empty_gazebo.launch.py로 설정하였습니다. LaunchDescription은 아래와 같습니다. (여러분은 패키지를 분리하지 않으셔도 좋습니다.)\nreturn LaunchDescription([ start_gazebo_server_cmd, start_gazebo_client_cmd, robot_state_publisher, joint_state_publisher, spawn_entity, ]) Xacro 파일을 통한 로봇 Spawn Gazebo는 package://를 통한 파일 접근을 인식할 수 없습니다. 따라서, fusionbot.urdf.xacro 파일 안의 관련된 부분을 모두 $(find pkg) 형태로 변형해줍니다. # From \u0026lt;link name=\u0026#34;base_link\u0026#34;\u0026gt; \u0026lt;inertial\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.0038631391370923516 -1.6603718341471133e-17 0.05277089743549162\u0026#34;/\u0026gt; \u0026lt;mass value=\u0026#34;2.3225264704023765\u0026#34;/\u0026gt; \u0026lt;inertia ixx=\u0026#34;0.00792\u0026#34; ixy=\u0026#34;-0.0\u0026#34; ixz=\u0026#34;-0.000339\u0026#34; iyy=\u0026#34;0.008432\u0026#34; iyz=\u0026#34;-0.0\u0026#34; izz=\u0026#34;0.014814\u0026#34;/\u0026gt; \u0026lt;/inertial\u0026gt; \u0026lt;visual\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0 0 0\u0026#34;/\u0026gt; \u0026lt;geometry\u0026gt; \u0026lt;mesh filename=\u0026#34;package://temp_description/meshes/base_link.stl\u0026#34; scale=\u0026#34;0.001 0.001 0.001\u0026#34;/\u0026gt; \u0026lt;/geometry\u0026gt; # To \u0026lt;link name=\u0026#34;base_link\u0026#34;\u0026gt; \u0026lt;inertial\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.0038631391370923516 -1.6603718341471133e-17 0.05277089743549162\u0026#34;/\u0026gt; \u0026lt;mass value=\u0026#34;2.3225264704023765\u0026#34;/\u0026gt; \u0026lt;inertia ixx=\u0026#34;0.00792\u0026#34; ixy=\u0026#34;-0.0\u0026#34; ixz=\u0026#34;-0.000339\u0026#34; iyy=\u0026#34;0.008432\u0026#34; iyz=\u0026#34;-0.0\u0026#34; izz=\u0026#34;0.014814\u0026#34;/\u0026gt; \u0026lt;/inertial\u0026gt; \u0026lt;visual\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0 0 0\u0026#34;/\u0026gt; \u0026lt;geometry\u0026gt; \u0026lt;mesh filename=\u0026#34;$(find temp_description)/meshes/base_link.stl\u0026#34; scale=\u0026#34;0.001 0.001 0.001\u0026#34;/\u0026gt; \u0026lt;/geometry\u0026gt; xacro 파일의 경로를 탐색한 뒤, robot_description과 호환을 위한 몇가지 변경을 적용하여 argument를 준비합니다. xacro_file = os.path.join(description_pkg_path, \u0026#39;urdf\u0026#39;, \u0026#39;fusionbot.urdf.xacro\u0026#39;) robot_description_content = Command( [ PathJoinSubstitution([FindExecutable(name=\u0026#34;xacro\u0026#34;)]), \u0026#34; \u0026#34;, xacro_file, \u0026#34; \u0026#34;, \u0026#34;name:=fusionbot\u0026#34;, \u0026#34; \u0026#34;, \u0026#34;prefix:=\u0026#39;\u0026#39;\u0026#34;, \u0026#34; \u0026#34;, \u0026#34;is_sim:=true\u0026#34;, ] ) robot_description = {\u0026#34;robot_description\u0026#34;: robot_description_content} 항상 정적 파일이 수정된 다음에는 colcon build를 잊지 맙시다!\nURDF 파일을 통한 로봇 Spawn urdf를 생성하고, 이를 통해 gazebo에서 로봇을 등장시킬 수 있습니다. xacro file ⇒ URDF로의 변환을 진행합니다. cd ~/ros2_ws/src/du2023-gz/\u0026lt;your-pkg\u0026gt;/urdf xacro fusionbot.urdf.xacro \u0026gt; fusionbot.urdf # 혹은 colcon build를 사용해도 됩니다. colcon build --packages-select temp_description 이렇게 만들어진 URDF 파일은 아래와 같이 절대 경로가 삽입되기 때문에 여러분의 환경에서만 사용 가능함에 유의합니다. \u0026lt;collision\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;-0.05 -0.0 -0.11\u0026#34;/\u0026gt; \u0026lt;geometry\u0026gt; \u0026lt;mesh filename=\u0026#34;/home/kimsooyoung/ros2_ws/install/test_description/share/test_description/meshes/lidar_1.stl\u0026#34; scale=\u0026#34;0.001 0.001 0.001\u0026#34;/\u0026gt; \u0026lt;/geometry\u0026gt; \u0026lt;/collision\u0026gt; \u0026lt;/link\u0026gt; URDF 파일을 robot_state_publisher에게 전달하는 방법은 아래와 같습니다. xacro 패키지의 내장 함수를 통해 손쉬운 변환이 가능합니다. urdf_file = os.path.join(description_pkg_path, \u0026#39;urdf\u0026#39;, \u0026#39;fusionbot.urdf\u0026#39;) doc = xacro.parse(open(urdf_file)) xacro.process_doc(doc) robot_description = {\u0026#39;robot_description\u0026#39;: doc.toxml()} 이렇게 두가지 방법을 배우는 까닭은 실제 오픈소스를 사용하다보면 xacro와 urdf를 혼용하여 배포하기 때문입니다.\n이제, 완성된 launch 파일을 통해 gazebo상에 로봇을 등장시켜봅시다. ros2 launch temp_description empty_gazebo.launch.py 지금 등장시킨 로봇은 색도 없고 제어기, 센서도 없기 때문에 단순 질량 덩어리에 불과합니다. 이제부터 로봇에 여러 요소들을 추가하여 실제 로봇과 유사하게 변신시켜보겠습니다.\nGazebo Plugins Gazebo에서 인식할 수 있는 색상을 지정하고, 센서와 제어기를 연동하여 실제 로봇 시뮬레이션을 완성해보고자 합니다. 지금부터 fusionbot.gazebo 파일을 수정하여 이를 구현해봅시다.\n우선, 비교적 쉬운 색상 변경부터 진행해봅시다.\n파일 최상단 여러 색상을 변수로 지정합니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34; ?\u0026gt; \u0026lt;robot name=\u0026#34;fusionbot\u0026#34; xmlns:xacro=\u0026#34;http://www.ros.org/wiki/xacro\u0026#34; \u0026gt; \u0026lt;xacro:property name=\u0026#34;body_color\u0026#34; value=\u0026#34;Gazebo/Silver\u0026#34; /\u0026gt; \u0026lt;xacro:property name=\u0026#34;lidar_color\u0026#34; value=\u0026#34;Gazebo/Blue\u0026#34; /\u0026gt; \u0026lt;xacro:property name=\u0026#34;wheel_color\u0026#34; value=\u0026#34;Gazebo/Black\u0026#34; /\u0026gt; 각 Link 내 material 태그 속성으로 선언한 변수를 할당합니다. \u0026lt;gazebo reference=\u0026#34;base_link\u0026#34;\u0026gt; \u0026lt;material\u0026gt;${body_color}\u0026lt;/material\u0026gt; \u0026lt;mu1\u0026gt;0.1\u0026lt;/mu1\u0026gt; \u0026lt;mu2\u0026gt;0.1\u0026lt;/mu2\u0026gt; \u0026lt;selfCollide\u0026gt;true\u0026lt;/selfCollide\u0026gt; \u0026lt;gravity\u0026gt;true\u0026lt;/gravity\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;gazebo reference=\u0026#34;lidar_1\u0026#34;\u0026gt; \u0026lt;material\u0026gt;${lidar_color}\u0026lt;/material\u0026gt; \u0026lt;mu1\u0026gt;0.2\u0026lt;/mu1\u0026gt; \u0026lt;mu2\u0026gt;0.2\u0026lt;/mu2\u0026gt; \u0026lt;selfCollide\u0026gt;true\u0026lt;/selfCollide\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;gazebo reference=\u0026#34;right_wheel_1\u0026#34;\u0026gt; \u0026lt;material\u0026gt;${wheel_color}\u0026lt;/material\u0026gt; \u0026lt;mu1\u0026gt;100000.0\u0026lt;/mu1\u0026gt; \u0026lt;mu2\u0026gt;100000.0\u0026lt;/mu2\u0026gt; \u0026lt;selfCollide\u0026gt;true\u0026lt;/selfCollide\u0026gt; \u0026lt;/gazebo\u0026gt; ... 패키지를 빌드한 후 다시 Gazebo launch file을 실행시켜봅시다. 지금부터 다양한 Gazebo Plugin들을 사용하여 로봇과 ROS 사이의 실질적인 연동을 해보겠습니다. 이를 위해 xacro 파일에 새로운 link들을 추가할 예정입니다.\nMono Camera fusionbot.urdf.xacro 수정 - camera_link와 camera_joint 추가 \u0026lt;link name=\u0026#34;camera_link\u0026#34;\u0026gt; \u0026lt;pose\u0026gt;0 0 0 0 0 0\u0026lt;/pose\u0026gt; \u0026lt;/link\u0026gt; ... \u0026lt;joint name=\u0026#34;camera_joint\u0026#34; type=\u0026#34;fixed\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.1 0.0 0.05\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;camera_link\u0026#34; /\u0026gt; \u0026lt;axis xyz=\u0026#34;0.0 0.0 0.0\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; urdf 폴더 안에 sensors라는 폴더를 추가한 뒤, mono_cam.gazebo를 추가합니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34; ?\u0026gt; \u0026lt;robot name=\u0026#34;fusionbot\u0026#34; xmlns:xacro=\u0026#34;http://www.ros.org/wiki/xacro\u0026#34; \u0026gt; \u0026lt;gazebo reference=\u0026#34;camera_link\u0026#34;\u0026gt; \u0026lt;sensor name=\u0026#34;front_camera\u0026#34; type=\u0026#34;camera\u0026#34;\u0026gt; \u0026lt;update_rate\u0026gt;30.0\u0026lt;/update_rate\u0026gt; \u0026lt;visualize\u0026gt;false\u0026lt;/visualize\u0026gt; \u0026lt;always_on\u0026gt;1\u0026lt;/always_on\u0026gt; \u0026lt;camera name=\u0026#34;front_camera\u0026#34;\u0026gt; \u0026lt;!-- math.atan(320 / 687.8065795898438) * 2 --\u0026gt; \u0026lt;horizontal_fov\u0026gt;0.8709216071359963\u0026lt;/horizontal_fov\u0026gt; \u0026lt;image\u0026gt; \u0026lt;width\u0026gt;1280\u0026lt;/width\u0026gt; \u0026lt;height\u0026gt;720\u0026lt;/height\u0026gt; \u0026lt;format\u0026gt;R8G8B8\u0026lt;/format\u0026gt; \u0026lt;!-- \u0026lt;format\u0026gt;B8G8R8\u0026lt;/format\u0026gt; --\u0026gt; \u0026lt;/image\u0026gt; \u0026lt;clip\u0026gt; \u0026lt;near\u0026gt;0.02\u0026lt;/near\u0026gt; \u0026lt;far\u0026gt;300\u0026lt;/far\u0026gt; \u0026lt;/clip\u0026gt; \u0026lt;noise\u0026gt; \u0026lt;type\u0026gt;gaussian\u0026lt;/type\u0026gt; \u0026lt;mean\u0026gt;0.0\u0026lt;/mean\u0026gt; \u0026lt;stddev\u0026gt;0.00007\u0026lt;/stddev\u0026gt; \u0026lt;/noise\u0026gt; \u0026lt;/camera\u0026gt; \u0026lt;plugin filename=\u0026#34;libgazebo_ros_camera.so\u0026#34; name=\u0026#34;camera_controller\u0026#34;\u0026gt; \u0026lt;ros\u0026gt; \u0026lt;!-- \u0026lt;namespace\u0026gt;custom_ns\u0026lt;/namespace\u0026gt; --\u0026gt; \u0026lt;remapping\u0026gt;image_raw:=image_raw\u0026lt;/remapping\u0026gt; \u0026lt;remapping\u0026gt;camera_info:=camera_info\u0026lt;/remapping\u0026gt; \u0026lt;/ros\u0026gt; \u0026lt;camera_name\u0026gt;front_camera\u0026lt;/camera_name\u0026gt; \u0026lt;frame_name\u0026gt;camera_link\u0026lt;/frame_name\u0026gt; \u0026lt;hack_baseline\u0026gt;0.07\u0026lt;/hack_baseline\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/sensor\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;/robot\u0026gt; update_rate data publish rate visualize 시각화 옵션 horizontal_fov 카메라의 화각 image 화질 옵션 noise 센서 노이즈 remapping topic 이름 재설정 camera_name topic의 namespace가 됩니다. frame_name camera가 장착되는 link hack_baseline stereo camera 사용 시 카메라 사이 거리 ⇒ 이렇게 xml 형태의 스크립트를 추가하여 gazebo plugin을 사용할 수 있습니다.\nfusionbot.gazebo 수정 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; ?\u0026gt; \u0026lt;robot name=\u0026#34;fusionbot\u0026#34; xmlns:xacro=\u0026#34;http://www.ros.org/wiki/xacro\u0026#34; \u0026gt; \u0026lt;xacro:property name=\u0026#34;body_color\u0026#34; value=\u0026#34;Gazebo/Silver\u0026#34; /\u0026gt; \u0026lt;xacro:property name=\u0026#34;lidar_color\u0026#34; value=\u0026#34;Gazebo/Blue\u0026#34; /\u0026gt; \u0026lt;xacro:property name=\u0026#34;wheel_color\u0026#34; value=\u0026#34;Gazebo/Black\u0026#34; /\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find temp_description)/urdf/sensors/mono_cam.gazebo\u0026#34; /\u0026gt; \u0026lt;gazebo\u0026gt; \u0026lt;plugin filename=\u0026#34;libgazebo_ros_control.so\u0026#34; name=\u0026#34;control\u0026#34;/\u0026gt; \u0026lt;/gazebo\u0026gt; 예제 재실행 colcon build --symlink-install --packages-select temp_description source install/local_setup.bash ros2 launch temp_description empty_gazebo.launch.py rviz를 통해 카메라 데이터를 확인해봅시다.\nDepth Camera fusionbot.urdf.xacro 수정 - depth_camera_link와 depth_camera_optical_joint 추가 \u0026lt;link name=\u0026#34;depth_camera_link\u0026#34;\u0026gt; \u0026lt;pose\u0026gt;0 0 0 0 0 0\u0026lt;/pose\u0026gt; \u0026lt;/link\u0026gt; ... \u0026lt;joint name=\u0026#34;depth_camera_optical_joint\u0026#34; type=\u0026#34;fixed\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;-1.57079632679 0 -1.57079632679\u0026#34; xyz=\u0026#34;0 0 0\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;depth_camera_link\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;depth_camera_optical_link\u0026#34; /\u0026gt; \u0026lt;axis xyz=\u0026#34;0.0 0.0 0.0\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; urdf 폴더 안에 sensors라는 폴더를 추가한 뒤, depth_cam.gazebo를 추가합니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34; ?\u0026gt; \u0026lt;robot name=\u0026#34;fusionbot\u0026#34; xmlns:xacro=\u0026#34;http://www.ros.org/wiki/xacro\u0026#34; \u0026gt; \u0026lt;gazebo reference=\u0026#34;depth_camera_link\u0026#34;\u0026gt; \u0026lt;sensor name=\u0026#34;front_depth_camera\u0026#34; type=\u0026#34;depth\u0026#34;\u0026gt; \u0026lt;update_rate\u0026gt;30.0\u0026lt;/update_rate\u0026gt; \u0026lt;visualize\u0026gt;false\u0026lt;/visualize\u0026gt; \u0026lt;always_on\u0026gt;1\u0026lt;/always_on\u0026gt; \u0026lt;camera name=\u0026#34;front_depth_camera\u0026#34;\u0026gt; \u0026lt;!-- math.atan(320 / 687.8065795898438) * 2 --\u0026gt; \u0026lt;horizontal_fov\u0026gt;0.8709216071359963\u0026lt;/horizontal_fov\u0026gt; \u0026lt;image\u0026gt; \u0026lt;width\u0026gt;1280\u0026lt;/width\u0026gt; \u0026lt;height\u0026gt;720\u0026lt;/height\u0026gt; \u0026lt;format\u0026gt;R8G8B8\u0026lt;/format\u0026gt; \u0026lt;!-- \u0026lt;format\u0026gt;B8G8R8\u0026lt;/format\u0026gt; --\u0026gt; \u0026lt;/image\u0026gt; \u0026lt;clip\u0026gt; \u0026lt;near\u0026gt;0.02\u0026lt;/near\u0026gt; \u0026lt;far\u0026gt;300\u0026lt;/far\u0026gt; \u0026lt;/clip\u0026gt; \u0026lt;noise\u0026gt; \u0026lt;type\u0026gt;gaussian\u0026lt;/type\u0026gt; \u0026lt;mean\u0026gt;0.0\u0026lt;/mean\u0026gt; \u0026lt;stddev\u0026gt;0.00007\u0026lt;/stddev\u0026gt; \u0026lt;/noise\u0026gt; \u0026lt;/camera\u0026gt; \u0026lt;plugin filename=\u0026#34;libgazebo_ros_camera.so\u0026#34; name=\u0026#34;camera_controller\u0026#34;\u0026gt; \u0026lt;ros\u0026gt; \u0026lt;!-- \u0026lt;namespace\u0026gt;custom_ns\u0026lt;/namespace\u0026gt; --\u0026gt; \u0026lt;remapping\u0026gt;front_depth_camera/image_raw:=front_depth_camera/image_raw\u0026lt;/remapping\u0026gt; \u0026lt;remapping\u0026gt;front_depth_camera/image_depth:=front_depth_camera/image_depth\u0026lt;/remapping\u0026gt; \u0026lt;remapping\u0026gt;front_depth_camera/camera_info:=front_depth_camera/camera_info\u0026lt;/remapping\u0026gt; \u0026lt;remapping\u0026gt;front_depth_camera/camera_info_depth:=front_depth_camera/camera_info_depth\u0026lt;/remapping\u0026gt; \u0026lt;remapping\u0026gt;front_depth_camera/points:=front_depth_camera/points\u0026lt;/remapping\u0026gt; \u0026lt;/ros\u0026gt; \u0026lt;camera_name\u0026gt;front_depth_camera\u0026lt;/camera_name\u0026gt; \u0026lt;frame_name\u0026gt;depth_camera_optical_link\u0026lt;/frame_name\u0026gt; \u0026lt;hack_baseline\u0026gt;0.07\u0026lt;/hack_baseline\u0026gt; \u0026lt;min_depth\u0026gt;0.001\u0026lt;/min_depth\u0026gt; \u0026lt;max_depth\u0026gt;300.0\u0026lt;/max_depth\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/sensor\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;/robot\u0026gt; sensor type depth min_depth, max_depth depth 탐지거리 ⇒ depth camera는 camera 좌표계를 사용하기 때문에 별도 joint를 지정해줘야 합니다.\nfusionbot.gazebo 수정 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; ?\u0026gt; \u0026lt;robot name=\u0026#34;fusionbot\u0026#34; xmlns:xacro=\u0026#34;http://www.ros.org/wiki/xacro\u0026#34; \u0026gt; \u0026lt;xacro:property name=\u0026#34;body_color\u0026#34; value=\u0026#34;Gazebo/Silver\u0026#34; /\u0026gt; \u0026lt;xacro:property name=\u0026#34;lidar_color\u0026#34; value=\u0026#34;Gazebo/Blue\u0026#34; /\u0026gt; \u0026lt;xacro:property name=\u0026#34;wheel_color\u0026#34; value=\u0026#34;Gazebo/Black\u0026#34; /\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find temp_description)/urdf/sensors/mono_cam.gazebo\u0026#34; /\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find fusionbot_gazebo)/urdf/sensors/depth_cam.gazebo\u0026#34; /\u0026gt; \u0026lt;gazebo\u0026gt; \u0026lt;plugin filename=\u0026#34;libgazebo_ros_control.so\u0026#34; name=\u0026#34;control\u0026#34;/\u0026gt; \u0026lt;/gazebo\u0026gt; 예제 재실행 colcon build --symlink-install --packages-select temp_description source install/local_setup.bash ros2 launch temp_description empty_gazebo.launch.py ⇒ rviz를 통해 카메라 데이터를 확인해봅시다.\n2D Lidar urdf sensors 폴더 안에 lidar_2d.gazebo를 추가합니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34; ?\u0026gt; \u0026lt;robot name=\u0026#34;fusionbot\u0026#34; xmlns:xacro=\u0026#34;http://www.ros.org/wiki/xacro\u0026#34; \u0026gt; \u0026lt;xacro:property name=\u0026#34;M_PI\u0026#34; value=\u0026#34;3.1415926535897931\u0026#34; /\u0026gt; \u0026lt;gazebo reference=\u0026#34;lidar_1\u0026#34;\u0026gt; \u0026lt;sensor name=\u0026#34;lidar\u0026#34; type=\u0026#34;ray\u0026#34;\u0026gt; \u0026lt;pose\u0026gt;0 0 0 0 0 0\u0026lt;/pose\u0026gt; \u0026lt;always_on\u0026gt;true\u0026lt;/always_on\u0026gt; \u0026lt;visualize\u0026gt;false\u0026lt;/visualize\u0026gt; \u0026lt;update_rate\u0026gt;10\u0026lt;/update_rate\u0026gt; \u0026lt;ray\u0026gt; \u0026lt;scan\u0026gt; \u0026lt;horizontal\u0026gt; \u0026lt;samples\u0026gt;360\u0026lt;/samples\u0026gt; \u0026lt;resolution\u0026gt;1.000000\u0026lt;/resolution\u0026gt; \u0026lt;min_angle\u0026gt;-${M_PI}\u0026lt;/min_angle\u0026gt; \u0026lt;max_angle\u0026gt;${M_PI}\u0026lt;/max_angle\u0026gt; \u0026lt;/horizontal\u0026gt; \u0026lt;/scan\u0026gt; \u0026lt;range\u0026gt; \u0026lt;min\u0026gt;0.15\u0026lt;/min\u0026gt; \u0026lt;max\u0026gt;12.0\u0026lt;/max\u0026gt; \u0026lt;resolution\u0026gt;0.5\u0026lt;/resolution\u0026gt; \u0026lt;/range\u0026gt; \u0026lt;noise\u0026gt; \u0026lt;type\u0026gt;gaussian\u0026lt;/type\u0026gt; \u0026lt;mean\u0026gt;0.0\u0026lt;/mean\u0026gt; \u0026lt;stddev\u0026gt;0.01\u0026lt;/stddev\u0026gt; \u0026lt;/noise\u0026gt; \u0026lt;/ray\u0026gt; \u0026lt;plugin name=\u0026#34;gazebo_ros_head_hokuyo_controller\u0026#34; filename=\u0026#34;libgazebo_ros_ray_sensor.so\u0026#34;\u0026gt; \u0026lt;ros\u0026gt; \u0026lt;remapping\u0026gt;~/out:=scan\u0026lt;/remapping\u0026gt; \u0026lt;/ros\u0026gt; \u0026lt;output_type\u0026gt;sensor_msgs/LaserScan\u0026lt;/output_type\u0026gt; \u0026lt;frame_name\u0026gt;lidar_1\u0026lt;/frame_name\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/sensor\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;/robot\u0026gt; horizontal 라이다의 탐지 범위와 샘플 수를 지정합니다. range 탐지거리의 범위입니다. output_type ROS 2에서 사용하는 2D 라이다 데이터입니다. ⇒ 해당 데이터 스펙은 실제 판매중인 rplidar a1을 구현하였습니다.\nfusionbot.gazebo 수정 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; ?\u0026gt; \u0026lt;robot name=\u0026#34;fusionbot\u0026#34; xmlns:xacro=\u0026#34;http://www.ros.org/wiki/xacro\u0026#34; \u0026gt; \u0026lt;xacro:property name=\u0026#34;body_color\u0026#34; value=\u0026#34;Gazebo/Silver\u0026#34; /\u0026gt; \u0026lt;xacro:property name=\u0026#34;lidar_color\u0026#34; value=\u0026#34;Gazebo/Blue\u0026#34; /\u0026gt; \u0026lt;xacro:property name=\u0026#34;wheel_color\u0026#34; value=\u0026#34;Gazebo/Black\u0026#34; /\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find temp_description)/urdf/sensors/mono_cam.gazebo\u0026#34; /\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find fusionbot_gazebo)/urdf/sensors/depth_cam.gazebo\u0026#34; /\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find temp_description)/urdf/sensors/lidar_2d.gazebo\u0026#34; /\u0026gt; \u0026lt;gazebo\u0026gt; \u0026lt;plugin filename=\u0026#34;libgazebo_ros_control.so\u0026#34; name=\u0026#34;control\u0026#34;/\u0026gt; \u0026lt;/gazebo\u0026gt; 예제 재실행 colcon build --symlink-install --packages-select temp_description source install/local_setup.bash ros2 launch temp_description empty_gazebo.launch.py ⇒ rviz를 통해 라이다 데이터를 확인해봅시다.\n비슷한 맥락에서, 3D lidar와 GPS, IMU 등 다양한 센서를 추가할 수 있습니다.\ngps : https://github.com/RB2023ROS/du2023-gz/blob/main/fusionbot_gazebo/urdf/sensors/gps.gazebo imu : https://github.com/RB2023ROS/du2023-gz/blob/main/fusionbot_gazebo/urdf/sensors/imu.gazebo 3d lidar : https://github.com/RB2023ROS/du2023-gz/blob/main/fusionbot_gazebo/urdf/sensors/lidar_3d.gazebo 이렇게 센서를 추가하는 방법은 gazebo_ros_pkg의 wiki 페이지를 참고하였습니다. 해당 페이지에는 ROS 1과 ROS 2에서의 사용법 차이점, 그리고 예시 world까지 안내하고 있습니다. ⇒ gazebo_ros_pkgs\nDiff Drive Controller 로봇 청소기와 같이 제자리 회전이 가능하며, 양쪽 바퀴 회전수 차이로 로봇을 이동시키는 타입을 DD Type이라고 부릅니다. gazebo_ros에서 제공되는 DD controller를 사용하여 Fusionbot이 이동할 수 있게 해보겠습니다.\nurdf 폴더 내부에 diff_drive.gazebo 파일을 추가한 뒤, 아래 내용을 붙여넣기 합니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34; ?\u0026gt; \u0026lt;robot name=\u0026#34;fusionbot\u0026#34; xmlns:xacro=\u0026#34;http://www.ros.org/wiki/xacro\u0026#34; \u0026gt; \u0026lt;gazebo\u0026gt; \u0026lt;plugin name=\u0026#39;fusionbot_joint_state\u0026#39; filename=\u0026#39;libgazebo_ros_joint_state_publisher.so\u0026#39;\u0026gt; \u0026lt;ros\u0026gt; \u0026lt;remapping\u0026gt;~/out:=joint_states\u0026lt;/remapping\u0026gt; \u0026lt;/ros\u0026gt; \u0026lt;update_rate\u0026gt;30\u0026lt;/update_rate\u0026gt; \u0026lt;joint_name\u0026gt;right_wheel_joint\u0026lt;/joint_name\u0026gt; \u0026lt;joint_name\u0026gt;left_wheel_joint\u0026lt;/joint_name\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;gazebo\u0026gt; \u0026lt;plugin name=\u0026#39;differential_drive_controller\u0026#39; filename=\u0026#39;libgazebo_ros_diff_drive.so\u0026#39;\u0026gt; \u0026lt;update_rate\u0026gt;30\u0026lt;/update_rate\u0026gt; \u0026lt;left_joint\u0026gt;left_wheel_joint\u0026lt;/left_joint\u0026gt; \u0026lt;right_joint\u0026gt;right_wheel_joint\u0026lt;/right_joint\u0026gt; \u0026lt;wheel_separation\u0026gt;0.2\u0026lt;/wheel_separation\u0026gt; \u0026lt;wheel_diameter\u0026gt;0.1\u0026lt;/wheel_diameter\u0026gt; \u0026lt;max_wheel_torque\u0026gt;50\u0026lt;/max_wheel_torque\u0026gt; \u0026lt;max_wheel_acceleration\u0026gt;1.0\u0026lt;/max_wheel_acceleration\u0026gt; \u0026lt;command_topic\u0026gt;cmd_vel\u0026lt;/command_topic\u0026gt; \u0026lt;publish_odom\u0026gt;1\u0026lt;/publish_odom\u0026gt; \u0026lt;publish_odom_tf\u0026gt;1\u0026lt;/publish_odom_tf\u0026gt; \u0026lt;publish_wheel_tf\u0026gt;0\u0026lt;/publish_wheel_tf\u0026gt; \u0026lt;odometry_topic\u0026gt;odom\u0026lt;/odometry_topic\u0026gt; \u0026lt;odometry_frame\u0026gt;odom\u0026lt;/odometry_frame\u0026gt; \u0026lt;robot_base_frame\u0026gt;base_footprint\u0026lt;/robot_base_frame\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;/robot\u0026gt; fusionbot.gazebo 파일을 다시 수정하고, launch 파일을 실행시키면 tf와 함께 제어되는 로봇을 확인하실 수 있습니다. (기본적으로 /cmd_vel topic을 통해 로봇을 조종할 수 있습니다.) ROS 1 Gazebo Package 제공드린 zip 파일을 사용해서 ROS 1에서 동작하는 gazebo package를 만들어보겠습니다. ROS 2보다 훨씬 간편합니다. 😊\n연습을 위해 다시 한 번 파일을 다운받겠습니다.\n📂 fusionbot_description.zip\nfusionbot.gazebo을 아래와 같이 수정합니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34; ?\u0026gt; \u0026lt;robot name=\u0026#34;fusionbot\u0026#34; xmlns:xacro=\u0026#34;http://www.ros.org/wiki/xacro\u0026#34; \u0026gt; \u0026lt;xacro:property name=\u0026#34;body_color\u0026#34; value=\u0026#34;Gazebo/Silver\u0026#34; /\u0026gt; \u0026lt;gazebo\u0026gt; \u0026lt;plugin filename=\u0026#34;libgazebo_ros_control.so\u0026#34; name=\u0026#34;control\u0026#34;/\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;gazebo reference=\u0026#34;base_link\u0026#34;\u0026gt; \u0026lt;material\u0026gt;${body_color}\u0026lt;/material\u0026gt; \u0026lt;mu1\u0026gt;0.1\u0026lt;/mu1\u0026gt; \u0026lt;mu2\u0026gt;0.1\u0026lt;/mu2\u0026gt; \u0026lt;selfCollide\u0026gt;true\u0026lt;/selfCollide\u0026gt; \u0026lt;gravity\u0026gt;true\u0026lt;/gravity\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;gazebo reference=\u0026#34;lidar_1\u0026#34;\u0026gt; \u0026lt;material\u0026gt;${body_color}\u0026lt;/material\u0026gt; \u0026lt;mu1\u0026gt;0.2\u0026lt;/mu1\u0026gt; \u0026lt;mu2\u0026gt;0.2\u0026lt;/mu2\u0026gt; \u0026lt;selfCollide\u0026gt;true\u0026lt;/selfCollide\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;gazebo reference=\u0026#34;right_wheel_1\u0026#34;\u0026gt; \u0026lt;material\u0026gt;${body_color}\u0026lt;/material\u0026gt; \u0026lt;mu1\u0026gt;100000.0\u0026lt;/mu1\u0026gt; \u0026lt;mu2\u0026gt;100000.0\u0026lt;/mu2\u0026gt; \u0026lt;selfCollide\u0026gt;true\u0026lt;/selfCollide\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;gazebo reference=\u0026#34;left_wheel_1\u0026#34;\u0026gt; \u0026lt;material\u0026gt;${body_color}\u0026lt;/material\u0026gt; \u0026lt;mu1\u0026gt;1500\u0026lt;/mu1\u0026gt; \u0026lt;mu2\u0026gt;1500\u0026lt;/mu2\u0026gt; \u0026lt;selfCollide\u0026gt;true\u0026lt;/selfCollide\u0026gt; \u0026lt;/gazebo\u0026gt; \u0026lt;/robot\u0026gt; fusionbot.xacro를 수정합니다. # From \u0026lt;joint name=\u0026#34;��ü3\u0026#34; type=\u0026#34;fixed\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.05 0.0 0.11\u0026#34;/\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34;/\u0026gt; \u0026lt;child link=\u0026#34;lidar_1\u0026#34;/\u0026gt; \u0026lt;/joint\u0026gt; \u0026lt;joint name=\u0026#34;ȸ��7\u0026#34; type=\u0026#34;continuous\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.0 -0.1 0.05\u0026#34;/\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34;/\u0026gt; \u0026lt;child link=\u0026#34;right_wheel_1\u0026#34;/\u0026gt; \u0026lt;axis xyz=\u0026#34;-0.0 -1.0 0.0\u0026#34;/\u0026gt; \u0026lt;/joint\u0026gt; \u0026lt;joint name=\u0026#34;ȸ��8\u0026#34; type=\u0026#34;continuous\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.0 0.1 0.05\u0026#34;/\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34;/\u0026gt; \u0026lt;child link=\u0026#34;left_wheel_1\u0026#34;/\u0026gt; \u0026lt;axis xyz=\u0026#34;-0.0 1.0 0.0\u0026#34;/\u0026gt; \u0026lt;/joint\u0026gt; # To \u0026lt;joint name=\u0026#34;lidar_joint\u0026#34; type=\u0026#34;fixed\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.05 0.0 0.11\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;lidar_1\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; \u0026lt;joint name=\u0026#34;right_wheel_joint\u0026#34; type=\u0026#34;continuous\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.0 -0.1 0.05\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;right_wheel_1\u0026#34; /\u0026gt; \u0026lt;axis xyz=\u0026#34;0.0 1.0 0.0\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; \u0026lt;joint name=\u0026#34;left_wheel_joint\u0026#34; type=\u0026#34;continuous\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.0 0.1 0.05\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;left_wheel_1\u0026#34; /\u0026gt; \u0026lt;axis xyz=\u0026#34;0.0 1.0 0.0\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; joint 축 방향 수정 \u0026lt;joint name=\u0026#34;right_wheel_joint\u0026#34; type=\u0026#34;continuous\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.0 -0.1 0.05\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;right_wheel_1\u0026#34; /\u0026gt; \u0026lt;axis xyz=\u0026#34;0.0 1.0 0.0\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; \u0026lt;joint name=\u0026#34;left_wheel_joint\u0026#34; type=\u0026#34;continuous\u0026#34;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.0 0.1 0.05\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;base_link\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;left_wheel_1\u0026#34; /\u0026gt; \u0026lt;axis xyz=\u0026#34;0.0 1.0 0.0\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; base_footprint 추가 \u0026lt;link name=\u0026#39;base_footprint\u0026#39; /\u0026gt; ... \u0026lt;joint name=\u0026#39;base_link_joint\u0026#39; type=\u0026#39;fixed\u0026#39;\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0 0 0\u0026#34; /\u0026gt; \u0026lt;parent link=\u0026#34;base_footprint\u0026#34; /\u0026gt; \u0026lt;child link=\u0026#34;base_link\u0026#34; /\u0026gt; \u0026lt;/joint\u0026gt; 다시 한 번 description을 실행합니다. 이번에는 launch file이 이름이 바뀌었습니다. catkin build fusionbot_description source devel/setup.bash roslaunch fusionbot_description display.launch ROS 1의 launch file은 xml 문법을 사용했습니다. joint_state_publisher와 robot_state_publisher를 사용하는 부분은 모두 ROS 2와 동일하며, robot_state_publisher는 robot_description을 요구하기 때문에 argument로 지정하고 있습니다.\n# display.launch \u0026lt;launch\u0026gt; \u0026lt;arg default=\u0026#34;$(find fusionbot_description)/urdf/fusionbot.xacro\u0026#34; name=\u0026#34;model\u0026#34;/\u0026gt; \u0026lt;arg default=\u0026#34;true\u0026#34; name=\u0026#34;gui\u0026#34;/\u0026gt; \u0026lt;arg default=\u0026#34;$(find fusionbot_description)/launch/urdf.rviz\u0026#34; name=\u0026#34;rvizconfig\u0026#34;/\u0026gt; \u0026lt;param command=\u0026#34;$(find xacro)/xacro $(arg model)\u0026#34; name=\u0026#34;robot_description\u0026#34;/\u0026gt; \u0026lt;param name=\u0026#34;use_gui\u0026#34; value=\u0026#34;$(arg gui)\u0026#34;/\u0026gt; \u0026lt;node name=\u0026#34;joint_state_publisher\u0026#34; pkg=\u0026#34;joint_state_publisher\u0026#34; type=\u0026#34;joint_state_publisher\u0026#34;/\u0026gt; \u0026lt;node name=\u0026#34;robot_state_publisher\u0026#34; pkg=\u0026#34;robot_state_publisher\u0026#34; type=\u0026#34;robot_state_publisher\u0026#34;/\u0026gt; \u0026lt;node args=\u0026#34;-d $(arg rvizconfig)\u0026#34; name=\u0026#34;rviz\u0026#34; pkg=\u0026#34;rviz\u0026#34; required=\u0026#34;true\u0026#34; type=\u0026#34;rviz\u0026#34;/\u0026gt; \u0026lt;/launch\u0026gt; fusionbot.xacro 수정 - package://를 통한 파일 접근을 모두 $(find pkg) 형태로 변형해줍니다. \u0026lt;link name=\u0026#34;base_link\u0026#34;\u0026gt; \u0026lt;inertial\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0.0037594591254762827 0.0 0.052804115668456025\u0026#34; /\u0026gt; \u0026lt;mass value=\u0026#34;2.3079643337726483\u0026#34; /\u0026gt; \u0026lt;inertia ixx=\u0026#34;0.00789\u0026#34; ixy=\u0026#34;0.0\u0026#34; ixz=\u0026#34;-0.000325\u0026#34; iyy=\u0026#34;0.008347\u0026#34; iyz=\u0026#34;0.0\u0026#34; izz=\u0026#34;0.01475\u0026#34; /\u0026gt; \u0026lt;/inertial\u0026gt; \u0026lt;visual\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0 0 0\u0026#34; /\u0026gt; \u0026lt;geometry\u0026gt; \u0026lt;mesh filename=\u0026#34;$(find fusionbot_description)/meshes/base_link.stl\u0026#34; scale=\u0026#34;0.001 0.001 0.001\u0026#34; /\u0026gt; \u0026lt;/geometry\u0026gt; \u0026lt;material name=\u0026#34;silver\u0026#34; /\u0026gt; \u0026lt;/visual\u0026gt; \u0026lt;collision\u0026gt; \u0026lt;origin rpy=\u0026#34;0 0 0\u0026#34; xyz=\u0026#34;0 0 0\u0026#34; /\u0026gt; \u0026lt;geometry\u0026gt; \u0026lt;mesh filename=\u0026#34;$(find fusionbot_description)/meshes/base_link.stl\u0026#34; scale=\u0026#34;0.001 0.001 0.001\u0026#34; /\u0026gt; \u0026lt;/geometry\u0026gt; \u0026lt;/collision\u0026gt; \u0026lt;/link\u0026gt; ROS 2에서 세팅하였던 센서와 제어 plugin을 다시 ROS 1 버전으로 수정해주어야 합니다. 해당 작업은 gazebo_ros_pkg의 wiki 페이지를 참고하면 되며 이번 예시에서는 카메라 센서 하나 정도만 함께 작업해보겠습니다. ⇒ gazebo_ros_pkg \u0026lt;plugin name=\u0026#34;plugin_name\u0026#34; filename=\u0026#34;libgazebo_ros_camera.so\u0026#34;\u0026gt; \u0026lt;alwaysOn\u0026gt;true\u0026lt;/alwaysOn\u0026gt; \u0026lt;updateRate\u0026gt;0.0\u0026lt;/updateRate\u0026gt; \u0026lt;robotNamespace\u0026gt;custom_ns\u0026lt;/robotNamespace\u0026gt; \u0026lt;cameraName\u0026gt;custom_camera\u0026lt;/cameraName\u0026gt; \u0026lt;imageTopicName\u0026gt;custom_image\u0026lt;/imageTopicName\u0026gt; \u0026lt;cameraInfoTopicName\u0026gt;custom_info\u0026lt;/cameraInfoTopicName\u0026gt; \u0026lt;frameName\u0026gt;custom_frame\u0026lt;/frameName\u0026gt; \u0026lt;hackBaseline\u0026gt;0.07\u0026lt;/hackBaseline\u0026gt; \u0026lt;distortionK1\u0026gt;0.1\u0026lt;/distortionK1\u0026gt; \u0026lt;distortionK2\u0026gt;0.2\u0026lt;/distortionK2\u0026gt; \u0026lt;distortionK3\u0026gt;0.3\u0026lt;/distortionK3\u0026gt; \u0026lt;distortionT1\u0026gt;0.5\u0026lt;/distortionT1\u0026gt; \u0026lt;distortionT2\u0026gt;0.5\u0026lt;/distortionT2\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin name=\u0026#34;plugin_name\u0026#34; filename=\u0026#34;libgazebo_ros_camera.so\u0026#34;\u0026gt; \u0026lt;!-- Change namespace, camera name and topics so - * Images are published to: /custom_ns/custom_camera/custom_image * Camera info is published to: /custom_ns/custom_camera/custom_info --\u0026gt; \u0026lt;ros\u0026gt; \u0026lt;namespace\u0026gt;custom_ns\u0026lt;/namespace\u0026gt; \u0026lt;remapping\u0026gt;image_raw:=custom_img\u0026lt;/remapping\u0026gt; \u0026lt;remapping\u0026gt;camera_info:=custom_info\u0026lt;/remapping\u0026gt; \u0026lt;/ros\u0026gt; \u0026lt;!-- Set camera name. If empty, defaults to sensor name (i.e. \u0026#34;sensor_name\u0026#34;) --\u0026gt; \u0026lt;camera_name\u0026gt;custom_camera\u0026lt;/camera_name\u0026gt; \u0026lt;!-- Set TF frame name. If empty, defaults to link name (i.e. \u0026#34;link_name\u0026#34;) --\u0026gt; \u0026lt;frame_name\u0026gt;custom_frame\u0026lt;/frame_name\u0026gt; \u0026lt;hack_baseline\u0026gt;0.07\u0026lt;/hack_baseline\u0026gt; \u0026lt;!-- No need to repeat distortion parameters or to set autoDistortion --\u0026gt; \u0026lt;/plugin\u0026gt; ⇒ ROS 1에 존재했던 태크들이 대부분 ROS 2넘어가면서 중복 제거와 재편성이 되었습니다. 해당 부분을 참고하여 우리 상황에 맞게 수정을 해보겠습니다.\n모든 작업이 완료된 패키지 압축 파일을 제공드리니 실습 도중 오류가 발생하면 참고하시기 바랍니다.\n이제 모든 plugin들을 추가하였으니, fusionbot.gazebo파일에 include를 작성해주면 urdf 수정은 끝이 납니다. \u0026lt;?xml version=\u0026#34;1.0\u0026#34; ?\u0026gt; \u0026lt;robot name=\u0026#34;fusionbot\u0026#34; xmlns:xacro=\u0026#34;http://www.ros.org/wiki/xacro\u0026#34; \u0026gt; \u0026lt;xacro:property name=\u0026#34;body_color\u0026#34; value=\u0026#34;Gazebo/Silver\u0026#34; /\u0026gt; \u0026lt;xacro:property name=\u0026#34;lidar_color\u0026#34; value=\u0026#34;Gazebo/Blue\u0026#34; /\u0026gt; \u0026lt;xacro:property name=\u0026#34;wheel_color\u0026#34; value=\u0026#34;Gazebo/Black\u0026#34; /\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find fusionbot_description)/urdf/sensors/mono_cam.gazebo\u0026#34; /\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find fusionbot_description)/urdf/sensors/depth_cam.gazebo\u0026#34; /\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find fusionbot_description)/urdf/sensors/lidar_2d.gazebo\u0026#34; /\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find fusionbot_description)/urdf/sensors/lidar_3d.gazebo\u0026#34; /\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find fusionbot_description)/urdf/sensors/imu.gazebo\u0026#34; /\u0026gt; \u0026lt;!-- hector_gazebo doesn\u0026#39;t supports noetic --\u0026gt; \u0026lt;!-- \u0026lt;xacro:include filename=\u0026#34;$(find fusionbot_description)/urdf/sensors/gps.gazebo\u0026#34; /\u0026gt; --\u0026gt; \u0026lt;xacro:include filename=\u0026#34;$(find fusionbot_description)/urdf/controllers/diff_drive.gazebo\u0026#34; /\u0026gt; \u0026lt;gazebo reference=\u0026#34;base_link\u0026#34;\u0026gt; \u0026lt;material\u0026gt;${body_color}\u0026lt;/material\u0026gt; gazebo를 실행시키기 위한 launch file을 만들고 패키지를 재빌드합니다. joint_state_publisher, robot_state_publisher, gazebo_ros와 urdf_spawner를 통해 gazebo 상에 로봇을 최종 등장시키는 launch file 입니다.\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;launch\u0026gt; \u0026lt;!-- Robot pose --\u0026gt; \u0026lt;arg name=\u0026#34;x\u0026#34; default=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;y\u0026#34; default=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;z\u0026#34; default=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;roll\u0026#34; default=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;pitch\u0026#34; default=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;yaw\u0026#34; default=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;world_name\u0026#34; default=\u0026#34;gcamp_world.world\u0026#34;/\u0026gt; \u0026lt;!-- \u0026lt;arg name=\u0026#34;world_file\u0026#34; default=\u0026#34;$(find fusionbot_description)/worlds/$(arg world_name)\u0026#34;/\u0026gt; --\u0026gt; \u0026lt;arg name=\u0026#34;model_name\u0026#34; default=\u0026#34;fusionbot\u0026#34;/\u0026gt; \u0026lt;!-- send urdf to param server --\u0026gt; \u0026lt;!-- xacro --\u0026gt; \u0026lt;param name=\u0026#34;robot_description\u0026#34; command=\u0026#34;$(find xacro)/xacro --inorder \u0026#39;$(find fusionbot_description)/urdf/fusionbot.xacro\u0026#39;\u0026#34; /\u0026gt; \u0026lt;!-- urdf or raw xml file --\u0026gt; \u0026lt;!-- \u0026lt;param name=\u0026#34;robot_description\u0026#34; command=\u0026#34;cat $(find museumGuide)/urdf_model/peoplebot.xml\u0026#34; /\u0026gt; --\u0026gt; \u0026lt;!-- Send fake joint values--\u0026gt; \u0026lt;node name=\u0026#34;joint_state_publisher\u0026#34; pkg=\u0026#34;joint_state_publisher\u0026#34; type=\u0026#34;joint_state_publisher\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;use_gui\u0026#34; value=\u0026#34;False\u0026#34;/\u0026gt; \u0026lt;/node\u0026gt; \u0026lt;!-- Send robot states to tf --\u0026gt; \u0026lt;node name=\u0026#34;robot_state_publisher\u0026#34; pkg=\u0026#34;robot_state_publisher\u0026#34; type=\u0026#34;robot_state_publisher\u0026#34; respawn=\u0026#34;false\u0026#34; output=\u0026#34;screen\u0026#34;/\u0026gt; \u0026lt;!-- Launch Gazebo World --\u0026gt; \u0026lt;include file=\u0026#34;$(find gazebo_ros)/launch/empty_world.launch\u0026#34;\u0026gt; \u0026lt;arg name=\u0026#34;use_sim_time\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;debug\u0026#34; value=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;arg name=\u0026#34;gui\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;!-- \u0026lt;arg name=\u0026#34;world_name\u0026#34; value=\u0026#34;$(arg world_file)\u0026#34;/\u0026gt; --\u0026gt; \u0026lt;/include\u0026gt; \u0026lt;!-- Spawn My Robot --\u0026gt; \u0026lt;node name=\u0026#34;urdf_spawner\u0026#34; pkg=\u0026#34;gazebo_ros\u0026#34; type=\u0026#34;spawn_model\u0026#34; respawn=\u0026#34;false\u0026#34; output=\u0026#34;screen\u0026#34; args=\u0026#34;-urdf -param robot_description -model $(arg model_name) -x $(arg x) -y $(arg y) -z $(arg z) -R $(arg roll) -P $(arg pitch) -Y $(arg yaw)\u0026#34;/\u0026gt; \u0026lt;/launch\u0026gt; 현재는 주석처리가 되어 있지만 여러분의 world를 만들어 보시고 world 폴더 내 위치시킨 다음 해당 world에서 로봇을 등장시키는 실습도 해보시기 바랍니다.\nWorld Extensive github에는 다른 사람들이 만들어 둔 다양한 gazebo world들이 있습니다. 이들을 사용하는 방법을 익혀두면 여러분의 수고를 덜면서 더욱 다채로운 예시를 실행할 수 있습니다.\n이번에 사용해볼 world는 clearpath의 cpr_gazebo 패키지안에 존재합니다. 해당 repo를 clone하고 빌드하겠습니다. cd ~/catkin_ws/src git clone https://github.com/clearpathrobotics/cpr_gazebo.git cd ~/catkin_ws catkin build cpr_office_gazebo source devel/setup.bash 이제, 우리의 launch file을 수정해보겠습니다. 제가 uncomment 라고 해둔 라인 아래를 주석 해제 하신 뒤 마지막 부분에 아래의 라인을 추가하십니다. \u0026lt;!-- Spawn Structure --\u0026gt; \u0026lt;param name=\u0026#34;office_geom\u0026#34; command=\u0026#34;$(find xacro)/xacro --inorder \u0026#39;$(find cpr_office_gazebo)/urdf/office_construction_geometry.urdf.xacro\u0026#39;\u0026#34; /\u0026gt; \u0026lt;node name=\u0026#34;office_world_spawner\u0026#34; pkg=\u0026#34;gazebo_ros\u0026#34; type=\u0026#34;spawn_model\u0026#34; args=\u0026#34;-urdf -model office_construction_geometry -param office_geom -x 0 -y 0 -z 0 -Y 0\u0026#34; /\u0026gt; 이제 마지막 예시를 실행해보겠습니다.\ncatkin build fusionbot_description source devel/setup.bash # Terminal 1 roslaunch fusionbot_description gazebo.launch # Terminal 2 rviz 다채로운 시뮬레이션 world에서 plugin을 통해 추가했던 수많은 센서 데이터들을 rviz를 사용하여 마음껏 시각화해보시기 바랍니다. 😃 "
},
{
	"uri": "/kr/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/kr/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]